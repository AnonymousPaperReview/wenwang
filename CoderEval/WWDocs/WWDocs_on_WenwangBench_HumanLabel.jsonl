{"file_path": "neo4j/_codec/hydration/v1/temporal.py", "project": "neo4j/neo4j-python-driver", "name": "hydrate_time", "docstring": "Hydrator for `Time` and `LocalTime` values.\n\n:param nanoseconds:\n:param tz:\n:return: Time", "ques_id": "62e60f43d76274f8a4026e28", "code": ["def hydrate_time(nanoseconds, tz=None):\n    if nanoseconds < 0:\n        raise ValueError('Nanoseconds must be non-negative')\n\n    if tz is None:\n        tz = timezone.utc\n\n    return tz.fromutc(datetime.datetime.utcfromtimestamp(nanoseconds)).replace(tzinfo=None)\n", "def hydrate_time(nanoseconds, tz=None):\n    if not isinstance(nanoseconds, int):\n        raise ValueError('Expected int for nanoseconds; got %s instead.' % type(nanoseconds))\n    if nanoseconds < 0:\n        raise ValueError('Nanoseconds must be non-negative; got %s instead.' % nanoseconds)\n\n    if tz is None:\n        tz = get_current_timezone()\n\n    return tz.fromutc(datetime.datetime.utcfromtimestamp(nanoseconds)).replace(tzinfo=None)\n", "def hydrate_time(nanoseconds, tz=None):\n    if not tz:\n        tz = timezone.get_default_timezone()\n    dt = datetime.fromtimestamp(nanoseconds, tz)\n    return dt.strftime('%H:%M:%S.%f')[:-3]\n", "def hydrate_time(nanoseconds, tz=None):\n    return datetime.fromtimestamp(nanoseconds, tz)\n", "def hydrate_time(nanoseconds, tz=None):\n    if not isinstance(nanoseconds, (int, float)):\n        raise ValueError('Nanoseconds must be int or float.')\n    if nanoseconds == int(nanoseconds):\n        nanoseconds = 0\n    time = datetime.datetime.utcfromtimestamp(nanoseconds).replace(\n        tzinfo=pytz.utc)\n    return time\n", "def hydrate_time(nanoseconds, tz=None):\n    if not tz:\n        tz = get_current_timezone()\n    if nanoseconds < 1000000:\n        return (nanoseconds * 1000000) / 1000000\n    else:\n        return (nanoseconds / 1000000) - 1000000\n", "def hydrate_time(nanoseconds, tz=None):\n    if not isinstance(nanoseconds, numbers.Integral):\n        raise ValueError(\"nanoseconds must be integer or float\")\n\n    if nanoseconds < 0:\n        raise ValueError(\"nanoseconds must be greater than 0\")\n\n    nanoseconds = abs(nanoseconds)\n    fraction = nanoseconds % 1\n\n    hours = int(nanoseconds / 3600)\n    minutes = int((nanoseconds % 3600) / 60)\n    seconds = int(nanoseconds % 60)\n\n    if hours > 0:\n        return datetime.time(hour=hours, minute=minutes, second=seconds)\n    else:\n        return datetime.time(hour=0, minute=minutes, second=seconds)\n", "def hydrate_time(nanoseconds, tz=None):\n    if tz is None:\n        tz = timezone.utc\n    return tz.fromutc(datetime.datetime.fromtimestamp(nanoseconds, tz))\n", "def hydrate_time(nanoseconds, tz=None):\n    if not nanoseconds:\n        return None\n    tzinfo = tz or timezone.utc\n    dt = datetime.datetime.utcfromtimestamp(nanoseconds, tzinfo)\n    return dt.replace(microsecond=(dt.microsecond + 1) // 1000)\n", "def hydrate_time(nanoseconds, tz=None):\n    if not isinstance(nanoseconds, int):\n        raise ValueError('Nanoseconds must be an integer')\n    if nanoseconds < 0:\n        raise ValueError('Nanoseconds must be greater than 0')\n\n    if tz is None:\n        tz = timezone.utc\n\n    # https://github.com/pytz/dateutil/blob/78e5bd7b3cb1d1d1fb3db3a1cb0ea9acdb6/dateutil/tzinfo.py#L223\n    nanos = nanoseconds // 1000000\n    sign = '-' if nanos < 10 else '+'\n    nanos = nanos % 1000000\n    nanos_int = int(nanos)\n\n    return datetime.time(\n        hour=nanos_int // 3600,\n        minute=(nanos_int // 60) % 60,\n        second=(nanos_int % 60)\n    ) + timedelta(microseconds=nanos_int % 1000)\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if nanoseconds < 0:\n        raise ValueError('Nanoseconds must be non-negative')\n\n    if tz is None:\n        tz = timezone.utc\n\n    return tz.fromutc(datetime.datetime.utcfromtimestamp(nanoseconds)).replace(tzinfo=None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if not isinstance(nanoseconds, int):\n        raise ValueError('Expected int for nanoseconds; got %s instead.' % type(nanoseconds))\n    if nanoseconds < 0:\n        raise ValueError('Nanoseconds must be non-negative; got %s instead.' % nanoseconds)\n\n    if tz is None:\n        tz = get_current_timezone()\n\n    return tz.fromutc(datetime.datetime.utcfromtimestamp(nanoseconds)).replace(tzinfo=None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if not tz:\n        tz = timezone.get_default_timezone()\n    dt = datetime.fromtimestamp(nanoseconds, tz)\n    return dt.strftime('%H:%M:%S.%f')[:-3]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    return datetime.fromtimestamp(nanoseconds, tz)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if not isinstance(nanoseconds, (int, float)):\n        raise ValueError('Nanoseconds must be int or float.')\n    if nanoseconds == int(nanoseconds):\n        nanoseconds = 0\n    time = datetime.datetime.utcfromtimestamp(nanoseconds).replace(\n        tzinfo=pytz.utc)\n    return time\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if not tz:\n        tz = get_current_timezone()\n    if nanoseconds < 1000000:\n        return (nanoseconds * 1000000) / 1000000\n    else:\n        return (nanoseconds / 1000000) - 1000000\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if not isinstance(nanoseconds, numbers.Integral):\n        raise ValueError(\"nanoseconds must be integer or float\")\n\n    if nanoseconds < 0:\n        raise ValueError(\"nanoseconds must be greater than 0\")\n\n    nanoseconds = abs(nanoseconds)\n    fraction = nanoseconds % 1\n\n    hours = int(nanoseconds / 3600)\n    minutes = int((nanoseconds % 3600) / 60)\n    seconds = int(nanoseconds % 60)\n\n    if hours > 0:\n        return datetime.time(hour=hours, minute=minutes, second=seconds)\n    else:\n        return datetime.time(hour=0, minute=minutes, second=seconds)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if tz is None:\n        tz = timezone.utc\n    return tz.fromutc(datetime.datetime.fromtimestamp(nanoseconds, tz))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if not nanoseconds:\n        return None\n    tzinfo = tz or timezone.utc\n    dt = datetime.datetime.utcfromtimestamp(nanoseconds, tzinfo)\n    return dt.replace(microsecond=(dt.microsecond + 1) // 1000)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if not isinstance(nanoseconds, int):\n        raise ValueError('Nanoseconds must be an integer')\n    if nanoseconds < 0:\n        raise ValueError('Nanoseconds must be greater than 0')\n\n    if tz is None:\n        tz = timezone.utc\n\n    # https://github.com/pytz/dateutil/blob/78e5bd7b3cb1d1d1fb3db3a1cb0ea9acdb6/dateutil/tzinfo.py#L223\n    nanos = nanoseconds // 1000000\n    sign = '-' if nanos < 10 else '+'\n    nanos = nanos % 1000000\n    nanos_int = int(nanos)\n\n    return datetime.time(\n        hour=nanos_int // 3600,\n        minute=(nanos_int // 60) % 60,\n        second=(nanos_int % 60)\n    ) + timedelta(microseconds=nanos_int % 1000)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_codec/hydration/v1/temporal.py", "project": "neo4j/neo4j-python-driver", "name": "dehydrate_timedelta", "docstring": "Dehydrator for `timedelta` values.\n\n:param value:\n:type value: timedelta\n:return:", "ques_id": "62e60f3bd76274f8a4026e10", "code": ["def dehydrate_timedelta(value):\n    if isinstance(value, datetime.timedelta):\n        return str(value)\n    raise BadRequest(\"Unsupported timedelta type: %s\" % type(value))\n", "def dehydrate_timedelta(value):\n    if value is None:\n        return None\n\n    return timedelta(seconds=value.total_seconds())\n", "def dehydrate_timedelta(value):\n    if value is None:\n        return None\n\n    return timedelta(seconds=value.total_seconds())\n", "def dehydrate_timedelta(value):\n    if value is None:\n        return None\n    return timedelta(seconds=value.total_seconds())\n", "def dehydrate_timedelta(value):\n    if value is None:\n        return None\n    return timedelta(seconds=value.total_seconds())\n", "def dehydrate_timedelta(value):\n    if isinstance(value, datetime.timedelta):\n        return \"{} days\".format(value.days)\n", "def dehydrate_timedelta(value):\n    if value is None:\n        return None\n\n    return timedelta(seconds=value.total_seconds())\n", "def dehydrate_timedelta(value):\n    if value.days < 0:\n        raise BadRequest(\"Cannot be negative\")\n\n    return timedelta(days=value.days)\n", "def dehydrate_timedelta(value):\n    if isinstance(value, datetime.timedelta):\n        return value\n\n    value = parse_timedelta(value)\n    if value:\n        return value.total_seconds()\n", "def dehydrate_timedelta(value):\n    if value.microseconds > 0:\n        return datetime.timedelta(microseconds=value.microseconds)\n    else:\n        return datetime.timedelta()\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def dehydrate_timedelta(value):\n    if isinstance(value, datetime.timedelta):\n        return str(value)\n    raise BadRequest(\"Unsupported timedelta type: %s\" % type(value))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if value is None:\n        return None\n\n    return timedelta(seconds=value.total_seconds())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if value is None:\n        return None\n\n    return timedelta(seconds=value.total_seconds())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if value is None:\n        return None\n    return timedelta(seconds=value.total_seconds())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if value is None:\n        return None\n    return timedelta(seconds=value.total_seconds())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if isinstance(value, datetime.timedelta):\n        return \"{} days\".format(value.days)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if value is None:\n        return None\n\n    return timedelta(seconds=value.total_seconds())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if value.days < 0:\n        raise BadRequest(\"Cannot be negative\")\n\n    return timedelta(days=value.days)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if isinstance(value, datetime.timedelta):\n        return value\n\n    value = parse_timedelta(value)\n    if value:\n        return value.total_seconds()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if value.microseconds > 0:\n        return datetime.timedelta(microseconds=value.microseconds)\n    else:\n        return datetime.timedelta()\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_codec/hydration/v1/temporal.py", "project": "neo4j/neo4j-python-driver", "name": "dehydrate_time", "docstring": "Dehydrator for `time` values.\n\n:param value:\n:type value: Time\n:return:", "ques_id": "62e60f37d76274f8a4026dfd", "code": ["def dehydrate_time(value):\n    \"Use ticks in the Time class to generate the Structure class. \"\n    if value is None:\n        return None\n\n    if isinstance(value, Time):\n        return value\n\n    if isinstance(value, datetime.datetime):\n        return Time(value)\n\n    if isinstance(value, datetime.date):\n        return Time(value)\n\n    try:\n        # Try to parse as a datetime.datetime object\n        return Time(value)\n    except ValueError:\n        pass\n\n    # Try to parse as a datetime.date object\n    try:\n        return Time(datetime.datetime.strptime(value, '%Y-%m-%d'))\n    except ValueError:\n        pass\n\n    try:\n        # Try to parse as a datetime.date object\n        return Time(datetime.datetime.strptime(value, '%Y-%m-%d'))\n    except ValueError:\n        pass\n\n    # Try to parse as a string\n    try:\n        return Time(value)\n", "def dehydrate_time(value):\n    if value is None:\n        return value\n\n    if isinstance(value, Structure):\n        return value\n\n    return Structure(value)\n", "def dehydrate_time(value):\n    \"Use ticks in the Time class to generate the Structure class. \"\n    if isinstance(value, Time):\n        return value\n    elif isinstance(value, datetime):\n        return Structure(value, 'time')\n    elif isinstance(value, date):\n        return Structure(value, 'date')\n    else:\n        raise TypeError('Can only dehydrate Structure classes or dates')\n", "def dehydrate_time(value):\n    \"Use ticks in the Time class to generate the Structure class. \"\n    if value is None:\n        return None\n\n    return Time(value)\n", "def dehydrate_time(value):\n    if not isinstance(value, datetime):\n        raise BadValueError('ticks must be a datetime instance')\n    return Structure(\n        ticks=value.timetuple()[:6],\n        **{\n            'element_class': Time\n        }\n    )\n", "def dehydrate_time(value):\n    if value is None:\n        return None\n    return Structure(value, **{'ticks': 1})\n", "def dehydrate_time(value):\n    if value is None:\n        return None\n\n    return Time(value)\n", "def dehydrate_time(value):\n    if isinstance(value, Structure):\n        return value\n    elif isinstance(value, Time):\n        return value\n    elif isinstance(value, int) or isinstance(value, float):\n        return Structure(time=value)\n    elif value.__class__ in (list, tuple, set):\n        return [dehydrate_time(item) for item in value]\n    else:\n        return value\n", "def dehydrate_time(value):\n    if value.tzinfo is None:\n        value = value.replace(tzinfo=FixedOffset(0, \"UTC\"))\n    return Structure(\n        time=value.astimezone(pytz.utc)\n    )\n", "def dehydrate_time(value):\n    if value.tzinfo is None:\n        value = value.replace(tzinfo=pytz.utc)\n    return Time(value)\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def dehydrate_time(value):\n    \"Use ticks in the Time class to generate the Structure class. \"\n    if value is None:\n        return None\n\n    if isinstance(value, Time):\n        return value\n\n    if isinstance(value, datetime.datetime):\n        return Time(value)\n\n    if isinstance(value, datetime.date):\n        return Time(value)\n\n    try:\n        # Try to parse as a datetime.datetime object\n        return Time(value)\n    except ValueError:\n        pass\n\n    # Try to parse as a datetime.date object\n    try:\n        return Time(datetime.datetime.strptime(value, '%Y-%m-%d'))\n    except ValueError:\n        pass\n\n    try:\n        # Try to parse as a datetime.date object\n        return Time(datetime.datetime.strptime(value, '%Y-%m-%d'))\n    except ValueError:\n        pass\n\n    # Try to parse as a string\n    try:\n        return Time(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    if value is None:\n        return value\n\n    if isinstance(value, Structure):\n        return value\n\n    return Structure(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    \"Use ticks in the Time class to generate the Structure class. \"\n    if isinstance(value, Time):\n        return value\n    elif isinstance(value, datetime):\n        return Structure(value, 'time')\n    elif isinstance(value, date):\n        return Structure(value, 'date')\n    else:\n        raise TypeError('Can only dehydrate Structure classes or dates')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    \"Use ticks in the Time class to generate the Structure class. \"\n    if value is None:\n        return None\n\n    return Time(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    if not isinstance(value, datetime):\n        raise BadValueError('ticks must be a datetime instance')\n    return Structure(\n        ticks=value.timetuple()[:6],\n        **{\n            'element_class': Time\n        }\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    if value is None:\n        return None\n    return Structure(value, **{'ticks': 1})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    if value is None:\n        return None\n\n    return Time(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    if isinstance(value, Structure):\n        return value\n    elif isinstance(value, Time):\n        return value\n    elif isinstance(value, int) or isinstance(value, float):\n        return Structure(time=value)\n    elif value.__class__ in (list, tuple, set):\n        return [dehydrate_time(item) for item in value]\n    else:\n        return value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    if value.tzinfo is None:\n        value = value.replace(tzinfo=FixedOffset(0, \"UTC\"))\n    return Structure(\n        time=value.astimezone(pytz.utc)\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    if value.tzinfo is None:\n        value = value.replace(tzinfo=pytz.utc)\n    return Time(value)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_codec/hydration/v1/spatial.py", "project": "neo4j/neo4j-python-driver", "name": "dehydrate_point", "docstring": "Dehydrator for Point data.\n\n:param value:\n:type value: Point\n:return:", "ques_id": "62e60f33d76274f8a4026de9", "code": ["def dehydrate_point(value):\n    if len(value) < 4:\n        raise ValidationError(\"Invalid point. The point must have at least 4 characters.\")\n    return value\n", "def dehydrate_point(value):\n    if len(value) == 4:\n        return Point(float(value[0]), float(value[1]), float(value[2]), float(value[3]))\n    elif len(value) == 8:\n        return Point(float(value[0]), float(value[1]), float(value[2]), float(value[3]), float(value[4]),\n                     float(value[5]), float(value[6]), float(value[7]))\n    else:\n        raise ValueError(\"Invalid point value length: %d\" % len(value))\n", "def dehydrate_point(value):\n    if len(value) == 1:\n        return Point(value[0])\n    else:\n        raise ValueError(\n            \"The value provided is not a valid structure class. \"\n            \"Expected a single value or a list of values.\"\n        )\n", "def dehydrate_point(value):\n    if len(value) == 4:\n        return Point(value[0], value[1], value[2])\n    elif len(value) == 2:\n        return Point(value[0], value[1])\n    elif len(value) == 3:\n        return Point(value[0], value[1], value[2], value[1])\n    else:\n        raise ValueError(\"Invalid value passed in for 'point' in \"\n                         \"GeoJSON feature constructor\")\n", "def dehydrate_point(value):\n    return {'type': 'Point', 'coordinates': list(value)}\n", "def dehydrate_point(value):\n    if len(value) < 4:\n        raise ValidationError(\"Invalid point format\")\n    return Point(*value[:4])\n", "def dehydrate_point(value):\n    if isinstance(value, list):\n        return [dehydrate_point(v) for v in value]\n    elif isinstance(value, dict):\n        return {dehydrate_point(k): dehydrate_point(v) for k, v in value.items()}\n    elif isinstance(value, tuple):\n        return tuple(dehydrate_point(v) for v in value)\n    elif isinstance(value, set):\n        return list(value)\n    elif isinstance(value, datetime.datetime):\n        return value.strftime('%Y-%m-%dT%H:%M:%SZ')\n    elif isinstance(value, datetime.date):\n        return value.strftime('%Y-%m-%d')\n    elif isinstance(value, datetime.timedelta):\n        return value.total_seconds()\n    elif isinstance(value, Decimal):\n        return float(value)\n    elif isinstance(value, str):\n        if value.lower() in ['true', 'false']:\n            return value.lower() == 'true'\n        return value in ['1', 'yes'", "def dehydrate_point(value):\n    return {\n        \"@type\": \"Point\",\n        \"x\": value[\"x\"],\n        \"y\": value[\"y\"]\n    }\n", "def dehydrate_point(value):\n    if len(value) < 4:\n        raise ValidationError(\"Point must be at least 4\")\n    return value\n", "def dehydrate_point(value):\n    if len(value) == 4:\n        return Point(\n            float(value[0]), float(value[1]), float(value[2]), float(value[3])\n        )\n    elif len(value) == 8:\n        return Point(\n            float(value[0]), float(value[1]), float(value[2]), float(value[4]), float(value[5]), float(value[6])\n        )\n    else:\n        raise ValueError(\"The point value must be 4 or 8 characters long.\")\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def dehydrate_point(value):\n    if len(value) < 4:\n        raise ValidationError(\"Invalid point. The point must have at least 4 characters.\")\n    return value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    if len(value) == 4:\n        return Point(float(value[0]), float(value[1]), float(value[2]), float(value[3]))\n    elif len(value) == 8:\n        return Point(float(value[0]), float(value[1]), float(value[2]), float(value[3]), float(value[4]),\n                     float(value[5]), float(value[6]), float(value[7]))\n    else:\n        raise ValueError(\"Invalid point value length: %d\" % len(value))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    if len(value) == 1:\n        return Point(value[0])\n    else:\n        raise ValueError(\n            \"The value provided is not a valid structure class. \"\n            \"Expected a single value or a list of values.\"\n        )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    if len(value) == 4:\n        return Point(value[0], value[1], value[2])\n    elif len(value) == 2:\n        return Point(value[0], value[1])\n    elif len(value) == 3:\n        return Point(value[0], value[1], value[2], value[1])\n    else:\n        raise ValueError(\"Invalid value passed in for 'point' in \"\n                         \"GeoJSON feature constructor\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    return {'type': 'Point', 'coordinates': list(value)}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    if len(value) < 4:\n        raise ValidationError(\"Invalid point format\")\n    return Point(*value[:4])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    if isinstance(value, list):\n        return [dehydrate_point(v) for v in value]\n    elif isinstance(value, dict):\n        return {dehydrate_point(k): dehydrate_point(v) for k, v in value.items()}\n    elif isinstance(value, tuple):\n        return tuple(dehydrate_point(v) for v in value)\n    elif isinstance(value, set):\n        return list(value)\n    elif isinstance(value, datetime.datetime):\n        return value.strftime('%Y-%m-%dT%H:%M:%SZ')\n    elif isinstance(value, datetime.date):\n        return value.strftime('%Y-%m-%d')\n    elif isinstance(value, datetime.timedelta):\n        return value.total_seconds()\n    elif isinstance(value, Decimal):\n        return float(value)\n    elif isinstance(value, str):\n        if value.lower() in ['true', 'false']:\n            return value.lower() == 'true'\n        return value in ['1', 'yes'", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    return {\n        \"@type\": \"Point\",\n        \"x\": value[\"x\"],\n        \"y\": value[\"y\"]\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    if len(value) < 4:\n        raise ValidationError(\"Point must be at least 4\")\n    return value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    if len(value) == 4:\n        return Point(\n            float(value[0]), float(value[1]), float(value[2]), float(value[3])\n        )\n    elif len(value) == 8:\n        return Point(\n            float(value[0]), float(value[1]), float(value[2]), float(value[4]), float(value[5]), float(value[6])\n        )\n    else:\n        raise ValueError(\"The point value must be 4 or 8 characters long.\")\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_data.py", "project": "neo4j/neo4j-python-driver", "name": "keys", "docstring": "Return the keys of the record.\n\n:return: list of key names", "ques_id": "62e60ed4d76274f8a4026da0", "code": ["def keys(self):\n    return self.__keys\n", "def keys(self):\n    return [key for key in self.__keys]\n", "def keys(self):\n    return [key for key in self.__keys]\n", "def keys(self):\n    return self.__keys\n", "def keys(self):\n    return self.__keys\n", "def keys(self):\n    return list(self.__objects.keys())\n", "def keys(self):\n    return list(self.__objects.keys())\n", "def keys(self):\n    return self.__keys\n", "def keys(self):\n    return list(self.__objects.keys())\n", "def keys(self):\n    return list(self.__keys)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def keys(self):\n    return self.__keys\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return [key for key in self.__keys]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return [key for key in self.__keys]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return self.__keys\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return self.__keys\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return list(self.__objects.keys())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return list(self.__objects.keys())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return self.__keys\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return list(self.__objects.keys())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return list(self.__keys)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_sync/io/_bolt.py", "project": "neo4j/neo4j-python-driver", "name": "protocol_handlers", "docstring": "Return a dictionary of available Bolt protocol handlers,\nkeyed by version tuple. If an explicit protocol version is\nprovided, the dictionary will contain either zero or one items,\ndepending on whether that version is supported. If no protocol\nversion is provided, all available versions will be returned.\n\n:param protocol_version: tuple identifying a specific protocol\n    version (e.g. (3, 5)) or None\n:return: dictionary of version tuple to handler class for all\n    relevant and supported protocol versions\n:raise TypeError: if protocol version is not passed in a tuple", "ques_id": "62e60ecfd76274f8a4026d6a", "code": ["def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = cls.protocol_version\n\n    if protocol_version == 1:\n        return (('bolt', 'bolt://'), )\n    elif protocol_version == 2:\n        return (('bolt', 'bolts://'), )\n    else:\n        raise NotImplementedError('Unknown protocol version: %s' % protocol_version)\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = cls.version\n\n    if protocol_version == '1.0':\n        return ['bolt']\n    elif protocol_version == '1.1':\n        return ['bolt', 'tcp']\n    elif protocol_version == '1.2':\n        return ['bolt', 'udp', 'tcp']\n    elif protocol_version == '1.3':\n        return ['bolt', 'tcp', 'udp']\n    elif protocol_version == '1.4':\n        return ['bolt', 'udp', 'tcp', 'udp']\n    elif protocol_version == '1.5':\n        return ['bolt', 'udp', 'tcp', 'udp', 'tcp']\n    elif protocol_version == '1.6':\n        return ['bolt', 'tcp', 'udp', 'tcp']\n    elif protocol_version == '1.7':\n        return ['bolt', 'udp', 'tcp', 'udp', 'tcp', 'udp']\n    elif protocol_version == '1.8", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = cls.protocol_version\n\n    if protocol_version == 1:\n        return [_BoltProtocol1]\n    elif protocol_version == 2:\n        return [_BoltProtocol2]\n    else:\n        raise ValueError(\"Unknown Bolt protocol version: %d\" % protocol_version)\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = cls.protocol_version\n\n    if protocol_version == 1:\n        return [_BoltProtocol1]\n    elif protocol_version == 2:\n        return [_BoltProtocol2]\n    else:\n        return []\n", "def protocol_handlers(cls, protocol_version=None):\n    protocol_version = protocol_version or cls.protocol_version\n    if protocol_version not in cls.protocol_handlers_map:\n        raise ValueError(\n            'Unsupported protocol_version: {}. Choose between {}.'.format(\n                protocol_version, list(cls.protocol_handlers_map.keys())))\n    return cls.protocol_handlers_map[protocol_version]\n", "def protocol_handlers(cls, protocol_version=None):\n    protocol_version = protocol_version or cls.protocol_version\n    if protocol_version not in ['1.0', '1.1', '1.2', '1.3']:\n        raise ValueError('Invalid protocol version: %s' % protocol_version)\n\n    handlers = {\n        '1.0': _handle_bolt_version_1.0,\n        '1.1': _handle_bolt_version_1.1,\n        '1.2': _handle_bolt_version_1.2,\n        '1.3': _handle_bolt_version_1.3\n    }\n\n    return handlers.get(protocol_version, _handle_bolt_version_no_change)\n", "def protocol_handlers(cls, protocol_version=None):\n    handlers = {\n        'bolt': ('bolt', True),\n        'tcp': ('tcp', False),\n        'udp': ('udp', False),\n    }\n    if protocol_version is None:\n        protocol_version = cls.protocol_version\n    if protocol_version in handlers:\n        return handlers[protocol_version]\n    else:\n        raise AssertionError(\n            'Protocol version {} not supported.'.format(protocol_version))\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = cls.protocol_version\n    return {\n        'http': 'bolt://http/{}'.format(protocol_version),\n        'https': 'bolt://https/{}'.format(protocol_version),\n    }\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = cls.protocol_version\n    if protocol_version == 1:\n        return ['bolt://']\n    elif protocol_version == 2:\n        return ['bolt+http', 'bolt+https']\n", "def protocol_handlers(cls, protocol_version=None):\n    protocol_version = protocol_version or '1.1'\n    if protocol_version == '1.1':\n        return [\n            (b'GET', b'/', cls.handler_called, None, True),\n            (b'POST', b'/', cls.handler_called, None, True),\n            (b'PUT', b'/', cls.handler_called, None, True),\n            (b'DELETE', b'/', cls.handler_called, None, True),\n        ]\n    else:\n        return [\n            (b'GET', b'/', cls.handler_called, None, True),\n            (b'PUT', b'/', cls.handler_called, None, True),\n            (b'POST', b'/', cls.handler_called, None, True),\n            (b'DELETE', b'/', cls.handler_called, None, True),\n        ]\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = cls.protocol_version\n\n    if protocol_version == 1:\n        return (('bolt', 'bolt://'), )\n    elif protocol_version == 2:\n        return (('bolt', 'bolts://'), )\n    else:\n        raise NotImplementedError('Unknown protocol version: %s' % protocol_version)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = cls.version\n\n    if protocol_version == '1.0':\n        return ['bolt']\n    elif protocol_version == '1.1':\n        return ['bolt', 'tcp']\n    elif protocol_version == '1.2':\n        return ['bolt', 'udp', 'tcp']\n    elif protocol_version == '1.3':\n        return ['bolt', 'tcp', 'udp']\n    elif protocol_version == '1.4':\n        return ['bolt', 'udp', 'tcp', 'udp']\n    elif protocol_version == '1.5':\n        return ['bolt', 'udp', 'tcp', 'udp', 'tcp']\n    elif protocol_version == '1.6':\n        return ['bolt', 'tcp', 'udp', 'tcp']\n    elif protocol_version == '1.7':\n        return ['bolt', 'udp', 'tcp', 'udp', 'tcp', 'udp']\n    elif protocol_version == '1.8", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = cls.protocol_version\n\n    if protocol_version == 1:\n        return [_BoltProtocol1]\n    elif protocol_version == 2:\n        return [_BoltProtocol2]\n    else:\n        raise ValueError(\"Unknown Bolt protocol version: %d\" % protocol_version)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = cls.protocol_version\n\n    if protocol_version == 1:\n        return [_BoltProtocol1]\n    elif protocol_version == 2:\n        return [_BoltProtocol2]\n    else:\n        return []\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    protocol_version = protocol_version or cls.protocol_version\n    if protocol_version not in cls.protocol_handlers_map:\n        raise ValueError(\n            'Unsupported protocol_version: {}. Choose between {}.'.format(\n                protocol_version, list(cls.protocol_handlers_map.keys())))\n    return cls.protocol_handlers_map[protocol_version]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    protocol_version = protocol_version or cls.protocol_version\n    if protocol_version not in ['1.0', '1.1', '1.2', '1.3']:\n        raise ValueError('Invalid protocol version: %s' % protocol_version)\n\n    handlers = {\n        '1.0': _handle_bolt_version_1.0,\n        '1.1': _handle_bolt_version_1.1,\n        '1.2': _handle_bolt_version_1.2,\n        '1.3': _handle_bolt_version_1.3\n    }\n\n    return handlers.get(protocol_version, _handle_bolt_version_no_change)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    handlers = {\n        'bolt': ('bolt', True),\n        'tcp': ('tcp', False),\n        'udp': ('udp', False),\n    }\n    if protocol_version is None:\n        protocol_version = cls.protocol_version\n    if protocol_version in handlers:\n        return handlers[protocol_version]\n    else:\n        raise AssertionError(\n            'Protocol version {} not supported.'.format(protocol_version))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = cls.protocol_version\n    return {\n        'http': 'bolt://http/{}'.format(protocol_version),\n        'https': 'bolt://https/{}'.format(protocol_version),\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        protocol_version = cls.protocol_version\n    if protocol_version == 1:\n        return ['bolt://']\n    elif protocol_version == 2:\n        return ['bolt+http', 'bolt+https']\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    protocol_version = protocol_version or '1.1'\n    if protocol_version == '1.1':\n        return [\n            (b'GET', b'/', cls.handler_called, None, True),\n            (b'POST', b'/', cls.handler_called, None, True),\n            (b'PUT', b'/', cls.handler_called, None, True),\n            (b'DELETE', b'/', cls.handler_called, None, True),\n        ]\n    else:\n        return [\n            (b'GET', b'/', cls.handler_called, None, True),\n            (b'PUT', b'/', cls.handler_called, None, True),\n            (b'POST', b'/', cls.handler_called, None, True),\n            (b'DELETE', b'/', cls.handler_called, None, True),\n        ]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/work/query.py", "project": "neo4j/neo4j-python-driver", "name": "unit_of_work", "docstring": "This function is a decorator for transaction functions that allows extra control over how the transaction is carried out.\n\nFor example, a timeout may be applied::\n\n    from neo4j import unit_of_work\n\n    @unit_of_work(timeout=100)\n    def count_people_tx(tx):\n        result = tx.run(\"MATCH (a:Person) RETURN count(a) AS persons\")\n        record = result.single()\n        return record[\"persons\"]\n\n:param metadata:\n    a dictionary with metadata.\n    Specified metadata will be attached to the executing transaction and visible in the output of ``dbms.listQueries`` and ``dbms.listTransactions`` procedures.\n    It will also get logged to the ``query.log``.\n    This functionality makes it easier to tag transactions and is equivalent to ``dbms.setTXMetaData`` procedure, see https://neo4j.com/docs/operations-manual/current/reference/procedures/ for procedure reference.\n:type metadata: dict\n\n:param timeout:\n    the transaction timeout in seconds.\n    Transactions that execute longer than the configured timeout will be terminated by the database.\n    This functionality allows to limit query/transaction execution time.\n    Specified timeout overrides the default timeout configured in the database using ``dbms.transaction.timeout`` setting.\n    Value should not represent a negative duration.\n    A zero duration will make the transaction execute indefinitely.\n    None will use the default timeout configured in the database.\n:type timeout: float or :const:`None`", "ques_id": "62e60e49d76274f8a4026d25", "code": ["def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        func.metadata = metadata\n        func.timeout = timeout\n        return func\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            promise = func(*args, **kwargs)\n            promise.metadata = metadata\n            promise.timeout = timeout\n            return promise\n\n        return wrapper\n\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        if func.__name__ in _active_workers:\n            raise WorkerError(\"Worker `{}` is already running.\".format(func.__name__))\n\n        if metadata is not None:\n            func.metadata = metadata\n        if timeout is not None:\n            func.timeout = timeout\n\n        _active_workers[func.__name__] = func\n        return func\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        if metadata is not None:\n            func._metadata = metadata\n        if timeout is not None:\n            func._timeout = timeout\n        return func\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        if not callable(func):\n            raise TypeError('@unit_of_work decorator must be callable.')\n        if metadata is None:\n            metadata = {}\n        if timeout is None:\n            timeout = DEFAULT_TIMEOUT\n        def wrapper(*args, **kwargs):\n            return func(*args, **kwargs)\n        wrapper.timeout = timeout\n        wrapper.metadata = metadata\n        return wrapper\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n\n    def decorator(func):\n        if not func.__name__.startswith('_'):\n            func.metadata = metadata or {}\n            func.timeout = timeout or DEFAULT_TIMEOUT\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            return func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            self = args[0]\n            self._metadata = metadata or self._metadata\n            self._timeout = timeout or self._timeout\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            return func(*args, **kwargs)\n        wrapper.__method__ = 'POST'\n        wrapper.__timeout__ = timeout\n        wrapper.__metadata__ = metadata or {}\n        return wrapper\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        func.metadata = metadata\n        func.timeout = timeout\n        return func\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(method):\n        @functools.wraps(method)\n        def wrapper(*args, **kwargs):\n            self = args[0]\n            self._timeout = timeout\n            self._metadata = metadata\n            return method(*args, **kwargs)\n        return wrapper\n    return decorator\n"], "level": "self_contained", "generate_results": [{"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        func.metadata = metadata\n        func.timeout = timeout\n        return func\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            promise = func(*args, **kwargs)\n            promise.metadata = metadata\n            promise.timeout = timeout\n            return promise\n\n        return wrapper\n\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        if func.__name__ in _active_workers:\n            raise WorkerError(\"Worker `{}` is already running.\".format(func.__name__))\n\n        if metadata is not None:\n            func.metadata = metadata\n        if timeout is not None:\n            func.timeout = timeout\n\n        _active_workers[func.__name__] = func\n        return func\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        if metadata is not None:\n            func._metadata = metadata\n        if timeout is not None:\n            func._timeout = timeout\n        return func\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        if not callable(func):\n            raise TypeError('@unit_of_work decorator must be callable.')\n        if metadata is None:\n            metadata = {}\n        if timeout is None:\n            timeout = DEFAULT_TIMEOUT\n        def wrapper(*args, **kwargs):\n            return func(*args, **kwargs)\n        wrapper.timeout = timeout\n        wrapper.metadata = metadata\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n\n    def decorator(func):\n        if not func.__name__.startswith('_'):\n            func.metadata = metadata or {}\n            func.timeout = timeout or DEFAULT_TIMEOUT\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            return func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            self = args[0]\n            self._metadata = metadata or self._metadata\n            self._timeout = timeout or self._timeout\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            return func(*args, **kwargs)\n        wrapper.__method__ = 'POST'\n        wrapper.__timeout__ = timeout\n        wrapper.__metadata__ = metadata or {}\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        func.metadata = metadata\n        func.timeout = timeout\n        return func\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def decorator(method):\n        @functools.wraps(method)\n        def wrapper(*args, **kwargs):\n            self = args[0]\n            self._timeout = timeout\n            self._metadata = metadata\n            return method(*args, **kwargs)\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_data.py", "project": "neo4j/neo4j-python-driver", "name": "index", "docstring": "Return the index of the given item.\n\n:param key: a key\n:return: index\n:rtype: int", "ques_id": "62e60e05d76274f8a4026cfd", "code": ["def index(self, key):\n    k = key if isinstance(key, int) else self._key_type(key)\n    i = bisect_left(self._keys, k)\n    j = bisect_right(self._keys, k)\n    return self._items[i:j].index(k) + i\n", "def index(self, key):\n    hash_key = self.hash_function(key)\n    return self._bucket_index(hash_key, len(self.buckets))\n", "def index(self, key):\n    return self.hash(key) % len(self.table)\n", "def index(self, key):\n    try:\n        return self._keys.index(key)\n    except ValueError:\n        raise KeyError('Key not found.')\n", "def index(self, key):\n    return self._keys.index(key)\n", "def index(self, key):\n    try:\n        return int(key)\n    except ValueError:\n        return self._keys.index(key)\n", "def index(self, key):\n    return self._key_to_index(self._hash(key))\n", "def index(self, key):\n    return self._kv.index(key)\n", "def index(self, key):\n    return int(self.hash(key) % self.__size)\n", "def index(self, key):\n    return self._key_to_index[self._hash(key)]\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def index(self, key):\n    k = key if isinstance(key, int) else self._key_type(key)\n    i = bisect_left(self._keys, k)\n    j = bisect_right(self._keys, k)\n    return self._items[i:j].index(k) + i\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    hash_key = self.hash_function(key)\n    return self._bucket_index(hash_key, len(self.buckets))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    return self.hash(key) % len(self.table)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    try:\n        return self._keys.index(key)\n    except ValueError:\n        raise KeyError('Key not found.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    return self._keys.index(key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    try:\n        return int(key)\n    except ValueError:\n        return self._keys.index(key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    return self._key_to_index(self._hash(key))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    return self._kv.index(key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    return int(self.hash(key) % self.__size)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    return self._key_to_index[self._hash(key)]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_data.py", "project": "neo4j/neo4j-python-driver", "name": "values", "docstring": "Return the values of the record, optionally filtering to\ninclude only certain values by index or key.\n\n:param keys: indexes or keys of the items to include; if none\n             are provided, all values will be included\n:return: list of values\n:rtype: list", "ques_id": "62e60da4d76274f8a4026cf1", "code": ["def values(self, *keys):\n    return [self[key] for key in keys]\n", "def values(self, *keys):\n    return [self[key] for key in keys]\n", "def values(self, *keys):\n    return list(self[k] for k in keys)\n", "def values(self, *keys):\n    return [self.get(key) for key in keys]\n", "def values(self, *keys):\n    return list(self.select(*keys))\n", "def values(self, *keys):\n    return [self[key] for key in keys]\n", "def values(self, *keys):\n    return [self[key] for key in keys]\n", "def values(self, *keys):\n    return [self[key] for key in keys]\n", "def values(self, *keys):\n    return [self[key] for key in keys]\n", "def values(self, *keys):\n    return [self[key] for key in keys]\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def values(self, *keys):\n    return [self[key] for key in keys]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def values(self, *keys):\n    return [self[key] for key in keys]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def values(self, *keys):\n    return list(self[k] for k in keys)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def values(self, *keys):\n    return [self.get(key) for key in keys]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def values(self, *keys):\n    return list(self.select(*keys))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def values(self, *keys):\n    return [self[key] for key in keys]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def values(self, *keys):\n    return [self[key] for key in keys]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def values(self, *keys):\n    return [self[key] for key in keys]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def values(self, *keys):\n    return [self[key] for key in keys]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def values(self, *keys):\n    return [self[key] for key in keys]\n", "is_pass": true, "return_code": 0}]}
{"file_path": "neo4j/_data.py", "project": "neo4j/neo4j-python-driver", "name": "data", "docstring": "Return the keys and values of this record as a dictionary,\noptionally including only certain values by index or key. Keys\nprovided in the items that are not in the record will be\ninserted with a value of :const:`None`; indexes provided\nthat are out of bounds will trigger an :exc:`IndexError`.\n\n:param keys: indexes or keys of the items to include; if none\n              are provided, all values will be included\n:return: dictionary of values, keyed by field name\n:raises: :exc:`IndexError` if an out-of-bounds index is specified", "ques_id": "62e60b10d76274f8a4026ccd", "code": ["def data(self, *keys):\n    return [self[k] for k in keys]\n", "def data(self, *keys):\n    return [getattr(self, key) for key in keys]\n", "def data(self, *keys):\n    return [self[key] for key in keys]\n", "def data(self, *keys):\n    return [self._process_key(k) for k in keys]\n", "def data(self, *keys):\n    return [self._storage[k] for k in keys]\n", "def data(self, *keys):\n    return self._data(*keys)\n", "def data(self, *keys):\n    return [self._data[key] for key in keys]\n", "def data(self, *keys):\n    return self._exporters[0].data(*keys)\n", "def data(self, *keys):\n    return [self._key(k) for k in keys]\n", "def data(self, *keys):\n    return [self._data[k] for k in keys]\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def data(self, *keys):\n    return [self[k] for k in keys]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    return [getattr(self, key) for key in keys]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    return [self[key] for key in keys]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    return [self._process_key(k) for k in keys]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    return [self._storage[k] for k in keys]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    return self._data(*keys)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    return [self._data[key] for key in keys]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    return self._exporters[0].data(*keys)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    return [self._key(k) for k in keys]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    return [self._data[k] for k in keys]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_codec/packstream/v1/__init__.py", "project": "neo4j/neo4j-python-driver", "name": "pop_u16", "docstring": "Remove the last two bytes of data, returning them as a big-endian\n16-bit unsigned integer.", "ques_id": "62e6087bd76274f8a4026bfa", "code": ["def pop_u16(self):\n    self.data.pop()\n    return self.pop_u16()\n", "def pop_u16(self):\n    self.data.pop()\n    return self.pop_u16()\n", "def pop_u16(self):\n    return self.data.pop(), self.data.pop()\n", "def pop_u16(self):\n    self.data.pop()\n    self.data.pop()\n    return self.data.pop()\n", "def pop_u16(self):\n    self.data.pop()\n    self.data.pop()\n    return self.data.pop()\n", "def pop_u16(self):\n    self.data.pop()\n    self.data.pop()\n    return self.data.pop()\n", "def pop_u16(self):\n    self.data = self.data[2:]\n    return self.data.pop()\n", "def pop_u16(self):\n    popped = self.data[-2:]\n    self.data = self.data[:-2]\n    return popped\n", "def pop_u16(self):\n    self.data.pop()\n    self.data.pop()\n    return self.pop_u16()\n", "def pop_u16(self):\n    self.data.pop()\n    self.data.pop()\n    return self.data.pop()\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def pop_u16(self):\n    self.data.pop()\n    return self.pop_u16()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    self.data.pop()\n    return self.pop_u16()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    return self.data.pop(), self.data.pop()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    self.data.pop()\n    self.data.pop()\n    return self.data.pop()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    self.data.pop()\n    self.data.pop()\n    return self.data.pop()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    self.data.pop()\n    self.data.pop()\n    return self.data.pop()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    self.data = self.data[2:]\n    return self.data.pop()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    popped = self.data[-2:]\n    self.data = self.data[:-2]\n    return popped\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    self.data.pop()\n    self.data.pop()\n    return self.pop_u16()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    self.data.pop()\n    self.data.pop()\n    return self.data.pop()\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_async/io/_bolt3.py", "project": "neo4j/neo4j-python-driver", "name": "discard", "docstring": "Appends a DISCARD message to the output queue.\n\n:param n: number of records to discard, default = -1 (ALL)\n:param qid: query ID to discard for, default = -1 (last query)\n:param dehydration_hooks:\n    Hooks to dehydrate types (dict from type (class) to dehydration\n    function). Dehydration functions receive the value and returns an\n    object of type understood by packstream.\n:param hydration_hooks:\n    Hooks to hydrate types (mapping from type (class) to\n    dehydration function). Dehydration functions receive the value of\n    type understood by packstream and are free to return anything.\n:param handlers: handler functions passed into the returned Response object", "ques_id": "62e6087ad76274f8a4026bf2", "code": ["def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from\n        type (class) to dehydration function). Dehydration functions\n        receives the value and returns an object of type desired by\n        packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from\n        type (class) to dehydration function). Dehydration functions\n        receives the value of type desired by packstream and are free\n        to return anything.\n    :param handlers: handler functions passed in the returned Response\n        object when received.\n    \"\"\"\n    return self._append(Request(discard=n, qid=qid,\n                                discard_method='discard',\n                       ", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function). Dehydration functions\n        receives the value and returns an object of type Undehyded (not dehydrated).\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n        Dehydration functions receives the value and returns an object of type Undehyded (not dehydrated).\n    :param handlers: handler functions passed in the returned Response object (unused).\n    \"\"\"\n    return self._append(ResponseType.DISCARD, n, qid, dehydration_hooks,\n                        hydration_hooks, handlers)\n", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hopers to dehydrate types (dict from type\n                                (class) to dehydration function). Dehydration\n                                functions receives the value and returns\n                                an object of type desired by packstream.\n    :param hydration_hooks: Hopers to dehydrate types (mapping from\n                                type (class) to dehydration function). Dehydration\n                                functions receives the value of type\n                                desired by packstream and are free to\n                       ", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n                                                            to dehydration function).\n                                Dehydration functions receive the value and returns an\n                                object of type understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from\n                                                                type (class) to dehydration\n                                                              ", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function). Dehydration functions\n        receives the value and returns an object of type understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function). Dehydration functions\n        receives the value of type understood by packstream and are free to return anything.\n    :param handlers: handler functions passed in the returned Response object is used to return the value of\n        understood by packstream when a response is received.\n    \"\"\"\n    self._append(discard.Discard(n, qid, dehydration_hooks, hydration_hooks, **handlers))\n", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type\n                                    (class) to dehydration function). Dehydration\n                                    functions receives the value and returns\n                                    an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from type\n                                                                to dehydration\n                                                                function).\n    :param handlers: handler function", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n        Dehydration functions receive the value and returns an object of type understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n        Dehydration functions receive the value of type understood by packstream and are free to return\n        anything.\n    :param handlers: handler functions passed in the returned Response object which will be used\n        to resolve the value of type understood by packstream and are free to return anything.\n    \"\"\"\n    self._enqueue('discard', n, qid, dehydration_hooks, hydration_hooks, handlers)\n", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function). Dehydration functions\n        receives the value and returns an object of type underdetected by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n        Dehydration functions receives the value of type underdetected by packstream and are free to return\n        anything.\n    :param handlers: handler functions passed in the returned Response object (unused).\n    \"\"\"\n    if not isinstance(handlers, dict):\n        raise TypeError(\"'handlers' must be of type dict.\")\n\n    self._add_message(DISCARD, n, qid, dehydration_hooks, hydration_hooks, handlers)\n", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n        Dehydration functions receive the value and returns an object of type understood by\n        packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n        Dehydration functions receive the value of type understood by packstream and are free to\n        return things.\n    :param handlers: handler functions passed in the returned Response object instead of the\n        Response object.\n    \"\"\"\n    self._send('DISCARD', {'n': n, 'qid': qid, 'dehydration_hooks': dehydration_hooks,\n                            'hydration_hooks': hydration_hooks, 'handler", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n        Dehydration functions receive the value and returns an object of type understood by\n        packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n        Dehydration functions receive the value of type understood by packstream and are free to\n        return anything.\n    :param handlers: handler functions passed in the returned Response object instead of the returned\n        Response object from the returned method\n    \"\"\"\n    self._enqueue('discard', n=n, qid=qid, dehydration_hooks=dehydration_hooks,\n                                             "], "level": "project_runnable", "generate_results": [{"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from\n        type (class) to dehydration function). Dehydration functions\n        receives the value and returns an object of type desired by\n        packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from\n        type (class) to dehydration function). Dehydration functions\n        receives the value of type desired by packstream and are free\n        to return anything.\n    :param handlers: handler functions passed in the returned Response\n        object when received.\n    \"\"\"\n    return self._append(Request(discard=n, qid=qid,\n                                discard_method='discard',\n                       ", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function). Dehydration functions\n        receives the value and returns an object of type Undehyded (not dehydrated).\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n        Dehydration functions receives the value and returns an object of type Undehyded (not dehydrated).\n    :param handlers: handler functions passed in the returned Response object (unused).\n    \"\"\"\n    return self._append(ResponseType.DISCARD, n, qid, dehydration_hooks,\n                        hydration_hooks, handlers)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hopers to dehydrate types (dict from type\n                                (class) to dehydration function). Dehydration\n                                functions receives the value and returns\n                                an object of type desired by packstream.\n    :param hydration_hooks: Hopers to dehydrate types (mapping from\n                                type (class) to dehydration function). Dehydration\n                                functions receives the value of type\n                                desired by packstream and are free to\n                       ", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n                                                            to dehydration function).\n                                Dehydration functions receive the value and returns an\n                                object of type understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from\n                                                                type (class) to dehydration\n                                                              ", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function). Dehydration functions\n        receives the value and returns an object of type understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function). Dehydration functions\n        receives the value of type understood by packstream and are free to return anything.\n    :param handlers: handler functions passed in the returned Response object is used to return the value of\n        understood by packstream when a response is received.\n    \"\"\"\n    self._append(discard.Discard(n, qid, dehydration_hooks, hydration_hooks, **handlers))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type\n                                    (class) to dehydration function). Dehydration\n                                    functions receives the value and returns\n                                    an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from type\n                                                                to dehydration\n                                                                function).\n    :param handlers: handler function", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n        Dehydration functions receive the value and returns an object of type understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n        Dehydration functions receive the value of type understood by packstream and are free to return\n        anything.\n    :param handlers: handler functions passed in the returned Response object which will be used\n        to resolve the value of type understood by packstream and are free to return anything.\n    \"\"\"\n    self._enqueue('discard', n, qid, dehydration_hooks, hydration_hooks, handlers)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function). Dehydration functions\n        receives the value and returns an object of type underdetected by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n        Dehydration functions receives the value of type underdetected by packstream and are free to return\n        anything.\n    :param handlers: handler functions passed in the returned Response object (unused).\n    \"\"\"\n    if not isinstance(handlers, dict):\n        raise TypeError(\"'handlers' must be of type dict.\")\n\n    self._add_message(DISCARD, n, qid, dehydration_hooks, hydration_hooks, handlers)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n        Dehydration functions receive the value and returns an object of type understood by\n        packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n        Dehydration functions receive the value of type understood by packstream and are free to\n        return things.\n    :param handlers: handler functions passed in the returned Response object instead of the\n        Response object.\n    \"\"\"\n    self._send('DISCARD', {'n': n, 'qid': qid, 'dehydration_hooks': dehydration_hooks,\n                            'hydration_hooks': hydration_hooks, 'handler", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n        Dehydration functions receive the value and returns an object of type understood by\n        packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n        Dehydration functions receive the value of type understood by packstream and are free to\n        return anything.\n    :param handlers: handler functions passed in the returned Response object instead of the returned\n        Response object from the returned method\n    \"\"\"\n    self._enqueue('discard', n=n, qid=qid, dehydration_hooks=dehydration_hooks,\n                                             ", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_async/io/_bolt3.py", "project": "neo4j/neo4j-python-driver", "name": "begin", "docstring": "Appends a BEGIN message to the output queue.\n\n:param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n:param bookmarks: iterable of bookmark values after which this transaction should begin\n:param metadata: custom metadata dictionary to attach to the transaction\n:param timeout: timeout for transaction execution (seconds)\n:param db: name of the database against which to begin the transaction\n    Requires Bolt 4.0+.\n:param imp_user: the user to impersonate\n    Requires Bolt 4.4+\n:param dehydration_hooks:\n    Hooks to dehydrate types (dict from type (class) to dehydration\n    function). Dehydration functions receive the value and returns an\n    object of type understood by packstream.\n:param hydration_hooks:\n    Hooks to hydrate types (mapping from type (class) to\n    dehydration function). Dehydration functions receive the value of\n    type understood by packstream and are free to return anything.\n:param handlers: handler functions passed into the returned Response object\n:return: Response object", "ques_id": "62e60879d76274f8a4026bec", "code": ["def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this\n                      transaction should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the\n              transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n                             to dehydration function). Dehydration functions\n                             receives the value and returns an object of\n                             type understood by packstream.\n    :param hyperlinks: hyperlinks to be processed\n    :param handlers: handler functions passe", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n                        should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n                            Dehydration functions receive the value and returns an object of type\n                            understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration\n                           function). Dehydration functions receive the value", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n                  (default)\n    :param bookmarks: iterable of bookmark values after which this\n                       transaction should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from\n                           type (class) to dehydration function). Dehydration\n                           functions receive the value and returns an object\n                           of type understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from\n          ", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n                 (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n                       should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydration types (dict from type (class)\n                              to dehydration function). Dehydration functions\n                              receives the value and returns an object of\n                              type understood by packstream.\n    :param hydration_hooks: Hooks to dehydration types (mapping from", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n                            Dehydration functions receive the value and returns an object of type understood by\n                            packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n                            Dehydration functions receive the value of type understood by packstream and are\n    ", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n                      should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n                             to dehydration function). Dehydration functions\n                             receives the value and returns an object of\n                             type understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from\n                           ", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n                      should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n                             Dehydration functions receive the value and returns an object of type\n                             understood by packstream.\n    :param handlers: handlers passed in to the returned Response object\n    :return: Response object\n    \"\"\"\n    return self._append('begin', mode=mode, bookmarks=boo", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n                       should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n                            Dehydration functions receive the value and returns an object of type\n                            understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n                            Dehydration functions receive the value", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n                      should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n                           Dehydration functions receive the value and returns an object of type\n                           understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n                           Dehydration functions receive the value of type", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n                      should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n               (Requires Bolt 4.0+)\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n                           to dehydration function). Dehydration functions\n                           receive the value and returns an object of type\n                           understood by packstream.\n    :param handlers: handler functions passed into the returned Response object\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this\n                      transaction should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the\n              transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n                             to dehydration function). Dehydration functions\n                             receives the value and returns an object of\n                             type understood by packstream.\n    :param hyperlinks: hyperlinks to be processed\n    :param handlers: handler functions passe", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n                        should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n                            Dehydration functions receive the value and returns an object of type\n                            understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration\n                           function). Dehydration functions receive the value", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n                  (default)\n    :param bookmarks: iterable of bookmark values after which this\n                       transaction should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from\n                           type (class) to dehydration function). Dehydration\n                           functions receive the value and returns an object\n                           of type understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from\n          ", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n                 (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n                       should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydration types (dict from type (class)\n                              to dehydration function). Dehydration functions\n                              receives the value and returns an object of\n                              type understood by packstream.\n    :param hydration_hooks: Hooks to dehydration types (mapping from", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n                            Dehydration functions receive the value and returns an object of type understood by\n                            packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n                            Dehydration functions receive the value of type understood by packstream and are\n    ", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n                      should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n                             to dehydration function). Dehydration functions\n                             receives the value and returns an object of\n                             type understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from\n                           ", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n                      should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n                             Dehydration functions receive the value and returns an object of type\n                             understood by packstream.\n    :param handlers: handlers passed in to the returned Response object\n    :return: Response object\n    \"\"\"\n    return self._append('begin', mode=mode, bookmarks=boo", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n                       should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n                            Dehydration functions receive the value and returns an object of type\n                            understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n                            Dehydration functions receive the value", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n                      should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n                           Dehydration functions receive the value and returns an object of type\n                           understood by packstream.\n    :param hydration_hooks: Hooks to dehydration functions (mapping from type (class) to dehydration function).\n                           Dehydration functions receive the value of type", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n                      should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n               (Requires Bolt 4.0+)\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n                           to dehydration function). Dehydration functions\n                           receive the value and returns an object of type\n                           understood by packstream.\n    :param handlers: handler functions passed into the returned Response object\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/time/_arithmetic.py", "project": "neo4j/neo4j-python-driver", "name": "round_half_to_even", "docstring": ">>> round_half_to_even(3)\n    3\n    >>> round_half_to_even(3.2)\n    3\n    >>> round_half_to_even(3.5)\n    4\n    >>> round_half_to_even(3.7)\n    4\n    >>> round_half_to_even(4)\n    4\n    >>> round_half_to_even(4.2)\n    4\n    >>> round_half_to_even(4.5)\n    4\n    >>> round_half_to_even(4.7)\n    5\n\n:param n:\n:return:", "ques_id": "62e60723d76274f8a4026b75", "code": ["def round_half_to_even(n):\n    return math.ceil(n / 2) * 2\n", "def round_half_to_even(n):\n    return int(n + 0.5)\n", "def round_half_to_even(n):\n    return (n + 0.5) / 2.\n", "def round_half_to_even(n):\n    return (n + 0.5) / 2\n", "def round_half_to_even(n):\n    return math.ceil(n / 2) * 2\n", "def round_half_to_even(n):\n    return int(n + 0.5)\n", "def round_half_to_even(n):\n    return n if n % 2 == 0 else (n + 1) / 2\n", "def round_half_to_even(n):\n    return n + (n - floor(n)) / 2\n", "def round_half_to_even(n):\n    return n + (n - floor(n)) / 2.\n", "def round_half_to_even(n):\n    return round(n + 0.5) - 0.5\n"], "level": "self_contained", "generate_results": [{"generate_code": "def round_half_to_even(n):\n    return math.ceil(n / 2) * 2\n", "is_pass": false, "return_code": 1}, {"generate_code": "def round_half_to_even(n):\n    return int(n + 0.5)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def round_half_to_even(n):\n    return (n + 0.5) / 2.\n", "is_pass": false, "return_code": 1}, {"generate_code": "def round_half_to_even(n):\n    return (n + 0.5) / 2\n", "is_pass": false, "return_code": 1}, {"generate_code": "def round_half_to_even(n):\n    return math.ceil(n / 2) * 2\n", "is_pass": false, "return_code": 1}, {"generate_code": "def round_half_to_even(n):\n    return int(n + 0.5)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def round_half_to_even(n):\n    return n if n % 2 == 0 else (n + 1) / 2\n", "is_pass": true, "return_code": 0}, {"generate_code": "def round_half_to_even(n):\n    return n + (n - floor(n)) / 2\n", "is_pass": false, "return_code": 1}, {"generate_code": "def round_half_to_even(n):\n    return n + (n - floor(n)) / 2.\n", "is_pass": false, "return_code": 1}, {"generate_code": "def round_half_to_even(n):\n    return round(n + 0.5) - 0.5\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_spatial/__init__.py", "project": "neo4j/neo4j-python-driver", "name": "point_type", "docstring": "Dynamically create a Point subclass.", "ques_id": "62e60707d76274f8a4026b69", "code": ["def point_type(name, fields, srid_map):\n    return type(\n        name,\n        fields,\n        {\n            '__module__': 'gisgraphy.geometry',\n           'srid': srid_map[name],\n            'coordinates': lambda: tuple([float(x) for x in fields[:-1]])\n        }\n    )\n", "def point_type(name, fields, srid_map):\n    return {\n        \"name\": name,\n        \"fields\": fields,\n        \"srid\": srid_map[name],\n    }\n", "def point_type(name, fields, srid_map):\n    return {\n        'type': 'Point',\n        'coordinates': [float(fields['lon']), float(fields['lat'])],\n        'name': name,\n       'srid': srid_map[fields['srid']],\n        'description': fields['description']\n    }\n", "def point_type(name, fields, srid_map):\n    field_names = ', '.join(fields.keys())\n    field_srids = ', '.join(['SRID={0}'.format(srid_map[f]) for f in fields])\n    return 'Point({0}, {1})'.format(field_names, field_srids)\n", "def point_type(name, fields, srid_map):\n\n    return {\n        'type': 'Point',\n        'coordinates': list(map(lambda x: srid_map[x], fields)),\n        'name': name,\n    }\n", "def point_type(name, fields, srid_map):\n    return type(name, fields, {\n        '__module__': 'django.contrib.gis',\n        '__doc__': 'Point Geometry ({})'.format(name),\n        'coordinates': lambda: tuple([\n            srid_map[f] for f in fields\n        ])\n    })\n", "def point_type(name, fields, srid_map):\n    field_list = []\n    for field in fields:\n        field_list.append(field.name)\n        if field.geom_type == 'Point':\n            srid = srid_map.get(field.geom_type)\n            if srid is None:\n                raise Exception('Invalid Spatial Reference Type')\n            else:\n                field_list.append('SRID={}'.format(srid))\n        elif field.geom_type == 'MultiPoint':\n            field_list.append('MULTIPOINT')\n        elif field.geom_type == 'LineString':\n            field_list.append('LINESTRING')\n        elif field.geom_type == 'Polygon':\n            field_list.append('POLYGON')\n        elif field.geom_type == 'GeometryCollection':\n            field_list.append('MULTIPOLYGON')\n        else:\n            raise Exception('Invalid Geometry Type')\n    return ', '.j", "def point_type(name, fields, srid_map):\n\n    return {\n        \"type\": \"Point\",\n        \"coordinates\": [fields[\"x\"], fields[\"y\"]],\n        \"name\": name,\n        \"srid\": srid_map[fields[\"srid\"]],\n    }\n", "def point_type(name, fields, srid_map):\n    return type(name, fields, {'srid': srid_map['SRID']})\n", "def point_type(name, fields, srid_map):\n    if isinstance(fields, str):\n        fields = [fields]\n    return {\n        'type': 'Point',\n        'coordinates': (\n            float(fields[0]),\n            float(fields[1])\n        ),\n        'dimensions': len(fields),\n        'name': name,\n       'srid': srid_map[fields[0]],\n        'description': fields[0] if len(fields) > 0 else None\n    }\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def point_type(name, fields, srid_map):\n    return type(\n        name,\n        fields,\n        {\n            '__module__': 'gisgraphy.geometry',\n           'srid': srid_map[name],\n            'coordinates': lambda: tuple([float(x) for x in fields[:-1]])\n        }\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n    return {\n        \"name\": name,\n        \"fields\": fields,\n        \"srid\": srid_map[name],\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n    return {\n        'type': 'Point',\n        'coordinates': [float(fields['lon']), float(fields['lat'])],\n        'name': name,\n       'srid': srid_map[fields['srid']],\n        'description': fields['description']\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n    field_names = ', '.join(fields.keys())\n    field_srids = ', '.join(['SRID={0}'.format(srid_map[f]) for f in fields])\n    return 'Point({0}, {1})'.format(field_names, field_srids)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n\n    return {\n        'type': 'Point',\n        'coordinates': list(map(lambda x: srid_map[x], fields)),\n        'name': name,\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n    return type(name, fields, {\n        '__module__': 'django.contrib.gis',\n        '__doc__': 'Point Geometry ({})'.format(name),\n        'coordinates': lambda: tuple([\n            srid_map[f] for f in fields\n        ])\n    })\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n    field_list = []\n    for field in fields:\n        field_list.append(field.name)\n        if field.geom_type == 'Point':\n            srid = srid_map.get(field.geom_type)\n            if srid is None:\n                raise Exception('Invalid Spatial Reference Type')\n            else:\n                field_list.append('SRID={}'.format(srid))\n        elif field.geom_type == 'MultiPoint':\n            field_list.append('MULTIPOINT')\n        elif field.geom_type == 'LineString':\n            field_list.append('LINESTRING')\n        elif field.geom_type == 'Polygon':\n            field_list.append('POLYGON')\n        elif field.geom_type == 'GeometryCollection':\n            field_list.append('MULTIPOLYGON')\n        else:\n            raise Exception('Invalid Geometry Type')\n    return ', '.j", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n\n    return {\n        \"type\": \"Point\",\n        \"coordinates\": [fields[\"x\"], fields[\"y\"]],\n        \"name\": name,\n        \"srid\": srid_map[fields[\"srid\"]],\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n    return type(name, fields, {'srid': srid_map['SRID']})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n    if isinstance(fields, str):\n        fields = [fields]\n    return {\n        'type': 'Point',\n        'coordinates': (\n            float(fields[0]),\n            float(fields[1])\n        ),\n        'dimensions': len(fields),\n        'name': name,\n       'srid': srid_map[fields[0]],\n        'description': fields[0] if len(fields) > 0 else None\n    }\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_meta.py", "project": "neo4j/neo4j-python-driver", "name": "deprecated", "docstring": "Decorator for deprecating functions and methods.\n\n::\n\n    @deprecated(\"'foo' has been deprecated in favour of 'bar'\")\n    def foo(x):\n        pass", "ques_id": "62e5dc9ed76274f8a4026b5b", "code": ["def deprecated(message):\n    def _decorator(func, message=message):\n        if hasattr(func, '__doc__') and func.__doc__:\n            func.__doc__ = _wrap_docstring(func.__doc__, message)\n        if hasattr(func, '__name__') and func.__name__:\n            func.__name__ = _wrap_string(func.__name__, message)\n        return func\n    return _decorator\n", "def deprecated(message):\n    def _decorator(func, message=message):\n        if message is None:\n            message = '%s is deprecated' % func.__name__\n\n        def newfunc(*args, **kwds):\n            warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwds)\n        return newfunc\n    return _decorator\n", "def deprecated(message):\n    def _decorator(func, message=message):\n        if hasattr(func, '__doc__'):\n            func.__doc__ = func.__doc__ + message\n        func.__is_deprecated__ = True\n        return func\n    return _decorator\n", "def deprecated(message):\n    def _decorator(func):\n        def newfunc(*args, **kwds):\n            warnings.warn(\"Call to deprecated function %s.\" % func.__name__,\n                          category=DeprecationWarning, stacklevel=2)\n            return func(*args, **kwds)\n        return newfunc\n    if hasattr(func, '__name__'):\n        func.__name__ = message\n    if hasattr(func, '__doc__'):\n        func.__doc__ = \"%s\\n\\nDeprecated function %s.\" % (message, func.__name__)\n    return _decorator\n", "def deprecated(message):\n    def decorate(func):\n        name = func.__name__\n        message = '%s is deprecated. %s' % (name, message)\n\n        def newfunc(*args, **kwds):\n            warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwds)\n        return newfunc\n    return decorate\n", "def deprecated(message):\n    def _decorator(func, message=message):\n        if message is None:\n            message = '%s is deprecated' % func.__name__\n\n        def newfunc(*args, **kwds):\n            warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwds)\n        return newfunc\n    return _decorator\n", "def deprecated(message):\n    def f__(f):\n        @wraps(f)\n        def f_(*args, **kwargs):\n            deprecation_warn(message)\n            return f(*args, **kwargs)\n        return f_\n    return f__\n", "def deprecated(message):\n    def decorate(func):\n        @functools.wraps(func)\n        def newfunc(*args, **kwargs):\n            deprecation_warn(message)\n            return func(*args, **kwargs)\n        return newfunc\n    return decorate\n", "def deprecated(message):\n    def _decorator(func):\n        @functools.wraps(func)\n        def newfunc(*args, **kwargs):\n            deprecation_warn(message)\n            return func(*args, **kwargs)\n        return newfunc\n    return _decorator\n", "def deprecated(message):\n    def _decorator(func, message=message):\n        if message is None:\n            message = '%s is deprecated' % func.__name__\n\n        def newfunc(*args, **kwds):\n            warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwds)\n        return newfunc\n    return _decorator\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def deprecated(message):\n    def _decorator(func, message=message):\n        if hasattr(func, '__doc__') and func.__doc__:\n            func.__doc__ = _wrap_docstring(func.__doc__, message)\n        if hasattr(func, '__name__') and func.__name__:\n            func.__name__ = _wrap_string(func.__name__, message)\n        return func\n    return _decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def _decorator(func, message=message):\n        if message is None:\n            message = '%s is deprecated' % func.__name__\n\n        def newfunc(*args, **kwds):\n            warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwds)\n        return newfunc\n    return _decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def _decorator(func, message=message):\n        if hasattr(func, '__doc__'):\n            func.__doc__ = func.__doc__ + message\n        func.__is_deprecated__ = True\n        return func\n    return _decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def _decorator(func):\n        def newfunc(*args, **kwds):\n            warnings.warn(\"Call to deprecated function %s.\" % func.__name__,\n                          category=DeprecationWarning, stacklevel=2)\n            return func(*args, **kwds)\n        return newfunc\n    if hasattr(func, '__name__'):\n        func.__name__ = message\n    if hasattr(func, '__doc__'):\n        func.__doc__ = \"%s\\n\\nDeprecated function %s.\" % (message, func.__name__)\n    return _decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def decorate(func):\n        name = func.__name__\n        message = '%s is deprecated. %s' % (name, message)\n\n        def newfunc(*args, **kwds):\n            warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwds)\n        return newfunc\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def _decorator(func, message=message):\n        if message is None:\n            message = '%s is deprecated' % func.__name__\n\n        def newfunc(*args, **kwds):\n            warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwds)\n        return newfunc\n    return _decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def f__(f):\n        @wraps(f)\n        def f_(*args, **kwargs):\n            deprecation_warn(message)\n            return f(*args, **kwargs)\n        return f_\n    return f__\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def decorate(func):\n        @functools.wraps(func)\n        def newfunc(*args, **kwargs):\n            deprecation_warn(message)\n            return func(*args, **kwargs)\n        return newfunc\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def _decorator(func):\n        @functools.wraps(func)\n        def newfunc(*args, **kwargs):\n            deprecation_warn(message)\n            return func(*args, **kwargs)\n        return newfunc\n    return _decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def _decorator(func, message=message):\n        if message is None:\n            message = '%s is deprecated' % func.__name__\n\n        def newfunc(*args, **kwds):\n            warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwds)\n        return newfunc\n    return _decorator\n", "is_pass": false, "return_code": 1}]}
{"file_path": "pre_commit/languages/r.py", "project": "pre-commit/pre-commit", "name": "_inline_r_setup", "docstring": "Some behaviour of R cannot be configured via env variables, but can\nonly be configured via R options once R has started. These are set here.", "ques_id": "62e4fc3c85ea98643089041e", "code": ["def _inline_r_setup(code: str) -> str:\n    env = os.environ\n    if 'R_CONFIG' in env:\n        config_file = env['R_CONFIG']\n        if config_file and os.path.isfile(config_file):\n            with open(config_file, 'r') as f:\n                code = f.read()\n    return code\n", "def _inline_r_setup(code: str) -> str:\n    env = os.environ\n    r_inline = env.get('R', None)\n    if r_inline is None:\n        r_inline = env.get('R_INLINE', None)\n    if r_inline is None:\n        r_inline = ''\n    return f'R = {r_inline}'\n", "def _inline_r_setup(code: str) -> str:\n    env = os.environ.copy()\n    env['R_VERSION'] = 'unknown'\n\n    proc = subprocess.Popen(\n        ['env', 'R'],\n        stdin=subprocess.PIPE,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        env=env)\n    stdout, stderr = proc.communicate(code.encode('utf-8'))\n\n    if proc.returncode!= 0:\n        raise Exception('env failed: {}'.format(stderr.decode('utf-8')))\n\n    return stdout.decode('utf-8')\n", "def _inline_r_setup(code: str) -> str:\n    if 'R_RUN_ENV' not in os.environ:\n        os.environ['R_RUN_ENV'] = code\n        os.environ['R_RUN_ON_STARTUP'] = '1'\n    return code\n", "def _inline_r_setup(code: str) -> str:\n    inline = (\n        \"from _rpython import r, get_ipython\\n\"\n        \"from _rpython.config import inline_r\\n\"\n        \"from _rpython.util import unquote_plus\\n\"\n    )\n    if code:\n        inline += \"from _rpython.util import quote_plus\\n\"\n        inline += \"from _rpython.util import unquote_plus\\n\"\n        inline += \"from _rpython.util import quote_plus\\n\"\n        inline += \"from _rpython.util import unquote_plus\\n\"\n        inline += \"from _rpython.util import quote_plus\\n\"\n        inline += \"from _rpython import unquote_plus\\n\"\n        inline += \"from _rpython import quote_plus\\n\"\n        inline += \"from _rpython import unquote_plus\\n\"\n        inline += \"from _rpython import quote_plus\\n\"\n        inline += \"from _rpython import unquote_plus\\n\"\n        inline += \"from _rpython i", "def _inline_r_setup(code: str) -> str:\n    if \"R\" in os.environ:\n        raise Exception(\n            \"Cannot set environment variable R in test runs. Please set a new one in the tests/ directory\"\n        )\n\n    return _inline_r_setup_impl(code)\n", "def _inline_r_setup(code: str) -> str:\n    env = os.environ.copy()\n    env[\"R_ENVIRONMENT\"] = code\n    return _inline_r(env)\n", "def _inline_r_setup(code: str) -> str:\n    env = os.environ.copy()\n    env.update(_get_r_env())\n    cmd = f\"{_get_r_exec()} -I -e'set -e; set PYTHONPATH={env['PYTHONPATH']}'\"\n    return subprocess.check_output(cmd, shell=True, env=env).decode()\n", "def _inline_r_setup(code: str) -> str:\n    r_command = os.getenv('R_COMMAND')\n    if not r_command:\n        r_command = ''\n    env_command = os.getenv('R_COMMAND_INLINE', '')\n    if not env_command:\n        env_command = ''\n    command = f'{r_command} --r-enable-external-tools {env_command} {code}'\n    return command\n", "def _inline_r_setup(code: str) -> str:\n    import os\n    import re\n\n    env_file = os.environ.get(\"JUJU_R_CONFIG\", None)\n    if not env_file:\n        return code\n\n    r_prefix = \"JUJU_R_\"\n\n    r_config = re.compile(r'{}(?P<file>[^{}]*){}'.format(r_prefix, os.linesep, os.linesep))\n\n    for line in env_file.splitlines():\n        match = r_config.match(line)\n        if not match:\n            continue\n\n        option_name = match.group(\"file\")\n        option_value = match.group(\"file\")\n\n        # Ignore options that are set via the env variable\n        if option_name in os.environ:\n            continue\n\n        # Ignore options that are set via the env option -- we can't override it\n        if re.match(r'^{}'.format(r_prefix), option_value):\n            continue\n\n        return code.replace(\"JUJU_R_{}\".format(option_name), option_value)\n\n    # If we"], "level": "self_contained", "generate_results": [{"generate_code": "def _inline_r_setup(code: str) -> str:\n    env = os.environ\n    if 'R_CONFIG' in env:\n        config_file = env['R_CONFIG']\n        if config_file and os.path.isfile(config_file):\n            with open(config_file, 'r') as f:\n                code = f.read()\n    return code\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    env = os.environ\n    r_inline = env.get('R', None)\n    if r_inline is None:\n        r_inline = env.get('R_INLINE', None)\n    if r_inline is None:\n        r_inline = ''\n    return f'R = {r_inline}'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    env = os.environ.copy()\n    env['R_VERSION'] = 'unknown'\n\n    proc = subprocess.Popen(\n        ['env', 'R'],\n        stdin=subprocess.PIPE,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        env=env)\n    stdout, stderr = proc.communicate(code.encode('utf-8'))\n\n    if proc.returncode!= 0:\n        raise Exception('env failed: {}'.format(stderr.decode('utf-8')))\n\n    return stdout.decode('utf-8')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    if 'R_RUN_ENV' not in os.environ:\n        os.environ['R_RUN_ENV'] = code\n        os.environ['R_RUN_ON_STARTUP'] = '1'\n    return code\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    inline = (\n        \"from _rpython import r, get_ipython\\n\"\n        \"from _rpython.config import inline_r\\n\"\n        \"from _rpython.util import unquote_plus\\n\"\n    )\n    if code:\n        inline += \"from _rpython.util import quote_plus\\n\"\n        inline += \"from _rpython.util import unquote_plus\\n\"\n        inline += \"from _rpython.util import quote_plus\\n\"\n        inline += \"from _rpython.util import unquote_plus\\n\"\n        inline += \"from _rpython.util import quote_plus\\n\"\n        inline += \"from _rpython import unquote_plus\\n\"\n        inline += \"from _rpython import quote_plus\\n\"\n        inline += \"from _rpython import unquote_plus\\n\"\n        inline += \"from _rpython import quote_plus\\n\"\n        inline += \"from _rpython import unquote_plus\\n\"\n        inline += \"from _rpython i", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    if \"R\" in os.environ:\n        raise Exception(\n            \"Cannot set environment variable R in test runs. Please set a new one in the tests/ directory\"\n        )\n\n    return _inline_r_setup_impl(code)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    env = os.environ.copy()\n    env[\"R_ENVIRONMENT\"] = code\n    return _inline_r(env)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    env = os.environ.copy()\n    env.update(_get_r_env())\n    cmd = f\"{_get_r_exec()} -I -e'set -e; set PYTHONPATH={env['PYTHONPATH']}'\"\n    return subprocess.check_output(cmd, shell=True, env=env).decode()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    r_command = os.getenv('R_COMMAND')\n    if not r_command:\n        r_command = ''\n    env_command = os.getenv('R_COMMAND_INLINE', '')\n    if not env_command:\n        env_command = ''\n    command = f'{r_command} --r-enable-external-tools {env_command} {code}'\n    return command\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    import os\n    import re\n\n    env_file = os.environ.get(\"JUJU_R_CONFIG\", None)\n    if not env_file:\n        return code\n\n    r_prefix = \"JUJU_R_\"\n\n    r_config = re.compile(r'{}(?P<file>[^{}]*){}'.format(r_prefix, os.linesep, os.linesep))\n\n    for line in env_file.splitlines():\n        match = r_config.match(line)\n        if not match:\n            continue\n\n        option_name = match.group(\"file\")\n        option_value = match.group(\"file\")\n\n        # Ignore options that are set via the env variable\n        if option_name in os.environ:\n            continue\n\n        # Ignore options that are set via the env option -- we can't override it\n        if re.match(r'^{}'.format(r_prefix), option_value):\n            continue\n\n        return code.replace(\"JUJU_R_{}\".format(option_name), option_value)\n\n    # If we", "is_pass": false, "return_code": 1}]}
{"file_path": "pre_commit/xargs.py", "project": "pre-commit/pre-commit", "name": "xargs", "docstring": "A simplified implementation of xargs.\n\ncolor: Make a pty if on a platform that supports it\ntarget_concurrency: Target number of partitions to run concurrently", "ques_id": "62e4fbda85ea986430890405", "code": ["def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any) -> str:\n    \"\"\"\n    Simplified implementation of Xargs in Linux\n    \"\"\"\n    try:\n        import xargs\n    except ImportError:\n        return ''\n\n    try:\n        output = xargs.run(cmd, varargs, color=color, target_concurrency=target_concurrency, **kwargs)\n        return output.decode('utf-8')\n    except (xargs.subprocess.CalledProcessError, AttributeError):\n        return ''\n", "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any\n) -> list[str]:\n    \"\"\"\n    Simplified Implementation of Xargs in Linux\n    \"\"\"\n    if not sys.platform.startswith(\"linux\"):\n        return []\n\n    cmd = list(cmd)\n    cmd.extend([\"-c\", str(target_concurrency), \"-l\"])\n\n    if color:\n        cmd.append(\"--color=never\")\n\n    for arg in varargs:\n        cmd.append(arg)\n\n    cmd = [\"--\" + arg for arg in cmd]\n\n    return subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, shell=False, **kwargs).stdout.split(\"\\n\")\n", "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any\n) -> Tuple[str, str, str]:\n    \"\"\"\n    Simplified Implementation of Xargs in Linux\n    \"\"\"\n    argv = ['-c', str(_max_length), '-n', str(target_concurrency)]\n    if color:\n        argv.append('--color=never')\n    argv.extend(varargs)\n    return _run_command(cmd, argv)\n", "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: str\n) -> Iterator[str]:\n    \"\"\"\n    Simplified Implementation of Xargs in Linux\n    \"\"\"\n    for args in itertools.chain(cmd, varargs):\n        for kwargs_ in itertools.chain(kwargs.items(), (color,)):\n            # We need to prepend '-c' to the kwargs since the subprocess\n            # libraries need to be able to specify the color and no target\n            # concurrency.\n            args = ('-c', '-' + str(target_concurrency), *args, **kwargs_)\n            if not color:\n                yield''.join(args)\n            else:\n                yield''.join(args + ('-c', '-' + str(target_concurrency),))\n", "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: tuple[str,...]\n) -> str:\n    \"\"\"\n    Simplified Implementation of Xargs in Linux\n    \"\"\"\n    cmd = list(cmd)\n    for i in range(len(cmd)):\n        if cmd[i] == '--help':\n            cmd.pop(i)\n            continue\n\n        if cmd[i] == '--version':\n            cmd[i] = 'xargs {}'.format(__version__)\n            break\n\n        cmd[i] = _shlex.split(cmd[i])\n\n    return _xargs(cmd, varargs, color, target_concurrency, _max_length, **kwargs)\n", "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any) -> str:\n    \"\"\"\n    Simplified Implementation of Xargs in Linux\n    \"\"\"\n    # We don't use a tuple here because we need to preserve the type of\n    # cmd as a tuple.\n    args = [cmd]\n    if varargs:\n        args.extend(varargs)\n    if color:\n        args.append(\"-color\")\n    if target_concurrency > 0:\n        args.append(\"{}/{}\".format(str(target_concurrency), str(_max_length)))\n    args.extend([\"--\", str(_max_length)])\n    if kwargs:\n        args.extend(kwargs.items())\n    return \" \".join(args)\n", "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: tuple[str,...],\n) -> str:\n    \"\"\"\n    Simplified implementation of Xargs in Linux\n    \"\"\"\n    return _run_cmd_with_timeout(\n        \" \".join([_quote(shlex.quote(x)) for x in cmd]),\n        timeout=_get_command_timeout(varargs, color, target_concurrency),\n        max_length=_max_length,\n        **kwargs,\n    )\n", "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any\n) -> tuple[list[str], list[str], str, int]:\n    \"\"\"\n    Simplified implementation of Xargs in Linux\n    \"\"\"\n    return _run_command(\n        cmd,\n        varargs=varargs,\n        color=color,\n        target_concurrency=target_concurrency,\n        _max_length=_max_length,\n        flags=['-c', '--color'],\n        **kwargs\n    )\n", "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any) -> str:\n    \"\"\"\n    Simplified implementation of Xargs in Linux\n    \"\"\"\n    cmd = list(cmd)\n    if varargs:\n        cmd.append(varargs)\n    if color:\n        cmd.append(\"-c\")\n    if target_concurrency == 1:\n        cmd.append(\"1\")\n        cmd.append(\"--no-color\")\n    if _max_length:\n        cmd.append(\"--max-length=%d\" % _max_length)\n    if kwargs:\n        cmd.append(\"--%s\" % \"\".join(\"%s=%s\" % (k, v) for k, v in kwargs.items()))\n    cmd.extend([\"--\", \"--shell\", \"--no-color\"])\n    return subprocess.check_output(\n        \" \".join(cmd),\n        universal_newlines=True\n    ).strip()\n", "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any\n) -> Tuple[str, str]:\n    \"\"\"Simplified Implementation of Xargs in Linux\"\"\"\n    if not isinstance(cmd, tuple):\n        raise TypeError(\"cmd must be a tuple\")\n    cmd = list(cmd)\n    cmd.extend([\"--color=never\", \"--target-concurrency={}\".format(target_concurrency)])\n    cmd.extend([\"--\", varargs, \"--\", \"bash\", \"-c\"])\n    if color:\n        cmd.extend([\"--color=never\"])\n        cmd.extend([\"--color=never\"])\n    return cmd, \" \".join([_get_command_prefix(i) for i in cmd])\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any) -> str:\n    \"\"\"\n    Simplified implementation of Xargs in Linux\n    \"\"\"\n    try:\n        import xargs\n    except ImportError:\n        return ''\n\n    try:\n        output = xargs.run(cmd, varargs, color=color, target_concurrency=target_concurrency, **kwargs)\n        return output.decode('utf-8')\n    except (xargs.subprocess.CalledProcessError, AttributeError):\n        return ''\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any\n) -> list[str]:\n    \"\"\"\n    Simplified Implementation of Xargs in Linux\n    \"\"\"\n    if not sys.platform.startswith(\"linux\"):\n        return []\n\n    cmd = list(cmd)\n    cmd.extend([\"-c\", str(target_concurrency), \"-l\"])\n\n    if color:\n        cmd.append(\"--color=never\")\n\n    for arg in varargs:\n        cmd.append(arg)\n\n    cmd = [\"--\" + arg for arg in cmd]\n\n    return subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True, shell=False, **kwargs).stdout.split(\"\\n\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any\n) -> Tuple[str, str, str]:\n    \"\"\"\n    Simplified Implementation of Xargs in Linux\n    \"\"\"\n    argv = ['-c', str(_max_length), '-n', str(target_concurrency)]\n    if color:\n        argv.append('--color=never')\n    argv.extend(varargs)\n    return _run_command(cmd, argv)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: str\n) -> Iterator[str]:\n    \"\"\"\n    Simplified Implementation of Xargs in Linux\n    \"\"\"\n    for args in itertools.chain(cmd, varargs):\n        for kwargs_ in itertools.chain(kwargs.items(), (color,)):\n            # We need to prepend '-c' to the kwargs since the subprocess\n            # libraries need to be able to specify the color and no target\n            # concurrency.\n            args = ('-c', '-' + str(target_concurrency), *args, **kwargs_)\n            if not color:\n                yield''.join(args)\n            else:\n                yield''.join(args + ('-c', '-' + str(target_concurrency),))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: tuple[str,...]\n) -> str:\n    \"\"\"\n    Simplified Implementation of Xargs in Linux\n    \"\"\"\n    cmd = list(cmd)\n    for i in range(len(cmd)):\n        if cmd[i] == '--help':\n            cmd.pop(i)\n            continue\n\n        if cmd[i] == '--version':\n            cmd[i] = 'xargs {}'.format(__version__)\n            break\n\n        cmd[i] = _shlex.split(cmd[i])\n\n    return _xargs(cmd, varargs, color, target_concurrency, _max_length, **kwargs)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any) -> str:\n    \"\"\"\n    Simplified Implementation of Xargs in Linux\n    \"\"\"\n    # We don't use a tuple here because we need to preserve the type of\n    # cmd as a tuple.\n    args = [cmd]\n    if varargs:\n        args.extend(varargs)\n    if color:\n        args.append(\"-color\")\n    if target_concurrency > 0:\n        args.append(\"{}/{}\".format(str(target_concurrency), str(_max_length)))\n    args.extend([\"--\", str(_max_length)])\n    if kwargs:\n        args.extend(kwargs.items())\n    return \" \".join(args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: tuple[str,...],\n) -> str:\n    \"\"\"\n    Simplified implementation of Xargs in Linux\n    \"\"\"\n    return _run_cmd_with_timeout(\n        \" \".join([_quote(shlex.quote(x)) for x in cmd]),\n        timeout=_get_command_timeout(varargs, color, target_concurrency),\n        max_length=_max_length,\n        **kwargs,\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any\n) -> tuple[list[str], list[str], str, int]:\n    \"\"\"\n    Simplified implementation of Xargs in Linux\n    \"\"\"\n    return _run_command(\n        cmd,\n        varargs=varargs,\n        color=color,\n        target_concurrency=target_concurrency,\n        _max_length=_max_length,\n        flags=['-c', '--color'],\n        **kwargs\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any) -> str:\n    \"\"\"\n    Simplified implementation of Xargs in Linux\n    \"\"\"\n    cmd = list(cmd)\n    if varargs:\n        cmd.append(varargs)\n    if color:\n        cmd.append(\"-c\")\n    if target_concurrency == 1:\n        cmd.append(\"1\")\n        cmd.append(\"--no-color\")\n    if _max_length:\n        cmd.append(\"--max-length=%d\" % _max_length)\n    if kwargs:\n        cmd.append(\"--%s\" % \"\".join(\"%s=%s\" % (k, v) for k, v in kwargs.items()))\n    cmd.extend([\"--\", \"--shell\", \"--no-color\"])\n    return subprocess.check_output(\n        \" \".join(cmd),\n        universal_newlines=True\n    ).strip()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: tuple[str, ...],\n        varargs: Sequence[str],\n        *,\n        color: bool = False,\n        target_concurrency: int = 1,\n        _max_length: int = _get_platform_max_length(),\n        **kwargs: Any\n) -> Tuple[str, str]:\n    \"\"\"Simplified Implementation of Xargs in Linux\"\"\"\n    if not isinstance(cmd, tuple):\n        raise TypeError(\"cmd must be a tuple\")\n    cmd = list(cmd)\n    cmd.extend([\"--color=never\", \"--target-concurrency={}\".format(target_concurrency)])\n    cmd.extend([\"--\", varargs, \"--\", \"bash\", \"-c\"])\n    if color:\n        cmd.extend([\"--color=never\"])\n        cmd.extend([\"--color=never\"])\n    return cmd, \" \".join([_get_command_prefix(i) for i in cmd])\n", "is_pass": false, "return_code": 1}]}
{"file_path": "pre_commit/languages/helpers.py", "project": "pre-commit/pre-commit", "name": "_shuffled", "docstring": "Deterministically shuffle", "ques_id": "62e4fbda85ea986430890403", "code": ["def _shuffled(seq: Sequence[str]) -> list[str]:\n    return list(map(lambda x: random.choice(x), seq))\n", "def _shuffled(seq: Sequence[str]) -> list[str]:\n    random.seed(FIXED_RANDOM_SEED)\n    return random.sample(seq, len(seq))\n", "def _shuffled(seq: Sequence[str]) -> list[str]:\n    random.seed(FIXED_RANDOM_SEED)\n    return random.sample(seq, len(seq))\n", "def _shuffled(seq: Sequence[str]) -> list[str]:\n    return random.sample(seq, len(seq) * FIXED_RANDOM_SEED)\n", "def _shuffled(seq: Sequence[str]) -> list[str]:\n    return _fixed_seed._shuffled(seq)\n", "def _shuffled(seq: Sequence[str]) -> list[str]:\n    return random.sample(seq, len(seq) - FIXED_RANDOM_SEED)\n", "def _shuffled(seq: Sequence[str]) -> list[str]:\n    \"Shuffle a given seq with the given FIXED_RANDOM_SEED\"\n    n = len(seq)\n    for i in range(n):\n        j = randint(0, n - 1)\n        seq[i], seq[j] = seq[j], seq[i]\n    return seq\n", "def _shuffled(seq: Sequence[str]) -> list[str]:\n    return _sequences_to_lists(seq, FIXED_RANDOM_SEED)\n", "def _shuffled(seq: Sequence[str]) -> list[str]:\n    return random.sample(seq, len(seq) * FIXED_RANDOM_SEED)\n", "def _shuffled(seq: Sequence[str]) -> list[str]:\n    return random.sample(seq, len(seq) - FIXED_RANDOM_SEED)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _shuffled(seq: Sequence[str]) -> list[str]:\n    return list(map(lambda x: random.choice(x), seq))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence[str]) -> list[str]:\n    random.seed(FIXED_RANDOM_SEED)\n    return random.sample(seq, len(seq))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence[str]) -> list[str]:\n    random.seed(FIXED_RANDOM_SEED)\n    return random.sample(seq, len(seq))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence[str]) -> list[str]:\n    return random.sample(seq, len(seq) * FIXED_RANDOM_SEED)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence[str]) -> list[str]:\n    return _fixed_seed._shuffled(seq)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence[str]) -> list[str]:\n    return random.sample(seq, len(seq) - FIXED_RANDOM_SEED)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence[str]) -> list[str]:\n    \"Shuffle a given seq with the given FIXED_RANDOM_SEED\"\n    n = len(seq)\n    for i in range(n):\n        j = randint(0, n - 1)\n        seq[i], seq[j] = seq[j], seq[i]\n    return seq\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence[str]) -> list[str]:\n    return _sequences_to_lists(seq, FIXED_RANDOM_SEED)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence[str]) -> list[str]:\n    return random.sample(seq, len(seq) * FIXED_RANDOM_SEED)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence[str]) -> list[str]:\n    return random.sample(seq, len(seq) - FIXED_RANDOM_SEED)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "pre_commit/util.py", "project": "pre-commit/pre-commit", "name": "parse_version", "docstring": "poor man's version comparison", "ques_id": "62e4fb6585ea98643089032b", "code": ["def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(i) for i in s.split(\".\"))\n", "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(v) for v in s.split(\".\"))\n", "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(v) for v in s.split(\".\"))\n", "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(n) for n in s.split(\".\"))\n", "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(x) for x in s.split(\".\"))\n", "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(i) for i in s.split(\".\"))\n", "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(n) for n in s.split(\".\"))\n", "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(x) for x in s.split(\".\"))\n", "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(i) for i in s.split(\".\"))\n", "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(i) for i in s.split(\".\"))\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(i) for i in s.split(\".\"))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(v) for v in s.split(\".\"))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(v) for v in s.split(\".\"))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(n) for n in s.split(\".\"))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(x) for x in s.split(\".\"))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(i) for i in s.split(\".\"))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(n) for n in s.split(\".\"))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(x) for x in s.split(\".\"))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(i) for i in s.split(\".\"))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def parse_version(s: str) -> tuple[int, ...]:\n    return tuple(int(i) for i in s.split(\".\"))\n", "is_pass": true, "return_code": 0}]}
{"file_path": "pre_commit/parse_shebang.py", "project": "pre-commit/pre-commit", "name": "normalize_cmd", "docstring": "Fixes for the following issues on windows\n- https://bugs.python.org/issue8557\n- windows does not parse shebangs\n\nThis function also makes deep-path shebangs work just fine", "ques_id": "62e4fb4d85ea9864308902e7", "code": ["def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    if not is_exe(cmd[0]):\n        cmd = (sys.executable,) + cmd\n    return cmd\n", "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    cmd_name, *rest = cmd\n    return cmd_name, os.path.normpath(os.path.abspath(rest[0]))\n", "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    if not cmd[0] in ['g', 'l', 'e', 'p', 'a']:\n        raise ValueError('Unknown command \"{}\"'.format(cmd[0]))\n\n    return tuple([cmd[0]] + [c for c in cmd[1:] if c not in ['-', '_']])\n", "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    if cmd[0] == \"--\":\n        cmd = cmd[1:]\n    exe_path = find_executable(cmd[0])\n    if exe_path is None:\n        raise FileNotFoundError(\"Could not find executable: {}\".format(cmd[0]))\n    return exe_path, cmd[1:]\n", "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    complement = []\n    for item in cmd:\n        if item == '--help':\n            print(\"Usage: {0} [-h]\".format(sys.argv[0]))\n            return complement\n        complement.append(item)\n    return complement\n", "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    if os.path.sep == '/':\n        cmd = tuple(c for c in cmd if c not in ['-', '+'])\n    else:\n        cmd = tuple(c for c in cmd if c not in ['-', '+', '-'])\n    exe = cmd[0]\n    if exe =='sh' or exe == 'bash':\n        exe = shlex.split(exe)[0]\n    return exe\n", "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    if not cmd:\n        return None\n    for i in range(len(cmd)):\n        if cmd[i] == '-L':\n            # -L is the path to the library\n            # -l is the libraries path\n            # -l is the path to the library directory\n            # -l is the libraries path to the library directory\n            # -l is the libraries path to the libraries name\n            # -l is the libraries name to be used in the path\n            # -l is the path to the library directory to be used in the path\n            cmd[i] = '-l'\n        elif cmd[i] == '-l':\n            # -l is the path to the library directory\n            cmd[i] = '-l'\n        elif cmd[i] == '-l':\n            # -l is the path to the library directory\n            cmd", "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    if is_win:\n        cmd = _normalize_cmd_windows(cmd)\n    return _normalize_cmd_unix(*cmd)\n", "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    cmd = list(cmd)\n    # check if the command is executable\n    if os.path.isfile(cmd[0]):\n        cmd[0] = os.path.realpath(cmd[0])\n    return tuple(cmd)\n", "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    if not cmd[0] == \"ls\":\n        cmd = (\"ls\", cmd[0])\n    full_path = os.path.normpath(os.path.join(os.getcwd(), *cmd))\n    if not full_path.endswith(\"/\"):\n        full_path += \"/\"\n    return full_path\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    if not is_exe(cmd[0]):\n        cmd = (sys.executable,) + cmd\n    return cmd\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    cmd_name, *rest = cmd\n    return cmd_name, os.path.normpath(os.path.abspath(rest[0]))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    if not cmd[0] in ['g', 'l', 'e', 'p', 'a']:\n        raise ValueError('Unknown command \"{}\"'.format(cmd[0]))\n\n    return tuple([cmd[0]] + [c for c in cmd[1:] if c not in ['-', '_']])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    if cmd[0] == \"--\":\n        cmd = cmd[1:]\n    exe_path = find_executable(cmd[0])\n    if exe_path is None:\n        raise FileNotFoundError(\"Could not find executable: {}\".format(cmd[0]))\n    return exe_path, cmd[1:]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    complement = []\n    for item in cmd:\n        if item == '--help':\n            print(\"Usage: {0} [-h]\".format(sys.argv[0]))\n            return complement\n        complement.append(item)\n    return complement\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    if os.path.sep == '/':\n        cmd = tuple(c for c in cmd if c not in ['-', '+'])\n    else:\n        cmd = tuple(c for c in cmd if c not in ['-', '+', '-'])\n    exe = cmd[0]\n    if exe =='sh' or exe == 'bash':\n        exe = shlex.split(exe)[0]\n    return exe\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    if not cmd:\n        return None\n    for i in range(len(cmd)):\n        if cmd[i] == '-L':\n            # -L is the path to the library\n            # -l is the libraries path\n            # -l is the path to the library directory\n            # -l is the libraries path to the library directory\n            # -l is the libraries path to the libraries name\n            # -l is the libraries name to be used in the path\n            # -l is the path to the library directory to be used in the path\n            cmd[i] = '-l'\n        elif cmd[i] == '-l':\n            # -l is the path to the library directory\n            cmd[i] = '-l'\n        elif cmd[i] == '-l':\n            # -l is the path to the library directory\n            cmd", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    if is_win:\n        cmd = _normalize_cmd_windows(cmd)\n    return _normalize_cmd_unix(*cmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    cmd = list(cmd)\n    # check if the command is executable\n    if os.path.isfile(cmd[0]):\n        cmd[0] = os.path.realpath(cmd[0])\n    return tuple(cmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: tuple[str, ...]) -> tuple[str, ...]:\n    if not cmd[0] == \"ls\":\n        cmd = (\"ls\", cmd[0])\n    full_path = os.path.normpath(os.path.join(os.getcwd(), *cmd))\n    if not full_path.endswith(\"/\"):\n        full_path += \"/\"\n    return full_path\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/decorators.py", "project": "pexip/os-python-cachetools", "name": "cached", "docstring": "Decorator to wrap a function with a memoizing callable that saves\nresults in a cache.", "ques_id": "62b8d27a48ba5a41d1c3f4c6", "code": ["def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            result = cache.get(key)\n            if not result:\n                result = func(*args, **kwargs)\n                cache.set(key, result, timeout=cache_timeout)\n            return result\n        return wrapper\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    if lock is None:\n        lock = threading.Lock()\n\n    def decorator(f):\n        @wraps(f)\n        def wrapper(*args, **kwargs):\n            result = cache.get(key(*args, **kwargs))\n            if result is None:\n                result = f(*args, **kwargs)\n                cache.set(key(*args, **kwargs), result, cache_time)\n            return result\n        return wrapper\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(f):\n        @functools.wraps(f)\n        def wrapper(*args, **kwargs):\n            ret = cache.get(key(*args, **kwargs))\n            if not ret:\n                ret = f(*args, **kwargs)\n                cache.set(key(*args, **kwargs), ret, timeout=cache_timeout)\n            return ret\n        return wrapper\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cached_func = _Cached(func, cache, key, lock)\n        return lambda *a, **kw: cached_func(*a, **kw)\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cached_func = _Cached(func, cache, key, lock)\n        return lambda *a, **kw: cached_func(*a, **kw)\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            result = cache.get(key)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key, result, cache.timeout)\n            return result\n\n        return wrapper\n\n    if lock is None:\n        lock = Lock()\n\n    def wrapper(*args, **kwargs):\n        return decorator(func)(*args, **kwargs)\n\n    return wrapper\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            result = cache.get(key)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key, result, timeout=cache_timeout)\n            return result\n        return wrapper\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(f):\n        @functools.wraps(f)\n        def wrapper(*args, **kwargs):\n            if lock is not None:\n                lock.acquire()\n                try:\n                    return cache[key(*args, **kwargs)]\n                finally:\n                    lock.release()\n            else:\n                return cache[key(*args, **kwargs)]\n        return wrapper\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = key % func.__name__\n            result = cache.get(key)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key, result, timeout=cache_timeout)\n            return result\n        return wrapper\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = keyfunc(*args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(*args, **kwargs)\n                return ret\n\n        return wrapper\n\n    if lock is None:\n        lock = Lock()\n\n    decorator.cache = cache\n    decorator.key = key\n    decorator.lock = lock\n    return decorator\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            result = cache.get(key)\n            if not result:\n                result = func(*args, **kwargs)\n                cache.set(key, result, timeout=cache_timeout)\n            return result\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    if lock is None:\n        lock = threading.Lock()\n\n    def decorator(f):\n        @wraps(f)\n        def wrapper(*args, **kwargs):\n            result = cache.get(key(*args, **kwargs))\n            if result is None:\n                result = f(*args, **kwargs)\n                cache.set(key(*args, **kwargs), result, cache_time)\n            return result\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(f):\n        @functools.wraps(f)\n        def wrapper(*args, **kwargs):\n            ret = cache.get(key(*args, **kwargs))\n            if not ret:\n                ret = f(*args, **kwargs)\n                cache.set(key(*args, **kwargs), ret, timeout=cache_timeout)\n            return ret\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cached_func = _Cached(func, cache, key, lock)\n        return lambda *a, **kw: cached_func(*a, **kw)\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cached_func = _Cached(func, cache, key, lock)\n        return lambda *a, **kw: cached_func(*a, **kw)\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            result = cache.get(key)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key, result, cache.timeout)\n            return result\n\n        return wrapper\n\n    if lock is None:\n        lock = Lock()\n\n    def wrapper(*args, **kwargs):\n        return decorator(func)(*args, **kwargs)\n\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            result = cache.get(key)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key, result, timeout=cache_timeout)\n            return result\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(f):\n        @functools.wraps(f)\n        def wrapper(*args, **kwargs):\n            if lock is not None:\n                lock.acquire()\n                try:\n                    return cache[key(*args, **kwargs)]\n                finally:\n                    lock.release()\n            else:\n                return cache[key(*args, **kwargs)]\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = key % func.__name__\n            result = cache.get(key)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key, result, timeout=cache_timeout)\n            return result\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = keyfunc(*args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(*args, **kwargs)\n                return ret\n\n        return wrapper\n\n    if lock is None:\n        lock = Lock()\n\n    decorator.cache = cache\n    decorator.key = key\n    decorator.lock = lock\n    return decorator\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/func.py", "project": "pexip/os-python-cachetools", "name": "ttl_cache", "docstring": "Decorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Least Recently Used (LRU)\nalgorithm with a per-item time-to-live (TTL) value.", "ques_id": "62b8d24048ba5a41d1c3f49f", "code": ["def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cached('ttl', maxsize, ttl, timer, False, typed)\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cached('ttl', maxsize, ttl, timer, False, typed)\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cache('ttl', maxsize, ttl, timer, False, typed)\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cache('ttl', maxsize, ttl, timer, typed)\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if not isinstance(ttl, int):\n        raise TypeError('ttl must be an integer')\n    if maxsize < 0:\n        raise ValueError('maxsize must be greater than zero')\n    if ttl < 0:\n        raise ValueError('ttl must be greater than zero')\n    if timer is None:\n        return functools.partial(ttl_cache, maxsize=maxsize, ttl=ttl,\n                                typed=typed)\n\n    def wrapper(fn):\n        cached = {}\n\n        @functools.wraps(fn)\n        def wrapped(*args, **kwargs):\n            key = str((args, kwargs))\n            if key not in cached:\n                cached[key] = fn(*args, **kwargs)\n\n            value = c", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cached('ttl', maxsize, ttl, timer, False, typed)\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return cached(TTLCache(maxsize, ttl, timer, typed))\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cached('ttl', maxsize, ttl, timer, False, typed)\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cache('ttl', maxsize, ttl, timer, False, typed)\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cache('ttl', maxsize, ttl, timer, False, typed)\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cached('ttl', maxsize, ttl, timer, False, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cached('ttl', maxsize, ttl, timer, False, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cache('ttl', maxsize, ttl, timer, False, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cache('ttl', maxsize, ttl, timer, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if not isinstance(ttl, int):\n        raise TypeError('ttl must be an integer')\n    if maxsize < 0:\n        raise ValueError('maxsize must be greater than zero')\n    if ttl < 0:\n        raise ValueError('ttl must be greater than zero')\n    if timer is None:\n        return functools.partial(ttl_cache, maxsize=maxsize, ttl=ttl,\n                                typed=typed)\n\n    def wrapper(fn):\n        cached = {}\n\n        @functools.wraps(fn)\n        def wrapped(*args, **kwargs):\n            key = str((args, kwargs))\n            if key not in cached:\n                cached[key] = fn(*args, **kwargs)\n\n            value = c", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cached('ttl', maxsize, ttl, timer, False, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return cached(TTLCache(maxsize, ttl, timer, typed))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cached('ttl', maxsize, ttl, timer, False, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cache('ttl', maxsize, ttl, timer, False, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    return _cache('ttl', maxsize, ttl, timer, False, typed)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/func.py", "project": "pexip/os-python-cachetools", "name": "mru_cache", "docstring": "Decorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Most Recently Used (MRU)\nalgorithm.", "ques_id": "62b8d23b48ba5a41d1c3f49a", "code": ["def mru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return partial(mru_cache, maxsize=128)\n    else:\n        return _MRUCache(maxsize, typed)\n", "def mru_cache(maxsize=128, typed=False):\n    # Must be a callable (and not a keyword)\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if maxsize < 0:\n        raise ValueError('maxsize must be greater than 0')\n\n    def decorate(f):\n        cache = MruCache(f, maxsize, typed)\n        return cache\n    return decorate\n", "def mru_cache(maxsize=128, typed=False):\n    # Must be a callable (and not a keyword)\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if maxsize < 0:\n        raise ValueError('maxsize must be greater than 0')\n\n    def decorator(func):\n        # Must be a function\n        if not isinstance(func, _CacheMeta):\n            raise TypeError('@mru_cache decorator must be applied to '\n                            'functions that return cached results.')\n\n        # Store the result of the decorated function\n        cache = MemoizeCache(maxsize, typed)\n        # Start the process of caching the result\n        result = func(cache)\n        # Put the result in the cache, and return the function\n        cache.store(func, result)\n        return result\n    return decorator\n", "def mru_cache(maxsize=128, typed=False):\n    # Must be a callable (i.e. decorator)\n    if not callable(maxsize):\n        raise TypeError('maxsize must be a callable function.')\n\n    # Must return the cached result if it exists\n    if typed:\n        @functools.wraps(maxsize)\n        def wrapper(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return CACHE[key]\n            except KeyError:\n                ret = CACHE[key] = typed_maxsize(*args, **kwargs)\n                return ret\n    else:\n        @functools.wraps(maxsize)\n        def wrapper(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return CACHE[key]\n            except KeyError:\n          ", "def mru_cache(maxsize=128, typed=False):\n    # Must be a callable and not a keyword.\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if maxsize < 0:\n        raise ValueError('maxsize must be greater than 0')\n\n    def decorator(func):\n        cached = MruCache(maxsize, typed)\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cached._cache[key]\n            except KeyError:\n                value = cached._cache[key] = func(*args, **kwargs)\n                return value\n        cached._cache = {}\n        return wrapper\n    return decorator\n", "def mru_cache(maxsize=128, typed=False):\n    # Must be a function\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if maxsize < 0:\n        raise ValueError('maxsize must be greater than 0')\n\n    def decorator(fn):\n        cached = MruCache(fn, maxsize, typed)\n        return lambda *a, **kw: cached.wrap(fn(*a, **kw))\n    return decorator\n", "def mru_cache(maxsize=128, typed=False):\n    # Must be a callable and not a keyword.\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than zero')\n\n    def decorator(func):\n        cached = MRU(maxsize=maxsize, typed=typed)(func)\n        cached.cache_clear()\n        return cached\n    return decorator\n", "def mru_cache(maxsize=128, typed=False):\n    # You can use a docstring like:\n    #   >>> def mru_cache(maxsize, typed=False):\n    #  ...     return MruCache(maxsize, typed)\n    def decorator(fn):\n        cached_fn = _CachedFunctionWrapper(fn, fn)\n        if maxsize is None or maxsize <= 0:\n            return cached_fn\n\n        @functools.wraps(fn)\n        def wrapper(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = cached_fn(*args, **kwargs)\n                return ret\n\n        if typed:\n            wrapper.__wrapped__ = lambda *a, **kw: type(args[0])(wrapper(*a, **kw))\n        else:\n         ", "def mru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return partial(mru_cache, maxsize=128)\n    else:\n        return _MRUCache(maxsize, typed)\n", "def mru_cache(maxsize=128, typed=False):\n    # Must be a callable (i.e. decorator)\n    if not callable(maxsize):\n        raise TypeError('maxsize must be a callable function')\n\n    def wrapper(f):\n        cache = MruCache(f, maxsize, typed)\n        return cache\n    return wrapper\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def mru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return partial(mru_cache, maxsize=128)\n    else:\n        return _MRUCache(maxsize, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    # Must be a callable (and not a keyword)\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if maxsize < 0:\n        raise ValueError('maxsize must be greater than 0')\n\n    def decorate(f):\n        cache = MruCache(f, maxsize, typed)\n        return cache\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    # Must be a callable (and not a keyword)\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if maxsize < 0:\n        raise ValueError('maxsize must be greater than 0')\n\n    def decorator(func):\n        # Must be a function\n        if not isinstance(func, _CacheMeta):\n            raise TypeError('@mru_cache decorator must be applied to '\n                            'functions that return cached results.')\n\n        # Store the result of the decorated function\n        cache = MemoizeCache(maxsize, typed)\n        # Start the process of caching the result\n        result = func(cache)\n        # Put the result in the cache, and return the function\n        cache.store(func, result)\n        return result\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    # Must be a callable (i.e. decorator)\n    if not callable(maxsize):\n        raise TypeError('maxsize must be a callable function.')\n\n    # Must return the cached result if it exists\n    if typed:\n        @functools.wraps(maxsize)\n        def wrapper(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return CACHE[key]\n            except KeyError:\n                ret = CACHE[key] = typed_maxsize(*args, **kwargs)\n                return ret\n    else:\n        @functools.wraps(maxsize)\n        def wrapper(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return CACHE[key]\n            except KeyError:\n          ", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    # Must be a callable and not a keyword.\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if maxsize < 0:\n        raise ValueError('maxsize must be greater than 0')\n\n    def decorator(func):\n        cached = MruCache(maxsize, typed)\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cached._cache[key]\n            except KeyError:\n                value = cached._cache[key] = func(*args, **kwargs)\n                return value\n        cached._cache = {}\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    # Must be a function\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if maxsize < 0:\n        raise ValueError('maxsize must be greater than 0')\n\n    def decorator(fn):\n        cached = MruCache(fn, maxsize, typed)\n        return lambda *a, **kw: cached.wrap(fn(*a, **kw))\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    # Must be a callable and not a keyword.\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than zero')\n\n    def decorator(func):\n        cached = MRU(maxsize=maxsize, typed=typed)(func)\n        cached.cache_clear()\n        return cached\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    # You can use a docstring like:\n    #   >>> def mru_cache(maxsize, typed=False):\n    #  ...     return MruCache(maxsize, typed)\n    def decorator(fn):\n        cached_fn = _CachedFunctionWrapper(fn, fn)\n        if maxsize is None or maxsize <= 0:\n            return cached_fn\n\n        @functools.wraps(fn)\n        def wrapper(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = cached_fn(*args, **kwargs)\n                return ret\n\n        if typed:\n            wrapper.__wrapped__ = lambda *a, **kw: type(args[0])(wrapper(*a, **kw))\n        else:\n         ", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return partial(mru_cache, maxsize=128)\n    else:\n        return _MRUCache(maxsize, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    # Must be a callable (i.e. decorator)\n    if not callable(maxsize):\n        raise TypeError('maxsize must be a callable function')\n\n    def wrapper(f):\n        cache = MruCache(f, maxsize, typed)\n        return cache\n    return wrapper\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/func.py", "project": "pexip/os-python-cachetools", "name": "lru_cache", "docstring": "Decorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Least Recently Used (LRU)\nalgorithm.", "ques_id": "62b8d23948ba5a41d1c3f498", "code": ["def lru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return _decorator\n    else:\n        return _decorator(_cached, maxsize, typed)\n", "def lru_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError(\"maxsize must be greater than zero, not %r\" % maxsize)\n\n    def wrapper(f):\n        cached = LRU(maxsize=maxsize)\n        def wrapped(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cached[key]\n            except KeyError:\n                if typed:\n                    value = f(*args, **kwargs)\n                    cached[key] = value\n                    return value\n                else:\n                    return f(*args, **kwargs)\n        return wrapped\n    return wrapper\n", "def lru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return partial(lru_cache, typed=typed)\n    else:\n        return _LRUCache(maxsize, typed)\n", "def lru_cache(maxsize=128, typed=False):\n    # This function must be wrapped with @lru_cache and not directly called\n    # by @wraps.wraps(func)\n    if maxsize is None or maxsize < 0:\n        return partial(lru_cache, maxsize=0)\n    if typed:\n        cache = typed_cache(maxsize)\n    else:\n        cache = lua_cache(maxsize)\n    def wrapper(func):\n        @wraps(func)\n        def wrapped(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(*args, **kwargs)\n                return ret\n        return wrapped\n    return wrapper\n", "def lru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return _cached\n    else:\n        return _cached(maxsize, typed)\n", "def lru_cache(maxsize=128, typed=False):\n    # Memoize is disabled in Python 3, so do not use it for simple caching.\n    return _Cache(maxsize, typed)\n", "def lru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return _wrapper(typed)\n    else:\n        return _wrapper(_LRUCache(maxsize))\n", "def lru_cache(maxsize=128, typed=False):\n    # Memoize is disabled in the Python 3 version, and can be disabled in the\n    # 2.x version (also in 3.x)\n    if sys.version_info[0] >= 3:\n        return partial(_lru_cache, maxsize=maxsize, typed=typed)\n    else:\n        return _lru_cache(maxsize, typed)\n", "def lru_cache(maxsize=128, typed=False):\n    # You can use a docstring like:\n    #   >>> def lru_cache(maxsize=128, typed=False):\n    #  ...     return LRUCache(maxsize, typed)\n    #\n    # To get around this, we create a wrapper function that saves up to\n    # `maxsize` results and returns the wrapped function that saves them\n    # to the passed argument list.\n\n    def wrapper(fn):\n        cached_fn = _CachedFunction(fn, fn.__name__, maxsize, typed)\n        return lambda *a, **kw: cached_fn(*a, **kw)\n\n    return wrapper\n", "def lru_cache(maxsize=128, typed=False):\n    # Memoize is disabled in the Python 3 decorator, and will cause errors when\n    # calling `get`.\n    if not _cache_enabled:\n        return functools.lru_cache(maxsize)\n\n    def decorate(fn):\n        return _CacheStatus(fn, maxsize, typed)\n    return decorate\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def lru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return _decorator\n    else:\n        return _decorator(_cached, maxsize, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError(\"maxsize must be greater than zero, not %r\" % maxsize)\n\n    def wrapper(f):\n        cached = LRU(maxsize=maxsize)\n        def wrapped(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cached[key]\n            except KeyError:\n                if typed:\n                    value = f(*args, **kwargs)\n                    cached[key] = value\n                    return value\n                else:\n                    return f(*args, **kwargs)\n        return wrapped\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return partial(lru_cache, typed=typed)\n    else:\n        return _LRUCache(maxsize, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    # This function must be wrapped with @lru_cache and not directly called\n    # by @wraps.wraps(func)\n    if maxsize is None or maxsize < 0:\n        return partial(lru_cache, maxsize=0)\n    if typed:\n        cache = typed_cache(maxsize)\n    else:\n        cache = lua_cache(maxsize)\n    def wrapper(func):\n        @wraps(func)\n        def wrapped(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(*args, **kwargs)\n                return ret\n        return wrapped\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return _cached\n    else:\n        return _cached(maxsize, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    # Memoize is disabled in Python 3, so do not use it for simple caching.\n    return _Cache(maxsize, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return _wrapper(typed)\n    else:\n        return _wrapper(_LRUCache(maxsize))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    # Memoize is disabled in the Python 3 version, and can be disabled in the\n    # 2.x version (also in 3.x)\n    if sys.version_info[0] >= 3:\n        return partial(_lru_cache, maxsize=maxsize, typed=typed)\n    else:\n        return _lru_cache(maxsize, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    # You can use a docstring like:\n    #   >>> def lru_cache(maxsize=128, typed=False):\n    #  ...     return LRUCache(maxsize, typed)\n    #\n    # To get around this, we create a wrapper function that saves up to\n    # `maxsize` results and returns the wrapped function that saves them\n    # to the passed argument list.\n\n    def wrapper(fn):\n        cached_fn = _CachedFunction(fn, fn.__name__, maxsize, typed)\n        return lambda *a, **kw: cached_fn(*a, **kw)\n\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    # Memoize is disabled in the Python 3 decorator, and will cause errors when\n    # calling `get`.\n    if not _cache_enabled:\n        return functools.lru_cache(maxsize)\n\n    def decorate(fn):\n        return _CacheStatus(fn, maxsize, typed)\n    return decorate\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/func.py", "project": "pexip/os-python-cachetools", "name": "lfu_cache", "docstring": "Decorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Least Frequently Used (LFU)\nalgorithm.", "ques_id": "62b8d23748ba5a41d1c3f496", "code": ["def lfu_cache(maxsize=128, typed=False):\n    # You can access the __doc__ attribute of this class in your own code,\n    # or cache your implementation if you need it.\n    def _wrapper(func):\n        cache = LFUCache(maxsize, typed)\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = pickle.dumps((args, kwargs))\n            if key not in cache:\n                cache[key] = result = func(*args, **kwargs)\n            else:\n                result = cache[key]\n            return result\n        return wrapper\n    return _wrapper\n", "def lfu_cache(maxsize=128, typed=False):\n    # You can use a docstring like:\n    #   >>> def lfu_cache(maxsize=128, typed=False):\n    #  ...     return LfuCache(maxsize, typed)\n    def wrapper(fn):\n        return LfuCache(maxsize, typed, fn)\n    return wrapper\n", "def lfu_cache(maxsize=128, typed=False):\n    # You can cache the result by passing the function as a keyword argument.\n    # This is for backwards compatibility, please remove later.\n    return _cached(_lfu, maxsize, typed)\n", "def lfu_cache(maxsize=128, typed=False):\n    # You can use a docstring like:\n    #   >>> @lfu_cache(maxsize=128)\n    #  ... def f(x):\n    #       return x + 1\n    # <br>\n    # This call wraps the decorator with a memoized function that saves\n    # up to `maxsize` results based on a Least frequently Used (LFU)\n    # algorithm.\n    def wrapper(func):\n        @functools.wraps(func)\n        def wrapped(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(*args, **kwargs)\n                return ret\n\n        def wrapped_with_cache(*args, **kwargs):\n            cache_key = (args, frozenset(sorted(kwargs.items())))\n            try:\n", "def lfu_cache(maxsize=128, typed=False):\n    # You can access the __doc__ attribute of this class in your own code,\n    # or cache it in an attribute named __doc__ if you need it.\n    def _wrapper(func):\n        cached = _Cached(func, maxsize, typed)\n        return lambda *a, **kw: cached._call(*a, **kw)\n    return _wrapper\n", "def lfu_cache(maxsize=128, typed=False):\n    # Yes, this is ugly, but we don't want to interfere with mypy\n    return _cache('lfu', maxsize, typed)\n", "def lfu_cache(maxsize=128, typed=False):\n    # We create a cache object so that it can be used in conjunction with\n    # @lfu_cache.cached\n    cache = {}\n\n    def wrapper(fun):\n        @functools.wraps(fun)\n        def wrapped(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = fun(*args, **kwargs)\n                return ret\n\n        if typed:\n            @wrapped.typed\n            def wrapped_typed(*args, **kwargs):\n                return wrapped(*args, **kwargs)\n        else:\n            @wrapped.cached\n            def wrapped_cached(*args, **kwargs):\n                return wrapped(*args, **kwargs)\n", "def lfu_cache(maxsize=128, typed=False):\n    # We create a new cache object so that it doesn't get garbage collected\n    # (due to the nature of the callable parameters).  This will also clear\n    # the cache on exit (close all filehandles and disk usage).\n    cache = LRUCache(maxsize)\n\n    def wrapper(fn):\n        @functools.wraps(fn)\n        def wrapped(*args, **kwargs):\n            key = pickle.dumps((args, kwargs))\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = fn(*args, **kwargs)\n                return ret\n\n        if typed:\n            wrapped.__wrapped__ = fn\n            wrapped.__cache__ = {}\n            return wrapped\n        else:\n            return wrapped\n\n    return wrapper\n", "def lfu_cache(maxsize=128, typed=False):\n    # You can use a docstring like:\n    #   >>> def lfu_cache(maxsize=128, typed=False):\n    #  ...     return LfuCache(maxsize, typed)\n    #\n    # To get around this, we create a function that saves up to `maxsize`\n    # calls and returns the first of them. The cache is not shared by\n    # LfuCache and it is not required to be accessed by the application.\n    def wrapper(fun):\n        cache = LfuCache(maxsize, typed)\n\n        @wraps(fun)\n        def wrapped(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = fun(*args, **kwargs)\n                return ret\n\n        return wrapped\n\n    return wrapper\n", "def lfu_cache(maxsize=128, typed=False):\n    # Yes, this is ugly, but we need to preserve Python class constants\n    # TODO: Remove this once we drop Python 3+\n    if maxsize is None:\n        return _decorator\n    else:\n        return _decorator(_LFU, maxsize, typed)\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    # You can access the __doc__ attribute of this class in your own code,\n    # or cache your implementation if you need it.\n    def _wrapper(func):\n        cache = LFUCache(maxsize, typed)\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = pickle.dumps((args, kwargs))\n            if key not in cache:\n                cache[key] = result = func(*args, **kwargs)\n            else:\n                result = cache[key]\n            return result\n        return wrapper\n    return _wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    # You can use a docstring like:\n    #   >>> def lfu_cache(maxsize=128, typed=False):\n    #  ...     return LfuCache(maxsize, typed)\n    def wrapper(fn):\n        return LfuCache(maxsize, typed, fn)\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    # You can cache the result by passing the function as a keyword argument.\n    # This is for backwards compatibility, please remove later.\n    return _cached(_lfu, maxsize, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    # You can use a docstring like:\n    #   >>> @lfu_cache(maxsize=128)\n    #  ... def f(x):\n    #       return x + 1\n    # <br>\n    # This call wraps the decorator with a memoized function that saves\n    # up to `maxsize` results based on a Least frequently Used (LFU)\n    # algorithm.\n    def wrapper(func):\n        @functools.wraps(func)\n        def wrapped(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(*args, **kwargs)\n                return ret\n\n        def wrapped_with_cache(*args, **kwargs):\n            cache_key = (args, frozenset(sorted(kwargs.items())))\n            try:\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    # You can access the __doc__ attribute of this class in your own code,\n    # or cache it in an attribute named __doc__ if you need it.\n    def _wrapper(func):\n        cached = _Cached(func, maxsize, typed)\n        return lambda *a, **kw: cached._call(*a, **kw)\n    return _wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    # Yes, this is ugly, but we don't want to interfere with mypy\n    return _cache('lfu', maxsize, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    # We create a cache object so that it can be used in conjunction with\n    # @lfu_cache.cached\n    cache = {}\n\n    def wrapper(fun):\n        @functools.wraps(fun)\n        def wrapped(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = fun(*args, **kwargs)\n                return ret\n\n        if typed:\n            @wrapped.typed\n            def wrapped_typed(*args, **kwargs):\n                return wrapped(*args, **kwargs)\n        else:\n            @wrapped.cached\n            def wrapped_cached(*args, **kwargs):\n                return wrapped(*args, **kwargs)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    # We create a new cache object so that it doesn't get garbage collected\n    # (due to the nature of the callable parameters).  This will also clear\n    # the cache on exit (close all filehandles and disk usage).\n    cache = LRUCache(maxsize)\n\n    def wrapper(fn):\n        @functools.wraps(fn)\n        def wrapped(*args, **kwargs):\n            key = pickle.dumps((args, kwargs))\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = fn(*args, **kwargs)\n                return ret\n\n        if typed:\n            wrapped.__wrapped__ = fn\n            wrapped.__cache__ = {}\n            return wrapped\n        else:\n            return wrapped\n\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    # You can use a docstring like:\n    #   >>> def lfu_cache(maxsize=128, typed=False):\n    #  ...     return LfuCache(maxsize, typed)\n    #\n    # To get around this, we create a function that saves up to `maxsize`\n    # calls and returns the first of them. The cache is not shared by\n    # LfuCache and it is not required to be accessed by the application.\n    def wrapper(fun):\n        cache = LfuCache(maxsize, typed)\n\n        @wraps(fun)\n        def wrapped(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = fun(*args, **kwargs)\n                return ret\n\n        return wrapped\n\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    # Yes, this is ugly, but we need to preserve Python class constants\n    # TODO: Remove this once we drop Python 3+\n    if maxsize is None:\n        return _decorator\n    else:\n        return _decorator(_LFU, maxsize, typed)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/fifo.py", "project": "pexip/os-python-cachetools", "name": "popitem", "docstring": "Remove and return the `(key, value)` pair first inserted.", "ques_id": "62b8d22f48ba5a41d1c3f488", "code": ["def popitem(self):\n    try:\n        key, value = dict.popitem(self)\n        self.__setitem__(key, value)\n    except KeyError as e:\n        raise exceptions.NotFound(e)\n    return key, value\n", "def popitem(self):\n    try:\n        key, value = dict.popitem(self)\n    except KeyError:\n        raise exceptions.NotFound('Key not found')\n    else:\n        self.__delitem__(key)\n        return (key, value)\n", "def popitem(self):\n    try:\n        key = next(iter(self))\n        self._list_remove(key)\n        return key, self.pop(key)\n    except KeyError:\n        raise KeyError('pop from an empty Deque')\n", "def popitem(self):\n    try:\n        key, value = dict.popitem(self)\n        self._list.remove(key)\n        return (key, value)\n    except KeyError:\n        raise KeyError('%s is not in the dictionary' % id(self))\n", "def popitem(self):\n    for k, v in super().popitem():\n        self.__delitem__(k)\n        yield k, v\n", "def popitem(self):\n    if not self.root:\n        raise KeyError('popitem(): dictionary is empty')\n\n    key = self.root.popitem()[0]\n    value = self.root.pop(key)\n\n    return key, value\n", "def popitem(self):\n    try:\n        key, value = dict.popitem(self)\n        self._list_add(key, value)\n        return (key, value)\n    except KeyError as e:\n        raise exceptions.BadRequestKeyError(str(e))\n", "def popitem(self):\n    if not self:\n        raise KeyError(\"{} is empty\".format(repr(self)))\n    key, value = dict.popitem(self)\n    self._list.remove(key)\n    return key, value\n", "def popitem(self):\n    try:\n        key, value = dict.popitem(self)\n        self.__delitem__(key)\n        return key, value\n    except KeyError:\n        raise exceptions.NotFound('Key \"%s\" not found.' % self.__key__)\n", "def popitem(self):\n    try:\n        key = next(iter(self))\n    except StopIteration:\n        raise KeyError('popitem(): dictionary is empty')\n    else:\n        value = dict.pop(self, key)\n        return key, value\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def popitem(self):\n    try:\n        key, value = dict.popitem(self)\n        self.__setitem__(key, value)\n    except KeyError as e:\n        raise exceptions.NotFound(e)\n    return key, value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key, value = dict.popitem(self)\n    except KeyError:\n        raise exceptions.NotFound('Key not found')\n    else:\n        self.__delitem__(key)\n        return (key, value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = next(iter(self))\n        self._list_remove(key)\n        return key, self.pop(key)\n    except KeyError:\n        raise KeyError('pop from an empty Deque')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key, value = dict.popitem(self)\n        self._list.remove(key)\n        return (key, value)\n    except KeyError:\n        raise KeyError('%s is not in the dictionary' % id(self))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    for k, v in super().popitem():\n        self.__delitem__(k)\n        yield k, v\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    if not self.root:\n        raise KeyError('popitem(): dictionary is empty')\n\n    key = self.root.popitem()[0]\n    value = self.root.pop(key)\n\n    return key, value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key, value = dict.popitem(self)\n        self._list_add(key, value)\n        return (key, value)\n    except KeyError as e:\n        raise exceptions.BadRequestKeyError(str(e))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    if not self:\n        raise KeyError(\"{} is empty\".format(repr(self)))\n    key, value = dict.popitem(self)\n    self._list.remove(key)\n    return key, value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key, value = dict.popitem(self)\n        self.__delitem__(key)\n        return key, value\n    except KeyError:\n        raise exceptions.NotFound('Key \"%s\" not found.' % self.__key__)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = next(iter(self))\n    except StopIteration:\n        raise KeyError('popitem(): dictionary is empty')\n    else:\n        value = dict.pop(self, key)\n        return key, value\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/cache.py", "project": "pexip/os-python-cachetools", "name": "setdefault", "docstring": "D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D", "ques_id": "62b8d22a48ba5a41d1c3f47e", "code": ["def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "def setdefault(self, key, default=None):\n    if not hasattr(self, '__contains__'):\n        raise TypeError('can not set default value of unhashable type')\n\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "def setdefault(self, key, default=None):\n    if key not in self:\n        self[key] = default\n    return self[key]\n", "def setdefault(self, key, default=None):\n    if key in self:\n        return self[key]\n    self[key] = default\n    return default\n", "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n"], "level": "self_contained", "generate_results": [{"generate_code": "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def setdefault(self, key, default=None):\n    if not hasattr(self, '__contains__'):\n        raise TypeError('can not set default value of unhashable type')\n\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def setdefault(self, key, default=None):\n    if key not in self:\n        self[key] = default\n    return self[key]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def setdefault(self, key, default=None):\n    if key in self:\n        return self[key]\n    self[key] = default\n    return default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "is_pass": true, "return_code": 0}]}
{"file_path": "cachetools/cache.py", "project": "pexip/os-python-cachetools", "name": "get", "docstring": "D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.", "ques_id": "62b8d22948ba5a41d1c3f47c", "code": ["def get(self, key, default=None):\n    if key in self.__dict__:\n        return self.__dict__[key]\n    return default\n", "def get(self, key, default=None):\n    if key in self:\n        return self[key]\n    return default\n", "def get(self, key, default=None):\n    if key in self.__dict__:\n        return self.__dict__[key]\n    return default\n", "def get(self, key, default=None):\n    return self.__dict__.get(key, default)\n", "def get(self, key, default=None):\n    return self.__dict__.get(key, default)\n", "def get(self, key, default=None):\n    return self.data.get(key, default)\n", "def get(self, key, default=None):\n    return self.data.get(key, default)\n", "def get(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        return default\n", "def get(self, key, default=None):\n    return self.__dict__.get(key, default)\n", "def get(self, key, default=None):\n    return self.__dict__.get(key, default)\n"], "level": "self_contained", "generate_results": [{"generate_code": "def get(self, key, default=None):\n    if key in self.__dict__:\n        return self.__dict__[key]\n    return default\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get(self, key, default=None):\n    if key in self:\n        return self[key]\n    return default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get(self, key, default=None):\n    if key in self.__dict__:\n        return self.__dict__[key]\n    return default\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get(self, key, default=None):\n    return self.__dict__.get(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get(self, key, default=None):\n    return self.__dict__.get(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get(self, key, default=None):\n    return self.data.get(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get(self, key, default=None):\n    return self.data.get(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        return default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get(self, key, default=None):\n    return self.__dict__.get(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get(self, key, default=None):\n    return self.__dict__.get(key, default)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/decorators.py", "project": "pexip/os-python-cachetools", "name": "cachedmethod", "docstring": "Decorator to wrap a class or instance method with a memoizing\ncallable that saves results in a cache.", "ques_id": "62b8d22548ba5a41d1c3f472", "code": ["def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = lock or (func, args, frozenset(sorted(kwargs.items())))\n            try:\n                return cache[key]\n            except KeyError:\n                result = cache[key] = func(*args, **kwargs)\n                return result\n        return wrapper\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        name = '_cached_' + func.__name__\n\n        def newfunc(*args, **kwds):\n            if not hasattr(cache, name):\n                setattr(cache, name, func(*args, **kwds))\n            return getattr(cache, name)\n        return update_wrapper(newfunc, func)\n    if lock is None:\n        lock = Lock()\n    decorator.__doc__ = func.__doc__\n    decorator.__name__ = func.__name__\n    decorator.cache = cache\n    decorator.key = key\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        name = '_%s_cached_' % func.__name__\n\n        def wrapper(*args, **kwargs):\n            if not hasattr(cache, name):\n                setattr(cache, name, func(*args, **kwargs))\n            return getattr(cache, name)\n\n        def inner(*args, **kwargs):\n            result = cache.get(key % args, None)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key % args, result, timeout=cache_timeout)\n            return result\n        return inner\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cachedmethods[key] = func\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            if lock is not None:\n                lock.acquire()\n                try:\n                    return cached[key](*args, **kwargs)\n                finally:\n                    lock.release()\n            else:\n                return cached[key](*args, **kwargs)\n        return wrapper\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cachedmethods[key] = func\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            if lock is not None:\n                lock.acquire()\n                try:\n                    return cachedmethods[key](*args, **kwargs)\n                finally:\n                    lock.release()\n            else:\n                return cachedmethods[key](*args, **kwargs)\n        return wrapper\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cachedmethods[key] = func\n        if lock is None:\n            lock = Lock()\n\n        def inner(*args, **kwargs):\n            lock.acquire()\n            try:\n                return cachedmethods[key].call(*args, **kwargs)\n            finally:\n                lock.release()\n        return inner\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cachedmethods[key] = func\n        @functools.wraps(func)\n        def wrapper(*args, **kw):\n            if lock is not None:\n                lock.acquire()\n                try:\n                    return cached[key](*args, **kw)\n                finally:\n                    lock.release()\n            else:\n                return cached[key](*args, **kw)\n        return wrapper\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cached_func = _CachedMethod(func, cache, key, lock)\n        return lambda *a, **kw: cached_func(*a, **kw)\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(*args, **kwargs)\n                return ret\n\n        return wrapper\n\n    if lock is None:\n        lock = threading.Lock()\n\n    def decorate(f):\n        @functools.wraps(f)\n        def wrapper(*args, **kwargs):\n            ret = f(*args, **kwargs)\n            lock.acquire()\n            try:\n                return cache[key]\n            except KeyError:\n                return cache[key] = functools.partial(f, *args, **kwargs)\n            fina", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cached = cache(func, key=key, lock=lock)\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            result = cached.get(args[0])\n            if result is None:\n                result = func(*args, **kwargs)\n                cached[args[0]] = result\n            return result\n        return wrapper\n    return decorator\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = lock or (func, args, frozenset(sorted(kwargs.items())))\n            try:\n                return cache[key]\n            except KeyError:\n                result = cache[key] = func(*args, **kwargs)\n                return result\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        name = '_cached_' + func.__name__\n\n        def newfunc(*args, **kwds):\n            if not hasattr(cache, name):\n                setattr(cache, name, func(*args, **kwds))\n            return getattr(cache, name)\n        return update_wrapper(newfunc, func)\n    if lock is None:\n        lock = Lock()\n    decorator.__doc__ = func.__doc__\n    decorator.__name__ = func.__name__\n    decorator.cache = cache\n    decorator.key = key\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        name = '_%s_cached_' % func.__name__\n\n        def wrapper(*args, **kwargs):\n            if not hasattr(cache, name):\n                setattr(cache, name, func(*args, **kwargs))\n            return getattr(cache, name)\n\n        def inner(*args, **kwargs):\n            result = cache.get(key % args, None)\n            if result is None:\n                result = func(*args, **kwargs)\n                cache.set(key % args, result, timeout=cache_timeout)\n            return result\n        return inner\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cachedmethods[key] = func\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            if lock is not None:\n                lock.acquire()\n                try:\n                    return cached[key](*args, **kwargs)\n                finally:\n                    lock.release()\n            else:\n                return cached[key](*args, **kwargs)\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cachedmethods[key] = func\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            if lock is not None:\n                lock.acquire()\n                try:\n                    return cachedmethods[key](*args, **kwargs)\n                finally:\n                    lock.release()\n            else:\n                return cachedmethods[key](*args, **kwargs)\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cachedmethods[key] = func\n        if lock is None:\n            lock = Lock()\n\n        def inner(*args, **kwargs):\n            lock.acquire()\n            try:\n                return cachedmethods[key].call(*args, **kwargs)\n            finally:\n                lock.release()\n        return inner\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cachedmethods[key] = func\n        @functools.wraps(func)\n        def wrapper(*args, **kw):\n            if lock is not None:\n                lock.acquire()\n                try:\n                    return cached[key](*args, **kw)\n                finally:\n                    lock.release()\n            else:\n                return cached[key](*args, **kw)\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cached_func = _CachedMethod(func, cache, key, lock)\n        return lambda *a, **kw: cached_func(*a, **kw)\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(*args, **kwargs)\n                return ret\n\n        return wrapper\n\n    if lock is None:\n        lock = threading.Lock()\n\n    def decorate(f):\n        @functools.wraps(f)\n        def wrapper(*args, **kwargs):\n            ret = f(*args, **kwargs)\n            lock.acquire()\n            try:\n                return cache[key]\n            except KeyError:\n                return cache[key] = functools.partial(f, *args, **kwargs)\n            fina", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cached = cache(func, key=key, lock=lock)\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            result = cached.get(args[0])\n            if result is None:\n                result = func(*args, **kwargs)\n                cached[args[0]] = result\n            return result\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}]}
{"file_path": "pysolbase/SolBase.py", "project": "champax/pysolbase", "name": "extostr", "docstring": "Format an exception.\n:param e: Any exception instance.\n:type e: Exception\n:param max_level: Maximum call stack level (default 30)\n:type max_level: int\n:param max_path_level: Maximum path level (default 5)\n:type max_path_level: int\n:return The exception readable string\n:rtype str", "ques_id": "62b8c517e0d34b282c18122e", "code": ["def extostr(cls, e, max_level=30, max_path_level=5):\n    out = []\n    if issubclass(e.__class__, exceptions.HTTPException):\n        out.append(\"HTTPException %s\" % e.code)\n        if hasattr(e, 'description'):\n            out.append(\" - %s\" % e.description)\n    else:\n        out.append(\"%s: %s\" % (cls.__name__, e))\n    if max_path_level > 1:\n        out.append(\"%s %s\" % (max_path_level, max_level))\n    if max_level > 1:\n        out.append(\" %s %s\" % (max_level, max_path_level))\n    if max_path_level > 1:\n        out.append(\" (%d more)\" % (max_path_level - 1))\n    if max_level > 1:\n        out.append(\" (%d more to %d)\" % (max_level, max_path_level - 1))\n    if max_path_level > 1:\n        out.append(\" %s\" % (\"/\" * max_path_level))\n    return \"\\n\".join(out)\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    return '%s: %s: %s' % (cls.__name__, e.__class__.__name__, e)\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    return \"{0}: {1} at {2}\".format(cls.__name__, e, hex(id(e)))\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    if issubclass(e.__class__, SyntaxError):\n        return '%s%s%s' % (\n            getattr(e, 'lineno', 1),\n            ':'if hasattr(e, 'lineno') else '',\n            e.args[0] if len(e.args) > 0 else '',\n        )\n\n    return super(Formatter, cls).extostr(e, max_level, max_path_level)\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    if e.args:\n        # we have args, so let's make sure we have something\n        # we can use to format the string\n        e.args = [format_exc()] + e.args\n    return str(e)\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    if issubclass(e.__class__, Exception):\n        e_str = str(e)\n    else:\n        e_str = '%s: %s' % (type(e).__name__, e)\n    return _safe_str(_safe_str(cls.__name__, e_str), max_level, max_path_level)\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    if isinstance(e, str):\n        return e\n\n    if not e.args:\n        return \"%s: %s\" % (cls.__name__, e)\n\n    path_str = \", \".join(['\"%s\"' % p for p in e.args[:max_path_level]])\n    level_str = \", \".join(['\"%s\"' % p for p in e.args[max_path_level:]])\n    return \"%s: %s: %s (%s)\" % (cls.__name__, level_str, path_str, e)\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    return '%s: %s: %s' % (cls.__name__, e.__class__.__name__, e)\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    if not e.args:\n        return ''\n    return '{}: {}'.format(cls.__name__,''.join(e.args))\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    return '%s: %s' % (cls.__name__, e)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    out = []\n    if issubclass(e.__class__, exceptions.HTTPException):\n        out.append(\"HTTPException %s\" % e.code)\n        if hasattr(e, 'description'):\n            out.append(\" - %s\" % e.description)\n    else:\n        out.append(\"%s: %s\" % (cls.__name__, e))\n    if max_path_level > 1:\n        out.append(\"%s %s\" % (max_path_level, max_level))\n    if max_level > 1:\n        out.append(\" %s %s\" % (max_level, max_path_level))\n    if max_path_level > 1:\n        out.append(\" (%d more)\" % (max_path_level - 1))\n    if max_level > 1:\n        out.append(\" (%d more to %d)\" % (max_level, max_path_level - 1))\n    if max_path_level > 1:\n        out.append(\" %s\" % (\"/\" * max_path_level))\n    return \"\\n\".join(out)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    return '%s: %s: %s' % (cls.__name__, e.__class__.__name__, e)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    return \"{0}: {1} at {2}\".format(cls.__name__, e, hex(id(e)))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    if issubclass(e.__class__, SyntaxError):\n        return '%s%s%s' % (\n            getattr(e, 'lineno', 1),\n            ':'if hasattr(e, 'lineno') else '',\n            e.args[0] if len(e.args) > 0 else '',\n        )\n\n    return super(Formatter, cls).extostr(e, max_level, max_path_level)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    if e.args:\n        # we have args, so let's make sure we have something\n        # we can use to format the string\n        e.args = [format_exc()] + e.args\n    return str(e)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    if issubclass(e.__class__, Exception):\n        e_str = str(e)\n    else:\n        e_str = '%s: %s' % (type(e).__name__, e)\n    return _safe_str(_safe_str(cls.__name__, e_str), max_level, max_path_level)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    if isinstance(e, str):\n        return e\n\n    if not e.args:\n        return \"%s: %s\" % (cls.__name__, e)\n\n    path_str = \", \".join(['\"%s\"' % p for p in e.args[:max_path_level]])\n    level_str = \", \".join(['\"%s\"' % p for p in e.args[max_path_level:]])\n    return \"%s: %s: %s (%s)\" % (cls.__name__, level_str, path_str, e)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    return '%s: %s: %s' % (cls.__name__, e.__class__.__name__, e)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    if not e.args:\n        return ''\n    return '{}: {}'.format(cls.__name__,''.join(e.args))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    return '%s: %s' % (cls.__name__, e)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "pysolbase/FileUtility.py", "project": "champax/pysolbase", "name": "append_text_to_file", "docstring": "Write to the specified filename, the provided binary buffer\nCreate the file if required.\n:param file_name:  File name.\n:type file_name: str\n:param text_buffer: Text buffer to write.\n:type text_buffer: str\n:param encoding: The encoding to use.\n:type encoding: str\n:param overwrite: If true, file is overwritten.\n:type overwrite: bool\n:return: The number of bytes written or lt 0 if error.\n:rtype int", "ques_id": "62b8bbbfe0d34b282c181210", "code": ["def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not isinstance(text_buffer, unicode):\n        text_buffer = unicode(text_buffer, encoding, errors='replace')\n\n    if overwrite or not os.path.exists(file_name):\n        with open(file_name, 'w') as f:\n            f.write(text_buffer)\n    else:\n        print('File \"%s\" already exists' % file_name)\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    with open(file_name, 'a', encoding=encoding) as f:\n        f.write(text_buffer.get_text(\n                                    select_ext=False,\n                                    overwrite=overwrite))\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if encoding is None:\n        encoding = get_encoding(file_name)\n    try:\n        if overwrite is False:\n            os.remove(file_name)\n        f = open(file_name, 'a', encoding=encoding)\n        f.write(text_buffer)\n        f.close()\n        return True\n    except Exception as e:\n        print('Error writing to file: ', e)\n        return False\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.exists(file_name):\n        raise IOError('File \"{}\" already exists. Use overwrite=True to overwrite it.'.format(file_name))\n\n    with io.open(file_name, 'w', encoding=encoding) as file_handle:\n        file_handle.writelines(text_buffer)\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not os.path.exists(os.path.dirname(file_name)):\n        os.makedirs(os.path.dirname(file_name))\n    with open(file_name, \"a\", encoding=encoding) as file_obj:\n        file_obj.write(text_buffer)\n    return True\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not os.path.isfile(file_name) or overwrite:\n        text_buffer.write(text_buffer.getvalue())\n        text_buffer.close()\n        os.chmod(file_name, 0o600)\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.isfile(file_name):\n        raise FileExistsError(\"File '{}' already exists\".format(file_name))\n    with open(file_name, 'w', encoding=encoding) as f:\n        f.writelines(text_buffer)\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.exists(file_name):\n        raise FileExistsError(\"File exists: %s\" % file_name)\n    with codecs.open(file_name, 'a', encoding=encoding) as text_file:\n        text_file.write(text_buffer)\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if os.path.isfile(file_name) and not overwrite:\n        raise IOError(\"File '{}' already exists and overwrite=False\".format(file_name))\n    with open(file_name, 'w', encoding=encoding) as file_:\n        file_.write(text_buffer.getvalue())\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.isfile(file_name):\n        raise IOError(\"File '%s' already exists\" % file_name)\n    if encoding:\n        with io.open(file_name, 'w', encoding=encoding) as f:\n            f.write(text_buffer)\n    else:\n        with io.open(file_name, 'w') as f:\n            f.write(text_buffer)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not isinstance(text_buffer, unicode):\n        text_buffer = unicode(text_buffer, encoding, errors='replace')\n\n    if overwrite or not os.path.exists(file_name):\n        with open(file_name, 'w') as f:\n            f.write(text_buffer)\n    else:\n        print('File \"%s\" already exists' % file_name)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    with open(file_name, 'a', encoding=encoding) as f:\n        f.write(text_buffer.get_text(\n                                    select_ext=False,\n                                    overwrite=overwrite))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if encoding is None:\n        encoding = get_encoding(file_name)\n    try:\n        if overwrite is False:\n            os.remove(file_name)\n        f = open(file_name, 'a', encoding=encoding)\n        f.write(text_buffer)\n        f.close()\n        return True\n    except Exception as e:\n        print('Error writing to file: ', e)\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.exists(file_name):\n        raise IOError('File \"{}\" already exists. Use overwrite=True to overwrite it.'.format(file_name))\n\n    with io.open(file_name, 'w', encoding=encoding) as file_handle:\n        file_handle.writelines(text_buffer)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not os.path.exists(os.path.dirname(file_name)):\n        os.makedirs(os.path.dirname(file_name))\n    with open(file_name, \"a\", encoding=encoding) as file_obj:\n        file_obj.write(text_buffer)\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not os.path.isfile(file_name) or overwrite:\n        text_buffer.write(text_buffer.getvalue())\n        text_buffer.close()\n        os.chmod(file_name, 0o600)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.isfile(file_name):\n        raise FileExistsError(\"File '{}' already exists\".format(file_name))\n    with open(file_name, 'w', encoding=encoding) as f:\n        f.writelines(text_buffer)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.exists(file_name):\n        raise FileExistsError(\"File exists: %s\" % file_name)\n    with codecs.open(file_name, 'a', encoding=encoding) as text_file:\n        text_file.write(text_buffer)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if os.path.isfile(file_name) and not overwrite:\n        raise IOError(\"File '{}' already exists and overwrite=False\".format(file_name))\n    with open(file_name, 'w', encoding=encoding) as file_:\n        file_.write(text_buffer.getvalue())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.isfile(file_name):\n        raise IOError(\"File '%s' already exists\" % file_name)\n    if encoding:\n        with io.open(file_name, 'w', encoding=encoding) as f:\n            f.write(text_buffer)\n    else:\n        with io.open(file_name, 'w') as f:\n            f.write(text_buffer)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "pysolbase/FileUtility.py", "project": "champax/pysolbase", "name": "file_to_textbuffer", "docstring": "Load a file toward a text buffer (UTF-8), using the specify encoding while reading.\nCAUTION : This will read the whole file IN MEMORY.\n:param file_name: File name.\n:type file_name: str\n:param encoding: Encoding to use.\n:type encoding: str\n:return: A text buffer or None in case of error.\n:rtype str", "ques_id": "62b8bbbfe0d34b282c18120f", "code": ["def file_to_textbuffer(file_name, encoding):\n    try:\n        buffer = gtk.TextBuffer()\n        with open(file_name, 'r', encoding=encoding) as f:\n            buffer.set_text(f.read())\n    except IOError:\n        print('Cannot open the file: %s' % file_name)\n        sys.exit(1)\n    return buffer\n", "def file_to_textbuffer(file_name, encoding):\n    try:\n        file = open(file_name, \"r\", encoding=encoding)\n    except IOError:\n        sublime.error_message(\"Cannot load file '{}'. File not found.\".format(file_name))\n        return None\n    text = file.read()\n    file.close()\n    return text\n", "def file_to_textbuffer(file_name, encoding):\n    with open(file_name, 'r', encoding=encoding) as f:\n        text = f.read()\n\n    return text\n", "def file_to_textbuffer(file_name, encoding):\n    try:\n        file_handle = open(file_name, \"r\", encoding=encoding)\n    except UnicodeDecodeError:\n        try:\n            file_handle = open(file_name, \"r\", errors=\"replace\")\n        except UnicodeDecodeError:\n            file_handle = open(file_name, \"r\", encoding=\"latin-1\")\n    text_buffer = file_handle.read()\n    file_handle.close()\n    return text_buffer\n", "def file_to_textbuffer(file_name, encoding):\n    text = read_file(file_name, encoding)\n    text_buffer = Gtk.TextBuffer.new_with_text(text)\n    text_buffer.set_wrap_mode(Gtk.WrapMode.WORD)\n    return text_buffer\n", "def file_to_textbuffer(file_name, encoding):\n    try:\n        buffer = unicode(open(file_name, encoding=encoding).read(), encoding=encoding)\n    except Exception as exc:\n        print('Unable to load file %s: %s' % (file_name, exc))\n        buffer = ''\n    return buffer\n", "def file_to_textbuffer(file_name, encoding):\n    # type: (str, str) -> TextBuffer\n    \"\"\"Load a file toward a text buffer\"\"\"\n    try:\n        text_buffer = sublime.load_resource(file_name)\n    except IOError:\n        if encoding == \"UTF-8\":\n            text_buffer = sublime.load_resource(\n                \"Packages/User/Documents/CloudSpotting/CloudSpotting_UTF8.txt\"\n            )\n        else:\n            text_buffer = sublime.load_resource(\n                \"Packages/User/Documents/CloudSpotting/CloudSpotting_CP1252.txt\"\n            )\n    return text_buffer\n", "def file_to_textbuffer(file_name, encoding):\n    buf = Gtk.TextBuffer()\n    with open(file_name, 'r', encoding=encoding) as f:\n        buf.set_text(f.read())\n    return buf\n", "def file_to_textbuffer(file_name, encoding):\n    try:\n        file = open(file_name, encoding=encoding)\n    except FileNotFoundError:\n        return None\n    text = file.read()\n    file.close()\n    return text\n", "def file_to_textbuffer(file_name, encoding):\n    try:\n        text = read_file(file_name, encoding)\n    except UnicodeDecodeError:\n        try:\n            text = read_file(file_name.encode('utf-8'), encoding)\n        except UnicodeDecodeError:\n            text = read_file(file_name, 'utf-8')\n    return text\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        buffer = gtk.TextBuffer()\n        with open(file_name, 'r', encoding=encoding) as f:\n            buffer.set_text(f.read())\n    except IOError:\n        print('Cannot open the file: %s' % file_name)\n        sys.exit(1)\n    return buffer\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        file = open(file_name, \"r\", encoding=encoding)\n    except IOError:\n        sublime.error_message(\"Cannot load file '{}'. File not found.\".format(file_name))\n        return None\n    text = file.read()\n    file.close()\n    return text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    with open(file_name, 'r', encoding=encoding) as f:\n        text = f.read()\n\n    return text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        file_handle = open(file_name, \"r\", encoding=encoding)\n    except UnicodeDecodeError:\n        try:\n            file_handle = open(file_name, \"r\", errors=\"replace\")\n        except UnicodeDecodeError:\n            file_handle = open(file_name, \"r\", encoding=\"latin-1\")\n    text_buffer = file_handle.read()\n    file_handle.close()\n    return text_buffer\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    text = read_file(file_name, encoding)\n    text_buffer = Gtk.TextBuffer.new_with_text(text)\n    text_buffer.set_wrap_mode(Gtk.WrapMode.WORD)\n    return text_buffer\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        buffer = unicode(open(file_name, encoding=encoding).read(), encoding=encoding)\n    except Exception as exc:\n        print('Unable to load file %s: %s' % (file_name, exc))\n        buffer = ''\n    return buffer\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    # type: (str, str) -> TextBuffer\n    \"\"\"Load a file toward a text buffer\"\"\"\n    try:\n        text_buffer = sublime.load_resource(file_name)\n    except IOError:\n        if encoding == \"UTF-8\":\n            text_buffer = sublime.load_resource(\n                \"Packages/User/Documents/CloudSpotting/CloudSpotting_UTF8.txt\"\n            )\n        else:\n            text_buffer = sublime.load_resource(\n                \"Packages/User/Documents/CloudSpotting/CloudSpotting_CP1252.txt\"\n            )\n    return text_buffer\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    buf = Gtk.TextBuffer()\n    with open(file_name, 'r', encoding=encoding) as f:\n        buf.set_text(f.read())\n    return buf\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        file = open(file_name, encoding=encoding)\n    except FileNotFoundError:\n        return None\n    text = file.read()\n    file.close()\n    return text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        text = read_file(file_name, encoding)\n    except UnicodeDecodeError:\n        try:\n            text = read_file(file_name.encode('utf-8'), encoding)\n        except UnicodeDecodeError:\n            text = read_file(file_name, 'utf-8')\n    return text\n", "is_pass": false, "return_code": 1}]}
{"file_path": "pysolbase/FileUtility.py", "project": "champax/pysolbase", "name": "is_file_exist", "docstring": "Check if file name exist.\n:param file_name: File name.\n:type file_name: str\n:return: Return true (exist), false (do not exist, or invalid file name)\n:rtype bool", "ques_id": "62b8bbbce0d34b282c18120d", "code": ["def is_file_exist(file_name):\n    if os.path.isfile(file_name):\n        return True\n    else:\n        return False\n", "def is_file_exist(file_name):\n    if not os.path.exists(file_name):\n        msg = 'File {} does not exists!'.format(file_name)\n        raise argparse.ArgumentTypeError(msg)\n    return file_name\n", "def is_file_exist(file_name):\n    if not os.path.isfile(file_name):\n        raise argparse.ArgumentTypeError('{} is not an existing file'.format(file_name))\n    return file_name\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def is_file_exist(file_name):\n    if os.path.isfile(file_name):\n        return True\n    else:\n        return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    if not os.path.exists(file_name):\n        msg = 'File {} does not exists!'.format(file_name)\n        raise argparse.ArgumentTypeError(msg)\n    return file_name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_file_exist(file_name):\n    if not os.path.isfile(file_name):\n        raise argparse.ArgumentTypeError('{} is not an existing file'.format(file_name))\n    return file_name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "pysolbase/SolBase.py", "project": "champax/pysolbase", "name": "_reset_logging", "docstring": "Reset", "ques_id": "62b8b99de0d34b282c1811f8", "code": ["def _reset_logging(cls):\n    # pylint: disable=protected-access\n    logging.Logger.manager.loggerDict = {}\n    logging.Logger.handlers = []\n", "def _reset_logging(cls):\n    # Remove all existing handlers\n    for h in logging.root.handlers:\n        logging.root.removeHandler(h)\n\n    # Add a new one\n    logging.root.addHandler(logging.NullHandler())\n", "def _reset_logging(cls):\n    logger = logging.getLogger('nodeenv')\n    for handler in logger.handlers:\n        if isinstance(handler, logging.NullHandler):\n            continue\n        handler.close()\n", "def _reset_logging(cls):\n    # Remove existing handlers\n    for h in logging.getLogger().handlers:\n        logging.getLogger().removeHandler(h)\n\n    # Add new handlers\n    for level in logging.getLogger().levels:\n        logging.getLogger().addHandler(logging.NullHandler())\n\n    # Configure logging\n    logging.basicConfig(\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        level=logging.DEBUG,\n    )\n", "def _reset_logging(cls):\n    root_logger = logging.getLogger()\n    root_logger.handlers = []\n", "def _reset_logging(cls):\n    logging.getLogger().handlers = []\n", "def _reset_logging(cls):\n    for handler in logging.getLogger().handlers:\n        logging.getLogger().removeHandler(handler)\n", "def _reset_logging(cls):\n    logging.getLogger().handlers = []\n", "def _reset_logging(cls):\n    root_logger = logging.getLogger()\n    root_logger.handlers = []\n\n    if cls._log_file_handler:\n        cls._log_file_handler.close()\n    if cls._log_file_handler is None:\n        cls._log_file_handler = logging.StreamHandler(sys.stdout)\n        cls._log_file_handler.setFormatter(logging.Formatter(cls._log_format))\n        root_logger.addHandler(cls._log_file_handler)\n\n    if cls._log_file_handler is not None:\n        cls._log_file_handler.setLevel(logging.DEBUG)\n", "def _reset_logging(cls):\n    global _logger\n    _logger = logging.getLogger(__name__)\n    _logger.removeHandler(cls._old_handler)\n    _logger.addHandler(logging.NullHandler())\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def _reset_logging(cls):\n    # pylint: disable=protected-access\n    logging.Logger.manager.loggerDict = {}\n    logging.Logger.handlers = []\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    # Remove all existing handlers\n    for h in logging.root.handlers:\n        logging.root.removeHandler(h)\n\n    # Add a new one\n    logging.root.addHandler(logging.NullHandler())\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    logger = logging.getLogger('nodeenv')\n    for handler in logger.handlers:\n        if isinstance(handler, logging.NullHandler):\n            continue\n        handler.close()\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    # Remove existing handlers\n    for h in logging.getLogger().handlers:\n        logging.getLogger().removeHandler(h)\n\n    # Add new handlers\n    for level in logging.getLogger().levels:\n        logging.getLogger().addHandler(logging.NullHandler())\n\n    # Configure logging\n    logging.basicConfig(\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n        level=logging.DEBUG,\n    )\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    root_logger = logging.getLogger()\n    root_logger.handlers = []\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    logging.getLogger().handlers = []\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    for handler in logging.getLogger().handlers:\n        logging.getLogger().removeHandler(handler)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    logging.getLogger().handlers = []\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    root_logger = logging.getLogger()\n    root_logger.handlers = []\n\n    if cls._log_file_handler:\n        cls._log_file_handler.close()\n    if cls._log_file_handler is None:\n        cls._log_file_handler = logging.StreamHandler(sys.stdout)\n        cls._log_file_handler.setFormatter(logging.Formatter(cls._log_format))\n        root_logger.addHandler(cls._log_file_handler)\n\n    if cls._log_file_handler is not None:\n        cls._log_file_handler.setLevel(logging.DEBUG)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    global _logger\n    _logger = logging.getLogger(__name__)\n    _logger.removeHandler(cls._old_handler)\n    _logger.addHandler(logging.NullHandler())\n", "is_pass": true, "return_code": 0}]}
{"file_path": "src/zope/interface/tests/test_declarations.py", "project": "pexip/os-zope", "name": "_getTargetClass", "docstring": "Define this to return the implementation in use,\nwithout the 'Py' or 'Fallback' suffix.", "ques_id": "62b8b59feb7e40a82d2d1291", "code": ["def _getTargetClass(self):\n    return AsyncHTTPClient\n", "def _getTargetClass(self):\n    return JavaScriptScriptTextTarget\n", "def _getTargetClass(self):\n    return AsyncHTTPClient\n", "def _getTargetClass(self):\n    return html.Target\n", "def _getTargetClass(self):\n    return AttributeInjector\n", "def _getTargetClass(self):\n    return TextTestResult\n", "def _getTargetClass(self):\n    return Template\n", "def _getTargetClass(self):\n    return DataTarget\n", "def _getTargetClass(self):\n    return Server\n", "def _getTargetClass(self):\n    return AsyncHTTPClient\n"], "level": "self_contained", "generate_results": [{"generate_code": "def _getTargetClass(self):\n    return AsyncHTTPClient\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return JavaScriptScriptTextTarget\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return AsyncHTTPClient\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return html.Target\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return AttributeInjector\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return TextTestResult\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return Template\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return DataTarget\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return Server\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return AsyncHTTPClient\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/ro.py", "project": "pexip/os-zope", "name": "_legacy_mergeOrderings", "docstring": "Merge multiple orderings so that within-ordering order is preserved\n\nOrderings are constrained in such a way that if an object appears\nin two or more orderings, then the suffix that begins with the\nobject must be in both orderings.\n\nFor example:\n\n>>> _mergeOrderings([\n... ['x', 'y', 'z'],\n... ['q', 'z'],\n... [1, 3, 5],\n... ['z']\n... ])\n['x', 'y', 'q', 1, 3, 5, 'z']", "ques_id": "62b8b590eb7e40a82d2d1275", "code": ["def _legacy_mergeOrderings(orderings):\n    merged = []\n    for o in orderings:\n        for el in o:\n            merged.append(el)\n    return merged\n", "def _legacy_mergeOrderings(orderings):\n    result = []\n    for o in orderings:\n        if o not in result:\n            result.append(o)\n    return result\n", "def _legacy_mergeOrderings(orderings):\n    orderings = list(orderings)\n    while orderings and orderings[0] == []:\n        orderings.pop(0)\n    while orderings and orderings[-1] == []:\n        orderings.pop()\n    return orderings\n", "def _legacy_mergeOrderings(orderings):\n    result = []\n    for o in orderings:\n        if len(o) == 1:\n            result.append(o[0])\n        else:\n            result.extend(o[0:-1])\n            result.append(o[-1])\n    return result\n", "def _legacy_mergeOrderings(orderings):\n    # We can't use set.union because there is no reliable way to do this\n    return list(set(orderings))\n", "def _legacy_mergeOrderings(orderings):\n    if len(orderings) == 1:\n        return orderings[0]\n    else:\n        return list(OrderedDict.fromkeys(orderings))\n", "def _legacy_mergeOrderings(orderings):\n    orderings = [x for x in orderings if x]\n    if not orderings:\n        return []\n    elif len(set([x[0] for x in orderings])) == 1:\n        return orderings[0]\n    else:\n        return _mergeOrderings([x[1:] for x in orderings])\n", "def _legacy_mergeOrderings(orderings):\n    orderings = list(orderings)\n    while len(orderings) > 1:\n        for i in range(len(orderings) - 1):\n            if orderings[i + 1] < orderings[i]:\n                orderings[i], orderings[i + 1] = orderings[i + 1], orderings[i]\n    return orderings\n", "def _legacy_mergeOrderings(orderings):\n    if len(orderings) == 0:\n        return []\n    elif len(orderings) == 1:\n        return orderings[0]\n    else:\n        first = orderings[0]\n        rest = orderings[1:]\n        return [first] + _legacy_mergeOrderings(rest)\n", "def _legacy_mergeOrderings(orderings):\n    orderings = list(orderings)\n    while len(set([o.start for o in orderings])) < len(orderings):\n        orderings.append(orderings.pop(0))\n    return orderings\n"], "level": "self_contained", "generate_results": [{"generate_code": "def _legacy_mergeOrderings(orderings):\n    merged = []\n    for o in orderings:\n        for el in o:\n            merged.append(el)\n    return merged\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    result = []\n    for o in orderings:\n        if o not in result:\n            result.append(o)\n    return result\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    orderings = list(orderings)\n    while orderings and orderings[0] == []:\n        orderings.pop(0)\n    while orderings and orderings[-1] == []:\n        orderings.pop()\n    return orderings\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    result = []\n    for o in orderings:\n        if len(o) == 1:\n            result.append(o[0])\n        else:\n            result.extend(o[0:-1])\n            result.append(o[-1])\n    return result\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    # We can't use set.union because there is no reliable way to do this\n    return list(set(orderings))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    if len(orderings) == 1:\n        return orderings[0]\n    else:\n        return list(OrderedDict.fromkeys(orderings))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    orderings = [x for x in orderings if x]\n    if not orderings:\n        return []\n    elif len(set([x[0] for x in orderings])) == 1:\n        return orderings[0]\n    else:\n        return _mergeOrderings([x[1:] for x in orderings])\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    orderings = list(orderings)\n    while len(orderings) > 1:\n        for i in range(len(orderings) - 1):\n            if orderings[i + 1] < orderings[i]:\n                orderings[i], orderings[i + 1] = orderings[i + 1], orderings[i]\n    return orderings\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    if len(orderings) == 0:\n        return []\n    elif len(orderings) == 1:\n        return orderings[0]\n    else:\n        first = orderings[0]\n        rest = orderings[1:]\n        return [first] + _legacy_mergeOrderings(rest)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    orderings = list(orderings)\n    while len(set([o.start for o in orderings])) < len(orderings):\n        orderings.append(orderings.pop(0))\n    return orderings\n", "is_pass": true, "return_code": 0}]}
{"file_path": "src/zope/interface/declarations.py", "project": "pexip/os-zope", "name": "directlyProvidedBy", "docstring": "Return the interfaces directly provided by the given object\n\nThe value returned is an `~zope.interface.interfaces.IDeclaration`.", "ques_id": "62b8b58deb7e40a82d2d1269", "code": ["def directlyProvidedBy(object):\n    providedBy = getattr(object, 'providedBy', None)\n    if providedBy is None:\n        providedBy = getattr(object, '__providedBy__', None)\n        if providedBy is None:\n            return None\n    if providedBy is object:\n        return interfaces.IDeclaration(object)\n    return providedBy\n", "def directlyProvidedBy(object):\n    providedBy = getattr(object, 'providedBy', None)\n    if providedBy is not None:\n        return providedBy\n    provides = providedBy = getattr(object, '__provides__', None)\n    if provides is not None:\n        return provides\n    raise TypeError(\n        \"%s doesn't provide any interfaces by itself.\" % object)\n", "def directlyProvidedBy(object):\n    providedBy = getattr(object, 'providedBy', None)\n    if providedBy is None:\n        providedBy = getattr(object, '__providedBy__', None)\n    if providedBy is None:\n        return None\n    return providedBy()\n", "def directlyProvidedBy(object):\n    providedBy = getattr(object, '__providedBy__', None)\n    if providedBy is not None:\n        provided = providedBy()\n    else:\n        provided = None\n    return provided\n", "def directlyProvidedBy(object):\n    providedBy = getattr(object, 'providedBy', None)\n    if providedBy is None:\n        providedBy = getattr(object, '__providedBy__', None)\n        if providedBy is None:\n            return None\n        object.__providedBy__ = providedBy\n    return providedBy\n", "def directlyProvidedBy(object):\n    if IContentType.providedBy(object):\n        providedBy = getattr(object, '__providedBy__', None)\n        if providedBy is not None:\n            return providedBy\n    if IContent.providedBy(object):\n        providedBy = getattr(object, '__providedBy__', None)\n        if providedBy is not None:\n            return providedBy\n    if IObject.providedBy(object):\n        providedBy = getattr(object, '__providedBy__', None)\n        if providedBy is not None:\n            return providedBy\n    if IDirectlyProvided.providedBy(object):\n        providedBy = getattr(object, '__providedBy__', None)\n        if providedBy is not None:\n            return providedBy\n    raise TypeError(\"%s does not provide directly providing interfaces\" % (object,))\n", "def directlyProvidedBy(object):\n    providedBy = getattr(object, '__providedBy__', None)\n    if providedBy is None:\n        providedBy = getattr(object, 'providedBy', None)\n    if providedBy is None:\n        return None\n    return providedBy()\n", "def directlyProvidedBy(object):\n    providedBy = getattr(object, 'providedBy', None)\n    if providedBy is None:\n        providedBy = getattr(object, '__parent__', None)\n        if providedBy is None:\n            return None\n    if providedBy is object:\n        raise ValueError(\"Can't resolve directlyProvidedBy to %r\" % object)\n    return providedBy\n", "def directlyProvidedBy(object):\n    return providedBy(object)[1]\n", "def directlyProvidedBy(object):\n    providedBy = getattr(object, 'providedBy', None)\n    if providedBy is not None:\n        providedBy = providedBy()\n    if providedBy is None:\n        raise ValueError(\"Object %s doesn't provide an implementation for \"\n                         \"'directlyProvidedBy'\" % (object,))\n    return providedBy\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def directlyProvidedBy(object):\n    providedBy = getattr(object, 'providedBy', None)\n    if providedBy is None:\n        providedBy = getattr(object, '__providedBy__', None)\n        if providedBy is None:\n            return None\n    if providedBy is object:\n        return interfaces.IDeclaration(object)\n    return providedBy\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    providedBy = getattr(object, 'providedBy', None)\n    if providedBy is not None:\n        return providedBy\n    provides = providedBy = getattr(object, '__provides__', None)\n    if provides is not None:\n        return provides\n    raise TypeError(\n        \"%s doesn't provide any interfaces by itself.\" % object)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    providedBy = getattr(object, 'providedBy', None)\n    if providedBy is None:\n        providedBy = getattr(object, '__providedBy__', None)\n    if providedBy is None:\n        return None\n    return providedBy()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    providedBy = getattr(object, '__providedBy__', None)\n    if providedBy is not None:\n        provided = providedBy()\n    else:\n        provided = None\n    return provided\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    providedBy = getattr(object, 'providedBy', None)\n    if providedBy is None:\n        providedBy = getattr(object, '__providedBy__', None)\n        if providedBy is None:\n            return None\n        object.__providedBy__ = providedBy\n    return providedBy\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    if IContentType.providedBy(object):\n        providedBy = getattr(object, '__providedBy__', None)\n        if providedBy is not None:\n            return providedBy\n    if IContent.providedBy(object):\n        providedBy = getattr(object, '__providedBy__', None)\n        if providedBy is not None:\n            return providedBy\n    if IObject.providedBy(object):\n        providedBy = getattr(object, '__providedBy__', None)\n        if providedBy is not None:\n            return providedBy\n    if IDirectlyProvided.providedBy(object):\n        providedBy = getattr(object, '__providedBy__', None)\n        if providedBy is not None:\n            return providedBy\n    raise TypeError(\"%s does not provide directly providing interfaces\" % (object,))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    providedBy = getattr(object, '__providedBy__', None)\n    if providedBy is None:\n        providedBy = getattr(object, 'providedBy', None)\n    if providedBy is None:\n        return None\n    return providedBy()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    providedBy = getattr(object, 'providedBy', None)\n    if providedBy is None:\n        providedBy = getattr(object, '__parent__', None)\n        if providedBy is None:\n            return None\n    if providedBy is object:\n        raise ValueError(\"Can't resolve directlyProvidedBy to %r\" % object)\n    return providedBy\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    return providedBy(object)[1]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    providedBy = getattr(object, 'providedBy', None)\n    if providedBy is not None:\n        providedBy = providedBy()\n    if providedBy is None:\n        raise ValueError(\"Object %s doesn't provide an implementation for \"\n                         \"'directlyProvidedBy'\" % (object,))\n    return providedBy\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/advice.py", "project": "pexip/os-zope", "name": "minimalBases", "docstring": "Reduce a list of base classes to its ordered minimum equivalent", "ques_id": "62b8b559eb7e40a82d2d11f8", "code": ["def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "def minimalBases(classes):\n    return [c for c in classes if issubclass(c, Base)]\n", "def minimalBases(classes):\n    return [c for c in classes if not _issubclass(c, Base)]\n", "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "def minimalBases(classes):\n    return [c for c in classes if issubclass(c, Base)]\n"], "level": "self_contained", "generate_results": [{"generate_code": "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    return [c for c in classes if issubclass(c, Base)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    return [c for c in classes if not _issubclass(c, Base)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    return [c for c in classes if not issubclass(c, Base)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    return [c for c in classes if issubclass(c, Base)]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/interface.py", "project": "pexip/os-zope", "name": "namesAndDescriptions", "docstring": "Return attribute names and descriptions defined by interface.", "ques_id": "62b8b4b9eb7e40a82d2d1134", "code": ["def namesAndDescriptions(self, all=False):\n    if all:\n        return [name for name, attr in self.__dict__.items() if type(attr) == type([])]\n    else:\n        return [name for name, attr in self.__dict__.items() if type(attr) == type({})]\n", "def namesAndDescriptions(self, all=False):\n    name = self.name\n    desc = self.description\n    if all:\n        return [name, desc]\n    else:\n        return [name, desc, self.__doc__]\n", "def namesAndDescriptions(self, all=False):\n    names = ['']\n    descs = []\n    if self.isClass:\n        names = self._get_attribute_names_from_cls(self.__class__)\n        descs = self._get_attribute_descriptions(self.__class__)\n    if all:\n        return names, descs\n    return names, descs, self.__class__.__name__\n", "def namesAndDescriptions(self, all=False):\n    desc = ''\n    if self.__doc__:\n        desc = self.__doc__.strip().splitlines()[0].rstrip()\n    names = ', '.join([name.strip().title() for name in self.__dict__])\n    if all:\n        return '%s(%s)' % (self.__class__.__name__, names)\n    else:\n        return '%s = %s' % (self.__class__.__name__, names)\n", "def namesAndDescriptions(self, all=False):\n    names = []\n    for key in self.__dict__:\n        if key!= '__dict__' and key!= '__weakref__' and not key.startswith('_'):\n            value = getattr(self, key)\n            if value is not None:\n                if isinstance(value, type) and issubclass(value, BaseAttribute):\n                    value = value.name\n                names.append(value)\n    if all:\n        return names\n    return ', '.join(names)\n", "def namesAndDescriptions(self, all=False):\n    attrs = self.__dict__.items()\n    if all:\n        return [(k, v) for k, v in attrs if not k.startswith('__')]\n    else:\n        return [(k, v) for k, v in attrs if k.startswith('__')]\n", "def namesAndDescriptions(self, all=False):\n    if all:\n        return [self.name, self.description]\n    else:\n        return [self.name, ', '.join(self.description)]\n", "def namesAndDescriptions(self, all=False):\n    if all:\n        return [self.name, self.description]\n    else:\n        return [self.name, ', '.join(self.description)]\n", "def namesAndDescriptions(self, all=False):\n    names = []\n    descriptions = []\n    for key in sorted(self.__dict__):\n        value = getattr(self, key)\n        if (value is not None) and (not isinstance(value, Descriptor)):\n            names.append(key)\n            descriptions.append(value.description())\n    if all:\n        return (names, descriptions)\n    else:\n        return (names, descriptions, self._description)\n", "def namesAndDescriptions(self, all=False):\n    if not all:\n        return \"{0} ({1})\".format(self.name, self.description)\n    else:\n        return \"{0} ({1}, {2})\".format(self.name, self.description, self.attributes.get('description', ''))\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def namesAndDescriptions(self, all=False):\n    if all:\n        return [name for name, attr in self.__dict__.items() if type(attr) == type([])]\n    else:\n        return [name for name, attr in self.__dict__.items() if type(attr) == type({})]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    name = self.name\n    desc = self.description\n    if all:\n        return [name, desc]\n    else:\n        return [name, desc, self.__doc__]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    names = ['']\n    descs = []\n    if self.isClass:\n        names = self._get_attribute_names_from_cls(self.__class__)\n        descs = self._get_attribute_descriptions(self.__class__)\n    if all:\n        return names, descs\n    return names, descs, self.__class__.__name__\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    desc = ''\n    if self.__doc__:\n        desc = self.__doc__.strip().splitlines()[0].rstrip()\n    names = ', '.join([name.strip().title() for name in self.__dict__])\n    if all:\n        return '%s(%s)' % (self.__class__.__name__, names)\n    else:\n        return '%s = %s' % (self.__class__.__name__, names)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    names = []\n    for key in self.__dict__:\n        if key!= '__dict__' and key!= '__weakref__' and not key.startswith('_'):\n            value = getattr(self, key)\n            if value is not None:\n                if isinstance(value, type) and issubclass(value, BaseAttribute):\n                    value = value.name\n                names.append(value)\n    if all:\n        return names\n    return ', '.join(names)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    attrs = self.__dict__.items()\n    if all:\n        return [(k, v) for k, v in attrs if not k.startswith('__')]\n    else:\n        return [(k, v) for k, v in attrs if k.startswith('__')]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    if all:\n        return [self.name, self.description]\n    else:\n        return [self.name, ', '.join(self.description)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    if all:\n        return [self.name, self.description]\n    else:\n        return [self.name, ', '.join(self.description)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    names = []\n    descriptions = []\n    for key in sorted(self.__dict__):\n        value = getattr(self, key)\n        if (value is not None) and (not isinstance(value, Descriptor)):\n            names.append(key)\n            descriptions.append(value.description())\n    if all:\n        return (names, descriptions)\n    else:\n        return (names, descriptions, self._description)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    if not all:\n        return \"{0} ({1})\".format(self.name, self.description)\n    else:\n        return \"{0} ({1}, {2})\".format(self.name, self.description, self.attributes.get('description', ''))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/interface.py", "project": "pexip/os-zope", "name": "names", "docstring": "Return the attribute names defined by the interface.", "ques_id": "62b8b416eb7e40a82d2d1129", "code": ["def names(self, all=False):\n    if all:\n        return dir(self)\n    return [name for name in dir(self.__class__) if not name.startswith(\"_\")]\n", "def names(self, all=False):\n    if all:\n        return self.__attributes.keys()\n    return self.__attributes\n", "def names(self, all=False):\n    if all:\n        return self._fields\n    return [k for k in self._fields if k!= '_id']\n", "def names(self, all=False):\n    names = []\n    for attr in dir(self):\n        if attr[0]!= '_' and not callable(getattr(self, attr)):\n            names.append(attr)\n\n    if all:\n        return names\n    return names[::-1]\n", "def names(self, all=False):\n    return [key for key in dir(self) if not key.startswith(\"_\") and not callable(getattr(self, key)) and not all]\n", "def names(self, all=False):\n    if all:\n        return dir(type(self))\n    else:\n        return list(self.keys())\n", "def names(self, all=False):\n    if all:\n        return [name for name in dir(self) if not name.startswith(\"_\")]\n    else:\n        return [name for name in dir(self) if not name.startswith(\"_\")] + \\\n               [name for name in self.__dict__ if not name.startswith(\"_\")]\n", "def names(self, all=False):\n    if all:\n        return list(self.__dict__.keys())\n    return list(self.__dict__.keys()) + list(self.__origin_attrs)\n", "def names(self, all=False):\n    if all:\n        return dir(type(self))\n    return [name for name, value in inspect.getmembers(type(self))\n            if not name.startswith('_') and not inspect.isfunction(value)]\n", "def names(self, all=False):\n    if all:\n        return dir(self)\n    else:\n        return [k for k in self.__dict__ if k[0]!= '_']\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def names(self, all=False):\n    if all:\n        return dir(self)\n    return [name for name in dir(self.__class__) if not name.startswith(\"_\")]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    if all:\n        return self.__attributes.keys()\n    return self.__attributes\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    if all:\n        return self._fields\n    return [k for k in self._fields if k!= '_id']\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    names = []\n    for attr in dir(self):\n        if attr[0]!= '_' and not callable(getattr(self, attr)):\n            names.append(attr)\n\n    if all:\n        return names\n    return names[::-1]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    return [key for key in dir(self) if not key.startswith(\"_\") and not callable(getattr(self, key)) and not all]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    if all:\n        return dir(type(self))\n    else:\n        return list(self.keys())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    if all:\n        return [name for name in dir(self) if not name.startswith(\"_\")]\n    else:\n        return [name for name in dir(self) if not name.startswith(\"_\")] + \\\n               [name for name in self.__dict__ if not name.startswith(\"_\")]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    if all:\n        return list(self.__dict__.keys())\n    return list(self.__dict__.keys()) + list(self.__origin_attrs)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    if all:\n        return dir(type(self))\n    return [name for name, value in inspect.getmembers(type(self))\n            if not name.startswith('_') and not inspect.isfunction(value)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    if all:\n        return dir(self)\n    else:\n        return [k for k in self.__dict__ if k[0]!= '_']\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/declarations.py", "project": "pexip/os-zope", "name": "_normalizeargs", "docstring": "Normalize declaration arguments\n\nNormalization arguments might contain Declarions, tuples, or single\ninterfaces.\n\nAnything but individial interfaces or implements specs will be expanded.", "ques_id": "62b8b3d6eb7e40a82d2d111c", "code": ["def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    for item in sequence:\n        if isinstance(item, InterfaceClass):\n            output.append(item)\n            continue\n        if isinstance(item, Implements):\n            output.extend(_normalizeargs(item.args, output=output))\n            output.append(item)\n            continue\n        output.append(item)\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    for arg in sequence:\n        if isinstance(arg, InterfaceClass):\n            arg = arg._implied\n        elif isinstance(arg, tuple):\n            arg = _normalizeargs(arg, output)\n        elif isinstance(arg, type) and issubclass(arg, Declaration):\n            pass\n        else:\n            output.append(arg)\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    for item in sequence:\n        if isinstance(item, InterfaceClass):\n            item = _normalizeargs(item, output)\n        elif isinstance(item, Implements):\n            item = _normalizeimplements(item, output)\n        elif isinstance(item, Declarations):\n            item = _normalizedeclarations(item, output)\n        elif isinstance(item, tuple) and len(item) == 2:\n            item = _normalizeargs(item[0], output)\n        output.append(item)\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    for item in sequence:\n        if isinstance(item, InterfaceClass) or isinstance(item, Implements):\n            output.append(_normalizeargs(item, output))\n        elif isinstance(item, Declaration):\n            output.append(item)\n        else:\n            output.extend(_normalizeargs(item, output))\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    if isinstance(sequence, InterfaceClass):\n        output.append(sequence)\n        return\n    for x in sequence:\n        _normalizeargs(x, output)\n    return output\n", "def _normalizeargs(sequence, output=None):\n    output = output or []\n    for arg in sequence:\n        if isinstance(arg, (InterfaceClass, Implements)):\n            arg = arg._with_bases(output)\n        elif not isinstance(arg, (list, tuple)):\n            output.append(arg)\n            continue\n        _normalizeargs(arg, output)\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    for arg in sequence:\n        if isinstance(arg, Declaration):\n            output.append(arg._normalizeargs())\n        elif isinstance(arg, InterfaceClass) or isinstance(arg, Implements):\n            output.append(arg._normalizeargs())\n        else:\n            output.append(arg)\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    if isinstance(sequence, InterfaceClass):\n        sequence = [sequence]\n    for obj in sequence:\n        if not isinstance(obj, InterfaceClass):\n            obj = getInterface(obj)\n        output.append(obj.normalize())\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    for arg in sequence:\n        if isinstance(arg, Decl):\n            output.append(arg._normalizeargs())\n        elif isinstance(arg, InterfaceClass):\n            output.append(arg)\n        elif isinstance(arg, Implementation):\n            output.extend(arg._normalizeargs())\n        else:\n            output.append(arg)\n    return output\n", "def _normalizeargs(sequence, output=None):\n    output = output or []\n\n    def normalize(arg, output):\n        if isinstance(arg, InterfaceClass):\n            output.append(arg._impl)\n        elif isinstance(arg, InterfaceSpec):\n            output.append(arg)\n        elif isinstance(arg, Implements):\n            output.extend(arg._impls)\n        elif isinstance(arg, tuple):\n            output.append(arg)\n        elif isinstance(arg, str):\n            output.append(normalize(arg, output))\n        else:\n            for i in range(len(arg)):\n                arg[i] = normalize(arg[i], output)\n        return output\n\n    if isinstance(sequence, Implements):\n        output = normalize(sequence._impls, output)\n    elif isinstance(sequence, tuple):\n        output = normalize(tuple(sequence), output)\n    else:\n        for i in range(le"], "level": "file_runnable", "generate_results": [{"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    for item in sequence:\n        if isinstance(item, InterfaceClass):\n            output.append(item)\n            continue\n        if isinstance(item, Implements):\n            output.extend(_normalizeargs(item.args, output=output))\n            output.append(item)\n            continue\n        output.append(item)\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    for arg in sequence:\n        if isinstance(arg, InterfaceClass):\n            arg = arg._implied\n        elif isinstance(arg, tuple):\n            arg = _normalizeargs(arg, output)\n        elif isinstance(arg, type) and issubclass(arg, Declaration):\n            pass\n        else:\n            output.append(arg)\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    for item in sequence:\n        if isinstance(item, InterfaceClass):\n            item = _normalizeargs(item, output)\n        elif isinstance(item, Implements):\n            item = _normalizeimplements(item, output)\n        elif isinstance(item, Declarations):\n            item = _normalizedeclarations(item, output)\n        elif isinstance(item, tuple) and len(item) == 2:\n            item = _normalizeargs(item[0], output)\n        output.append(item)\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    for item in sequence:\n        if isinstance(item, InterfaceClass) or isinstance(item, Implements):\n            output.append(_normalizeargs(item, output))\n        elif isinstance(item, Declaration):\n            output.append(item)\n        else:\n            output.extend(_normalizeargs(item, output))\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    if isinstance(sequence, InterfaceClass):\n        output.append(sequence)\n        return\n    for x in sequence:\n        _normalizeargs(x, output)\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    output = output or []\n    for arg in sequence:\n        if isinstance(arg, (InterfaceClass, Implements)):\n            arg = arg._with_bases(output)\n        elif not isinstance(arg, (list, tuple)):\n            output.append(arg)\n            continue\n        _normalizeargs(arg, output)\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    for arg in sequence:\n        if isinstance(arg, Declaration):\n            output.append(arg._normalizeargs())\n        elif isinstance(arg, InterfaceClass) or isinstance(arg, Implements):\n            output.append(arg._normalizeargs())\n        else:\n            output.append(arg)\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    if isinstance(sequence, InterfaceClass):\n        sequence = [sequence]\n    for obj in sequence:\n        if not isinstance(obj, InterfaceClass):\n            obj = getInterface(obj)\n        output.append(obj.normalize())\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n    for arg in sequence:\n        if isinstance(arg, Decl):\n            output.append(arg._normalizeargs())\n        elif isinstance(arg, InterfaceClass):\n            output.append(arg)\n        elif isinstance(arg, Implementation):\n            output.extend(arg._normalizeargs())\n        else:\n            output.append(arg)\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    output = output or []\n\n    def normalize(arg, output):\n        if isinstance(arg, InterfaceClass):\n            output.append(arg._impl)\n        elif isinstance(arg, InterfaceSpec):\n            output.append(arg)\n        elif isinstance(arg, Implements):\n            output.extend(arg._impls)\n        elif isinstance(arg, tuple):\n            output.append(arg)\n        elif isinstance(arg, str):\n            output.append(normalize(arg, output))\n        else:\n            for i in range(len(arg)):\n                arg[i] = normalize(arg[i], output)\n        return output\n\n    if isinstance(sequence, Implements):\n        output = normalize(sequence._impls, output)\n    elif isinstance(sequence, tuple):\n        output = normalize(tuple(sequence), output)\n    else:\n        for i in range(le", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/_compat.py", "project": "pexip/os-zope", "name": "_c_optimizations_available", "docstring": "Return the C optimization module, if available, otherwise\na false value.\n\nIf the optimizations are required but not available, this\nraises the ImportError.\n\nThis does not say whether they should be used or not.", "ques_id": "62b8b3d5eb7e40a82d2d1110", "code": ["def _c_optimizations_available():\n    try:\n        from. import c_optimizations as c_optimizations\n    except ImportError:\n        return False\n    else:\n        return c_optimizations\n", "def _c_optimizations_available():\n    try:\n        import c_optimizations\n        return c_optimizations\n    except ImportError:\n        return False\n", "def _c_optimizations_available():\n    try:\n        import c_optimizations\n    except ImportError:\n        return False\n    return c_optimizations\n", "def _c_optimizations_available():\n    try:\n        import c_optimizations  # noqa\n    except ImportError:\n        return False\n    else:\n        return c_optimizations\n", "def _c_optimizations_available():\n    try:\n        import c_optimizations\n        return c_optimizations\n    except ImportError:\n        return False\n", "def _c_optimizations_available():\n    try:\n        import c_optimizations\n    except ImportError:\n        return False\n    return c_optimizations\n", "def _c_optimizations_available():\n    try:\n        import c_optimizations  # noqa\n        return c_optimizations\n    except ImportError:\n        return False\n", "def _c_optimizations_available():\n    try:\n        import C_OPTIMIZED_MODULES\n        return C_OPTIMIZED_MODULES\n    except ImportError:\n        return False\n", "def _c_optimizations_available():\n    try:\n        import c_optimizations\n        return c_optimizations\n    except ImportError:\n        return False\n", "def _c_optimizations_available():\n    try:\n        import c_optimizations  # noqa\n    except ImportError:\n        return False\n    else:\n        return c_optimizations\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _c_optimizations_available():\n    try:\n        from. import c_optimizations as c_optimizations\n    except ImportError:\n        return False\n    else:\n        return c_optimizations\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        import c_optimizations\n        return c_optimizations\n    except ImportError:\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        import c_optimizations\n    except ImportError:\n        return False\n    return c_optimizations\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        import c_optimizations  # noqa\n    except ImportError:\n        return False\n    else:\n        return c_optimizations\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        import c_optimizations\n        return c_optimizations\n    except ImportError:\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        import c_optimizations\n    except ImportError:\n        return False\n    return c_optimizations\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        import c_optimizations  # noqa\n        return c_optimizations\n    except ImportError:\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        import C_OPTIMIZED_MODULES\n        return C_OPTIMIZED_MODULES\n    except ImportError:\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        import c_optimizations\n        return c_optimizations\n    except ImportError:\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        import c_optimizations  # noqa\n    except ImportError:\n        return False\n    else:\n        return c_optimizations\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/_compat.py", "project": "pexip/os-zope", "name": "_should_attempt_c_optimizations", "docstring": "Return a true value if we should attempt to use the C optimizations.\n\nThis takes into account whether we're on PyPy and the value of the\n``PURE_PYTHON`` environment variable, as defined in `_use_c_impl`.", "ques_id": "62b8b3d4eb7e40a82d2d110f", "code": ["def _should_attempt_c_optimizations():\n    c_opt_flags = ['-O0', '-O1', '-O2']\n    return any(flag in sys.argv for flag in c_opt_flags)\n", "def _should_attempt_c_optimizations():\n    if _USE_CUDA:\n        return _should_attempt_cuda_optimizations()\n    else:\n        return _should_attempt_c_optimizations()\n", "def _should_attempt_c_optimizations():\n    return _should_use_optimizations('c')\n", "def _should_attempt_c_optimizations():\n    return _c_optimization_enabled() and _c_optimization_stack()\n", "def _should_attempt_c_optimizations():\n    # We can use the C optimizations only when the maximum number of functions\n    # is reached. If we can use the Python optimizations, we can use the C\n    # implementation.\n    return _py_optimizations() and _c_optimizations()\n", "def _should_attempt_c_optimizations():\n    if _pypy_enabled:\n        return False\n    else:\n        return hasattr(optimize, '_c_optimizations')\n", "def _should_attempt_c_optimizations():\n    return (\n        _c_optimizations_enabled()\n        and _c_optimizations_minimize_stack()\n        and not _c_optimizations_stack_forget_results()\n    )\n", "def _should_attempt_c_optimizations():\n    return False\n", "def _should_attempt_c_optimizations():\n    return os.environ.get('TRAVIS', 'false').lower() == 'true'\n", "def _should_attempt_c_optimizations():\n    return _c_optimizations_enabled() and _c_optimizations_sane()\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _should_attempt_c_optimizations():\n    c_opt_flags = ['-O0', '-O1', '-O2']\n    return any(flag in sys.argv for flag in c_opt_flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    if _USE_CUDA:\n        return _should_attempt_cuda_optimizations()\n    else:\n        return _should_attempt_c_optimizations()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    return _should_use_optimizations('c')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    return _c_optimization_enabled() and _c_optimization_stack()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    # We can use the C optimizations only when the maximum number of functions\n    # is reached. If we can use the Python optimizations, we can use the C\n    # implementation.\n    return _py_optimizations() and _c_optimizations()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    if _pypy_enabled:\n        return False\n    else:\n        return hasattr(optimize, '_c_optimizations')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    return (\n        _c_optimizations_enabled()\n        and _c_optimizations_minimize_stack()\n        and not _c_optimizations_stack_forget_results()\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    return os.environ.get('TRAVIS', 'false').lower() == 'true'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _should_attempt_c_optimizations():\n    return _c_optimizations_enabled() and _c_optimizations_sane()\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/_compat.py", "project": "pexip/os-zope", "name": "_c_optimizations_ignored", "docstring": "The opposite of `_c_optimizations_required`.", "ques_id": "62b8b3d4eb7e40a82d2d110e", "code": ["def _c_optimizations_ignored():\n    return (os.getenv('PURE_PYTHON', '').lower()!= '0')\n", "def _c_optimizations_ignored():\n    pure_python = os.environ.get(\"PURE_PYTHON\", False)\n    return pure_python is False and pure_python!= 0\n", "def _c_optimizations_ignored():\n    return (os.environ.get('PURE_PYTHON') is not None and\n            os.getenv('C_OPTIMIZATIONS_IGNORE_PURE_PYTHON') == '1')\n", "def _c_optimizations_ignored():\n    global _c_optimizations\n    return (_c_optimizations is not None) and (_c_optimizations!= 0)\n", "def _c_optimizations_ignored():\n    return (os.getenv(\"PURE_PYTHON\", None) is None and\n            os.getenv(\"COVERAGE_DEBUG\", False) is False)\n", "def _c_optimizations_ignored():\n    return os.getenv(\"PURE_PYTHON\", \"\").lower() == \"0\"\n", "def _c_optimizations_ignored():\n    return (\n        os.environ.get(\"PURE_PYTHON\", None) is None\n        and os.getenv(\"C_OPTIMIZE\", False)\n        == \"0\"\n    )\n", "def _c_optimizations_ignored():\n    return (get_env().get('PURE_PYTHON', False) is not None and\n            get_env().get('C_OPTIMIZATIONS_IGNORE_C_EXCEPTIONS', False))\n", "def _c_optimizations_ignored():\n    if not os.environ.get(\"PURE_PYTHON\"):\n        return True\n    return False\n", "def _c_optimizations_ignored():\n    return os.environ.get('PURE_PYTHON') is None and os.getenv('C_OPTIMIZATIONS') is False\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def _c_optimizations_ignored():\n    return (os.getenv('PURE_PYTHON', '').lower()!= '0')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_ignored():\n    pure_python = os.environ.get(\"PURE_PYTHON\", False)\n    return pure_python is False and pure_python!= 0\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _c_optimizations_ignored():\n    return (os.environ.get('PURE_PYTHON') is not None and\n            os.getenv('C_OPTIMIZATIONS_IGNORE_PURE_PYTHON') == '1')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _c_optimizations_ignored():\n    global _c_optimizations\n    return (_c_optimizations is not None) and (_c_optimizations!= 0)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_ignored():\n    return (os.getenv(\"PURE_PYTHON\", None) is None and\n            os.getenv(\"COVERAGE_DEBUG\", False) is False)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_ignored():\n    return os.getenv(\"PURE_PYTHON\", \"\").lower() == \"0\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _c_optimizations_ignored():\n    return (\n        os.environ.get(\"PURE_PYTHON\", None) is None\n        and os.getenv(\"C_OPTIMIZE\", False)\n        == \"0\"\n    )\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _c_optimizations_ignored():\n    return (get_env().get('PURE_PYTHON', False) is not None and\n            get_env().get('C_OPTIMIZATIONS_IGNORE_C_EXCEPTIONS', False))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_ignored():\n    if not os.environ.get(\"PURE_PYTHON\"):\n        return True\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_ignored():\n    return os.environ.get('PURE_PYTHON') is None and os.getenv('C_OPTIMIZATIONS') is False\n", "is_pass": true, "return_code": 0}]}
{"file_path": "src/zope/interface/_compat.py", "project": "pexip/os-zope", "name": "_c_optimizations_required", "docstring": "Return a true value if the C optimizations are required.\n\nThis uses the ``PURE_PYTHON`` variable as documented in `_use_c_impl`.", "ques_id": "62b8b3d4eb7e40a82d2d110d", "code": ["def _c_optimizations_required():\n    # Note: this function is only for testing purposes.\n    return _C_OPTIMIZED and _C_PARALLEL_INDENT > 0\n", "def _c_optimizations_required():\n    return _c_optimizations_enabled() and _c_optimizations_forced()\n", "def _c_optimizations_required():\n    return _c_optimizations_flag and _c_optimizations_available()\n", "def _c_optimizations_required():\n    if c_optimizations_enabled():\n        return True\n\n    return False\n", "def _c_optimizations_required():\n    return (_c_optimizations_enabled() and\n            _c_optimizations_forced_sync_on() and\n            _c_optimizations_sync_on())\n", "def _c_optimizations_required():\n    return (c_opt_state.optimization_required or\n            _c_optimizations_enabled() or\n            _c_optimizations_parallel() or\n            _c_optimizations_parallel_enabled())\n", "def _c_optimizations_required():\n    # If c_optimizations is not set or empty, return True.\n    if not _c_optimizations():\n        return True\n\n    # If the optimization function requires c_optimizations, return True.\n    if _c_optimizations_function():\n        return True\n\n    # If the optimization function requires a C function, return True.\n    if _c_optimizations_function('c_optimizations'):\n        return True\n\n    # Otherwise, return False.\n    return False\n", "def _c_optimizations_required():\n    return (\n        c_optimizations_enabled() and\n        _c_optimizations_enabled() and\n        disable_c_code_optimizations()\n    )\n", "def _c_optimizations_required():\n    if c_opt_required:\n        logging.debug(\"Optimization required.\")\n        return True\n    else:\n        return False\n", "def _c_optimizations_required():\n    return (\n        c_opt_count() < MAX_OPTIMIZATIONS\n        and c_opt_infected() < MAX_INFECTED_OPTIMIZATIONS\n    )\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def _c_optimizations_required():\n    # Note: this function is only for testing purposes.\n    return _C_OPTIMIZED and _C_PARALLEL_INDENT > 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_required():\n    return _c_optimizations_enabled() and _c_optimizations_forced()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_required():\n    return _c_optimizations_flag and _c_optimizations_available()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_required():\n    if c_optimizations_enabled():\n        return True\n\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_required():\n    return (_c_optimizations_enabled() and\n            _c_optimizations_forced_sync_on() and\n            _c_optimizations_sync_on())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_required():\n    return (c_opt_state.optimization_required or\n            _c_optimizations_enabled() or\n            _c_optimizations_parallel() or\n            _c_optimizations_parallel_enabled())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_required():\n    # If c_optimizations is not set or empty, return True.\n    if not _c_optimizations():\n        return True\n\n    # If the optimization function requires c_optimizations, return True.\n    if _c_optimizations_function():\n        return True\n\n    # If the optimization function requires a C function, return True.\n    if _c_optimizations_function('c_optimizations'):\n        return True\n\n    # Otherwise, return False.\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_required():\n    return (\n        c_optimizations_enabled() and\n        _c_optimizations_enabled() and\n        disable_c_code_optimizations()\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_required():\n    if c_opt_required:\n        logging.debug(\"Optimization required.\")\n        return True\n    else:\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_required():\n    return (\n        c_opt_count() < MAX_OPTIMIZATIONS\n        and c_opt_infected() < MAX_INFECTED_OPTIMIZATIONS\n    )\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/histogram.py", "project": "ynikitenko/lena", "name": "reset", "docstring": "Reset the histogram.\n\nCurrent context is reset to an empty dict.\nBins are reinitialized with the *initial_value*\nor with *make_bins()* (depending on the initialization).", "ques_id": "62b87b989a0c4fa8b80b35ee", "code": ["def reset(self):\n    self.bins = {}\n    self.current_bin = None\n    self.bin_size = 0\n    self.current_total = 0\n", "def reset(self):\n    self._ctx = {}\n    self._bins = {}\n    self._make_bins()\n", "def reset(self):\n    self.__initial_value = {}\n    self.__bins = {}\n", "def reset(self):\n    self.__dict__ = {}\n    self.make_bins()\n", "def reset(self):\n    self.__dict__.clear()\n    self.make_bins()\n", "def reset(self):\n    self.__dict__ = {}\n    self.make_bins()\n", "def reset(self):\n    self._current_context = {}\n    self._current_bins = {}\n    self._current_bin_values = {}\n    self._current_bin_results = {}\n", "def reset(self):\n    self._context.clear()\n    self._context['bins'] = {}\n    self._context['currency'] = ''\n    self._context['formats'] = {}\n    self._context['default'] = {'currency': ''}\n    self._context['currencies'] = {}\n    self._context['_formats_key'] = None\n", "def reset(self):\n    self.__dict__.clear()\n    self.make_bins()\n", "def reset(self):\n    self._ctx = {}\n    self._bins = {}\n    self._bin_idx = 0\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def reset(self):\n    self.bins = {}\n    self.current_bin = None\n    self.bin_size = 0\n    self.current_total = 0\n", "is_pass": true, "return_code": 0}, {"generate_code": "def reset(self):\n    self._ctx = {}\n    self._bins = {}\n    self._make_bins()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self.__initial_value = {}\n    self.__bins = {}\n", "is_pass": true, "return_code": 0}, {"generate_code": "def reset(self):\n    self.__dict__ = {}\n    self.make_bins()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self.__dict__.clear()\n    self.make_bins()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self.__dict__ = {}\n    self.make_bins()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self._current_context = {}\n    self._current_bins = {}\n    self._current_bin_values = {}\n    self._current_bin_results = {}\n", "is_pass": true, "return_code": 0}, {"generate_code": "def reset(self):\n    self._context.clear()\n    self._context['bins'] = {}\n    self._context['currency'] = ''\n    self._context['formats'] = {}\n    self._context['default'] = {'currency': ''}\n    self._context['currencies'] = {}\n    self._context['_formats_key'] = None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self.__dict__.clear()\n    self.make_bins()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self._ctx = {}\n    self._bins = {}\n    self._bin_idx = 0\n", "is_pass": true, "return_code": 0}]}
{"file_path": "lena/structures/graph.py", "project": "ynikitenko/lena", "name": "to_csv", "docstring": ".. deprecated:: 0.5 in Lena 0.5 to_csv is not used.\n      Iterables are converted to tables.\n\nConvert graph's points to CSV.\n\n*separator* delimits values, the default is comma.\n\n*header*, if not ``None``, is the first string of the output\n(new line is added automatically).\n\nSince a graph can be multidimensional,\nfor each point first its coordinate is converted to string\n(separated by *separator*), then each part of its value.\n\nTo convert :class:`Graph` to CSV inside a Lena sequence,\nuse :class:`lena.output.ToCSV`.", "ques_id": "62b87b859a0c4fa8b80b35d7", "code": ["def to_csv(self, separator=\",\", header=None):\n    from.output import ToCSV\n    return ToCSV(self, separator=separator, header=header)\n", "def to_csv(self, separator=\",\", header=None):\n    return to_csv(self, separator=separator, header=header)\n", "def to_csv(self, separator=\",\", header=None):\n    from..output import ToCSV\n    return ToCSV(self, separator=separator, header=header)\n", "def to_csv(self, separator=\",\", header=None):\n    from..utils.io import StringIO\n\n    return ToCSV(self, separator=separator, header=header).stream()\n", "def to_csv(self, separator=\",\", header=None):\n    import warnings\n    warnings.warn(\"to_csv is deprecated. Please use graph.to_csv(separator, header) instead\",\n                  DeprecationWarning)\n    return self.to_csv_iterable(separator, header)\n", "def to_csv(self, separator=\",\", header=None):\n    return ToCSV(self, separator=separator, header=header)\n", "def to_csv(self, separator=\",\", header=None):\n    return to_csv(self, separator=separator, header=header)\n", "def to_csv(self, separator=\",\", header=None):\n    return list(self.graph.points_to_csv(separator=separator, header=header))\n", "def to_csv(self, separator=\",\", header=None):\n    return ToCSV(separator=separator, header=header).do(self)\n", "def to_csv(self, separator=\",\", header=None):\n    import warnings\n    from..utils.deprecation import deprecate\n    warnings.warn(\"to_csv is deprecated, and will be removed in a \"\n                  \"future release. Please use graph.to_csv(separator=',', \"\n                  \"header=None) instead.\",\n                  DeprecationWarning)\n    return self.to_csv_from_points(separator=separator, header=header)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def to_csv(self, separator=\",\", header=None):\n    from.output import ToCSV\n    return ToCSV(self, separator=separator, header=header)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    return to_csv(self, separator=separator, header=header)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    from..output import ToCSV\n    return ToCSV(self, separator=separator, header=header)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    from..utils.io import StringIO\n\n    return ToCSV(self, separator=separator, header=header).stream()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    import warnings\n    warnings.warn(\"to_csv is deprecated. Please use graph.to_csv(separator, header) instead\",\n                  DeprecationWarning)\n    return self.to_csv_iterable(separator, header)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    return ToCSV(self, separator=separator, header=header)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    return to_csv(self, separator=separator, header=header)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    return list(self.graph.points_to_csv(separator=separator, header=header))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    return ToCSV(separator=separator, header=header).do(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    import warnings\n    from..utils.deprecation import deprecate\n    warnings.warn(\"to_csv is deprecated, and will be removed in a \"\n                  \"future release. Please use graph.to_csv(separator=',', \"\n                  \"header=None) instead.\",\n                  DeprecationWarning)\n    return self.to_csv_from_points(separator=separator, header=header)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/graph.py", "project": "ynikitenko/lena", "name": "_get_err_indices", "docstring": "Get error indices corresponding to a coordinate.", "ques_id": "62b87b839a0c4fa8b80b35cb", "code": ["def _get_err_indices(self, coord_name):\n    if coord_name in self._coord_names:\n        return self._coord_names.index(coord_name)\n    else:\n        return []\n", "def _get_err_indices(self, coord_name):\n    return [i for i, val in enumerate(self.coords) if val == coord_name]\n", "def _get_err_indices(self, coord_name):\n    return [i for i, (c, m) in enumerate(self._coords) if c == coord_name]\n", "def _get_err_indices(self, coord_name):\n    if coord_name not in self._coord_name_to_err_dict:\n        return []\n    return [self._coord_name_to_err_dict[coord_name][i]\n            for i in range(self.dim)]\n", "def _get_err_indices(self, coord_name):\n    err_idx = []\n    for idx, (name, val) in enumerate(self.coords[coord_name].items()):\n        if isinstance(val, (int, float, np.int64, np.int32)):\n            err_idx.append(idx)\n    return err_idx\n", "def _get_err_indices(self, coord_name):\n    err_indices = []\n    for i, c in enumerate(self._coords):\n        if c == coord_name:\n            err_indices.append(i)\n\n    return err_indices\n", "def _get_err_indices(self, coord_name):\n    if coord_name not in self._coord_names:\n        raise ValueError(\"coord_name '%s' is not a valid coordinate name.\" % coord_name)\n    return self._coord_names.index(coord_name)\n", "def _get_err_indices(self, coord_name):\n\n    return [i for i, coord in enumerate(self._coords)\n            if coord_name in coord.name]\n", "def _get_err_indices(self, coord_name):\n    return [i for i, c in enumerate(self.__coords) if c.name == coord_name]\n", "def _get_err_indices(self, coord_name):\n    return [i for i, (x, y) in enumerate(self._coords)\n            if x == coord_name and y == coord_name]\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def _get_err_indices(self, coord_name):\n    if coord_name in self._coord_names:\n        return self._coord_names.index(coord_name)\n    else:\n        return []\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    return [i for i, val in enumerate(self.coords) if val == coord_name]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    return [i for i, (c, m) in enumerate(self._coords) if c == coord_name]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    if coord_name not in self._coord_name_to_err_dict:\n        return []\n    return [self._coord_name_to_err_dict[coord_name][i]\n            for i in range(self.dim)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    err_idx = []\n    for idx, (name, val) in enumerate(self.coords[coord_name].items()):\n        if isinstance(val, (int, float, np.int64, np.int32)):\n            err_idx.append(idx)\n    return err_idx\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    err_indices = []\n    for i, c in enumerate(self._coords):\n        if c == coord_name:\n            err_indices.append(i)\n\n    return err_indices\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    if coord_name not in self._coord_names:\n        raise ValueError(\"coord_name '%s' is not a valid coordinate name.\" % coord_name)\n    return self._coord_names.index(coord_name)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n\n    return [i for i, coord in enumerate(self._coords)\n            if coord_name in coord.name]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    return [i for i, c in enumerate(self.__coords) if c.name == coord_name]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    return [i for i, (x, y) in enumerate(self._coords)\n            if x == coord_name and y == coord_name]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/graph.py", "project": "ynikitenko/lena", "name": "_update_context", "docstring": "Update *context* with the properties of this graph.\n\n*context.error* is appended with indices of errors.\nExample subcontext for a graph with fields \"E,t,error_E_low\":\n{\"error\": {\"x_low\": {\"index\": 2}}}.\nNote that error names are called \"x\", \"y\" and \"z\"\n(this corresponds to first three coordinates,\nif they are present), which allows to simplify plotting.\nExisting values are not removed\nfrom *context.value* and its subcontexts.\n\nCalled on \"destruction\" of the graph (for example,\nin :class:`.ToCSV`). By destruction we mean conversion\nto another structure (like text) in the flow.\nThe graph object is not really destroyed in this process.", "ques_id": "62b87b7e9a0c4fa8b80b35bc", "code": ["def _update_context(self, context):\n    self._update_value_context(context, self.value)\n    self._update_error_context(context, self.error)\n", "def _update_context(self, context):\n    context.error = []\n    context.value = {}\n    for key, value in self.items():\n        if key not in context.value:\n            context.value[key] = {}\n        if isinstance(value, Edge):\n            context.value[key]['edge_index'] = value.edge_index\n            context.value[key]['node_index'] = value.node_index\n        elif isinstance(value, Node):\n            context.value[key]['node_index'] = value.index\n            context.value[key]['edge_index'] = value.edge_index\n        else:\n            context.value[key] = value\n", "def _update_context(self, context):\n    if self._value is not None:\n        context.error = {\"x\": {\"index\": self._value.index}}\n", "def _update_context(self, context):\n\n    context.error = []\n    for i, (x, y, z) in enumerate(self.value):\n        try:\n            error = context.error.append(i)\n        except AttributeError:\n            error = []\n        context.value[i] = (x, y, z)\n        if isinstance(error, tuple):\n            context.error_E_low[i] = error\n        else:\n            context.error.append(error)\n", "def _update_context(self, context):\n    context.error = []\n    for k, v in self._data.items():\n        if k!= \"error\":\n            context.value[k] = v.value\n        else:\n            context.error.append(k)\n", "def _update_context(self, context):\n    self._update_error_context(context)\n    self._update_value_context(context)\n", "def _update_context(self, context):\n\n    self._update_context_properties(context)\n    self._update_context_errors(context)\n", "def _update_context(self, context):\n    for field in self._fields:\n        if field in context:\n            setattr(context[field], 'index', self._indices[field])\n        else:\n            context[field] = self._default_values[field]\n\n    for key, val in context.items():\n        if key in self._value_attrs:\n            setattr(context[key], key, val)\n        elif key in self._error_attrs:\n            setattr(context[key], key, val)\n        else:\n            raise KeyError(\"Graph key {} not found in context.\".format(key))\n", "def _update_context(self, context):\n    context.error = []\n    context.value = {}\n    context.indices = []\n    context.update(self.properties)\n    context.update(self._properties)\n    context.update(self._style)\n    context.update(self._transitions)\n    context.update(self._nodes)\n", "def _update_context(self, context):\n    # Attributes that are assigned to the context are handled by this\n    # method so it can be overridden by subclasses.\n    self._update_attributes(context, \"error\")\n    # Update context with the graph data\n    context.value = self._graph._graph\n    context.error = context.error = self._graph._graph.error\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def _update_context(self, context):\n    self._update_value_context(context, self.value)\n    self._update_error_context(context, self.error)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    context.error = []\n    context.value = {}\n    for key, value in self.items():\n        if key not in context.value:\n            context.value[key] = {}\n        if isinstance(value, Edge):\n            context.value[key]['edge_index'] = value.edge_index\n            context.value[key]['node_index'] = value.node_index\n        elif isinstance(value, Node):\n            context.value[key]['node_index'] = value.index\n            context.value[key]['edge_index'] = value.edge_index\n        else:\n            context.value[key] = value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    if self._value is not None:\n        context.error = {\"x\": {\"index\": self._value.index}}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n\n    context.error = []\n    for i, (x, y, z) in enumerate(self.value):\n        try:\n            error = context.error.append(i)\n        except AttributeError:\n            error = []\n        context.value[i] = (x, y, z)\n        if isinstance(error, tuple):\n            context.error_E_low[i] = error\n        else:\n            context.error.append(error)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    context.error = []\n    for k, v in self._data.items():\n        if k!= \"error\":\n            context.value[k] = v.value\n        else:\n            context.error.append(k)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    self._update_error_context(context)\n    self._update_value_context(context)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n\n    self._update_context_properties(context)\n    self._update_context_errors(context)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    for field in self._fields:\n        if field in context:\n            setattr(context[field], 'index', self._indices[field])\n        else:\n            context[field] = self._default_values[field]\n\n    for key, val in context.items():\n        if key in self._value_attrs:\n            setattr(context[key], key, val)\n        elif key in self._error_attrs:\n            setattr(context[key], key, val)\n        else:\n            raise KeyError(\"Graph key {} not found in context.\".format(key))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    context.error = []\n    context.value = {}\n    context.indices = []\n    context.update(self.properties)\n    context.update(self._properties)\n    context.update(self._style)\n    context.update(self._transitions)\n    context.update(self._nodes)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    # Attributes that are assigned to the context are handled by this\n    # method so it can be overridden by subclasses.\n    self._update_attributes(context, \"error\")\n    # Update context with the graph data\n    context.value = self._graph._graph\n    context.error = context.error = self._graph._graph.error\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/hist_functions.py", "project": "ynikitenko/lena", "name": "integral", "docstring": "Compute integral (scale for a histogram).\n\n*bins* contain values, and *edges* form the mesh\nfor the integration.\nTheir format is defined in :class:`.histogram` description.", "ques_id": "62b87b4f9a0c4fa8b80b3580", "code": ["def integral(bins, edges):\n    area = 0\n    for i in range(len(edges) - 1):\n        area += bins[edges[i]][edges[i + 1]]\n    return area\n", "def integral(bins, edges):\n    area = 0.0\n    for i in range(1, len(bins) - 1):\n        area += bins[i] * (edges[i - 1] + edges[i])\n    return area\n", "def integral(bins, edges):\n    if bins is None:\n        bins = np.arange(edges[0], edges[1])\n    area = 0\n    for b in bins:\n        area += (b - edges[0]) * (b - edges[1])\n    return area / 2\n", "def integral(bins, edges):\n    total = 0\n    for i in range(len(bins)):\n        for j in range(len(bins)):\n            if i == j:\n                continue\n            else:\n                total += (bins[i] + bins[j]) * (edges[i] + edges[j])\n\n    return total\n", "def integral(bins, edges):\n    if len(bins)!= len(edges):\n        raise ValueError(\"bins and edges must be the same length\")\n\n    area = 0\n    for i in range(len(bins)):\n        area += bins[i] * edges[i]\n\n    return area\n", "def integral(bins, edges):\n    area = 0\n    for x in edges:\n        area += bins[x] * (bins[x + 1] - bins[x])\n    return area\n", "def integral(bins, edges):\n    area = 0\n    for x, y in edges:\n        area += bins[x] * bins[y]\n    return area\n", "def integral(bins, edges):\n    area = 0\n    for i in range(bins):\n        area += sum(edges[i:i+2])\n    return area\n", "def integral(bins, edges):\n    area = 0\n    for i in range(bins):\n        area += edges[i] * (edges[i + 1] - edges[i])\n    return area\n", "def integral(bins, edges):\n    area = 0.0\n    for i in edges:\n        area += bins[i[0]][i[1]]\n    return area\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def integral(bins, edges):\n    area = 0\n    for i in range(len(edges) - 1):\n        area += bins[edges[i]][edges[i + 1]]\n    return area\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    area = 0.0\n    for i in range(1, len(bins) - 1):\n        area += bins[i] * (edges[i - 1] + edges[i])\n    return area\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    if bins is None:\n        bins = np.arange(edges[0], edges[1])\n    area = 0\n    for b in bins:\n        area += (b - edges[0]) * (b - edges[1])\n    return area / 2\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    total = 0\n    for i in range(len(bins)):\n        for j in range(len(bins)):\n            if i == j:\n                continue\n            else:\n                total += (bins[i] + bins[j]) * (edges[i] + edges[j])\n\n    return total\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    if len(bins)!= len(edges):\n        raise ValueError(\"bins and edges must be the same length\")\n\n    area = 0\n    for i in range(len(bins)):\n        area += bins[i] * edges[i]\n\n    return area\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    area = 0\n    for x in edges:\n        area += bins[x] * (bins[x + 1] - bins[x])\n    return area\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    area = 0\n    for x, y in edges:\n        area += bins[x] * bins[y]\n    return area\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    area = 0\n    for i in range(bins):\n        area += sum(edges[i:i+2])\n    return area\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    area = 0\n    for i in range(bins):\n        area += edges[i] * (edges[i + 1] - edges[i])\n    return area\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    area = 0.0\n    for i in edges:\n        area += bins[i[0]][i[1]]\n    return area\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/core/check_sequence_type.py", "project": "ynikitenko/lena", "name": "is_fill_request_seq", "docstring": "Test whether *seq* can be converted to a FillRequestSeq.\n\nTrue only if it is a FillRequest element\nor contains at least one such,\nand it is not a Source sequence.", "ques_id": "62b87b199a0c4fa8b80b354e", "code": ["def is_fill_request_seq(seq):\n    try:\n        [FillRequestSeq(x) for x in seq]\n    except (TypeError, ValueError):\n        return False\n    return True\n", "def is_fill_request_seq(seq):\n    try:\n        [FillRequestSeq(x) for x in seq]\n    except (TypeError, ValueError):\n        return False\n    else:\n        return True\n", "def is_fill_request_seq(seq):\n    try:\n        [FillRequestSeq(str(x)) for x in seq]\n    except (TypeError, ValueError, AttributeError):\n        return False\n    else:\n        return True\n", "def is_fill_request_seq(seq):\n    try:\n        for x in seq:\n            bool(x)\n    except TypeError:\n        return False\n    return True\n", "def is_fill_request_seq(seq):\n    try:\n        [FillRequestSeq(s) for s in seq]\n        return True\n    except (TypeError, ValueError, AttributeError):\n        return False\n", "def is_fill_request_seq(seq):\n    try:\n        [int(x) for x in seq]\n    except ValueError:\n        return False\n    return True\n", "def is_fill_request_seq(seq):\n    try:\n        for item in seq:\n            int(item)\n        return True\n    except ValueError:\n        return False\n", "def is_fill_request_seq(seq):\n    try:\n        for item in seq:\n            bool(item)\n    except TypeError:\n        return False\n    else:\n        return True\n", "def is_fill_request_seq(seq):\n    try:\n        [FillRequestSeq(req) for req in seq]\n    except (TypeError, ValueError, AttributeError):\n        return False\n    return True\n", "def is_fill_request_seq(seq):\n    try:\n        [FillRequestSeq(x) for x in seq]\n        return True\n    except (TypeError, ValueError):\n        return False\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def is_fill_request_seq(seq):\n    try:\n        [FillRequestSeq(x) for x in seq]\n    except (TypeError, ValueError):\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    try:\n        [FillRequestSeq(x) for x in seq]\n    except (TypeError, ValueError):\n        return False\n    else:\n        return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    try:\n        [FillRequestSeq(str(x)) for x in seq]\n    except (TypeError, ValueError, AttributeError):\n        return False\n    else:\n        return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    try:\n        for x in seq:\n            bool(x)\n    except TypeError:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    try:\n        [FillRequestSeq(s) for s in seq]\n        return True\n    except (TypeError, ValueError, AttributeError):\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    try:\n        [int(x) for x in seq]\n    except ValueError:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    try:\n        for item in seq:\n            int(item)\n        return True\n    except ValueError:\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    try:\n        for item in seq:\n            bool(item)\n    except TypeError:\n        return False\n    else:\n        return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    try:\n        [FillRequestSeq(req) for req in seq]\n    except (TypeError, ValueError, AttributeError):\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    try:\n        [FillRequestSeq(x) for x in seq]\n        return True\n    except (TypeError, ValueError):\n        return False\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/core/check_sequence_type.py", "project": "ynikitenko/lena", "name": "is_fill_request_el", "docstring": "Object contains executable methods 'fill' and 'request'.", "ques_id": "62b87b099a0c4fa8b80b3538", "code": ["def is_fill_request_el(obj):\n    return (isinstance(obj, FillRequest) and\n            hasattr(obj,'request_id') and\n            hasattr(obj, 'fill_amount') and\n            hasattr(obj, 'price'))\n", "def is_fill_request_el(obj):\n    return hasattr(obj, 'fill') and hasattr(obj,'request')\n", "def is_fill_request_el(obj):\n    return ('fill' in obj.attrs and\n           'request' in obj.attrs and\n           'request_id' in obj.attrs)\n", "def is_fill_request_el(obj):\n    return (\n        'fill' in dir(obj) and\n        hasattr(obj.fill, '__call__') and\n        hasattr(obj.fill,'request')\n    )\n", "def is_fill_request_el(obj):\n    return (\n        hasattr(obj, 'fill')\n        and hasattr(obj,'request')\n        and hasattr(obj, 'attributes')\n    )\n", "def is_fill_request_el(obj):\n    return (isinstance(obj, FillRequest) and\n            hasattr(obj,'request_id') and\n            hasattr(obj, 'amount') and\n            hasattr(obj, 'currency'))\n", "def is_fill_request_el(obj):\n    return (isinstance(obj, FillRequest)\n            and hasattr(obj,'request')\n            and hasattr(obj, 'total_amount'))\n", "def is_fill_request_el(obj):\n    return hasattr(obj, '_fill') and hasattr(obj, '_request')\n", "def is_fill_request_el(obj):\n    return (hasattr(obj, 'fill') and\n            hasattr(obj,'request') and\n            hasattr(obj, 'is_success'))\n", "def is_fill_request_el(obj):\n    return hasattr(obj, 'fill') and hasattr(obj,'request')\n"], "level": "self_contained", "generate_results": [{"generate_code": "def is_fill_request_el(obj):\n    return (isinstance(obj, FillRequest) and\n            hasattr(obj,'request_id') and\n            hasattr(obj, 'fill_amount') and\n            hasattr(obj, 'price'))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return hasattr(obj, 'fill') and hasattr(obj,'request')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_fill_request_el(obj):\n    return ('fill' in obj.attrs and\n           'request' in obj.attrs and\n           'request_id' in obj.attrs)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return (\n        'fill' in dir(obj) and\n        hasattr(obj.fill, '__call__') and\n        hasattr(obj.fill,'request')\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return (\n        hasattr(obj, 'fill')\n        and hasattr(obj,'request')\n        and hasattr(obj, 'attributes')\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return (isinstance(obj, FillRequest) and\n            hasattr(obj,'request_id') and\n            hasattr(obj, 'amount') and\n            hasattr(obj, 'currency'))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return (isinstance(obj, FillRequest)\n            and hasattr(obj,'request')\n            and hasattr(obj, 'total_amount'))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return hasattr(obj, '_fill') and hasattr(obj, '_request')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return (hasattr(obj, 'fill') and\n            hasattr(obj,'request') and\n            hasattr(obj, 'is_success'))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return hasattr(obj, 'fill') and hasattr(obj,'request')\n", "is_pass": true, "return_code": 0}]}
{"file_path": "lena/core/check_sequence_type.py", "project": "ynikitenko/lena", "name": "is_run_el", "docstring": "Object contains executable method 'run'.", "ques_id": "62b87af99a0c4fa8b80b3524", "code": ["def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n"], "level": "self_contained", "generate_results": [{"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}]}
{"file_path": "lena/core/check_sequence_type.py", "project": "ynikitenko/lena", "name": "is_fill_compute_el", "docstring": "Object contains executable methods 'fill' and 'compute'.", "ques_id": "62b87af69a0c4fa8b80b351a", "code": ["def is_fill_compute_el(obj):\n    return hasattr(obj, \"__fill__\") and hasattr(obj, \"__compute__\")\n", "def is_fill_compute_el(obj):\n    return hasattr(obj, '__dict__') and hasattr(obj, '__init__') and hasattr(obj, 'compute')\n", "def is_fill_compute_el(obj):\n    return hasattr(obj, '__dict__') and \\\n           isinstance(obj.__dict__, dict) and \\\n           hasattr(obj, '__weakref__') and \\\n           isinstance(obj.__weakref__(), weakref.ref)\n", "def is_fill_compute_el(obj):\n    return (hasattr(obj, '__dict__') and\n            'fill' in obj.__dict__ and\n            hasattr(obj.fill, '__call__') and\n            callable(obj.fill))\n", "def is_fill_compute_el(obj):\n    return (hasattr(obj, '__dict__') and\n            'fill' in obj.__dict__ and\n            hasattr(obj.fill, '__call__') and\n            hasattr(obj.fill, 'compute'))\n", "def is_fill_compute_el(obj):\n    return hasattr(obj, 'fill') and hasattr(obj, 'compute')\n", "def is_fill_compute_el(obj):\n    return hasattr(obj, '__dict__') and hasattr(obj, '__weakref__')\n", "def is_fill_compute_el(obj):\n    return (\n        isinstance(obj, Fill) and\n        hasattr(obj, 'compute') and\n        hasattr(obj,'set_fill_value') and\n        hasattr(obj,'set_fill_color')\n    )\n", "def is_fill_compute_el(obj):\n    return (hasattr(obj, \"__dict__\") and\n            \"_fill\" in obj.__dict__ and\n            \"_compute\" in obj.__dict__)\n", "def is_fill_compute_el(obj):\n    return hasattr(obj, '_fill_compute') and hasattr(obj, '_compute')\n"], "level": "self_contained", "generate_results": [{"generate_code": "def is_fill_compute_el(obj):\n    return hasattr(obj, \"__fill__\") and hasattr(obj, \"__compute__\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return hasattr(obj, '__dict__') and hasattr(obj, '__init__') and hasattr(obj, 'compute')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_fill_compute_el(obj):\n    return hasattr(obj, '__dict__') and \\\n           isinstance(obj.__dict__, dict) and \\\n           hasattr(obj, '__weakref__') and \\\n           isinstance(obj.__weakref__(), weakref.ref)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return (hasattr(obj, '__dict__') and\n            'fill' in obj.__dict__ and\n            hasattr(obj.fill, '__call__') and\n            callable(obj.fill))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return (hasattr(obj, '__dict__') and\n            'fill' in obj.__dict__ and\n            hasattr(obj.fill, '__call__') and\n            hasattr(obj.fill, 'compute'))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return hasattr(obj, 'fill') and hasattr(obj, 'compute')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_fill_compute_el(obj):\n    return hasattr(obj, '__dict__') and hasattr(obj, '__weakref__')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return (\n        isinstance(obj, Fill) and\n        hasattr(obj, 'compute') and\n        hasattr(obj,'set_fill_value') and\n        hasattr(obj,'set_fill_color')\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return (hasattr(obj, \"__dict__\") and\n            \"_fill\" in obj.__dict__ and\n            \"_compute\" in obj.__dict__)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return hasattr(obj, '_fill_compute') and hasattr(obj, '_compute')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/context/functions.py", "project": "ynikitenko/lena", "name": "difference", "docstring": "Return a dictionary with items from *d1* not contained in *d2*.\n\n*level* sets the maximum depth of recursion. For infinite recursion,\nset that to -1. For level 1,\nif a key is present both in *d1* and *d2* but has different values,\nit is included into the difference.\nSee :func:`intersection` for more details.\n\n*d1* and *d2* remain unchanged. However, *d1* or some of its\nsubdictionaries may be returned directly.\nMake a deep copy of the result when appropriate.\n\n.. versionadded:: 0.5\n   add keyword argument *level*.", "ques_id": "62b87af19a0c4fa8b80b34f7", "code": ["def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    if not d1:\n        return d2\n    if not d2:\n        return d1\n    if isinstance(d1, dict) and isinstance(d2, dict):\n        return _difference_dict(d1, d2, level)\n    return d1 if d1 not in d2 else d2\n", "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    d2_items = d2.items()\n    result = OrderedDict()\n    for key, value in d1_items:\n        if key not in d2 or d2[key]!= value:\n            result[level] = key\n    return result\n", "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    d1 = dict(d1)\n    return _difference(d1, d2, level)\n", "def difference(d1, d2, level=-1):\n    d = {}\n    for key in d1:\n        if key not in d2:\n            d[key] = d1[key]\n    if level!= -1:\n        d = diff(d, d1.get(level, {}), level + 1)\n    return d\n", "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    d2_set = set(d2)\n    result = {}\n    for key in d1:\n        if key not in d2_set:\n            result[key] = d1[key]\n    return result\n", "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    d = {}\n    for k in d1:\n        if k not in d2:\n            if level < 0:\n                continue\n            d[k] = d1[k]\n        elif d1[k]!= d2[k]:\n            d[k] = d1[k]\n    return d\n", "def difference(d1, d2, level=-1):\n    result = {}\n    for k in d2:\n        if k not in d1:\n            if level!= -1:\n                key_str = '.'.join([str(level), k])\n            else:\n                key_str = k\n            result[key_str] = d2[k]\n    return result\n", "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    d = {}\n    for key in d1:\n        if key not in d2 and (level == -1 or d1[key] < d2[level]):\n            level += 1\n        d[key] = d1[key]\n    for key in d2:\n        if key not in d1 and (level == -1 or d2[key] < d1[level]):\n            level -= 1\n        d[key] = d2[key]\n    return d\n", "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    if not d1:\n        return d2\n    if not d2:\n        return d1\n    if level == 0:\n        return d1\n    result = {}\n    for key in d1:\n        if key not in d2:\n            result[key] = d1[key]\n    return result\n", "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    d3 = {}\n    for k in d1:\n        if k not in d2 and level!= 0:\n            d3[k] = d1[k]\n        elif k not in d2 or d1[k]!= d2[k]:\n            d3[k] = d1[k]\n    return d3\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    if not d1:\n        return d2\n    if not d2:\n        return d1\n    if isinstance(d1, dict) and isinstance(d2, dict):\n        return _difference_dict(d1, d2, level)\n    return d1 if d1 not in d2 else d2\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    d2_items = d2.items()\n    result = OrderedDict()\n    for key, value in d1_items:\n        if key not in d2 or d2[key]!= value:\n            result[level] = key\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    d1 = dict(d1)\n    return _difference(d1, d2, level)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    d = {}\n    for key in d1:\n        if key not in d2:\n            d[key] = d1[key]\n    if level!= -1:\n        d = diff(d, d1.get(level, {}), level + 1)\n    return d\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    d2_set = set(d2)\n    result = {}\n    for key in d1:\n        if key not in d2_set:\n            result[key] = d1[key]\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    d = {}\n    for k in d1:\n        if k not in d2:\n            if level < 0:\n                continue\n            d[k] = d1[k]\n        elif d1[k]!= d2[k]:\n            d[k] = d1[k]\n    return d\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    result = {}\n    for k in d2:\n        if k not in d1:\n            if level!= -1:\n                key_str = '.'.join([str(level), k])\n            else:\n                key_str = k\n            result[key_str] = d2[k]\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    d = {}\n    for key in d1:\n        if key not in d2 and (level == -1 or d1[key] < d2[level]):\n            level += 1\n        d[key] = d1[key]\n    for key in d2:\n        if key not in d1 and (level == -1 or d2[key] < d1[level]):\n            level -= 1\n        d[key] = d2[key]\n    return d\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    if not d1:\n        return d2\n    if not d2:\n        return d1\n    if level == 0:\n        return d1\n    result = {}\n    for key in d1:\n        if key not in d2:\n            result[key] = d1[key]\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    \"Return a dictionary with items from d1 not contained in d2. \"\n    d3 = {}\n    for k in d1:\n        if k not in d2 and level!= 0:\n            d3[k] = d1[k]\n        elif k not in d2 or d1[k]!= d2[k]:\n            d3[k] = d1[k]\n    return d3\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/histogram.py", "project": "ynikitenko/lena", "name": "fill", "docstring": "Fill histogram at *coord* with the given *weight*.\n\nCoordinates outside the histogram edges are ignored.", "ques_id": "62b87af09a0c4fa8b80b34f1", "code": ["def fill(self, coord, weight=1):\n    self._data[coord] = weight\n", "def fill(self, coord, weight=1):\n    self._fill(coord, weight)\n", "def fill(self, coord, weight=1):\n    if self._bins is None:\n        raise ValueError(\"No histogram bin information available.\")\n    if coord >= self._bins or coord < 0:\n        raise ValueError(\"Invalid coordinate.\")\n    if coord < 0:\n        coord += self._bins\n    self._data[coord] += weight\n", "def fill(self, coord, weight=1):\n    if self._bins == 1:\n        return\n\n    if coord >= self._bins or coord < 0:\n        raise IndexError('coord {} outside histogram edges {}'.format(coord, self.edges))\n\n    for i in range(self._bins):\n        self._data[i][coord + i] += weight\n", "def fill(self, coord, weight=1):\n    if coord >= self.size:\n        raise IndexError('coord outside histogram')\n    self.data[coord] += weight\n", "def fill(self, coord, weight=1):\n    self._update(self._buf, coord, weight)\n", "def fill(self, coord, weight=1):\n    if not self._bin_edges:\n        raise ValueError(\"bin edges are not set\")\n    if coord in self:\n        raise ValueError(\"coordinate \" + str(coord) + \" already set\")\n\n    edges = self._bin_edges[1:] - self._bin_edges[:-1]\n    self._data[coord] = weight * np.diff(edges) / np.diff(self._bin_edges)\n", "def fill(self, coord, weight=1):\n    self._fill(self._find(coord), weight)\n", "def fill(self, coord, weight=1):\n    self._data[coord] = weight\n", "def fill(self, coord, weight=1):\n    if self._min <= coord < self._max:\n        self._hist[coord] += weight\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def fill(self, coord, weight=1):\n    self._data[coord] = weight\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    self._fill(coord, weight)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    if self._bins is None:\n        raise ValueError(\"No histogram bin information available.\")\n    if coord >= self._bins or coord < 0:\n        raise ValueError(\"Invalid coordinate.\")\n    if coord < 0:\n        coord += self._bins\n    self._data[coord] += weight\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    if self._bins == 1:\n        return\n\n    if coord >= self._bins or coord < 0:\n        raise IndexError('coord {} outside histogram edges {}'.format(coord, self.edges))\n\n    for i in range(self._bins):\n        self._data[i][coord + i] += weight\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    if coord >= self.size:\n        raise IndexError('coord outside histogram')\n    self.data[coord] += weight\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    self._update(self._buf, coord, weight)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    if not self._bin_edges:\n        raise ValueError(\"bin edges are not set\")\n    if coord in self:\n        raise ValueError(\"coordinate \" + str(coord) + \" already set\")\n\n    edges = self._bin_edges[1:] - self._bin_edges[:-1]\n    self._data[coord] = weight * np.diff(edges) / np.diff(self._bin_edges)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    self._fill(self._find(coord), weight)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    self._data[coord] = weight\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    if self._min <= coord < self._max:\n        self._hist[coord] += weight\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/data/core.py", "project": "rak-n-rok/Krake", "name": "_validate_labels", "docstring": "Check that keys and values in the given labels match against their corresponding\nregular expressions.\n\nArgs:\n    labels (dict): the different labels to validate.\n\nRaises:\n    ValidationError: if any of the keys and labels does not match their respective\n        regular expression. The error contains as message the list of all errors\n        which occurred in the labels. Each element of the list is a dictionary with\n        one key-value pair:\n        - key: the label key or label value for which an error occurred as string.\n        - value: the error message.\n\n        .. code:: python\n\n            # Example:\n            labels = {\n                \"key1\": \"valid\",\n                \"key2\": [\"invalid\"],\n                \"$$\": \"invalid\",\n                True: True,\n            }\n            try:\n                _validate_labels(labels)\n            except ValidationError as err:\n                assert err.messages == [\n                    {\"['invalid']\": 'expected string or bytes-like object'},\n                    {'$$': \"Label key '$$' does not match the regex [...]\"},\n                    {'True': 'expected string or bytes-like object'},\n                    {'True': 'expected string or bytes-like object'},\n                ]", "ques_id": "62b86aa3b4d922cb0e688d36", "code": ["def _validate_labels(labels):\n    if not isinstance(labels, dict):\n        raise ValueError('labels must be a dict')\n\n    for key, value in labels.items():\n        if key not in _LABELS:\n            raise ValueError('labels key \"{}\" is not a valid label'.format(key))\n        _LABELS[key].validate_value(value)\n", "def _validate_labels(labels):\n    for k, v in labels.items():\n        _validate_key(k)\n        _validate_value(v)\n", "def _validate_labels(labels):\n    for key, value in labels.items():\n        validate_key(key)\n        validate_value(value)\n", "def _validate_labels(labels):\n    if not isinstance(labels, dict):\n        raise ValueError('expected a dictionary')\n    for label, value in labels.items():\n        if not isinstance(label, str):\n            raise ValueError('expected a label string')\n        if not isinstance(value, str):\n            raise ValueError('expected a value string')\n", "def _validate_labels(labels):\n    for k, v in labels.items():\n        if k not in _LABELS:\n            raise ValueError('Unknown label {}'.format(k))\n        if v not in ['True', 'False']:\n            raise ValueError('Invalid value for label {}: must be True or False'.format(k))\n", "def _validate_labels(labels):\n    for k, v in labels.items():\n        assert _validate_key(k)\n        assert _validate_value(v)\n", "def _validate_labels(labels):\n    for key, value in labels.items():\n        if key not in _LABELS:\n            raise exceptions.InvalidKeyError(key)\n        if not isinstance(value, _LABELS[key]):\n            raise exceptions.InvalidValueError(key, value)\n", "def _validate_labels(labels):\n    for k, v in labels.items():\n        validate_key(k)\n        validate_value(v)\n", "def _validate_labels(labels):\n    for key in labels.keys():\n        if not key in _LABELS:\n            raise AssertionError(\n                \"Unknown label '{}' in section '{}'\".format(key, labels.section)\n            )\n        _LABELS[key].validate(labels[key])\n    return labels\n", "def _validate_labels(labels):\n    for key, value in iteritems(labels):\n        if key not in VALID_KEY_NAMES and not _validate_key(key):\n            raise AttributeError('Label \"%s\" is not a valid key.' % key)\n        if value not in VALID_VALUE_NAMES and not _validate_value(value):\n            raise AttributeError('Label \"%s\" is not a valid value.' % value)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _validate_labels(labels):\n    if not isinstance(labels, dict):\n        raise ValueError('labels must be a dict')\n\n    for key, value in labels.items():\n        if key not in _LABELS:\n            raise ValueError('labels key \"{}\" is not a valid label'.format(key))\n        _LABELS[key].validate_value(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for k, v in labels.items():\n        _validate_key(k)\n        _validate_value(v)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for key, value in labels.items():\n        validate_key(key)\n        validate_value(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    if not isinstance(labels, dict):\n        raise ValueError('expected a dictionary')\n    for label, value in labels.items():\n        if not isinstance(label, str):\n            raise ValueError('expected a label string')\n        if not isinstance(value, str):\n            raise ValueError('expected a value string')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for k, v in labels.items():\n        if k not in _LABELS:\n            raise ValueError('Unknown label {}'.format(k))\n        if v not in ['True', 'False']:\n            raise ValueError('Invalid value for label {}: must be True or False'.format(k))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for k, v in labels.items():\n        assert _validate_key(k)\n        assert _validate_value(v)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for key, value in labels.items():\n        if key not in _LABELS:\n            raise exceptions.InvalidKeyError(key)\n        if not isinstance(value, _LABELS[key]):\n            raise exceptions.InvalidValueError(key, value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for k, v in labels.items():\n        validate_key(k)\n        validate_value(v)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for key in labels.keys():\n        if not key in _LABELS:\n            raise AssertionError(\n                \"Unknown label '{}' in section '{}'\".format(key, labels.section)\n            )\n        _LABELS[key].validate(labels[key])\n    return labels\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for key, value in iteritems(labels):\n        if key not in VALID_KEY_NAMES and not _validate_key(key):\n            raise AttributeError('Label \"%s\" is not a valid key.' % key)\n        if value not in VALID_VALUE_NAMES and not _validate_value(value):\n            raise AttributeError('Label \"%s\" is not a valid value.' % value)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/data/core.py", "project": "rak-n-rok/Krake", "name": "_get_resource_name_regex", "docstring": "Build or return the regular expressions that are used to validate\nthe name of the Krake resources.\n\nReturns:\n    (re.Pattern): the compiled regular expressions, to validate\n    the resource name.", "ques_id": "62b86a9eb4d922cb0e688d25", "code": ["def _get_resource_name_regex():\n    return [\n        r'^(?P<resource_id>[^/]+)$',\n        r'^kinesis\\.kinesis\\.instances/(?P<topic_name>.+)$',\n    ]\n", "def _get_resource_name_regex():\n    return r'^(?P<resource_id>[a-z0-9\\-]+)\\/(?P<type>((?:km|s)\\/)?(?P<name>[a-zA-Z0-9\\-_\\.]+))$'\n", "def _get_resource_name_regex():\n    return r'^(?P<resource_name>(?:staging|backup|web)\\.)+[a-zA-Z0-9\\-]+$'\n", "def _get_resource_name_regex():\n    return r'^(krake|krake-)?([a-zA-Z0-9_]+)$'\n", "def _get_resource_name_regex():\n    return r\"\"\"\n    (?P<resource_id>(?:[a-z0-9]{8}-){3}[a-z0-9]{12})\\s+\n    (?P<resource_name>.+)$\n    \"\"\"\n", "def _get_resource_name_regex():\n    return [\n        r\"^resource-(?P<name>.*).kinesis$\",\n        r\"^resource-(?P<name>.*).kinesis.{0,1}$\",\n        r\"^resource-(?P<name>.*).kinesis.{0,1}.json$\",\n    ]\n", "def _get_resource_name_regex():\n    return [\n        r\"(?P<resource_id>.+?)\\.snowflake\\.com\",\n        r\"(?P<resource_id>.+?)\\.snowflake\\.net\",\n        r\"(?P<resource_id>.+?)\\.snowflake\\.org\",\n        r\"(?P<resource_id>.+?)\\.snowflake\\.com\",\n        r\"(?P<resource_id>.+?)\\.snowflake\\.net\",\n        r\"(?P<resource_id>.+?)\\.snowflake\\.org\"\n    ]\n", "def _get_resource_name_regex():\n    return r\"^(?P<resource_name>(?:sros|sros-)\\d+)$\"\n", "def _get_resource_name_regex():\n    return [\n        r\"(?P<resource_id>\\S+)\\.(?P<kinesis_stream_name>.+)\"\n        r\"\\.kinesis$\"\n    ]\n", "def _get_resource_name_regex():\n    return [\n        r\"^(snowflake|hive|mysql|mssql|sqlite|sqlite3|postgresql|snowflake)\\.(.*)$\",\n    ]\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _get_resource_name_regex():\n    return [\n        r'^(?P<resource_id>[^/]+)$',\n        r'^kinesis\\.kinesis\\.instances/(?P<topic_name>.+)$',\n    ]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    return r'^(?P<resource_id>[a-z0-9\\-]+)\\/(?P<type>((?:km|s)\\/)?(?P<name>[a-zA-Z0-9\\-_\\.]+))$'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    return r'^(?P<resource_name>(?:staging|backup|web)\\.)+[a-zA-Z0-9\\-]+$'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    return r'^(krake|krake-)?([a-zA-Z0-9_]+)$'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    return r\"\"\"\n    (?P<resource_id>(?:[a-z0-9]{8}-){3}[a-z0-9]{12})\\s+\n    (?P<resource_name>.+)$\n    \"\"\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    return [\n        r\"^resource-(?P<name>.*).kinesis$\",\n        r\"^resource-(?P<name>.*).kinesis.{0,1}$\",\n        r\"^resource-(?P<name>.*).kinesis.{0,1}.json$\",\n    ]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    return [\n        r\"(?P<resource_id>.+?)\\.snowflake\\.com\",\n        r\"(?P<resource_id>.+?)\\.snowflake\\.net\",\n        r\"(?P<resource_id>.+?)\\.snowflake\\.org\",\n        r\"(?P<resource_id>.+?)\\.snowflake\\.com\",\n        r\"(?P<resource_id>.+?)\\.snowflake\\.net\",\n        r\"(?P<resource_id>.+?)\\.snowflake\\.org\"\n    ]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    return r\"^(?P<resource_name>(?:sros|sros-)\\d+)$\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    return [\n        r\"(?P<resource_id>\\S+)\\.(?P<kinesis_stream_name>.+)\"\n        r\"\\.kinesis$\"\n    ]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    return [\n        r\"^(snowflake|hive|mysql|mssql|sqlite|sqlite3|postgresql|snowflake)\\.(.*)$\",\n    ]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/data/core.py", "project": "rak-n-rok/Krake", "name": "validate_value", "docstring": "Validate the given value against the corresponding regular expression.\n\nArgs:\n    value: the string to validate\n\nRaises:\n    ValidationError: if the given value is not conform to the regular expression.", "ques_id": "62b86a4fb4d922cb0e688cf8", "code": ["def validate_value(value):\n    pattern = re.compile(value)\n    return pattern.match(value)\n", "def validate_value(value):\n    return _REGEX_PATTERN.match(value)\n", "def validate_value(value):\n    if isinstance(value, six.string_types):\n        value = re.compile(value)\n    return value\n", "def validate_value(value):\n    return re.match(REGEX, value)\n", "def validate_value(value):\n    regex = re.compile(value)\n    return regex.match(value)\n", "def validate_value(value):\n    regex = value_to_regex(value)\n    return re.match(regex, value, flags=re.IGNORECASE)\n", "def validate_value(value):\n    regex = REGEX_VALUES[value]\n    if not re.search(regex, value):\n        raise ValueError('Value does not match the regular expression')\n", "def validate_value(value):\n    if not isinstance(value, str):\n        raise ValueError('expected a string value, got {}'.format(type(value)))\n    match = REGEX_PATTERN.match(value)\n    if not match:\n        raise ValueError('invalid regular expression: {}'.format(value))\n    return match.groupdict()\n", "def validate_value(value):\n    value = str(value)\n    regex = get_regex(value)\n    if not regex:\n        raise ValueError(\"Value %s is not a valid regular expression\" % value)\n    return regex\n", "def validate_value(value):\n    return _REGEX_VALUE.match(value)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def validate_value(value):\n    pattern = re.compile(value)\n    return pattern.match(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    return _REGEX_PATTERN.match(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    if isinstance(value, six.string_types):\n        value = re.compile(value)\n    return value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    return re.match(REGEX, value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    regex = re.compile(value)\n    return regex.match(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    regex = value_to_regex(value)\n    return re.match(regex, value, flags=re.IGNORECASE)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    regex = REGEX_VALUES[value]\n    if not re.search(regex, value):\n        raise ValueError('Value does not match the regular expression')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    if not isinstance(value, str):\n        raise ValueError('expected a string value, got {}'.format(type(value)))\n    match = REGEX_PATTERN.match(value)\n    if not match:\n        raise ValueError('invalid regular expression: {}'.format(value))\n    return match.groupdict()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    value = str(value)\n    regex = get_regex(value)\n    if not regex:\n        raise ValueError(\"Value %s is not a valid regular expression\" % value)\n    return regex\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    return _REGEX_VALUE.match(value)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/data/core.py", "project": "rak-n-rok/Krake", "name": "validate_key", "docstring": "Validate the given key against the corresponding regular expression.\n\nArgs:\n    key: the string to validate\n\nRaises:\n    ValidationError: if the given key is not conform to the regular expression.", "ques_id": "62b86a4fb4d922cb0e688cf7", "code": ["def validate_key(key):\n    return _KEY_PATTERN.match(key)\n", "def validate_key(key):\n    # TODO: Implement this function\n    raise NotImplementedError(\"Not yet implemented.\")\n", "def validate_key(key):\n    if not KEY_RE.match(key):\n        raise ValueError(\"Invalid key %r\" % key)\n", "def validate_key(key):\n    regex = key_regex()\n    return regex.match(key)\n", "def validate_key(key):\n    regex = re.compile(REGEX_KEY)\n    if not regex.match(key):\n        raise InvalidKey('Key \"{}\" is not valid.'.format(key))\n", "def validate_key(key):\n    return _KEY_RE.match(key)\n", "def validate_key(key):\n    return re.match(_KEY_REGEX, key)\n", "def validate_key(key):\n    return _key_re.match(key)\n", "def validate_key(key):\n    regex = _keys[key]['regex']\n    if not isinstance(regex, re.__class__):\n        raise ValueError(\"Invalid regular expression: \" + repr(regex))\n", "def validate_key(key):\n    if not KEY_RE.match(key):\n        raise InvalidKeyError('Invalid key \"{}\". Must match the regular expression \"{}\".'.format(key, KEY_REGEX))\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def validate_key(key):\n    return _KEY_PATTERN.match(key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    # TODO: Implement this function\n    raise NotImplementedError(\"Not yet implemented.\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    if not KEY_RE.match(key):\n        raise ValueError(\"Invalid key %r\" % key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    regex = key_regex()\n    return regex.match(key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    regex = re.compile(REGEX_KEY)\n    if not regex.match(key):\n        raise InvalidKey('Key \"{}\" is not valid.'.format(key))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    return _KEY_RE.match(key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    return re.match(_KEY_REGEX, key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    return _key_re.match(key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    regex = _keys[key]['regex']\n    if not isinstance(regex, re.__class__):\n        raise ValueError(\"Invalid regular expression: \" + repr(regex))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    if not KEY_RE.match(key):\n        raise InvalidKeyError('Invalid key \"{}\". Must match the regular expression \"{}\".'.format(key, KEY_REGEX))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/controller/kubernetes/hooks.py", "project": "rak-n-rok/Krake", "name": "generate_default_observer_schema_dict", "docstring": "Together with :func:``generate_default_observer_schema_list``, this function is\ncalled recursively to generate part of a default ``observer_schema`` from part of a\nKubernetes resource, defined respectively by ``manifest_dict`` or ``manifest_list``.\n\nArgs:\n    manifest_dict (dict): Partial Kubernetes resources\n    first_level (bool, optional): If True, indicates that the dictionary represents\n        the whole observer schema of a Kubernetes resource\n\nReturns:\n    dict: Generated partial observer_schema\n\nThis function creates a new dictionary from ``manifest_dict`` and replaces all\nnon-list and non-dict values by ``None``.\n\nIn case of ``first_level`` dictionary (i.e. complete ``observer_schema`` for a\nresource), the values of the identifying fields are copied from the manifest file.", "ques_id": "62b86a01b4d922cb0e688ccc", "code": ["def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if first_level:\n        default_observer_schema_dict = {}\n    else:\n        default_observer_schema_dict = {\n            'type':'string',\n            'format': 'uri'\n        }\n    default_observer_schema_dict['format'] = \\\n        manifest_dict.get('default-observer-format', 'uri')\n    return default_observer_schema_dict\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    # generate dict of value types\n    value_types = {}\n    for key in manifest_dict:\n        if not first_level:\n            yield '', ''\n        value_types[key] = generate_default_value_type(manifest_dict, key)\n        if value_types[key] is None:\n            yield '', ''\n        else:\n            yield key, value_types[key]\n    # generate new dict of value types\n    yield '', ''\n    for key in sorted(value_types.keys()):\n        yield key, value_types[key]\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if not first_level:\n        yield 'default', None\n\n    for key, value in manifest_dict['properties'].items():\n        if isinstance(value, dict):\n            yield key, generate_default_observer_schema_dict(value, first_level=False)\n        else:\n            yield key, value\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    observer_schema_dict = {}\n\n    for key, value in manifest_dict.items():\n        if isinstance(value, dict):\n            if first_level:\n                observer_schema_dict[key] = {}\n            else:\n                observer_schema_dict[key] = []\n            generate_default_observer_schema_dict(\n                observer_schema_dict[key], value, first_level)\n        else:\n            if first_level:\n                observer_schema_dict[key] = value\n            else:\n                observer_schema_dict[key] = {}\n    return observer_schema_dict\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    schema_dict = {}\n    if first_level:\n        for key, value in manifest_dict.items():\n            if isinstance(value, dict):\n                schema_dict[key] = generate_default_observer_schema_dict(\n                    value, first_level=False\n                )\n            else:\n                schema_dict[key] = value\n        return schema_dict\n    else:\n        for key, value in manifest_dict.items():\n            if isinstance(value, list):\n                schema_dict[key] = generate_default_observer_schema_list(\n                    value, first_level=False\n                )\n            else:\n                schema_dict[key] = value\n        return schema_dict\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    schema_dict = {}\n    for key, value in manifest_dict.items():\n        key_type = type(key)\n        if key_type is dict:\n            value_type = type(value)\n        elif key_type is list:\n            value_type = type([])\n        else:\n            value_type = type(value)\n        if first_level:\n            schema_dict[key] = {\n                \"type\": \"string\",\n                \"format\": \"string\"\n            }\n            schema_dict[key][\"default\"] = value\n            continue\n        schema_dict[key] = {\n            \"type\": \"string\",\n            \"format\": \"string\"\n        }\n        schema_dict[key][\"default\"] = value\n        schema_dict[key][\"minimum\"] = key_type(value)\n        schema_dict[key][\"maximum\"] = key_type(value)\n   ", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    schema_dict = {}\n    for key in manifest_dict:\n        schema_dict[key] = generate_default_observer_schema_value_type(\n            manifest_dict[key], first_level=first_level\n        )\n\n    return schema_dict\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    schema_dict = copy.deepcopy(manifest_dict)\n    for key in schema_dict:\n        if first_level:\n            value_type = type(schema_dict[key])\n            if value_type == list:\n                schema_dict[key] = list(map(lambda item: generate_default_observer_schema_dict(item), schema_dict[key]))\n            elif value_type == dict:\n                schema_dict[key] = dict(map(lambda item: generate_default_observer_schema_dict(item), schema_dict[key]))\n            else:\n                schema_dict[key] = generate_default_observer_schema_dict(schema_dict[key])\n        else:\n            if schema_dict[key] == '':\n                schema_dict[key] = None\n            else:\n                schema_dict[key] = generate_default_observer_schema_dict(schema_dict[key])\n    return schema_dict\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    default_schema_dict = {}\n    for key, value in manifest_dict.items():\n        if isinstance(value, dict):\n            if not first_level:\n                default_schema_dict[key] = {}\n            first_level = True\n            for k, v in value.items():\n                default_schema_dict[key][k] = generate_default_observer_schema_dict(v, first_level)\n        elif isinstance(value, list):\n            default_schema_dict[key] = []\n            for idx, element in enumerate(value):\n                if isinstance(element, dict):\n                    if not first_level:\n                        default_schema_dict[key][idx] = {}\n                    first_level = False\n                    for k, v in element.items():\n                     ", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    default_observer_schema_dict = {}\n    for key, value in manifest_dict.items():\n        if key in OBSERVER_SCHEMA_KEYS:\n            if value is None and not first_level:\n                continue\n            if value is None:\n                default_observer_schema_dict[key] = None\n            elif isinstance(value, list):\n                if len(value) > 0:\n                    default_observer_schema_dict[key] = []\n                for item in value:\n                    if isinstance(item, dict):\n                        default_observer_schema_dict[key].append(item)\n                    else:\n                        default_observer_schema_dict[key].append(item.serialize(\n                            allow_unknown=first_level))\n           "], "level": "file_runnable", "generate_results": [{"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if first_level:\n        default_observer_schema_dict = {}\n    else:\n        default_observer_schema_dict = {\n            'type':'string',\n            'format': 'uri'\n        }\n    default_observer_schema_dict['format'] = \\\n        manifest_dict.get('default-observer-format', 'uri')\n    return default_observer_schema_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    # generate dict of value types\n    value_types = {}\n    for key in manifest_dict:\n        if not first_level:\n            yield '', ''\n        value_types[key] = generate_default_value_type(manifest_dict, key)\n        if value_types[key] is None:\n            yield '', ''\n        else:\n            yield key, value_types[key]\n    # generate new dict of value types\n    yield '', ''\n    for key in sorted(value_types.keys()):\n        yield key, value_types[key]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if not first_level:\n        yield 'default', None\n\n    for key, value in manifest_dict['properties'].items():\n        if isinstance(value, dict):\n            yield key, generate_default_observer_schema_dict(value, first_level=False)\n        else:\n            yield key, value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    observer_schema_dict = {}\n\n    for key, value in manifest_dict.items():\n        if isinstance(value, dict):\n            if first_level:\n                observer_schema_dict[key] = {}\n            else:\n                observer_schema_dict[key] = []\n            generate_default_observer_schema_dict(\n                observer_schema_dict[key], value, first_level)\n        else:\n            if first_level:\n                observer_schema_dict[key] = value\n            else:\n                observer_schema_dict[key] = {}\n    return observer_schema_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    schema_dict = {}\n    if first_level:\n        for key, value in manifest_dict.items():\n            if isinstance(value, dict):\n                schema_dict[key] = generate_default_observer_schema_dict(\n                    value, first_level=False\n                )\n            else:\n                schema_dict[key] = value\n        return schema_dict\n    else:\n        for key, value in manifest_dict.items():\n            if isinstance(value, list):\n                schema_dict[key] = generate_default_observer_schema_list(\n                    value, first_level=False\n                )\n            else:\n                schema_dict[key] = value\n        return schema_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    schema_dict = {}\n    for key, value in manifest_dict.items():\n        key_type = type(key)\n        if key_type is dict:\n            value_type = type(value)\n        elif key_type is list:\n            value_type = type([])\n        else:\n            value_type = type(value)\n        if first_level:\n            schema_dict[key] = {\n                \"type\": \"string\",\n                \"format\": \"string\"\n            }\n            schema_dict[key][\"default\"] = value\n            continue\n        schema_dict[key] = {\n            \"type\": \"string\",\n            \"format\": \"string\"\n        }\n        schema_dict[key][\"default\"] = value\n        schema_dict[key][\"minimum\"] = key_type(value)\n        schema_dict[key][\"maximum\"] = key_type(value)\n   ", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    schema_dict = {}\n    for key in manifest_dict:\n        schema_dict[key] = generate_default_observer_schema_value_type(\n            manifest_dict[key], first_level=first_level\n        )\n\n    return schema_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    schema_dict = copy.deepcopy(manifest_dict)\n    for key in schema_dict:\n        if first_level:\n            value_type = type(schema_dict[key])\n            if value_type == list:\n                schema_dict[key] = list(map(lambda item: generate_default_observer_schema_dict(item), schema_dict[key]))\n            elif value_type == dict:\n                schema_dict[key] = dict(map(lambda item: generate_default_observer_schema_dict(item), schema_dict[key]))\n            else:\n                schema_dict[key] = generate_default_observer_schema_dict(schema_dict[key])\n        else:\n            if schema_dict[key] == '':\n                schema_dict[key] = None\n            else:\n                schema_dict[key] = generate_default_observer_schema_dict(schema_dict[key])\n    return schema_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    default_schema_dict = {}\n    for key, value in manifest_dict.items():\n        if isinstance(value, dict):\n            if not first_level:\n                default_schema_dict[key] = {}\n            first_level = True\n            for k, v in value.items():\n                default_schema_dict[key][k] = generate_default_observer_schema_dict(v, first_level)\n        elif isinstance(value, list):\n            default_schema_dict[key] = []\n            for idx, element in enumerate(value):\n                if isinstance(element, dict):\n                    if not first_level:\n                        default_schema_dict[key][idx] = {}\n                    first_level = False\n                    for k, v in element.items():\n                     ", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    default_observer_schema_dict = {}\n    for key, value in manifest_dict.items():\n        if key in OBSERVER_SCHEMA_KEYS:\n            if value is None and not first_level:\n                continue\n            if value is None:\n                default_observer_schema_dict[key] = None\n            elif isinstance(value, list):\n                if len(value) > 0:\n                    default_observer_schema_dict[key] = []\n                for item in value:\n                    if isinstance(item, dict):\n                        default_observer_schema_dict[key].append(item)\n                    else:\n                        default_observer_schema_dict[key].append(item.serialize(\n                            allow_unknown=first_level))\n           ", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/controller/kubernetes/hooks.py", "project": "rak-n-rok/Krake", "name": "update_last_applied_manifest_list_from_resp", "docstring": "Together with :func:``update_last_applied_manifest_dict_from_resp``, this\nfunction is called recursively to update a partial ``last_applied_manifest``\nfrom a partial Kubernetes response\n\nArgs:\n    last_applied_manifest (list): partial ``last_applied_manifest`` being\n        updated\n    observer_schema (list): partial ``observer_schema``\n    response (list): partial response from the Kubernetes API.\n\nThis function go through all observed fields, and initialized their value in\nlast_applied_manifest if they are not yet present", "ques_id": "62b869ebb4d922cb0e688cc6", "code": ["def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Reurring recommendations for :func:``update_last_applied_manifest_dict_from_resp``\n\n    This function is called recursively to update a partial ``last_applied_manifest``\n    from a partial Kubes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema``\n        response (list): partial response from the Kubes API. This function go\n            through all observed fields, and initialized their value in last_applied_manifest\n            if they are not yet present in last_applied_manifest\n    \"\"\"\n    for obs in response:\n        if isinstance(obs, dict):\n            if 'last_applied_manifest' in obs:\n                obs['last_applied_manifest'] = update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest=obs['last_ap", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Reurrespects :func:``update_last_applied_manifest_dict_from_resp``,\n    this function is called recursively to update a partial ``last_applied_manifest``\n    from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` being response from the Kubernetes API.\n        response (list): partial response from the Kubernetes API. This function go through all\n            observed fields, and initialized their value in last_applied_manifest\n            if they are not yet present in the Kubernetes API\n    \"\"\"\n    for observed_field in observer_schema:\n        if observed_field in response:\n            last_applied_manifest.append(\n                update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest=last_ap", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` being updated\n        response (list): partial response from the Kubernetes API. This function\n        go through all observed fields, and initialized their value in last_applied_manifest\n        if they are not yet present\n    \"\"\"\n    for k, v in response.items():\n        if k not in last_applied_manifest:\n            last_applied_manifest[k] = v\n        elif isinstance(v, dict) and v.get(\"$ref\"):\n            last_applied_manifest[k] = update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[k], observer_schema, v\n            )\n    return last_applied_manifest\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Reurring recursively update the last_applied_manifest from a partial ``last_applied_manifest``\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` response\n        response (list): partial response from the Kubernetes API. This function\n            go through all observed fields, and initialized their value in last_applied_manifest\n            if they are not yet present\n    \"\"\"\n    for field in last_applied_manifest:\n        if field not in observer_schema:\n            last_applied_manifest[field] = response[field]\n        elif isinstance(observer_schema[field], list):\n            last_applied_manifest[field] = update_last_applied_manifest_list_from_resp(\n                last_applied_manifest[field], observer_schema[field], response[field]\n            )\n      ", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Reurring recommendations are not supported for Kubernetes API\n    \"\"\"\n    # Get the last applied manifest from the response\n    last_applied_manifest_dict = parse_last_applied_manifest(\n        last_applied_manifest,\n        observer_schema,\n    )\n\n    # Update last_applied_manifest from the response\n    response[-1]['last_applied_manifest'] = last_applied_manifest_dict\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Reurring recommendations for :func:``update_last_applied_manifest_dict_from_resp``, this function is called recursively to update\n    a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` being response\n        response (list): partial response from the Kubernetes API. This function go through all observed fields, and initialized\n            their value in last_applied_manifest it they are not yet present in\n    \"\"\"\n    for manifest in response:\n        if manifest[\"apiVersion\"]!= \"v1\":\n            continue\n\n        manifest[\"lastAppliedManifest\"] = update_last_applied_manifest_dict_from_resp(\n            last_applied_manifest, observer_schema, manifest[\"name\"]\n        )\n\n    return response\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial\n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being\n            updated\n        observer_schema (list): partial ``observer_schema`` being updated\n        response (list): partial response from the Kubernetes API. This\n            function go through all observed fields, and initialized their\n            value in last_applied_manifest if they are not yet present\n    \"\"\"\n    for field in response:\n        if field not in last_applied_manifest:\n            last_applied_manifest.append(field)\n            continue\n        last_applied_manifest[-1][field] = update_last_applied_manifest_dict_from_resp(\n            last_applied_manifest[-1], observer_schema, response[field]\n        )\n    return last_applied_manifest\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Reurring recursively calls to update the last_applied_manifest from a partial\n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` being response from the Kubernetes API\n        response (list): partial response from the Kubernetes API. This function go through\n        all observed fields, and initialized their value in last_applied_manifest if they are\n        not yet present in last_applied_manifest\n    \"\"\"\n    for field in observer_schema:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = {}\n        update_last_applied_manifest_dict_from_resp(\n            last_applied_manifest[field], observer_schema[field], response[field]\n        )\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema``\n        response (list): partial response from the Kubernetes API. This function go through\n            all observed fields, and initialized their value in last_applied_manifest\n            if they are not yet present\n    \"\"\"\n    for obs in response:\n        if obs.get(\"metadata\", {}).get(\"name\") in last_applied_manifest:\n            obs[\"metadata\"][\"name\"] = update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest, observer_schema, obs\n            )\n    return last_applied_manifest\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial\n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being\n            updated\n        observer_schema (list): partial ``observer_schema``\n        response (list): partial response from the Kubernetes API. This\n            function go through all observed fields, and initialized their\n            value in last_applied_manifest if they are not yet present\n    \"\"\"\n    for manifest in response:\n        if manifest.get(\"last_applied_manifest\") is None:\n            last_applied_manifest.append(manifest)\n        else:\n            update_last_applied_manifest_list_from_resp(\n                last_applied_manifest=manifest.get(\"last_applied_manifest\"),\n                observer_schema=observer_schema,\n           "], "level": "file_runnable", "generate_results": [{"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Reurring recommendations for :func:``update_last_applied_manifest_dict_from_resp``\n\n    This function is called recursively to update a partial ``last_applied_manifest``\n    from a partial Kubes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema``\n        response (list): partial response from the Kubes API. This function go\n            through all observed fields, and initialized their value in last_applied_manifest\n            if they are not yet present in last_applied_manifest\n    \"\"\"\n    for obs in response:\n        if isinstance(obs, dict):\n            if 'last_applied_manifest' in obs:\n                obs['last_applied_manifest'] = update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest=obs['last_ap", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Reurrespects :func:``update_last_applied_manifest_dict_from_resp``,\n    this function is called recursively to update a partial ``last_applied_manifest``\n    from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` being response from the Kubernetes API.\n        response (list): partial response from the Kubernetes API. This function go through all\n            observed fields, and initialized their value in last_applied_manifest\n            if they are not yet present in the Kubernetes API\n    \"\"\"\n    for observed_field in observer_schema:\n        if observed_field in response:\n            last_applied_manifest.append(\n                update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest=last_ap", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` being updated\n        response (list): partial response from the Kubernetes API. This function\n        go through all observed fields, and initialized their value in last_applied_manifest\n        if they are not yet present\n    \"\"\"\n    for k, v in response.items():\n        if k not in last_applied_manifest:\n            last_applied_manifest[k] = v\n        elif isinstance(v, dict) and v.get(\"$ref\"):\n            last_applied_manifest[k] = update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[k], observer_schema, v\n            )\n    return last_applied_manifest\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Reurring recursively update the last_applied_manifest from a partial ``last_applied_manifest``\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` response\n        response (list): partial response from the Kubernetes API. This function\n            go through all observed fields, and initialized their value in last_applied_manifest\n            if they are not yet present\n    \"\"\"\n    for field in last_applied_manifest:\n        if field not in observer_schema:\n            last_applied_manifest[field] = response[field]\n        elif isinstance(observer_schema[field], list):\n            last_applied_manifest[field] = update_last_applied_manifest_list_from_resp(\n                last_applied_manifest[field], observer_schema[field], response[field]\n            )\n      ", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Reurring recommendations are not supported for Kubernetes API\n    \"\"\"\n    # Get the last applied manifest from the response\n    last_applied_manifest_dict = parse_last_applied_manifest(\n        last_applied_manifest,\n        observer_schema,\n    )\n\n    # Update last_applied_manifest from the response\n    response[-1]['last_applied_manifest'] = last_applied_manifest_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Reurring recommendations for :func:``update_last_applied_manifest_dict_from_resp``, this function is called recursively to update\n    a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` being response\n        response (list): partial response from the Kubernetes API. This function go through all observed fields, and initialized\n            their value in last_applied_manifest it they are not yet present in\n    \"\"\"\n    for manifest in response:\n        if manifest[\"apiVersion\"]!= \"v1\":\n            continue\n\n        manifest[\"lastAppliedManifest\"] = update_last_applied_manifest_dict_from_resp(\n            last_applied_manifest, observer_schema, manifest[\"name\"]\n        )\n\n    return response\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial\n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being\n            updated\n        observer_schema (list): partial ``observer_schema`` being updated\n        response (list): partial response from the Kubernetes API. This\n            function go through all observed fields, and initialized their\n            value in last_applied_manifest if they are not yet present\n    \"\"\"\n    for field in response:\n        if field not in last_applied_manifest:\n            last_applied_manifest.append(field)\n            continue\n        last_applied_manifest[-1][field] = update_last_applied_manifest_dict_from_resp(\n            last_applied_manifest[-1], observer_schema, response[field]\n        )\n    return last_applied_manifest\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Reurring recursively calls to update the last_applied_manifest from a partial\n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` being response from the Kubernetes API\n        response (list): partial response from the Kubernetes API. This function go through\n        all observed fields, and initialized their value in last_applied_manifest if they are\n        not yet present in last_applied_manifest\n    \"\"\"\n    for field in observer_schema:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = {}\n        update_last_applied_manifest_dict_from_resp(\n            last_applied_manifest[field], observer_schema[field], response[field]\n        )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema``\n        response (list): partial response from the Kubernetes API. This function go through\n            all observed fields, and initialized their value in last_applied_manifest\n            if they are not yet present\n    \"\"\"\n    for obs in response:\n        if obs.get(\"metadata\", {}).get(\"name\") in last_applied_manifest:\n            obs[\"metadata\"][\"name\"] = update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest, observer_schema, obs\n            )\n    return last_applied_manifest\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial\n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being\n            updated\n        observer_schema (list): partial ``observer_schema``\n        response (list): partial response from the Kubernetes API. This\n            function go through all observed fields, and initialized their\n            value in last_applied_manifest if they are not yet present\n    \"\"\"\n    for manifest in response:\n        if manifest.get(\"last_applied_manifest\") is None:\n            last_applied_manifest.append(manifest)\n        else:\n            update_last_applied_manifest_list_from_resp(\n                last_applied_manifest=manifest.get(\"last_applied_manifest\"),\n                observer_schema=observer_schema,\n           ", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/controller/kubernetes/hooks.py", "project": "rak-n-rok/Krake", "name": "update_last_applied_manifest_dict_from_resp", "docstring": "Together with :func:``update_last_applied_manifest_list_from_resp``, this\nfunction is called recursively to update a partial ``last_applied_manifest``\nfrom a partial Kubernetes response\n\nArgs:\n    last_applied_manifest (dict): partial ``last_applied_manifest`` being\n        updated\n    observer_schema (dict): partial ``observer_schema``\n    response (dict): partial response from the Kubernetes API.\n\nRaises:\n    KeyError: If the observed field is not present in the Kubernetes response\n\nThis function go through all observed fields, and initialized their value in\nlast_applied_manifest if they are not yet present", "ques_id": "62b869eab4d922cb0e688cc5", "code": ["def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        else:\n            last_applied_manifest[field] = update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[field], observer_schema, response[field]\n            )\n    return last_applied_manifest\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        else:\n            last_applied_manifest[field] = update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[field], observer_schema, response[field]\n            )\n    return last_applied_manifest\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for k, v in response.items():\n        if k in last_applied_manifest:\n            last_applied_manifest[k].update_from_resp(\n                last_applied_manifest[k], observer_schema, v\n            )\n        else:\n            last_applied_manifest[k] = v\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field[\"name\"] not in last_applied_manifest:\n            last_applied_manifest[field[\"name\"]] = field[\"default\"]\n        else:\n            last_applied_manifest[field[\"name\"]] = update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[field[\"name\"]],\n                field,\n                response,\n            )\n    return last_applied_manifest\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field[\"name\"] not in last_applied_manifest:\n            last_applied_manifest[field[\"name\"]] = field[\"value\"]\n        elif isinstance(last_applied_manifest[field[\"name\"]], list):\n            last_applied_manifest[field[\"name\"]].append(\n                update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest[field[\"name\"]],\n                    observer_schema,\n                    response\n                )\n            )\n        else:\n            last_applied_manifest[field[\"name\"]] = last_applied_manifest[field[\"name\"]]\n    return last_applied_manifest\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for key, value in response.items():\n        if key not in last_applied_manifest:\n            last_applied_manifest[key] = {}\n        if isinstance(value, dict):\n            update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[key], value, observer_schema\n            )\n        elif isinstance(value, list):\n            for item in value:\n                if isinstance(item, dict):\n                    update_last_applied_manifest_dict_from_resp(\n                        last_applied_manifest[key], item, observer_schema\n                    )\n                else:\n                    update_last_applied_manifest_value_from_resp(\n                        last_applied_manifest[key], item, observer_schema\n                   ", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema['fields']:\n        if field['name'] not in last_applied_manifest:\n            last_applied_manifest[field['name']] = field['value']\n        elif field['type']!= 'object':\n            last_applied_manifest[field['name']] = field['value']\n        elif field['type'] == 'array':\n            last_applied_manifest[field['name']] = [\n                update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest, observer_schema, result\n                ) for result in field['value']\n            ]\n    return last_applied_manifest\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        else:\n            last_applied_manifest[field] = update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[field], observer_schema, response[field]\n            )\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field[\"name\"] in last_applied_manifest:\n            if field[\"type\"] == \"object\":\n                update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest[field[\"name\"]],\n                    field,\n                    response,\n                )\n            else:\n                setattr(last_applied_manifest, field[\"name\"], field[\"type\"](response[field[\"name\"]]))\n    return last_applied_manifest\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field[\"name\"] not in last_applied_manifest:\n            last_applied_manifest[field[\"name\"]] = field[\"default\"]\n        else:\n            last_applied_manifest[field[\"name\"]] = update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[field[\"name\"]], field, response\n            )\n\n    return last_applied_manifest\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        else:\n            last_applied_manifest[field] = update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[field], observer_schema, response[field]\n            )\n    return last_applied_manifest\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        else:\n            last_applied_manifest[field] = update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[field], observer_schema, response[field]\n            )\n    return last_applied_manifest\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for k, v in response.items():\n        if k in last_applied_manifest:\n            last_applied_manifest[k].update_from_resp(\n                last_applied_manifest[k], observer_schema, v\n            )\n        else:\n            last_applied_manifest[k] = v\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field[\"name\"] not in last_applied_manifest:\n            last_applied_manifest[field[\"name\"]] = field[\"default\"]\n        else:\n            last_applied_manifest[field[\"name\"]] = update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[field[\"name\"]],\n                field,\n                response,\n            )\n    return last_applied_manifest\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field[\"name\"] not in last_applied_manifest:\n            last_applied_manifest[field[\"name\"]] = field[\"value\"]\n        elif isinstance(last_applied_manifest[field[\"name\"]], list):\n            last_applied_manifest[field[\"name\"]].append(\n                update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest[field[\"name\"]],\n                    observer_schema,\n                    response\n                )\n            )\n        else:\n            last_applied_manifest[field[\"name\"]] = last_applied_manifest[field[\"name\"]]\n    return last_applied_manifest\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for key, value in response.items():\n        if key not in last_applied_manifest:\n            last_applied_manifest[key] = {}\n        if isinstance(value, dict):\n            update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[key], value, observer_schema\n            )\n        elif isinstance(value, list):\n            for item in value:\n                if isinstance(item, dict):\n                    update_last_applied_manifest_dict_from_resp(\n                        last_applied_manifest[key], item, observer_schema\n                    )\n                else:\n                    update_last_applied_manifest_value_from_resp(\n                        last_applied_manifest[key], item, observer_schema\n                   ", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema['fields']:\n        if field['name'] not in last_applied_manifest:\n            last_applied_manifest[field['name']] = field['value']\n        elif field['type']!= 'object':\n            last_applied_manifest[field['name']] = field['value']\n        elif field['type'] == 'array':\n            last_applied_manifest[field['name']] = [\n                update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest, observer_schema, result\n                ) for result in field['value']\n            ]\n    return last_applied_manifest\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        else:\n            last_applied_manifest[field] = update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[field], observer_schema, response[field]\n            )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field[\"name\"] in last_applied_manifest:\n            if field[\"type\"] == \"object\":\n                update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest[field[\"name\"]],\n                    field,\n                    response,\n                )\n            else:\n                setattr(last_applied_manifest, field[\"name\"], field[\"type\"](response[field[\"name\"]]))\n    return last_applied_manifest\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field[\"name\"] not in last_applied_manifest:\n            last_applied_manifest[field[\"name\"]] = field[\"default\"]\n        else:\n            last_applied_manifest[field[\"name\"]] = update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[field[\"name\"]], field, response\n            )\n\n    return last_applied_manifest\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/controller/kubernetes/hooks.py", "project": "rak-n-rok/Krake", "name": "generate_default_observer_schema", "docstring": "Generate the default observer schema for each Kubernetes resource present in\n``spec.manifest`` for which a custom observer schema hasn't been specified.\n\nArgs:\n    app (krake.data.kubernetes.Application): The application for which to generate a\n        default observer schema", "ques_id": "62b869eab4d922cb0e688cbf", "code": ["def generate_default_observer_schema(app):\n    for filename in os.listdir(app.config['KUBECTL_SPEC_DIR']):\n        if filename.endswith('.yaml') and 'observer' not in filename:\n            with open(\n                os.path.join(app.config['KUBECTL_SPEC_DIR'], filename)\n            ) as f:\n                yaml_spec = yaml.safe_load(f.read())\n\n            schema = app.resolve(yaml_spec['schema'])\n            yield schema\n", "def generate_default_observer_schema(app):\n    if app.config.get('OBSERVER_SCHEMA'):\n        return\n\n    def get_custom_observer_schema(path, resource):\n        if path == '/custom-observer-schema':\n            return resource\n\n        return app.config.get('OBSERVER_SCHEMA')(path, resource)\n\n    app.on_created.append(get_custom_observer_schema)\n", "def generate_default_observer_schema(app):\n    for resource in app.resources:\n        if 'observer' not in resource.custom:\n            app.resources.generate_schema(resource)\n", "def generate_default_observer_schema(app):\n    spec = app.spec\n    if spec.manifest.get('observer') is None:\n        resources = app.resources\n        for resource in resources:\n            if not hasattr(resource, 'custom_observer_schema'):\n                yield _prepare_custom_observer_schema(resource, app)\n", "def generate_default_observer_schema(app):\n    for filename in os.listdir(app.config['PATH_TO_RESOURCES']):\n        if filename.endswith('.yaml'):\n            with open(\n                os.path.join(app.config['PATH_TO_RESOURCES'], filename)\n            ) as f:\n                yaml_spec = yaml.safe_load(f.read())\n            if 'observer' not in yaml_spec:\n                yield _get_custom_observer_schema(yaml_spec)\n", "def generate_default_observer_schema(app):\n    if app.config[\"OBSERVER_SCHEMA\"] is not None:\n        return\n\n    spec = app.spec.to_dict()\n    custom_observer_schema = {}\n    for resource in spec[\"resources\"]:\n        if resource[\"type\"] == \"custom\":\n            custom_observer_schema[resource[\"name\"]] = resource[\"schema\"]\n\n    app.config[\"OBSERVER_SCHEMA\"] = custom_observer_schema\n", "def generate_default_observer_schema(app):\n    spec = app.spec.to_dict()\n    for resource in spec['resources']:\n        if resource['type'] == 'custom:observer':\n            resource['custom_observer_schema'] = generate_custom_observer_schema(\n                app,\n                resource\n            )\n", "def generate_default_observer_schema(app):\n    spec = app.spec.to_dict()\n    for resource in spec.get('resources', {}).values():\n        if not resource.get('customObserver', False):\n            resource['customObserver'] = {\n                'type':'string',\n                'format': 'ipv4',\n                'default': '10.0.0.1'\n            }\n", "def generate_default_observer_schema(app):\n    if app.config.get('Kubernetes', {}).get('observer'):\n        manifest = app.config.get('Kubernetes', {}).get('manifest')\n        if manifest:\n            try:\n                _validate_schema(manifest)\n            except ValidationError as e:\n                raise ValueError(\n                    'Observer schema in the manifest is invalid: {}'.format(\n                        e.message\n                    )\n                )\n", "def generate_default_observer_schema(app):\n    env = app.env\n    resource_specs = env.get_resource_specs()\n    for resource_spec in resource_specs.values():\n        if 'observer' not in resource_spec:\n            continue\n\n        _, _, schema = resource_spec['observer'].partition(':')\n        env.add_schema('observer', schema)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def generate_default_observer_schema(app):\n    for filename in os.listdir(app.config['KUBECTL_SPEC_DIR']):\n        if filename.endswith('.yaml') and 'observer' not in filename:\n            with open(\n                os.path.join(app.config['KUBECTL_SPEC_DIR'], filename)\n            ) as f:\n                yaml_spec = yaml.safe_load(f.read())\n\n            schema = app.resolve(yaml_spec['schema'])\n            yield schema\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    if app.config.get('OBSERVER_SCHEMA'):\n        return\n\n    def get_custom_observer_schema(path, resource):\n        if path == '/custom-observer-schema':\n            return resource\n\n        return app.config.get('OBSERVER_SCHEMA')(path, resource)\n\n    app.on_created.append(get_custom_observer_schema)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    for resource in app.resources:\n        if 'observer' not in resource.custom:\n            app.resources.generate_schema(resource)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    spec = app.spec\n    if spec.manifest.get('observer') is None:\n        resources = app.resources\n        for resource in resources:\n            if not hasattr(resource, 'custom_observer_schema'):\n                yield _prepare_custom_observer_schema(resource, app)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    for filename in os.listdir(app.config['PATH_TO_RESOURCES']):\n        if filename.endswith('.yaml'):\n            with open(\n                os.path.join(app.config['PATH_TO_RESOURCES'], filename)\n            ) as f:\n                yaml_spec = yaml.safe_load(f.read())\n            if 'observer' not in yaml_spec:\n                yield _get_custom_observer_schema(yaml_spec)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    if app.config[\"OBSERVER_SCHEMA\"] is not None:\n        return\n\n    spec = app.spec.to_dict()\n    custom_observer_schema = {}\n    for resource in spec[\"resources\"]:\n        if resource[\"type\"] == \"custom\":\n            custom_observer_schema[resource[\"name\"]] = resource[\"schema\"]\n\n    app.config[\"OBSERVER_SCHEMA\"] = custom_observer_schema\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    spec = app.spec.to_dict()\n    for resource in spec['resources']:\n        if resource['type'] == 'custom:observer':\n            resource['custom_observer_schema'] = generate_custom_observer_schema(\n                app,\n                resource\n            )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    spec = app.spec.to_dict()\n    for resource in spec.get('resources', {}).values():\n        if not resource.get('customObserver', False):\n            resource['customObserver'] = {\n                'type':'string',\n                'format': 'ipv4',\n                'default': '10.0.0.1'\n            }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    if app.config.get('Kubernetes', {}).get('observer'):\n        manifest = app.config.get('Kubernetes', {}).get('manifest')\n        if manifest:\n            try:\n                _validate_schema(manifest)\n            except ValidationError as e:\n                raise ValueError(\n                    'Observer schema in the manifest is invalid: {}'.format(\n                        e.message\n                    )\n                )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    env = app.env\n    resource_specs = env.get_resource_specs()\n    for resource_spec in resource_specs.values():\n        if 'observer' not in resource_spec:\n            continue\n\n        _, _, schema = resource_spec['observer'].partition(':')\n        env.add_schema('observer', schema)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "sqlparams/__init__.py", "project": "cpburnz/python-sql-parameters", "name": "format", "docstring": "Convert the SQL query to use the out-style parameters instead of\nthe in-style parameters.\n\n*sql* (:class:`str` or :class:`bytes`) is the SQL query.\n\n*params* (:class:`~collections.abc.Mapping` or :class:`~collections.abc.Sequence`)\ncontains the set of in-style parameters. It maps each parameter\n(:class:`str` or :class:`int`) to value. If :attr:`.SQLParams.in_style`\nis a named parameter style. then *params* must be a :class:`~collections.abc.Mapping`.\nIf :attr:`.SQLParams.in_style` is an ordinal parameter style, then\n*params* must be a :class:`~collections.abc.Sequence`.\n\nReturns a :class:`tuple` containing:\n\n-       The formatted SQL query (:class:`str` or :class:`bytes`).\n\n-       The set of converted out-style parameters (:class:`dict` or\n        :class:`list`).", "ques_id": "62b43427903eeb48555d3ea5", "code": ["def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\n\"\"\"\nConvert sql using self._converter.convert\n\"\"\"\nreturn self._converter.format(sql, params)\n", "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\nif isinstance(params, dict):\nparams = self._converter.convert(params)\n\nif not isinstance(params, (list, tuple)):\nparams = (params,)\n\nparam_str = self._converter.format(sql, params)\n\nreturn param_str, params\n", "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\nparams = self._converter.convert(params)\n\nreturn self._engine.format(sql, params)\n", "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\n\nparams = self._converter.convert(params)\n\nreturn self._converter.format(sql, params)\n", "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\n\"\"\"Convert sql using self._converter.convert\"\"\"\n\nparams = self._converter.convert(params)\n\nreturn self._formatter.format(sql, params)\n", "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\n\nif isinstance(params, Mapping):\nparams = params.items()\n\nparams = tuple(params) if isinstance(params, tuple) else params\n\nparams = self._converter.convert(sql, params)\n\nreturn params\n", "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\nif isinstance(params, Mapping):\nparams = self._converter.convert(params)\n\nreturn self._converter.format(sql, params)\n", "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\nparams = self._converter.convert(params)\n\nreturn self._converter.format(sql, params)\n", "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\nreturn self._converter.convert(sql, params)\n", "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\nreturn self._converter.format(sql, params)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\n\"\"\"\nConvert sql using self._converter.convert\n\"\"\"\nreturn self._converter.format(sql, params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\nif isinstance(params, dict):\nparams = self._converter.convert(params)\n\nif not isinstance(params, (list, tuple)):\nparams = (params,)\n\nparam_str = self._converter.format(sql, params)\n\nreturn param_str, params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\nparams = self._converter.convert(params)\n\nreturn self._engine.format(sql, params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\n\nparams = self._converter.convert(params)\n\nreturn self._converter.format(sql, params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\n\"\"\"Convert sql using self._converter.convert\"\"\"\n\nparams = self._converter.convert(params)\n\nreturn self._formatter.format(sql, params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\n\nif isinstance(params, Mapping):\nparams = params.items()\n\nparams = tuple(params) if isinstance(params, tuple) else params\n\nparams = self._converter.convert(sql, params)\n\nreturn params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\nif isinstance(params, Mapping):\nparams = self._converter.convert(params)\n\nreturn self._converter.format(sql, params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\nparams = self._converter.convert(params)\n\nreturn self._converter.format(sql, params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\nreturn self._converter.convert(sql, params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tparams: Union[Dict[Union[str, int], Any], Sequence[Any]],\n\t) -> Tuple[AnyStr, Union[Dict[Union[str, int], Any], Sequence[Any]]]:\nreturn self._converter.format(sql, params)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "sqlparams/__init__.py", "project": "cpburnz/python-sql-parameters", "name": "formatmany", "docstring": "Convert the SQL query to use the out-style parameters instead of the\nin-style parameters.\n\n*sql* (:class:`str` or :class:`bytes`) is the SQL query.\n\n*many_params* (:class:`~collections.abc.Iterable`) contains each set\nof in-style parameters (*params*).\n\n-       *params* (:class:`~collections.abc.Mapping` or :class:`~collections.abc.Sequence`)\n        contains the set of in-style parameters. It maps each parameter\n        (:class:`str` or :class:`int`) to value. If :attr:`.SQLParams.in_style`\n        is a named parameter style. then *params* must be a :class:`~collections.abc.Mapping`.\n        If :attr:`.SQLParams.in_style` is an ordinal parameter style. then\n        *params* must be a :class:`~collections.abc.Sequence`.\n\nReturns a :class:`tuple` containing:\n\n-       The formatted SQL query (:class:`str` or :class:`bytes`).\n\n-       A :class:`list` containing each set of converted out-style\n        parameters (:class:`dict` or :class:`list`).", "ques_id": "62b43428903eeb48555d3eaa", "code": ["def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\nreturn self._converter.formatmany(sql, many_params)\n", "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"Convert sql using self._converter.convert_many\"\"\"\nparams = []\nresults = None\nif many_params is None:\nresults = []\nelse:\nresults = []\nparams = self._converter.convert_many(sql, many_params, params)\nif not params:\nreturn sql, results\nfor param in params:\nresults.append(param)\nreturn sql, results\n", "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"\nConvert sql using self._converter.convert_many\n\n\"\"\"\nparams = []\nfor param in many_params:\nparams.append(self._converter.convert_many(param))\nreturn self._format(sql, params)\n", "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"Convert sql using self._converter.convert_many\"\"\"\nparams = []\nresults = []\nif many_params:\nparams = many_params\n\nparams = self._converter.convert_many(sql, params)\nif params:\nresults = self.format(sql, params)\nreturn sql, results\n", "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"Convert sql using self._converter.convert_many\"\"\"\nreturn self._converter.convert_many(sql, many_params)\n", "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"\nConvert sql using self._converter.convert_many\n\"\"\"\nparams = self._converter.convert_many(sql, many_params)\nreturn self.format(*params)\n", "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"\nConvert sql using self._converter.convert_many\n\nReturns a tuple with converted data, and a list of converted errors.\n\"\"\"\nparams, errors = self._converter.convert_many(sql, many_params)\nreturn params, errors\n", "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\nreturn self._converter.formatmany(sql, many_params)\n", "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"\nConvert sql using self._converter.convert_many\n\"\"\"\nreturn self._converter.convert_many(sql, many_params)\n", "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"\nConvert sql using self._converter.convert_many\n\n:param sql: sql to be converted\n:param many_params: list of params to be converted\n:return: result, converted many or some other format\n\"\"\"\nresult, params = self._converter.convert_many(sql, many_params)\nreturn result, params\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\nreturn self._converter.formatmany(sql, many_params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"Convert sql using self._converter.convert_many\"\"\"\nparams = []\nresults = None\nif many_params is None:\nresults = []\nelse:\nresults = []\nparams = self._converter.convert_many(sql, many_params, params)\nif not params:\nreturn sql, results\nfor param in params:\nresults.append(param)\nreturn sql, results\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"\nConvert sql using self._converter.convert_many\n\n\"\"\"\nparams = []\nfor param in many_params:\nparams.append(self._converter.convert_many(param))\nreturn self._format(sql, params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"Convert sql using self._converter.convert_many\"\"\"\nparams = []\nresults = []\nif many_params:\nparams = many_params\n\nparams = self._converter.convert_many(sql, params)\nif params:\nresults = self.format(sql, params)\nreturn sql, results\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"Convert sql using self._converter.convert_many\"\"\"\nreturn self._converter.convert_many(sql, many_params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"\nConvert sql using self._converter.convert_many\n\"\"\"\nparams = self._converter.convert_many(sql, many_params)\nreturn self.format(*params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"\nConvert sql using self._converter.convert_many\n\nReturns a tuple with converted data, and a list of converted errors.\n\"\"\"\nparams, errors = self._converter.convert_many(sql, many_params)\nreturn params, errors\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\nreturn self._converter.formatmany(sql, many_params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"\nConvert sql using self._converter.convert_many\n\"\"\"\nreturn self._converter.convert_many(sql, many_params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: AnyStr,\n\t\tmany_params: Union[Iterable[Dict[Union[str, int], Any]], Iterable[Sequence[Any]]],\n\t) -> Tuple[AnyStr, Union[List[Dict[Union[str, int], Any]], List[Sequence[Any]]]]:\n\"\"\"\nConvert sql using self._converter.convert_many\n\n:param sql: sql to be converted\n:param many_params: list of params to be converted\n:return: result, converted many or some other format\n\"\"\"\nresult, params = self._converter.convert_many(sql, many_params)\nreturn result, params\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/validator.py", "project": "zimeon/ocfl-py", "name": "validate", "docstring": "Validate OCFL object at path or pyfs root.\n\nReturns True if valid (warnings permitted), False otherwise.", "ques_id": "62b45df05108cfac7f2109ce", "code": ["def validate(self, path):\n    return self.fs.validate(path)\n", "def validate(self, path):\n    try:\n        self.stat(path)\n    except OSError:\n        return False\n    return True\n", "def validate(self, path):\n    if not is_string(path):\n        return False\n    return self.exists(path)\n", "def validate(self, path):\n    return self._validate(path)\n", "def validate(self, path):\n    return self._validate(path)\n", "def validate(self, path):\n    return self._validate(path)\n", "def validate(self, path):\n    return self._validate(path)\n", "def validate(self, path):\n    if not isinstance(path, (six.string_types, six.text_type)):\n        raise TypeError('path must be a string or unicode type')\n    if not self.exists(path):\n        raise OSError('path does not exist: %s' % path)\n    return True if self.isdir(path) else False\n", "def validate(self, path):\n    return isfile(join(path, self.OCFL_FILENAME)) or \\\n      isdir(join(path, self.OCFL_ROOT))\n", "def validate(self, path):\n    return self._validate(path)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate(self, path):\n    return self.fs.validate(path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    try:\n        self.stat(path)\n    except OSError:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    if not is_string(path):\n        return False\n    return self.exists(path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    return self._validate(path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    return self._validate(path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    return self._validate(path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    return self._validate(path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    if not isinstance(path, (six.string_types, six.text_type)):\n        raise TypeError('path must be a string or unicode type')\n    if not self.exists(path):\n        raise OSError('path does not exist: %s' % path)\n    return True if self.isdir(path) else False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    return isfile(join(path, self.OCFL_FILENAME)) or \\\n      isdir(join(path, self.OCFL_ROOT))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    return self._validate(path)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/validation_logger.py", "project": "zimeon/ocfl-py", "name": "status_str", "docstring": "Return string of validator status, with optional prefix.", "ques_id": "62b45df15108cfac7f2109dc", "code": ["def status_str(self, prefix=''):\n    result = prefix + '\\n'\n    for message in self.messages:\n        result += str(message) + '\\n'\n    return result\n", "def status_str(self, prefix=''):\n    s = prefix + ', '.join(sorted(self.messages)) + '\\n'\n    for m in self.messages:\n        s += '%s: %s\\n' % (m.path, m.message)\n    return s\n", "def status_str(self, prefix=''):\n    s = ''\n    for m in sorted(self.messages, key=lambda x: x.line, reverse=True):\n        s += '%s%s: %s\\n' % (prefix, m.path, m.line)\n    return s\n", "def status_str(self, prefix=''):\n    result = prefix + '\\n'\n    for m in sorted(self.messages, key=lambda x: x.lineno):\n        result += str(m) + '\\n'\n        for line in m.lines:\n            result +=''+ line + '\\n'\n    return result\n", "def status_str(self, prefix=''):\n    s = prefix +' '\n    for m in self.messages:\n        s += m +''\n    return s\n", "def status_str(self, prefix=''):\n    result = prefix + ': '\n    for m in sorted(self.messages, key=lambda x: x.line):\n        result += '%s%s: %s' % (prefix, m.name, m.line)\n    return result\n", "def status_str(self, prefix=''):\n    result = prefix + '============================================================================================================\\n'\n    for message in self.messages:\n        result += prefix +'' + message.status_str(prefix=' ') + '\\n'\n    return result\n", "def status_str(self, prefix=''):\n    if self._messages:\n        s = prefix + ': '\n        for m in sorted(self._messages, key=lambda x: x.lineno):\n            s += str(m) + '\\n'\n        return s\n    else:\n        return ''\n", "def status_str(self, prefix=''):\n    result = ''\n    for m in self.messages:\n        result += '%s%s\\n' % (prefix, m)\n    return result\n", "def status_str(self, prefix=''):\n    if len(self.messages) == 0:\n        return ''\n    out = prefix + '- '\n    for m in self.messages:\n        out += m.status_str(prefix +'  ')\n    return out\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def status_str(self, prefix=''):\n    result = prefix + '\\n'\n    for message in self.messages:\n        result += str(message) + '\\n'\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    s = prefix + ', '.join(sorted(self.messages)) + '\\n'\n    for m in self.messages:\n        s += '%s: %s\\n' % (m.path, m.message)\n    return s\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    s = ''\n    for m in sorted(self.messages, key=lambda x: x.line, reverse=True):\n        s += '%s%s: %s\\n' % (prefix, m.path, m.line)\n    return s\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    result = prefix + '\\n'\n    for m in sorted(self.messages, key=lambda x: x.lineno):\n        result += str(m) + '\\n'\n        for line in m.lines:\n            result +=''+ line + '\\n'\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    s = prefix +' '\n    for m in self.messages:\n        s += m +''\n    return s\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    result = prefix + ': '\n    for m in sorted(self.messages, key=lambda x: x.line):\n        result += '%s%s: %s' % (prefix, m.name, m.line)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    result = prefix + '============================================================================================================\\n'\n    for message in self.messages:\n        result += prefix +'' + message.status_str(prefix=' ') + '\\n'\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    if self._messages:\n        s = prefix + ': '\n        for m in sorted(self._messages, key=lambda x: x.lineno):\n            s += str(m) + '\\n'\n        return s\n    else:\n        return ''\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    result = ''\n    for m in self.messages:\n        result += '%s%s\\n' % (prefix, m)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    if len(self.messages) == 0:\n        return ''\n    out = prefix + '- '\n    for m in self.messages:\n        out += m.status_str(prefix +'  ')\n    return out\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/validator.py", "project": "zimeon/ocfl-py", "name": "status_str", "docstring": "Return string representation of validation log, with optional prefix.", "ques_id": "62b45df15108cfac7f2109dd", "code": ["def status_str(self, prefix=''):\n    return '{}{}'.format(prefix, self.log.status_str)\n", "def status_str(self, prefix=''):\n    return '{}{}: {}'.format(prefix, self.__class__.__name__, self.log.status_str)\n", "def status_str(self, prefix=''):\n    return '{0}{1}'.format(prefix, self.log.status_str)\n", "def status_str(self, prefix=''):\n    return '{}{}: {}'.format(prefix, self.__class__.__name__, self.log.status_str)\n", "def status_str(self, prefix=''):\n    if self.log.status == 'finished':\n        status = 'finished ({})'.format(self.log.file_name)\n    elif self.log.status == 'error':\n        status = 'error ({})'.format(self.log.file_name)\n    elif self.log.status == 'aborted':\n        status = 'aborted ({})'.format(self.log.file_name)\n    else:\n        status = self.log.status_str\n    if prefix:\n        status = '{} {}'.format(prefix, status)\n    return status\n", "def status_str(self, prefix=''):\n    return '{}{}: {}'.format(prefix, self.__class__.__name__, self.log.status_str)\n", "def status_str(self, prefix=''):\n    return '{0}{1}'.format(prefix, self.log.status_str)\n", "def status_str(self, prefix=''):\n    return '{}{}: {}'.format(prefix, self.__class__.__name__, self.log.status_str)\n", "def status_str(self, prefix=''):\n    return '{0}{1}'.format(prefix, self.log.status_str)\n", "def status_str(self, prefix=''):\n    return '{}{}'.format(prefix, self.log.status_str)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def status_str(self, prefix=''):\n    return '{}{}'.format(prefix, self.log.status_str)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return '{}{}: {}'.format(prefix, self.__class__.__name__, self.log.status_str)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return '{0}{1}'.format(prefix, self.log.status_str)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return '{}{}: {}'.format(prefix, self.__class__.__name__, self.log.status_str)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    if self.log.status == 'finished':\n        status = 'finished ({})'.format(self.log.file_name)\n    elif self.log.status == 'error':\n        status = 'error ({})'.format(self.log.file_name)\n    elif self.log.status == 'aborted':\n        status = 'aborted ({})'.format(self.log.file_name)\n    else:\n        status = self.log.status_str\n    if prefix:\n        status = '{} {}'.format(prefix, status)\n    return status\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return '{}{}: {}'.format(prefix, self.__class__.__name__, self.log.status_str)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return '{0}{1}'.format(prefix, self.log.status_str)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return '{}{}: {}'.format(prefix, self.__class__.__name__, self.log.status_str)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return '{0}{1}'.format(prefix, self.log.status_str)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return '{}{}'.format(prefix, self.log.status_str)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/dispositor.py", "project": "zimeon/ocfl-py", "name": "is_valid", "docstring": "Return True if identifier is valid, always True in this base implementation.", "ques_id": "62b45e135108cfac7f2109f4", "code": ["def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n"], "level": "self_contained", "generate_results": [{"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}]}
{"file_path": "ocfl/inventory_validator.py", "project": "zimeon/ocfl-py", "name": "validate", "docstring": "Validate a given inventory.\n\nIf extract_spec_version is True then will look at the type value to determine\nthe specification version. In the case that there is no type value or it isn't\nvalid, then other tests will be based on the version given in self.spec_version.", "ques_id": "62b45e145108cfac7f210a07", "code": ["def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            self.spec_version = inventory.get_type().version\n        except AttributeError:\n            self.spec_version = None\n    else:\n        self.spec_version = None\n\n    self._validate_inventory(inventory)\n\n    return inventory\n", "def validate(self, inventory, extract_spec_version=False):\n    self._validate_inventory(inventory)\n    if extract_spec_version:\n        self._validate_spec_version(inventory)\n", "def validate(self, inventory, extract_spec_version=False):\n    if not isinstance(inventory, dict):\n        raise AnsibleFilterError(\"The inventory parameter must be a dict.\")\n\n    validated_inventory = {}\n    for k, v in inventory.items():\n        if k in self.required_keys:\n            if v is None:\n                continue\n            if k in self.optional_keys:\n                v = self.optional_keys[k](v)\n            if extract_spec_version:\n                v = self.extract_spec_version(v)\n            validated_inventory[k] = v\n        elif k in self.optional_keys:\n            pass\n        elif k in self.required_keys:\n            raise AnsibleFilterError(\"Unknown key %s in inventory %s\" % (k, inventory))\n        elif k in self.optional_keys:\n            pass\n        else:\n            rais", "def validate(self, inventory, extract_spec_version=False):\n    inventory = self._prepare_inventory(inventory)\n\n    # Validate the inventory\n    try:\n        validate(inventory, self.type, extract_spec_version=extract_spec_version)\n    except ValidationError as e:\n        raise InventoryValidationError(str(e))\n", "def validate(self, inventory, extract_spec_version=False):\n    # TODO: I think this is wrong and is not needed anymore.\n    #       It should be improved to use a separate test case\n    #       class for type validation.\n    if not inventory.get(\"type\"):\n        return\n    # TODO: I think this is wrong and is not needed anymore.\n    #       It should be improved to use a separate test case\n    #       class for specification validation.\n    if not inventory.get(\"spec_version\"):\n        return\n    if extract_spec_version:\n        try:\n            ver = Version(inventory[\"spec_version\"])\n        except Exception:\n            raise exceptions.ValidationError(\n                \"Invalid spec_version (%s) for inventory %s\" %\n                (inventory[\"spec_version\"], inventory[\"name\"])\n            )\n        if ver.matches(self.spec_version):\n            return\n        raise exceptions.ValidationE", "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        type_ = inventory.get('type', {})\n        if'version' in type_:\n            type_value = type_.get('version')\n            return self.spec_version == type_value\n        else:\n            return True\n    return True\n", "def validate(self, inventory, extract_spec_version=False):\n    if self.is_valid_inventory(inventory):\n        if extract_spec_version:\n            return self._extract_spec_version(inventory)\n        return True\n    return False\n", "def validate(self, inventory, extract_spec_version=False):\n    if not self.validate_inventory(inventory):\n        return False\n\n    # if the inventory is empty, return false\n    if len(inventory) == 0:\n        return False\n\n    if extract_spec_version:\n        # if the version is not valid, then extract the version\n        try:\n            version = inventory['__version__']\n            spec_version = int(version.split('.')[0])\n            if spec_version!= self.spec_version:\n                return False\n        except KeyError:\n            return False\n    else:\n        spec_version = self.spec_version\n\n    # if the version is not valid, then extract the type value\n    try:\n        type_value = inventory['type']\n        type_value = type_value.split('.')[1]\n        if type_value!= self.type_value:\n            return False\n    except KeyError:\n        retur", "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        self.spec_version = inventory.get('metadata', {}).get(\n            'instance_type', {}).get('spec_version', '0.0')\n    return super(InventoryFormatVersion, self).validate(\n        inventory, extract_spec_version=extract_spec_version)\n", "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            inventory['type'] = self.spec_version\n        except KeyError:\n            inventory['type'] = None\n\n    if not self.is_valid_inventory(inventory):\n        raise ValidationError(\"The given inventory is not a valid infrastructure instance.\")\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            self.spec_version = inventory.get_type().version\n        except AttributeError:\n            self.spec_version = None\n    else:\n        self.spec_version = None\n\n    self._validate_inventory(inventory)\n\n    return inventory\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    self._validate_inventory(inventory)\n    if extract_spec_version:\n        self._validate_spec_version(inventory)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    if not isinstance(inventory, dict):\n        raise AnsibleFilterError(\"The inventory parameter must be a dict.\")\n\n    validated_inventory = {}\n    for k, v in inventory.items():\n        if k in self.required_keys:\n            if v is None:\n                continue\n            if k in self.optional_keys:\n                v = self.optional_keys[k](v)\n            if extract_spec_version:\n                v = self.extract_spec_version(v)\n            validated_inventory[k] = v\n        elif k in self.optional_keys:\n            pass\n        elif k in self.required_keys:\n            raise AnsibleFilterError(\"Unknown key %s in inventory %s\" % (k, inventory))\n        elif k in self.optional_keys:\n            pass\n        else:\n            rais", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    inventory = self._prepare_inventory(inventory)\n\n    # Validate the inventory\n    try:\n        validate(inventory, self.type, extract_spec_version=extract_spec_version)\n    except ValidationError as e:\n        raise InventoryValidationError(str(e))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    # TODO: I think this is wrong and is not needed anymore.\n    #       It should be improved to use a separate test case\n    #       class for type validation.\n    if not inventory.get(\"type\"):\n        return\n    # TODO: I think this is wrong and is not needed anymore.\n    #       It should be improved to use a separate test case\n    #       class for specification validation.\n    if not inventory.get(\"spec_version\"):\n        return\n    if extract_spec_version:\n        try:\n            ver = Version(inventory[\"spec_version\"])\n        except Exception:\n            raise exceptions.ValidationError(\n                \"Invalid spec_version (%s) for inventory %s\" %\n                (inventory[\"spec_version\"], inventory[\"name\"])\n            )\n        if ver.matches(self.spec_version):\n            return\n        raise exceptions.ValidationE", "is_pass": true, "return_code": 0}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        type_ = inventory.get('type', {})\n        if'version' in type_:\n            type_value = type_.get('version')\n            return self.spec_version == type_value\n        else:\n            return True\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    if self.is_valid_inventory(inventory):\n        if extract_spec_version:\n            return self._extract_spec_version(inventory)\n        return True\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    if not self.validate_inventory(inventory):\n        return False\n\n    # if the inventory is empty, return false\n    if len(inventory) == 0:\n        return False\n\n    if extract_spec_version:\n        # if the version is not valid, then extract the version\n        try:\n            version = inventory['__version__']\n            spec_version = int(version.split('.')[0])\n            if spec_version!= self.spec_version:\n                return False\n        except KeyError:\n            return False\n    else:\n        spec_version = self.spec_version\n\n    # if the version is not valid, then extract the type value\n    try:\n        type_value = inventory['type']\n        type_value = type_value.split('.')[1]\n        if type_value!= self.type_value:\n            return False\n    except KeyError:\n        retur", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        self.spec_version = inventory.get('metadata', {}).get(\n            'instance_type', {}).get('spec_version', '0.0')\n    return super(InventoryFormatVersion, self).validate(\n        inventory, extract_spec_version=extract_spec_version)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            inventory['type'] = self.spec_version\n        except KeyError:\n            inventory['type'] = None\n\n    if not self.is_valid_inventory(inventory):\n        raise ValidationError(\"The given inventory is not a valid infrastructure instance.\")\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/inventory_validator.py", "project": "zimeon/ocfl-py", "name": "check_digests_present_and_used", "docstring": "Check all digests in manifest that are needed are present and used.", "ques_id": "62b45e145108cfac7f210a09", "code": ["def check_digests_present_and_used(self, manifest_files, digests_used):\n    for filename in manifest_files:\n        digest_file = self._get_digest_file_path(filename)\n        if not os.path.isfile(digest_file):\n            continue\n\n        with open(digest_file, \"r\") as f:\n            digest_contents = f.read()\n\n        for digest in digests_used:\n            if digest not in digest_contents:\n                error(\"Digest '{}' is missing for file '{}'\".format(digest, filename))\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest_name in digests_used:\n        if digest_name not in manifest_files:\n            return (\"{} digest '{}' is missing from manifest. \"\n                    \"All files are missing.\".format(self.__class__.__name__,\n                                                  digest_name))\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest_file in manifest_files:\n        if digest_file not in digests_used:\n            err = \"Digest {} not present in {}\".format(digest_file, manifest_files)\n            return err\n    return None\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    result = {}\n    for filename in manifest_files:\n        manifest_digest = self.digest_of_file(filename)\n        if manifest_digest in digests_used:\n            result[filename] = manifest_digest\n            continue\n        if self.digest_is_missing(filename):\n            result[filename] ='missing'\n            continue\n        if self.digest_is_in_use(filename):\n            result[filename] = 'in_use'\n            continue\n        if self.digest_is_disallowed(filename):\n            result[filename] = 'disallowed'\n            continue\n        if self.digest_is_unused(filename):\n            result[filename] = 'unused'\n            continue\n        if self.digest_is_invalid(filename):\n            result[filename] = 'invalid'\n            continue\n        if self.digest_is_stale(fil", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in digests_used:\n        if digest not in manifest_files:\n            return \"{} is not present in manifest files\".format(digest)\n    return None\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    missing_digests = []\n    for digest in digests_used:\n        if digest not in manifest_files:\n            missing_digests.append(digest)\n\n    if missing_digests:\n        return \"{} digests are not present in {}:\\n{}\".format(\n            len(missing_digests),\n            \", \".join(manifest_files),\n            \"\\n\".join([\"  {}: {}\".format(digest, self.digest_needed(digest))\n                       for digest in missing_digests]))\n\n    return None\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in digests_used:\n        if digest not in manifest_files:\n            return (\"Digest '{}' is not present in manifest files. \"\n                    \"Required digests are not present.\".format(digest))\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in digests_used:\n        if digest in manifest_files:\n            self.__check_file_line(manifest_files[digest], digest)\n        else:\n            self.__error(\"Manifest file does not have a line with this name: \" + digest)\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in digests_used:\n        if digest not in manifest_files:\n            return \"manifest file '%s' not found\" % digest\n    return None\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in digests_used:\n        if digest not in manifest_files:\n            return \"manifest file %s not found in manifest\" % digest\n    return None\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for filename in manifest_files:\n        digest_file = self._get_digest_file_path(filename)\n        if not os.path.isfile(digest_file):\n            continue\n\n        with open(digest_file, \"r\") as f:\n            digest_contents = f.read()\n\n        for digest in digests_used:\n            if digest not in digest_contents:\n                error(\"Digest '{}' is missing for file '{}'\".format(digest, filename))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest_name in digests_used:\n        if digest_name not in manifest_files:\n            return (\"{} digest '{}' is missing from manifest. \"\n                    \"All files are missing.\".format(self.__class__.__name__,\n                                                  digest_name))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest_file in manifest_files:\n        if digest_file not in digests_used:\n            err = \"Digest {} not present in {}\".format(digest_file, manifest_files)\n            return err\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    result = {}\n    for filename in manifest_files:\n        manifest_digest = self.digest_of_file(filename)\n        if manifest_digest in digests_used:\n            result[filename] = manifest_digest\n            continue\n        if self.digest_is_missing(filename):\n            result[filename] ='missing'\n            continue\n        if self.digest_is_in_use(filename):\n            result[filename] = 'in_use'\n            continue\n        if self.digest_is_disallowed(filename):\n            result[filename] = 'disallowed'\n            continue\n        if self.digest_is_unused(filename):\n            result[filename] = 'unused'\n            continue\n        if self.digest_is_invalid(filename):\n            result[filename] = 'invalid'\n            continue\n        if self.digest_is_stale(fil", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in digests_used:\n        if digest not in manifest_files:\n            return \"{} is not present in manifest files\".format(digest)\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    missing_digests = []\n    for digest in digests_used:\n        if digest not in manifest_files:\n            missing_digests.append(digest)\n\n    if missing_digests:\n        return \"{} digests are not present in {}:\\n{}\".format(\n            len(missing_digests),\n            \", \".join(manifest_files),\n            \"\\n\".join([\"  {}: {}\".format(digest, self.digest_needed(digest))\n                       for digest in missing_digests]))\n\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in digests_used:\n        if digest not in manifest_files:\n            return (\"Digest '{}' is not present in manifest files. \"\n                    \"Required digests are not present.\".format(digest))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in digests_used:\n        if digest in manifest_files:\n            self.__check_file_line(manifest_files[digest], digest)\n        else:\n            self.__error(\"Manifest file does not have a line with this name: \" + digest)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in digests_used:\n        if digest not in manifest_files:\n            return \"manifest file '%s' not found\" % digest\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in digests_used:\n        if digest not in manifest_files:\n            return \"manifest file %s not found in manifest\" % digest\n    return None\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/inventory_validator.py", "project": "zimeon/ocfl-py", "name": "validate_as_prior_version", "docstring": "Check that prior is a valid prior version of the current inventory object.\n\nThe input variable prior is also expected to be an InventoryValidator object\nand both self and prior inventories are assumed to have been checked for\ninternal consistency.", "ques_id": "62b45e165108cfac7f210a16", "code": ["def validate_as_prior_version(self, prior):\n    msg = \"Prior object must be an instance of BaseInventoryValidator\"\n    assert isinstance(prior, BaseInventoryValidator), msg\n    msg = \"Prior object must be of type {}\".format(BaseInventoryValidator)\n    assert prior.validate(self), msg\n    return \"\"\n", "def validate_as_prior_version(self, prior):\n    error(\"Can't use 'prior' in a validation context of an inventory \"\n          \"with a different inventory version.\")\n", "def validate_as_prior_version(self, prior):\n\n    if prior is None:\n        return\n\n    # We can only have one of the following types of priors:\n    #   - None: the input parameter is not a valid inventory prior.\n    #   - a string: the input parameter is a valid inventory prior.\n    if not isinstance(prior, inventory_validator.InventoryValidator):\n        return \"Invalid input type: %r\" % prior\n\n    # The input parameter is a valid inventory prior.\n    return None\n", "def validate_as_prior_version(self, prior):\n\n    if prior.get_name()!= self.get_name() or prior.get_version()!= self.get_version():\n        return Error(self.invalid_inventory_schema,\n                     \"Inventory '%s' does not match expected version '%s'\" %\n                     (prior.get_name(), self.get_version()))\n", "def validate_as_prior_version(self, prior):\n    if prior.name in self.names():\n        if prior > self.prior:\n            return \"%s cannot be greater than %s\" % (prior.name, self.prior.name)\n        elif prior < self.prior:\n            return \"%s cannot be lesser than %s\" % (prior.name, self.prior.name)\n    return \"\"\n", "def validate_as_prior_version(self, prior):\n\n    if not isinstance(prior, InventoryValidator):\n        return \"prior is not an instance of InventoryValidator\"\n\n    if self!= prior:\n        return \"incompatible prior version\"\n    return None\n", "def validate_as_prior_version(self, prior):\n    err = \"Validation Error: \"\n    err += \"'{}' is not a valid inventory prior version of '{}'\"\n    raise NotImplementedError(err.format(prior.name, self.name))\n", "def validate_as_prior_version(self, prior):\n    err_msg = \"\"\"\n    The input variable prior is a valid prior version of the current\n    inventory object. The input variable prior is also expected to be\n    an InventoryValidator object and both self and prior inventories\n    are assumed to have been checked for internal consistency.\n    \"\"\"\n    if not isinstance(prior, InventoryValidator):\n        raise TypeError(err_msg)\n    if not prior.validate(self):\n        raise ValueError(err_msg)\n", "def validate_as_prior_version(self, prior):\n    if not isinstance(prior, self.__class__):\n        return (\n            \"invalid type: expected {} but got {}\"\n           .format(self.__class__.__name__, type(prior).__name__)\n        )\n\n    if prior.validate(self):\n        return None\n\n    return self.error(\n        field_name=self._field_name,\n        message=self.__class__.__name__,\n        inventory=prior.get_inventory_message(),\n    )\n", "def validate_as_prior_version(self, prior):\n    if prior is None:\n        return \"prior is None\"\n    if not isinstance(prior, self.__class__):\n        return \"invalid inventory prior type\"\n    if prior.name!= self.name:\n        return \"invalid inventory prior name\"\n    if not self.validate_inventory_requirements(prior.requirements):\n        return \"invalid inventory requirements\"\n    return None\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def validate_as_prior_version(self, prior):\n    msg = \"Prior object must be an instance of BaseInventoryValidator\"\n    assert isinstance(prior, BaseInventoryValidator), msg\n    msg = \"Prior object must be of type {}\".format(BaseInventoryValidator)\n    assert prior.validate(self), msg\n    return \"\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_as_prior_version(self, prior):\n    error(\"Can't use 'prior' in a validation context of an inventory \"\n          \"with a different inventory version.\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_as_prior_version(self, prior):\n\n    if prior is None:\n        return\n\n    # We can only have one of the following types of priors:\n    #   - None: the input parameter is not a valid inventory prior.\n    #   - a string: the input parameter is a valid inventory prior.\n    if not isinstance(prior, inventory_validator.InventoryValidator):\n        return \"Invalid input type: %r\" % prior\n\n    # The input parameter is a valid inventory prior.\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_as_prior_version(self, prior):\n\n    if prior.get_name()!= self.get_name() or prior.get_version()!= self.get_version():\n        return Error(self.invalid_inventory_schema,\n                     \"Inventory '%s' does not match expected version '%s'\" %\n                     (prior.get_name(), self.get_version()))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_as_prior_version(self, prior):\n    if prior.name in self.names():\n        if prior > self.prior:\n            return \"%s cannot be greater than %s\" % (prior.name, self.prior.name)\n        elif prior < self.prior:\n            return \"%s cannot be lesser than %s\" % (prior.name, self.prior.name)\n    return \"\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_as_prior_version(self, prior):\n\n    if not isinstance(prior, InventoryValidator):\n        return \"prior is not an instance of InventoryValidator\"\n\n    if self!= prior:\n        return \"incompatible prior version\"\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_as_prior_version(self, prior):\n    err = \"Validation Error: \"\n    err += \"'{}' is not a valid inventory prior version of '{}'\"\n    raise NotImplementedError(err.format(prior.name, self.name))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_as_prior_version(self, prior):\n    err_msg = \"\"\"\n    The input variable prior is a valid prior version of the current\n    inventory object. The input variable prior is also expected to be\n    an InventoryValidator object and both self and prior inventories\n    are assumed to have been checked for internal consistency.\n    \"\"\"\n    if not isinstance(prior, InventoryValidator):\n        raise TypeError(err_msg)\n    if not prior.validate(self):\n        raise ValueError(err_msg)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_as_prior_version(self, prior):\n    if not isinstance(prior, self.__class__):\n        return (\n            \"invalid type: expected {} but got {}\"\n           .format(self.__class__.__name__, type(prior).__name__)\n        )\n\n    if prior.validate(self):\n        return None\n\n    return self.error(\n        field_name=self._field_name,\n        message=self.__class__.__name__,\n        inventory=prior.get_inventory_message(),\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_as_prior_version(self, prior):\n    if prior is None:\n        return \"prior is None\"\n    if not isinstance(prior, self.__class__):\n        return \"invalid inventory prior type\"\n    if prior.name!= self.name:\n        return \"invalid inventory prior name\"\n    if not self.validate_inventory_requirements(prior.requirements):\n        return \"invalid inventory requirements\"\n    return None\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/inventory_validator.py", "project": "zimeon/ocfl-py", "name": "get_logical_path_map", "docstring": "Get a map of logical paths in state to files on disk for version in inventory.\n\nReturns a dictionary: logical_path_in_state -> set(content_files)\n\nThe set of content_files may includes references to duplicate files in\nlater versions than the version being described.", "ques_id": "62b45e165108cfac7f210a17", "code": ["def get_logical_path_map(inventory, version):\n    if version not in inventory:\n        raise ValueError(\n            'The given inventory is not in the version {0}'.format(version))\n    return inventory[version]['files']\n", "def get_logical_path_map(inventory, version):\n    if version not in inventory:\n        raise Exception('Inventory does not have a state with the given name.')\n    return inventory[version]\n", "def get_logical_path_map(inventory, version):\n    if version not in inventory:\n        raise ValueError('The given version ({}) is not in the inventory!'.format(version))\n\n    return inventory[version]\n", "def get_logical_path_map(inventory, version):\n    if version not in inventory:\n        return {}\n    return inventory[version]\n", "def get_logical_path_map(inventory, version):\n    return _get_path_map(inventory, version)\n", "def get_logical_path_map(inventory, version):\n    path_map = {}\n    for key, value in inventory.items():\n        if key in ['__parent__', '__name__']:\n            continue\n        if isinstance(value, dict):\n            path_map[key] = get_logical_path_map(value, version)\n        elif isinstance(value, (list, tuple)):\n            logical_path = get_logical_path(value, version)\n            if logical_path:\n                path_map[key] = logical_path\n    return path_map\n", "def get_logical_path_map(inventory, version):\n    if version == 1:\n        return {k: v.paths for k, v in inventory.items()}\n    else:\n        return {k: v.logical_paths for k, v in inventory.items()}\n", "def get_logical_path_map(inventory, version):\n    if version not in inventory:\n        return {}\n    else:\n        return inventory[version]\n", "def get_logical_path_map(inventory, version):\n    return {\n        'group_by_arch': get_group_by_arch(inventory, version),\n        'group_by_os': get_group_by_os(inventory, version),\n        'group_by_service': get_group_by_service(inventory, version),\n        'group_by_version': get_group_by_version(inventory, version),\n    }\n", "def get_logical_path_map(inventory, version):\n    if not isinstance(inventory, dict):\n        raise ValueError(\"inventory must be of type dict\")\n\n    if not isinstance(version, str):\n        raise ValueError(\"version must be of type str\")\n\n    if version not in inventory:\n        raise ValueError(\"version '{}' is not in inventory\".format(version))\n\n    return inventory[version]\n"], "level": "self_contained", "generate_results": [{"generate_code": "def get_logical_path_map(inventory, version):\n    if version not in inventory:\n        raise ValueError(\n            'The given inventory is not in the version {0}'.format(version))\n    return inventory[version]['files']\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    if version not in inventory:\n        raise Exception('Inventory does not have a state with the given name.')\n    return inventory[version]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    if version not in inventory:\n        raise ValueError('The given version ({}) is not in the inventory!'.format(version))\n\n    return inventory[version]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    if version not in inventory:\n        return {}\n    return inventory[version]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    return _get_path_map(inventory, version)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    path_map = {}\n    for key, value in inventory.items():\n        if key in ['__parent__', '__name__']:\n            continue\n        if isinstance(value, dict):\n            path_map[key] = get_logical_path_map(value, version)\n        elif isinstance(value, (list, tuple)):\n            logical_path = get_logical_path(value, version)\n            if logical_path:\n                path_map[key] = logical_path\n    return path_map\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    if version == 1:\n        return {k: v.paths for k, v in inventory.items()}\n    else:\n        return {k: v.logical_paths for k, v in inventory.items()}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    if version not in inventory:\n        return {}\n    else:\n        return inventory[version]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    return {\n        'group_by_arch': get_group_by_arch(inventory, version),\n        'group_by_os': get_group_by_os(inventory, version),\n        'group_by_service': get_group_by_service(inventory, version),\n        'group_by_version': get_group_by_version(inventory, version),\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    if not isinstance(inventory, dict):\n        raise ValueError(\"inventory must be of type dict\")\n\n    if not isinstance(version, str):\n        raise ValueError(\"version must be of type str\")\n\n    if version not in inventory:\n        raise ValueError(\"version '{}' is not in inventory\".format(version))\n\n    return inventory[version]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/inventory_validator.py", "project": "zimeon/ocfl-py", "name": "validate_fixity", "docstring": "Validate fixity block in inventory.\n\nCheck the structure of the fixity block and makes sure that only files\nlisted in the manifest are referenced.", "ques_id": "62b45e175108cfac7f210a19", "code": ["def validate_fixity(self, fixity, manifest_files):\n    error = \"\"\n    if 'files' in fixity:\n        for file in fixity['files']:\n            if file not in manifest_files:\n                error += \"{} not found.\\n\".format(file)\n                break\n    return error\n", "def validate_fixity(self, fixity, manifest_files):\n\n    if not fixity:\n        self._log.error('Fixity block cannot be empty')\n        return {'error': 'Fixity block cannot be empty'}\n\n    return self._validate_fixity_single(fixity, manifest_files)\n", "def validate_fixity(self, fixity, manifest_files):\n    errors = []\n    for file in fixity:\n        if file in manifest_files:\n            continue\n        errors.append(\"{0} does not have a file in the inventory.\".format(file))\n    return errors\n", "def validate_fixity(self, fixity, manifest_files):\n    errors = []\n    for file_name, _, _ in fixity:\n        if file_name in manifest_files:\n            errors.append(\n                'File \"{}\" is referenced in the manifest!'.format(file_name))\n    return errors\n", "def validate_fixity(self, fixity, manifest_files):\n    if 'files' in fixity:\n        return fixity\n    else:\n        return {'error': 'Fixity block must contain a list of files'}\n", "def validate_fixity(self, fixity, manifest_files):\n    errors = []\n    for file_path in fixity.get(\"files\", []):\n        if file_path in manifest_files:\n            continue\n\n        errors.append(\"File not found in manifest: {}\".format(file_path))\n    return errors\n", "def validate_fixity(self, fixity, manifest_files):\n    errors = []\n    for file in manifest_files:\n        if not fixity.get(file):\n            errors.append(\"File {} not found\".format(file))\n    return errors\n", "def validate_fixity(self, fixity, manifest_files):\n    referenced_files = []\n    for filename, contents in fixity.items():\n        if filename not in manifest_files:\n            referenced_files.append(filename)\n    if referenced_files:\n        return \"Referenced files in fixity block: {}\".format(\n            \", \".join(referenced_files)\n        )\n    else:\n        return \"\"\n", "def validate_fixity(self, fixity, manifest_files):\n    for f in manifest_files:\n        if f in fixity:\n            return \"\"\"Referenced file '{0}' already present in inventory.\n                        Please remove it from your inventory or use 'uninstall' to reinstall.\"\"\".format(f)\n\n    return \"\"\"Fixity block is not valid.\n                Please add some files to your inventory or use 'uninstall' to reinstall.\"\"\"\n", "def validate_fixity(self, fixity, manifest_files):\n    for file in fixity['files']:\n        if file not in manifest_files:\n            return (\n                \"Fixity file {} does not exist in inventory\".format(file))\n    return None\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    error = \"\"\n    if 'files' in fixity:\n        for file in fixity['files']:\n            if file not in manifest_files:\n                error += \"{} not found.\\n\".format(file)\n                break\n    return error\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n\n    if not fixity:\n        self._log.error('Fixity block cannot be empty')\n        return {'error': 'Fixity block cannot be empty'}\n\n    return self._validate_fixity_single(fixity, manifest_files)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    errors = []\n    for file in fixity:\n        if file in manifest_files:\n            continue\n        errors.append(\"{0} does not have a file in the inventory.\".format(file))\n    return errors\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    errors = []\n    for file_name, _, _ in fixity:\n        if file_name in manifest_files:\n            errors.append(\n                'File \"{}\" is referenced in the manifest!'.format(file_name))\n    return errors\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    if 'files' in fixity:\n        return fixity\n    else:\n        return {'error': 'Fixity block must contain a list of files'}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    errors = []\n    for file_path in fixity.get(\"files\", []):\n        if file_path in manifest_files:\n            continue\n\n        errors.append(\"File not found in manifest: {}\".format(file_path))\n    return errors\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    errors = []\n    for file in manifest_files:\n        if not fixity.get(file):\n            errors.append(\"File {} not found\".format(file))\n    return errors\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    referenced_files = []\n    for filename, contents in fixity.items():\n        if filename not in manifest_files:\n            referenced_files.append(filename)\n    if referenced_files:\n        return \"Referenced files in fixity block: {}\".format(\n            \", \".join(referenced_files)\n        )\n    else:\n        return \"\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    for f in manifest_files:\n        if f in fixity:\n            return \"\"\"Referenced file '{0}' already present in inventory.\n                        Please remove it from your inventory or use 'uninstall' to reinstall.\"\"\".format(f)\n\n    return \"\"\"Fixity block is not valid.\n                Please add some files to your inventory or use 'uninstall' to reinstall.\"\"\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    for file in fixity['files']:\n        if file not in manifest_files:\n            return (\n                \"Fixity file {} does not exist in inventory\".format(file))\n    return None\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/file_utils.py", "project": "scieloorg/packtools", "name": "files_list", "docstring": "Return the files in `path`", "ques_id": "62b463153879012d19481498", "code": ["def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "def files_list(path):\n    return [os.path.join(path, f) for f in os.listdir(path)]\n", "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "def files_list(path):\n    return [os.path.join(path, f) for f in os.listdir(path)]\n", "def files_list(path):\n    if not os.path.exists(path):\n        return []\n    return os.listdir(path)\n", "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [os.path.join(path, f) for f in os.listdir(path)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [os.path.join(path, f) for f in os.listdir(path)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    if not os.path.exists(path):\n        return []\n    return os.listdir(path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "_group_files_by_xml_filename", "docstring": "Group files by their XML basename\n\nGroups files by their XML basename and returns data in dict format.\n\nParameters\n----------\nxml_filename : str\n    XML filenames\nfiles : list\n    list of files in the folder or zipfile\n\nReturns\n-------\ndict\n    key: name of the XML files\n    value: Package", "ques_id": "62b463153879012d1948149a", "code": ["def _group_files_by_xml_filename(source, xmls, files):\n    file_groups = defaultdict(list)\n    for file_name in files:\n        file_groups[file_name].append(source.get_xml_by_filename(file_name))\n    return dict(file_groups)\n", "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for xml_filename in xmls:\n        data.setdefault(xml_filename, []).append(source)\n    for filename in files:\n        for xml_filename in xmls:\n            if filename == xml_filename:\n                continue\n            if filename not in data.get(xml_filename, []):\n                data[xml_filename].append(filename)\n    return data\n", "def _group_files_by_xml_filename(source, xmls, files):\n    groups = {}\n    for xml_file in xmls:\n        for filename in files:\n            if filename == xml_file:\n                continue\n            xml_file_data = source.get_xml_file_data(xml_file)\n            groups.setdefault(filename, []).append(xml_file_data)\n    return groups\n", "def _group_files_by_xml_filename(source, xmls, files):\n    data = OrderedDict()\n    for xml in xmls:\n        for filename in files:\n            if filename in source:\n                data[xml] = source[filename]\n    return data\n", "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for xml_filename in xmls:\n        data.setdefault(xml_filename, [])\n        for filename in files:\n            if filename == source or filename.endswith(xml_filename):\n                data[xml_filename].append(source + filename)\n    return data\n", "def _group_files_by_xml_filename(source, xmls, files):\n    for xml in xmls:\n        for file in files:\n            if file.startswith(xml):\n                path = os.path.join(source, file)\n                with open(path) as data_file:\n                    data = json.load(data_file)\n                return data\n", "def _group_files_by_xml_filename(source, xmls, files):\n    groups = {}\n    for xml_file in xmls:\n        xml_filename = os.path.basename(xml_file)\n        groups.setdefault(xml_filename, [])\n        groups[xml_filename].append((source, xml_file))\n    for xml_file in files:\n        xml_filename = os.path.basename(xml_file)\n        groups.setdefault(xml_filename, [])\n        groups[xml_filename].append((source, None))\n    return groups\n", "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for file in files:\n        data[file] = {}\n        for xml in xmls:\n            if file == xml[0] and xml[1] == file:\n                file_name = xml[2]\n            else:\n                full_file_name = os.path.join(source, file, xml)\n                if not os.path.exists(full_file_name):\n                    continue\n                with open(full_file_name) as f:\n                    data[file][file_name] = f.read()\n    return data\n", "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for xml_filename in xmls:\n        for filename in files:\n            if filename in source.get(xml_filename, []):\n                data[filename] = source[xml_filename]\n\n    return data\n", "def _group_files_by_xml_filename(source, xmls, files):\n    groups = defaultdict(list)\n    for filename, xml in zip(files, xmls):\n        group = _get_xml_filename_group(source, xml)\n        groups[group].append(filename)\n    return groups\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    file_groups = defaultdict(list)\n    for file_name in files:\n        file_groups[file_name].append(source.get_xml_by_filename(file_name))\n    return dict(file_groups)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for xml_filename in xmls:\n        data.setdefault(xml_filename, []).append(source)\n    for filename in files:\n        for xml_filename in xmls:\n            if filename == xml_filename:\n                continue\n            if filename not in data.get(xml_filename, []):\n                data[xml_filename].append(filename)\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    groups = {}\n    for xml_file in xmls:\n        for filename in files:\n            if filename == xml_file:\n                continue\n            xml_file_data = source.get_xml_file_data(xml_file)\n            groups.setdefault(filename, []).append(xml_file_data)\n    return groups\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    data = OrderedDict()\n    for xml in xmls:\n        for filename in files:\n            if filename in source:\n                data[xml] = source[filename]\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for xml_filename in xmls:\n        data.setdefault(xml_filename, [])\n        for filename in files:\n            if filename == source or filename.endswith(xml_filename):\n                data[xml_filename].append(source + filename)\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    for xml in xmls:\n        for file in files:\n            if file.startswith(xml):\n                path = os.path.join(source, file)\n                with open(path) as data_file:\n                    data = json.load(data_file)\n                return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    groups = {}\n    for xml_file in xmls:\n        xml_filename = os.path.basename(xml_file)\n        groups.setdefault(xml_filename, [])\n        groups[xml_filename].append((source, xml_file))\n    for xml_file in files:\n        xml_filename = os.path.basename(xml_file)\n        groups.setdefault(xml_filename, [])\n        groups[xml_filename].append((source, None))\n    return groups\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for file in files:\n        data[file] = {}\n        for xml in xmls:\n            if file == xml[0] and xml[1] == file:\n                file_name = xml[2]\n            else:\n                full_file_name = os.path.join(source, file, xml)\n                if not os.path.exists(full_file_name):\n                    continue\n                with open(full_file_name) as f:\n                    data[file][file_name] = f.read()\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for xml_filename in xmls:\n        for filename in files:\n            if filename in source.get(xml_filename, []):\n                data[filename] = source[xml_filename]\n\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    groups = defaultdict(list)\n    for filename, xml in zip(files, xmls):\n        group = _get_xml_filename_group(source, xml)\n        groups[group].append(filename)\n    return groups\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "match_file_by_prefix", "docstring": "Identify if a `file_path` belongs to a document package by a given `prefix`\n\nRetorna `True` para documentos pertencentes a um pacote.\n\nParameters\n----------\nprefix : str\n    Filename prefix\nfile_path : str\n    File path\nReturns\n-------\nbool\n    True - file belongs to the package", "ques_id": "62b463153879012d1948149b", "code": ["def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or file_path.startswith(\n        prefix + \".\"\n    )\n", "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or \\\n        file_path.startswith(prefix + \".\" ) or \\\n        file_path.startswith(\".\" )\n", "def match_file_by_prefix(prefix, file_path):\n    return (file_path.startswith(prefix) and\n            (not file_path.startswith('.') or\n             '.' not in file_path))\n", "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or \\\n           file_path.startswith(prefix + \".\" + os.path.sep)\n", "def match_file_by_prefix(prefix, file_path):\n    return (os.path.basename(file_path) == prefix and\n            os.path.isfile(file_path) and\n            os.path.splitext(file_path)[0] == '')\n", "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or file_path.startswith(prefix + \".\" )\n", "def match_file_by_prefix(prefix, file_path):\n    return (file_path.startswith(prefix) and\n            os.path.basename(file_path)[0]!= '.' and\n            os.path.basename(file_path)[0]!= '..')\n", "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or \\\n           file_path.startswith(prefix + \".\" )\n", "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or file_path.startswith(prefix + \".\" )\n", "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or \\\n           file_path.startswith(prefix + \".\" ) or \\\n           file_path.startswith(\".\" )\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or file_path.startswith(\n        prefix + \".\"\n    )\n", "is_pass": true, "return_code": 0}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or \\\n        file_path.startswith(prefix + \".\" ) or \\\n        file_path.startswith(\".\" )\n", "is_pass": true, "return_code": 0}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return (file_path.startswith(prefix) and\n            (not file_path.startswith('.') or\n             '.' not in file_path))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or \\\n           file_path.startswith(prefix + \".\" + os.path.sep)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return (os.path.basename(file_path) == prefix and\n            os.path.isfile(file_path) and\n            os.path.splitext(file_path)[0] == '')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or file_path.startswith(prefix + \".\" )\n", "is_pass": true, "return_code": 0}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return (file_path.startswith(prefix) and\n            os.path.basename(file_path)[0]!= '.' and\n            os.path.basename(file_path)[0]!= '..')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or \\\n           file_path.startswith(prefix + \".\" )\n", "is_pass": true, "return_code": 0}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or file_path.startswith(prefix + \".\" )\n", "is_pass": true, "return_code": 0}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + \"-\") or \\\n           file_path.startswith(prefix + \".\" ) or \\\n           file_path.startswith(\".\" )\n", "is_pass": true, "return_code": 0}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "select_filenames_by_prefix", "docstring": "Get files which belongs to a document package.\n\nRetorna os arquivos da lista `files` cujos nomes iniciam com `prefix`\n\nParameters\n----------\nprefix : str\n    Filename prefix\nfiles : str list\n    Files paths\nReturns\n-------\nlist\n    files paths which basename files matches to prefix", "ques_id": "62b463153879012d1948149c", "code": ["def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    filenames = []\n    for filename in files:\n        if filename.startswith(prefix):\n            filenames.append(filename)\n    return filenames\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    filenames = []\n    for filename in files:\n        if filename.startswith(prefix):\n            filenames.append(filename)\n    return filenames\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "_explore_folder", "docstring": "Get packages' data from folder\n\nGroups files by their XML basename and returns data in dict format.\n\nParameters\n----------\nfolder : str\n    Folder of the package\nReturns\n-------\ndict", "ques_id": "62b463153879012d1948149d", "code": ["def _explore_folder(folder):\n    for filename in _group_files_by_xml_filename(folder):\n        yield _read_xml_file(filename)\n", "def _explore_folder(folder):\n    for path, subdirs, files in os.walk(folder):\n        for filename in files:\n            if filename.endswith(\".xml\"):\n                path_to_file = os.path.join(path, filename)\n                _group_files_by_xml_filename(path_to_file)\n", "def _explore_folder(folder):\n    for root, dirs, files in os.walk(folder):\n        for filename in files:\n            if not filename.endswith('.xml'):\n                continue\n            filepath = os.path.join(root, filename)\n            _group_files_by_xml_filename(filepath)\n", "def _explore_folder(folder):\n    for filename in os.listdir(folder):\n        if filename.endswith(\".xml\"):\n            _group_files_by_xml_filename(os.path.join(folder, filename))\n", "def _explore_folder(folder):\n    for filename in os.listdir(folder):\n        if filename.endswith(\".xml\"):\n            yield _group_files_by_xml_filename(os.path.join(folder, filename))\n", "def _explore_folder(folder):\n    for filename in os.listdir(folder):\n        filepath = os.path.join(folder, filename)\n        if os.path.isfile(filepath):\n            yield filepath, _group_files_by_xml_filename(filepath)\n", "def _explore_folder(folder):\n    return {fn: _group_files_by_xml_filename(fn) for fn in os.listdir(folder)}\n", "def _explore_folder(folder):\n    for fname in os.listdir(folder):\n        fpath = os.path.join(folder, fname)\n        if not fname.endswith('.xml'):\n            continue\n        yield _group_files_by_xml_filename(fpath)\n", "def _explore_folder(folder):\n    for filename in os.listdir(folder):\n        if filename.endswith(\".xml\"):\n            yield _group_files_by_xml_filename(folder, filename)\n", "def _explore_folder(folder):\n    for filename in os.listdir(folder):\n        if not filename.endswith('.xml'):\n            continue\n\n        xml_filename = filename[:-4]\n        group = _group_files_by_xml_filename(folder, xml_filename)\n        if group:\n            yield group\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _explore_folder(folder):\n    for filename in _group_files_by_xml_filename(folder):\n        yield _read_xml_file(filename)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    for path, subdirs, files in os.walk(folder):\n        for filename in files:\n            if filename.endswith(\".xml\"):\n                path_to_file = os.path.join(path, filename)\n                _group_files_by_xml_filename(path_to_file)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    for root, dirs, files in os.walk(folder):\n        for filename in files:\n            if not filename.endswith('.xml'):\n                continue\n            filepath = os.path.join(root, filename)\n            _group_files_by_xml_filename(filepath)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    for filename in os.listdir(folder):\n        if filename.endswith(\".xml\"):\n            _group_files_by_xml_filename(os.path.join(folder, filename))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    for filename in os.listdir(folder):\n        if filename.endswith(\".xml\"):\n            yield _group_files_by_xml_filename(os.path.join(folder, filename))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    for filename in os.listdir(folder):\n        filepath = os.path.join(folder, filename)\n        if os.path.isfile(filepath):\n            yield filepath, _group_files_by_xml_filename(filepath)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    return {fn: _group_files_by_xml_filename(fn) for fn in os.listdir(folder)}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    for fname in os.listdir(folder):\n        fpath = os.path.join(folder, fname)\n        if not fname.endswith('.xml'):\n            continue\n        yield _group_files_by_xml_filename(fpath)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    for filename in os.listdir(folder):\n        if filename.endswith(\".xml\"):\n            yield _group_files_by_xml_filename(folder, filename)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    for filename in os.listdir(folder):\n        if not filename.endswith('.xml'):\n            continue\n\n        xml_filename = filename[:-4]\n        group = _group_files_by_xml_filename(folder, xml_filename)\n        if group:\n            yield group\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "_eval_file", "docstring": "Identifica o tipo de arquivo do pacote: `asset` ou `rendition`.\n\nIdentifica o tipo de arquivo do pacote e atualiza `packages` com o tipo e\no endere\u00e7o do arquivo em an\u00e1lise.\n\nParameters\n----------\nprefix : str\n    nome do arquivo XML sem extens\u00e3o\nfilename : str\n    filename\nfile_folder : str\n    file folder\n\nReturns\n-------\ndict", "ques_id": "62b463153879012d1948149f", "code": ["def _eval_file(prefix, file_path):\n    if file_path.lower().endswith(\".pdf\"):\n        ftype = \"pdf\"\n    elif file_path.lower().endswith(\".xml\"):\n        ftype = \"xml\"\n    else:\n        return None\n\n    if ftype == \"pdf\":\n        return {\"component_id\": file_path, \"file_path\": file_path, \"ftype\": \"pdf\"}\n    elif ftype == \"xml\":\n        return {\"component_id\": file_path, \"file_path\": file_path, \"ftype\": \"xml\"}\n", "def _eval_file(prefix, file_path):\n    if file_path.lower().endswith('.xml'):\n        return None\n\n    ftype = 'pdf'\n    if file_path.lower().endswith('.pdf'):\n        ftype = 'ps'\n    return {'component_id': file_path, 'file_path': file_path, 'ftype': ftype}\n", "def _eval_file(prefix, file_path):\n    if file_path.lower().endswith(('.xml', '.pdf')):\n        return None\n    if file_path.lower().endswith(('.csv', '.tsv')):\n        return {'component_id': None, 'file_path': file_path}\n    if file_path.lower().endswith(('.txt', '.xlsx')):\n        return {'component_id': None, 'file_path': file_path, 'ftype': 'text'}\n    if file_path.lower().endswith(('.pdf', '.svg')):\n        return None\n    return {'component_id': None, 'file_path': file_path, 'ftype': 'other'}\n", "def _eval_file(prefix, file_path):\n    ftype = \"\"\n    if file_path.endswith(\".pdf\"):\n        ftype = \"pdf\"\n        return {\"component_id\": \"\", \"file_path\": file_path, \"ftype\": ftype}\n    if file_path.endswith(\".xml\") or file_path.endswith(\".xml.gz\"):\n        ftype = \"xml\"\n        return {\"component_id\": \"\", \"file_path\": file_path, \"ftype\": ftype}\n    return None\n", "def _eval_file(prefix, file_path):\n    if file_path.lower().endswith((\".pdf\", \".xml\")):\n        return {\"component_id\": file_path, \"file_path\": file_path, \"ftype\": \"pdf\"}\n    return None\n", "def _eval_file(prefix, file_path):\n    ext = os.path.splitext(file_path)[1]\n    if ext in ['.xml', '.xml.gz', '.xml']:\n        return None\n    if ext == '.pdf':\n        return {'component_id': 'component_1', 'file_path': file_path}\n    return {'component_id': 'component_1', 'file_path': file_path, 'ftype': ext}\n", "def _eval_file(prefix, file_path):\n    file_type = None\n    if file_path.startswith(prefix):\n        file_type = \"pdf\"\n    elif file_path.startswith('/'):\n        file_type = \"xml\"\n    elif file_path.startswith('./'):\n        file_type = \"flash\"\n    return {\"component_id\": None,\n            \"file_path\": file_path,\n            \"ftype\": file_type}\n", "def _eval_file(prefix, file_path):\n    if file_path.startswith(prefix):\n        return {\n            'component_id': file_path[len(prefix):].split('.', 1)[0],\n            'file_path': file_path,\n            'ftype': 'xml'\n        }\n    elif file_path.endswith('.xml'):\n        return {\n            'component_id': file_path[:-4].split('.', 1)[0],\n            'file_path': file_path,\n            'ftype': 'xml'\n        }\n    else:\n        return None\n", "def _eval_file(prefix, file_path):\n    if file_path.startswith(prefix):\n        return {'component_id': file_path[len(prefix):], 'file_path': file_path, 'ftype': 'pdf'}\n    elif file_path.startswith('/'):\n        return {'component_id': file_path[1:], 'file_path': file_path, 'ftype': 'xml'}\n    return None\n", "def _eval_file(prefix, file_path):\n    if file_path.startswith(prefix):\n        return {'component_id': file_path.split('/')[-1],\n                'file_path': file_path,\n                'ftype': 'pdf'}\n    elif file_path.startswith('/'):\n        return {'component_id': file_path.split('/')[-1],\n                'file_path': file_path,\n                'ftype': 'xml'}\n    return None\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _eval_file(prefix, file_path):\n    if file_path.lower().endswith(\".pdf\"):\n        ftype = \"pdf\"\n    elif file_path.lower().endswith(\".xml\"):\n        ftype = \"xml\"\n    else:\n        return None\n\n    if ftype == \"pdf\":\n        return {\"component_id\": file_path, \"file_path\": file_path, \"ftype\": \"pdf\"}\n    elif ftype == \"xml\":\n        return {\"component_id\": file_path, \"file_path\": file_path, \"ftype\": \"xml\"}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    if file_path.lower().endswith('.xml'):\n        return None\n\n    ftype = 'pdf'\n    if file_path.lower().endswith('.pdf'):\n        ftype = 'ps'\n    return {'component_id': file_path, 'file_path': file_path, 'ftype': ftype}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    if file_path.lower().endswith(('.xml', '.pdf')):\n        return None\n    if file_path.lower().endswith(('.csv', '.tsv')):\n        return {'component_id': None, 'file_path': file_path}\n    if file_path.lower().endswith(('.txt', '.xlsx')):\n        return {'component_id': None, 'file_path': file_path, 'ftype': 'text'}\n    if file_path.lower().endswith(('.pdf', '.svg')):\n        return None\n    return {'component_id': None, 'file_path': file_path, 'ftype': 'other'}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    ftype = \"\"\n    if file_path.endswith(\".pdf\"):\n        ftype = \"pdf\"\n        return {\"component_id\": \"\", \"file_path\": file_path, \"ftype\": ftype}\n    if file_path.endswith(\".xml\") or file_path.endswith(\".xml.gz\"):\n        ftype = \"xml\"\n        return {\"component_id\": \"\", \"file_path\": file_path, \"ftype\": ftype}\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    if file_path.lower().endswith((\".pdf\", \".xml\")):\n        return {\"component_id\": file_path, \"file_path\": file_path, \"ftype\": \"pdf\"}\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    ext = os.path.splitext(file_path)[1]\n    if ext in ['.xml', '.xml.gz', '.xml']:\n        return None\n    if ext == '.pdf':\n        return {'component_id': 'component_1', 'file_path': file_path}\n    return {'component_id': 'component_1', 'file_path': file_path, 'ftype': ext}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    file_type = None\n    if file_path.startswith(prefix):\n        file_type = \"pdf\"\n    elif file_path.startswith('/'):\n        file_type = \"xml\"\n    elif file_path.startswith('./'):\n        file_type = \"flash\"\n    return {\"component_id\": None,\n            \"file_path\": file_path,\n            \"ftype\": file_type}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    if file_path.startswith(prefix):\n        return {\n            'component_id': file_path[len(prefix):].split('.', 1)[0],\n            'file_path': file_path,\n            'ftype': 'xml'\n        }\n    elif file_path.endswith('.xml'):\n        return {\n            'component_id': file_path[:-4].split('.', 1)[0],\n            'file_path': file_path,\n            'ftype': 'xml'\n        }\n    else:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    if file_path.startswith(prefix):\n        return {'component_id': file_path[len(prefix):], 'file_path': file_path, 'ftype': 'pdf'}\n    elif file_path.startswith('/'):\n        return {'component_id': file_path[1:], 'file_path': file_path, 'ftype': 'xml'}\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    if file_path.startswith(prefix):\n        return {'component_id': file_path.split('/')[-1],\n                'file_path': file_path,\n                'ftype': 'pdf'}\n    elif file_path.startswith('/'):\n        return {'component_id': file_path.split('/')[-1],\n                'file_path': file_path,\n                'ftype': 'xml'}\n    return None\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "add_rendition", "docstring": "{\n    \"original\": \"artigo02.pdf\",\n    \"en\": \"artigo02-en.pdf\",\n}", "ques_id": "62b463153879012d194814a1", "code": ["def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "def add_rendition(self, lang, file_path):\n    if lang not in self._renditions:\n        self._renditions[lang] = {}\n    self._renditions[lang][file_path] = sanitize_file_path(file_path)\n", "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "def add_rendition(self, lang, file_path):\n    if lang not in self._renditions:\n        self._renditions[lang] = {}\n    self._renditions[lang][file_path] = file_path\n", "def add_rendition(self, lang, file_path):\n    if lang not in self._renditions:\n        self._renditions[lang] = {}\n    self._renditions[lang][file_path] = None\n", "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_rendition(self, lang, file_path):\n    if lang not in self._renditions:\n        self._renditions[lang] = {}\n    self._renditions[lang][file_path] = sanitize_file_path(file_path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_rendition(self, lang, file_path):\n    if lang not in self._renditions:\n        self._renditions[lang] = {}\n    self._renditions[lang][file_path] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_rendition(self, lang, file_path):\n    if lang not in self._renditions:\n        self._renditions[lang] = {}\n    self._renditions[lang][file_path] = None\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_rendition(self, lang, file_path):\n    self._renditions[lang] = file_path\n", "is_pass": true, "return_code": 0}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "add_asset", "docstring": "\"{\n    \"artigo02-gf03.tiff\": \"/path/artigo02-gf03.tiff\",\n    \"artigo02-gf03.jpg\": \"/path/artigo02-gf03.jpg\",\n    \"artigo02-gf03.png\": \"/path/artigo02-gf03.png\",\n}", "ques_id": "62b463163879012d194814a2", "code": ["def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_asset(self, basename, file_path):\n    self._assets[basename] = file_path\n", "is_pass": true, "return_code": 0}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "_explore_zipfile", "docstring": "Get packages' data from zip_path\n\nGroups files by their XML basename and returns data in dict format.\n\nParameters\n----------\nzip_path : str\n    zip file path\nReturns\n-------\ndict", "ques_id": "62b463163879012d194814a4", "code": ["def _explore_zipfile(zip_path):\n    for filename in _group_files_by_xml_filename(zip_path):\n        yield filename\n", "def _explore_zipfile(zip_path):\n    return _group_files_by_xml_filename(_get_zip_file_as_string(zip_path))\n", "def _explore_zipfile(zip_path):\n    return _group_files_by_xml_filename(_zip_path, _zip_path)\n", "def _explore_zipfile(zip_path):\n    # remove the.zip extension from the zip path\n    zip_path = zip_path[:-4]\n    for filename in _group_files_by_xml_filename(zip_path):\n        yield filename\n", "def _explore_zipfile(zip_path):\n    zip_path = _group_files_by_xml_filename(zip_path)\n    return list(zip_path)\n", "def _explore_zipfile(zip_path):\n    return {\n        os.path.splitext(os.path.basename(f))[0]: _group_files_by_xml_filename(f)\n        for f in os.listdir(zip_path)\n        if os.path.splitext(f)[1] == \".xml\"\n    }\n", "def _explore_zipfile(zip_path):\n    if not zip_path:\n        return\n    result = []\n    for filename in _group_files_by_xml_filename(zip_path):\n        if not filename.endswith('.xml'):\n            continue\n        result.append(filename)\n    return result\n", "def _explore_zipfile(zip_path):\n    if not zip_path:\n        return []\n    results = []\n    for root, dirs, files in os.walk(zip_path):\n        for filename in files:\n            if filename.endswith('.xml'):\n                results.append(os.path.join(root, filename))\n    return _group_files_by_xml_filename(results)\n", "def _explore_zipfile(zip_path):\n    return _group_files_by_xml_filename(_read_zip(zip_path))\n", "def _explore_zipfile(zip_path):\n    return _group_files_by_xml_filename(_find_xml_files(zip_path))\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _explore_zipfile(zip_path):\n    for filename in _group_files_by_xml_filename(zip_path):\n        yield filename\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    return _group_files_by_xml_filename(_get_zip_file_as_string(zip_path))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    return _group_files_by_xml_filename(_zip_path, _zip_path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    # remove the.zip extension from the zip path\n    zip_path = zip_path[:-4]\n    for filename in _group_files_by_xml_filename(zip_path):\n        yield filename\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    zip_path = _group_files_by_xml_filename(zip_path)\n    return list(zip_path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    return {\n        os.path.splitext(os.path.basename(f))[0]: _group_files_by_xml_filename(f)\n        for f in os.listdir(zip_path)\n        if os.path.splitext(f)[1] == \".xml\"\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    if not zip_path:\n        return\n    result = []\n    for filename in _group_files_by_xml_filename(zip_path):\n        if not filename.endswith('.xml'):\n            continue\n        result.append(filename)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    if not zip_path:\n        return []\n    results = []\n    for root, dirs, files in os.walk(zip_path):\n        for filename in files:\n            if filename.endswith('.xml'):\n                results.append(os.path.join(root, filename))\n    return _group_files_by_xml_filename(results)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    return _group_files_by_xml_filename(_read_zip(zip_path))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    return _group_files_by_xml_filename(_find_xml_files(zip_path))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/file_utils.py", "project": "scieloorg/packtools", "name": "files_list_from_zipfile", "docstring": "Return the files in `zip_path`\n\nExample:\n\n```\n[\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200069.pdf',\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200069.xml',\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200071.pdf',\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200071.xml',\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200071-gf01.tif',\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200071-gf02.tif',\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200071-gf03.tif',\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200071-gf04.tif',\n]\n```", "ques_id": "62b463163879012d194814a6", "code": ["def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zip_file:\n        return [\n            name\n            for name in zip_file.namelist()\n            if os.path.splitext(name)[1] == \".py\"\n        ]\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [path.name for path in zf.namelist()]\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [path.name for path in zf.namelist()]\n", "def files_list_from_zipfile(zip_path):\n    with ZipFile(zip_path) as zf:\n        return [fname for fname in zf.namelist() if not fname.startswith('.')]\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [name for name in zf.namelist() if not name.startswith('.')]\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [f for f in zf.namelist() if not f.startswith('.')]\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zip:\n        return [name for name in zip.namelist() if not name.startswith('.')]\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [path.split(os.sep)[-1] for path in zf.namelist()]\n", "def files_list_from_zipfile(zip_path):\n    with ZipFile(zip_path) as zf:\n        return [name for name in zf.namelist() if not name.startswith('.')]\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return list(zf.namelist())\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zip_file:\n        return [\n            name\n            for name in zip_file.namelist()\n            if os.path.splitext(name)[1] == \".py\"\n        ]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [path.name for path in zf.namelist()]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [path.name for path in zf.namelist()]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with ZipFile(zip_path) as zf:\n        return [fname for fname in zf.namelist() if not fname.startswith('.')]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [name for name in zf.namelist() if not name.startswith('.')]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [f for f in zf.namelist() if not f.startswith('.')]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zip:\n        return [name for name in zip.namelist() if not name.startswith('.')]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [path.split(os.sep)[-1] for path in zf.namelist()]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with ZipFile(zip_path) as zf:\n        return [name for name in zf.namelist() if not name.startswith('.')]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return list(zf.namelist())\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/sps/utils/xml_utils.py", "project": "scieloorg/packtools", "name": "fix_namespace_prefix_w", "docstring": "Convert text that defaults to 'w:st=\"' to 'w-st=\"'", "ques_id": "62b4631b3879012d194814dd", "code": ["def fix_namespace_prefix_w(content):\n    return re.sub(r'w:([a-zA-Z0-9\\-]+)=',\n                  'w-st=\"{0}\"'.format(content), content)\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:([a-zA-Z0-9_]+)=\"([a-zA-Z0-9_]+)\"',\n                  r'w-st=\"\\1-\\2\"', content)\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:(\\w+)st=\"(.+)\"', r'\\1-st=\\2', content)\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r\"w:(st=|w-st=)(.+?)\\1\", r\"\\1-\\2\", content)\n", "def fix_namespace_prefix_w(content):\n    return re.sub(\n        r\"w:(\\w+):st=(['\\\"])(.*?)(['\\\"])\",\n        r\"\\1-\\2\",\n        content,\n    )\n", "def fix_namespace_prefix_w(content):\n    return re.sub(\n        r'w:(\\w+)st=\"(.+?)\"',\n        r'w-st=\"\\1\"',\n        content,\n        flags=re.I\n    )\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:([a-z0-9_]+)=\"([a-z0-9_]+)\"', r'\\1-\\2', content)\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:([a-zA-Z0-9_]+)=\"([a-zA-Z0-9_]+)\"', r'\\1-st=\\2', content)\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:(\\w+)st=\"(.*)\"', r'\\1-st=\\2', content)\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:([a-zA-Z0-9]+)st=\"([a-zA-Z0-9]+)\"',\n                  r'w-st=\"\\1-\\2\"', content)\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:([a-zA-Z0-9\\-]+)=',\n                  'w-st=\"{0}\"'.format(content), content)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:([a-zA-Z0-9_]+)=\"([a-zA-Z0-9_]+)\"',\n                  r'w-st=\"\\1-\\2\"', content)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:(\\w+)st=\"(.+)\"', r'\\1-st=\\2', content)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return re.sub(r\"w:(st=|w-st=)(.+?)\\1\", r\"\\1-\\2\", content)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return re.sub(\n        r\"w:(\\w+):st=(['\\\"])(.*?)(['\\\"])\",\n        r\"\\1-\\2\",\n        content,\n    )\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return re.sub(\n        r'w:(\\w+)st=\"(.+?)\"',\n        r'w-st=\"\\1\"',\n        content,\n        flags=re.I\n    )\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:([a-z0-9_]+)=\"([a-z0-9_]+)\"', r'\\1-\\2', content)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:([a-zA-Z0-9_]+)=\"([a-zA-Z0-9_]+)\"', r'\\1-st=\\2', content)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:(\\w+)st=\"(.*)\"', r'\\1-st=\\2', content)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return re.sub(r'w:([a-zA-Z0-9]+)st=\"([a-zA-Z0-9]+)\"',\n                  r'w-st=\"\\1-\\2\"', content)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "packtools/sps/utils/xml_utils.py", "project": "scieloorg/packtools", "name": "match_pubdate", "docstring": "Returns the first match in the pubdate_xpaths list", "ques_id": "62b463283879012d1948153d", "code": ["def match_pubdate(node, pubdate_xpaths):\n    return next((p for p in pubdate_xpaths if match_xpath(node, p)), None)\n", "def match_pubdate(node, pubdate_xpaths):\n    return next((p for p in pubdate_xpaths if match_xpath(node, p)), None)\n", "def match_pubdate(node, pubdate_xpaths):\n    return next((x for x in pubdate_xpaths if x.match(node)), None)\n", "def match_pubdate(node, pubdate_xpaths):\n    return next((p for p in pubdate_xpaths if match_xpath(node, p)), None)\n", "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        try:\n            return etree.XPath(pubdate_xpath, namespaces=node.nsmap)[0].text\n        except IndexError:\n            pass\n    return None\n", "def match_pubdate(node, pubdate_xpaths):\n    return next(iter(filter(\n        lambda x: x.match(node),\n        pubdate_xpaths\n    )), None)\n", "def match_pubdate(node, pubdate_xpaths):\n    return next(iter(matching_nodes(node, pubdate_xpaths)), None)\n", "def match_pubdate(node, pubdate_xpaths):\n    return next((x for x in pubdate_xpaths if x.match(node)), None)\n", "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        if pubdate_xpath(node):\n            return pubdate_xpath(node)\n", "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        try:\n            return next(\n                etree.XPath(pubdate_xpath, namespaces=node.nsmap)\n                   .xpath(node)\n            )\n        except StopIteration:\n            continue\n    return None\n"], "level": "self_contained", "generate_results": [{"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next((p for p in pubdate_xpaths if match_xpath(node, p)), None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next((p for p in pubdate_xpaths if match_xpath(node, p)), None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next((x for x in pubdate_xpaths if x.match(node)), None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next((p for p in pubdate_xpaths if match_xpath(node, p)), None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        try:\n            return etree.XPath(pubdate_xpath, namespaces=node.nsmap)[0].text\n        except IndexError:\n            pass\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next(iter(filter(\n        lambda x: x.match(node),\n        pubdate_xpaths\n    )), None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next(iter(matching_nodes(node, pubdate_xpaths)), None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next((x for x in pubdate_xpaths if x.match(node)), None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        if pubdate_xpath(node):\n            return pubdate_xpath(node)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        try:\n            return next(\n                etree.XPath(pubdate_xpath, namespaces=node.nsmap)\n                   .xpath(node)\n            )\n        except StopIteration:\n            continue\n    return None\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/sps/models/front_articlemeta_issue.py", "project": "scieloorg/packtools", "name": "_extract_number_and_supplment_from_issue_element", "docstring": "Extract the possible values of number and suppl from the contents of issue.", "ques_id": "62b463303879012d19481579", "code": ["def _extract_number_and_supplment_from_issue_element(issue):\n    number = _extract_text_from_issue_element(issue, './/number')\n    sup = _extract_text_from_issue_element(issue, './/supplement')\n    return number, sup\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = ''\n    sup = ''\n    if 'number' in issue.attrib:\n        number = issue.attrib['number']\n    if'sup' in issue.attrib:\n        sup = issue.attrib['sup']\n    return number, sup\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('.//number')\n    sup = issue.find('.//supplement')\n    if number is None or sup is None:\n        return None, None\n    if number.text is None:\n        return None, None\n    if sup.text is None:\n        return number.text, sup.text\n    return number.text, sup.text\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = None\n    sup = None\n    for element in issue:\n        if element.tag == 'number':\n            number = element.text\n        elif element.tag =='supplement':\n            sup = element.text\n    return number, sup\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = None\n    supplement = None\n    for child in issue:\n        if child.tag == \"number\":\n            number = child.text\n        elif child.tag == \"sup\":\n            supplement = child.text\n    return number, supplement\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    return (\n        _extract_number(issue),\n        _extract_sup(issue),\n    )\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('.//Number')\n    sup = issue.find('.//Supplementary')\n    return number, sup\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('number').text\n    sup = issue.find('sup').text\n    return number, sup\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = None\n    sup = None\n    for child in issue:\n        if child.tag == \"number\":\n            number = child.text\n        elif child.tag == \"sup\":\n            sup = child.text\n        elif child.tag == \"type\":\n            break\n    return number, sup\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    return (\n        issue.find('number').text,\n        issue.find('sup').text\n    )\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = _extract_text_from_issue_element(issue, './/number')\n    sup = _extract_text_from_issue_element(issue, './/supplement')\n    return number, sup\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = ''\n    sup = ''\n    if 'number' in issue.attrib:\n        number = issue.attrib['number']\n    if'sup' in issue.attrib:\n        sup = issue.attrib['sup']\n    return number, sup\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('.//number')\n    sup = issue.find('.//supplement')\n    if number is None or sup is None:\n        return None, None\n    if number.text is None:\n        return None, None\n    if sup.text is None:\n        return number.text, sup.text\n    return number.text, sup.text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = None\n    sup = None\n    for element in issue:\n        if element.tag == 'number':\n            number = element.text\n        elif element.tag =='supplement':\n            sup = element.text\n    return number, sup\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = None\n    supplement = None\n    for child in issue:\n        if child.tag == \"number\":\n            number = child.text\n        elif child.tag == \"sup\":\n            supplement = child.text\n    return number, supplement\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    return (\n        _extract_number(issue),\n        _extract_sup(issue),\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('.//Number')\n    sup = issue.find('.//Supplementary')\n    return number, sup\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('number').text\n    sup = issue.find('sup').text\n    return number, sup\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = None\n    sup = None\n    for child in issue:\n        if child.tag == \"number\":\n            number = child.text\n        elif child.tag == \"sup\":\n            sup = child.text\n        elif child.tag == \"type\":\n            break\n    return number, sup\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    return (\n        issue.find('number').text,\n        issue.find('sup').text\n    )\n", "is_pass": false, "return_code": 1}]}
{"file_path": "boolean/boolean.py", "project": "bastikr/boolean", "name": "pretty", "docstring": "Return a pretty formatted representation of self.", "ques_id": "62b46740d2f69a53b466171a", "code": ["def pretty(self, indent=0, debug=False):\n    if debug:\n        indent_string = \" \" * indent\n        return f\"{indent_string}{self.__class__.__name__}({self.obj!r})\"\n    else:\n        return f\"{indent_string}{self.__class__.__name__}({self.obj!r}, {self.debug_details!r})\"\n", "def pretty(self, indent=0, debug=False):\n    if self.__class__.__name__ == \"Reactor\":\n        return super().pretty(indent=indent, debug=debug)\n    return super().pretty(indent=indent, debug=debug)\n", "def pretty(self, indent=0, debug=False):\n    if self.is_none():\n        return \"None\"\n    debug_details = \"\" if debug else \"\"\n    if self.__dict__:\n        repr_details = \", \".join(\n            [f\"'{k}'={v}\" for k, v in self.__dict__.items()]\n        )\n        return (\n            f\"{self.__class__.__name__}({debug_details}{repr_details})\"\n            if debug\n            else f\"{self.__class__.__name__}({repr_details})\"\n        )\n    else:\n        return \"<{} at {}>\".format(self.__class__.__name__, hex(id(self)))\n", "def pretty(self, indent=0, debug=False):\n    if debug:\n        debug_details = f\"{self.__class__.__name__}({self.obj!r})\"\n    else:\n        debug_details = \"\"\n    return (\n        f\"{indent}{debug_details}\"\n        f\"({debug_details}{self.__dict__})\"\n    )\n", "def pretty(self, indent=0, debug=False):\n    if self.is_pointer and self.name in PRIMITIVE_TYPES:\n        return (\n            f\"{debug_details}{self.name}({self.__class__.__name__}({self.obj!r}))\"\n        )\n    if not self.is_pointer:\n        return (\n            f\"{debug_details}{self.name}({self.__class__.__name__}({self.obj!r}))\"\n        )\n    if self.name in PRIMITIVE_TYPES:\n        return (\n            f\"{debug_details}{self.name}({self.__class__.__name__}({self.obj!r}, {self.is_pointer}))\"\n        )\n    return (\n        f\"{debug_details}{self.name}({self.__class__.__name__}({self.obj!r}, {self.is_pointer}, {self.name}))\"\n    )\n", "def pretty(self, indent=0, debug=False):\n    debug_details = \"\"\n    if debug:\n        debug_details = f\"{self.__class__.__name__}({self.obj})\"\n    pretty_str = (\n        f\"{indent}{self.__class__.__name__}({debug_details}{self.__str__()})\"\n    )\n    return pretty_str\n", "def pretty(self, indent=0, debug=False):\n    return (\n        (\" \" * indent) + f\"{self.__class__.__name__}({debug_details}{self.obj})\"\n    )\n", "def pretty(self, indent=0, debug=False):\n    debug_details = f\"{self.__class__.__name__}: {self.obj}\"\n    if debug:\n        debug_details += f\", \" + f\"{self.__dict__}\"\n    else:\n        debug_details = \"\"\n    return (\n        f\"{indent}\"\n        f\"{self.__class__.__name__}({debug_details}{self.obj})\"\n    )\n", "def pretty(self, indent=0, debug=False):\n    debug_details = \"\"\n    if debug:\n        debug_details = \": \" + self.__class__.__name__\n    return (\n        f\"{indent}{self.__class__.__name__}({debug_details}{self.obj})\"\n    )\n", "def pretty(self, indent=0, debug=False):\n    debug_details = ''\n    if debug:\n        debug_details +='({})'.format(self.__class__.__name__)\n    if self.__dict__ is not None:\n        return (\n            (''* indent) +\n            debug_details +\n            f'\\n{self.__dict__}'\n        )\n    else:\n        return debug_details + (\n            f'\\n{self.__class__.__name__} object not serializable'\n        )\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def pretty(self, indent=0, debug=False):\n    if debug:\n        indent_string = \" \" * indent\n        return f\"{indent_string}{self.__class__.__name__}({self.obj!r})\"\n    else:\n        return f\"{indent_string}{self.__class__.__name__}({self.obj!r}, {self.debug_details!r})\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    if self.__class__.__name__ == \"Reactor\":\n        return super().pretty(indent=indent, debug=debug)\n    return super().pretty(indent=indent, debug=debug)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    if self.is_none():\n        return \"None\"\n    debug_details = \"\" if debug else \"\"\n    if self.__dict__:\n        repr_details = \", \".join(\n            [f\"'{k}'={v}\" for k, v in self.__dict__.items()]\n        )\n        return (\n            f\"{self.__class__.__name__}({debug_details}{repr_details})\"\n            if debug\n            else f\"{self.__class__.__name__}({repr_details})\"\n        )\n    else:\n        return \"<{} at {}>\".format(self.__class__.__name__, hex(id(self)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    if debug:\n        debug_details = f\"{self.__class__.__name__}({self.obj!r})\"\n    else:\n        debug_details = \"\"\n    return (\n        f\"{indent}{debug_details}\"\n        f\"({debug_details}{self.__dict__})\"\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    if self.is_pointer and self.name in PRIMITIVE_TYPES:\n        return (\n            f\"{debug_details}{self.name}({self.__class__.__name__}({self.obj!r}))\"\n        )\n    if not self.is_pointer:\n        return (\n            f\"{debug_details}{self.name}({self.__class__.__name__}({self.obj!r}))\"\n        )\n    if self.name in PRIMITIVE_TYPES:\n        return (\n            f\"{debug_details}{self.name}({self.__class__.__name__}({self.obj!r}, {self.is_pointer}))\"\n        )\n    return (\n        f\"{debug_details}{self.name}({self.__class__.__name__}({self.obj!r}, {self.is_pointer}, {self.name}))\"\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    debug_details = \"\"\n    if debug:\n        debug_details = f\"{self.__class__.__name__}({self.obj})\"\n    pretty_str = (\n        f\"{indent}{self.__class__.__name__}({debug_details}{self.__str__()})\"\n    )\n    return pretty_str\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    return (\n        (\" \" * indent) + f\"{self.__class__.__name__}({debug_details}{self.obj})\"\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    debug_details = f\"{self.__class__.__name__}: {self.obj}\"\n    if debug:\n        debug_details += f\", \" + f\"{self.__dict__}\"\n    else:\n        debug_details = \"\"\n    return (\n        f\"{indent}\"\n        f\"{self.__class__.__name__}({debug_details}{self.obj})\"\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    debug_details = \"\"\n    if debug:\n        debug_details = \": \" + self.__class__.__name__\n    return (\n        f\"{indent}{self.__class__.__name__}({debug_details}{self.obj})\"\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    debug_details = ''\n    if debug:\n        debug_details +='({})'.format(self.__class__.__name__)\n    if self.__dict__ is not None:\n        return (\n            (''* indent) +\n            debug_details +\n            f'\\n{self.__dict__}'\n        )\n    else:\n        return debug_details + (\n            f'\\n{self.__class__.__name__} object not serializable'\n        )\n", "is_pass": false, "return_code": 1}]}
{"file_path": "boolean/boolean.py", "project": "bastikr/boolean", "name": "absorb", "docstring": "Given an `args` sequence of expressions, return a new list of expression\napplying absorption and negative absorption.\n\nSee https://en.wikipedia.org/wiki/Absorption_law\n\nAbsorption::\n\n    A & (A | B) = A, A | (A & B) = A\n\nNegative absorption::\n\n    A & (~A | B) = A & B, A | (~A & B) = A | B", "ques_id": "62b46746d2f69a53b4661722", "code": ["def absorb(self, args):\n    return args\n", "def absorb(self, args):\n    return [self.absorb_term(arg) for arg in args]\n", "def absorb(self, args):\n    if self.is_non_assignment_operator(args):\n        raise ValueError(\"Cannot absorb non-assignment operators.\")\n    args = list(args)\n    for i in range(len(args)):\n        if args[i].is_assignment_operator():\n            args[i] = self.assignment_operator(args[i])\n        elif args[i].is_subscript_operator():\n            args[i] = self.slice_operator(args[i])\n        elif args[i].is_scalar_operator():\n            args[i] = self.scalar_operator(args[i])\n        else:\n            raise ValueError(\"Cannot absorb unknown operator {}\".format(i))\n    return args\n", "def absorb(self, args):\n    return [self._absorb(arg) for arg in args]\n", "def absorb(self, args):\n    return [self.absorb_one(arg) for arg in args]\n", "def absorb(self, args):\n    return [self.absorb_expr(arg) for arg in args]\n", "def absorb(self, args):\n\n    return [arg for arg in args if arg not in self.args]\n", "def absorb(self, args):\n\n    return args\n", "def absorb(self, args):\n    return [self.absorb_one(arg) for arg in args]\n", "def absorb(self, args):\n\n    # TODO: return a new list of expressions (not lists) when possible\n\n    if len(args) == 0:\n        return args\n\n    for i, arg in enumerate(args):\n        if isinstance(arg, Expression):\n            args[i] = arg.absorb()\n        else:\n            raise TypeError(\"Expecting expression instance, got %s\" % type(arg))\n\n    return args\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def absorb(self, args):\n    return args\n", "is_pass": true, "return_code": 0}, {"generate_code": "def absorb(self, args):\n    return [self.absorb_term(arg) for arg in args]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n    if self.is_non_assignment_operator(args):\n        raise ValueError(\"Cannot absorb non-assignment operators.\")\n    args = list(args)\n    for i in range(len(args)):\n        if args[i].is_assignment_operator():\n            args[i] = self.assignment_operator(args[i])\n        elif args[i].is_subscript_operator():\n            args[i] = self.slice_operator(args[i])\n        elif args[i].is_scalar_operator():\n            args[i] = self.scalar_operator(args[i])\n        else:\n            raise ValueError(\"Cannot absorb unknown operator {}\".format(i))\n    return args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n    return [self._absorb(arg) for arg in args]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n    return [self.absorb_one(arg) for arg in args]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n    return [self.absorb_expr(arg) for arg in args]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n\n    return [arg for arg in args if arg not in self.args]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n\n    return args\n", "is_pass": true, "return_code": 0}, {"generate_code": "def absorb(self, args):\n    return [self.absorb_one(arg) for arg in args]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n\n    # TODO: return a new list of expressions (not lists) when possible\n\n    if len(args) == 0:\n        return args\n\n    for i, arg in enumerate(args):\n        if isinstance(arg, Expression):\n            args[i] = arg.absorb()\n        else:\n            raise TypeError(\"Expecting expression instance, got %s\" % type(arg))\n\n    return args\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/controller/kubernetes/hooks.py", "project": "rak-n-rok/Krake", "name": "on", "docstring": "Decorator function to add a new handler to the registry.\n\nArgs:\n    hook (HookType): Hook attribute for which to register the handler.\n\nReturns:\n    callable: Decorator for registering listeners for the specified\n    hook.", "ques_id": "62b86707b4d922cb0e688c2a", "code": ["def on(self, hook):\n    def decorator(func):\n        if hook not in self._hooks:\n            self._hooks[hook] = []\n        self._hooks[hook].append(func)\n        return func\n    return decorator\n", "def on(self, hook):\n\n    def decorator(func):\n        if hook not in self._hooks:\n            self._hooks[hook] = []\n        self._hooks[hook].append(func)\n        return func\n    return decorator\n", "def on(self, hook):\n\n    def decorator(func):\n        if hook not in self.hooks:\n            self.hooks[hook] = []\n        self.hooks[hook].append(func)\n        return func\n\n    return decorator\n", "def on(self, hook):\n    def wrapper(handler):\n        if hook not in self._registry[hook]:\n            self._registry[hook].append(hook)\n        return handler\n    return wrapper\n", "def on(self, hook):\n\n    def decorator(func):\n        if hook not in self._registry:\n            self._registry[hook] = [func]\n        else:\n            self._registry[hook].append(func)\n        return func\n\n    return decorator\n", "def on(self, hook):\n\n    def decorator(func):\n        if hook not in self._hooks:\n            self._hooks[hook] = []\n        self._hooks[hook].append(func)\n        return func\n\n    return decorator\n", "def on(self, hook):\n    def decorator(func):\n        self.register_hook(hook, func)\n        return func\n    return decorator\n", "def on(self, hook):\n    def decorator(func):\n        self._hooks[hook].append(func)\n        return func\n    return decorator\n", "def on(self, hook):\n\n    def decorator(func):\n        if hook not in self._hooks:\n            self._hooks[hook] = []\n        self._hooks[hook].append(func)\n        return func\n\n    return decorator\n", "def on(self, hook):\n    def decorator(func):\n        if hook not in self._hooks:\n            self._hooks[hook] = []\n        self._hooks[hook].append(func)\n        return func\n    return decorator\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def on(self, hook):\n    def decorator(func):\n        if hook not in self._hooks:\n            self._hooks[hook] = []\n        self._hooks[hook].append(func)\n        return func\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n\n    def decorator(func):\n        if hook not in self._hooks:\n            self._hooks[hook] = []\n        self._hooks[hook].append(func)\n        return func\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n\n    def decorator(func):\n        if hook not in self.hooks:\n            self.hooks[hook] = []\n        self.hooks[hook].append(func)\n        return func\n\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n    def wrapper(handler):\n        if hook not in self._registry[hook]:\n            self._registry[hook].append(hook)\n        return handler\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n\n    def decorator(func):\n        if hook not in self._registry:\n            self._registry[hook] = [func]\n        else:\n            self._registry[hook].append(func)\n        return func\n\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n\n    def decorator(func):\n        if hook not in self._hooks:\n            self._hooks[hook] = []\n        self._hooks[hook].append(func)\n        return func\n\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n    def decorator(func):\n        self.register_hook(hook, func)\n        return func\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n    def decorator(func):\n        self._hooks[hook].append(func)\n        return func\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n\n    def decorator(func):\n        if hook not in self._hooks:\n            self._hooks[hook] = []\n        self._hooks[hook].append(func)\n        return func\n\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n    def decorator(func):\n        if hook not in self._hooks:\n            self._hooks[hook] = []\n        self._hooks[hook].append(func)\n        return func\n    return decorator\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/tests/conftest.py", "project": "rak-n-rok/Krake", "name": "base_config", "docstring": "Creates a configuration with some simple parameters, which have a default value\nthat can be set.\n\nArgs:\n    user (str): the name of the user for the static authentication\n    etcd_host (str): the host for the database.\n    etcd_port (int): the port for the database.\n\nReturns:\n    dict: the created configuration.", "ques_id": "62b86729b4d922cb0e688c2f", "code": ["def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    c = Configuration(user)\n    c.key_params[\"tls\"] = {\"key\": \"127.0.0.1:{}\".format(etcd_port)}\n    c.key_params[\"authentication\"] = {\"key\": \"{}:{}\".format(user, \"password\")}\n    c.key_params[\"authorization\"] = {\"key\": \"{}:{}\".format(user, \"token\")}\n    c.key_params[\"docs\"] = {\"key\": \"{}:{}\".format(user, \"docs\")}\n    c.key_params[\"log\"] = {\"key\": \"{}:{}\".format(user, \"log\")}\n\n    return c\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = Config()\n    for k in [\"tls\", \"authentication\", \"authorization\", \"etcd\", \"docs\", \"log\"]:\n        config.set(\"general\", k, \"{}\".format(k))\n\n    config.set(\"tls\", \"certificate-authority\", \"/etc/ssl/certs/ca-certificates.pem\")\n    config.set(\"tls\", \"key-file\", \"/etc/ssl/private/ca-certificates.pem\")\n    config.set(\"tls\", \"client-certificate\", \"/etc/ssl/certs/client-certificates.pem\")\n    config.set(\"tls\", \"client-key\", \"/etc/ssl/private/ca-certificates.pem\")\n\n    config.set(\"docs\", \"address\", \"http://{}:{}\".format(etcd_host, etcd_port))\n    config.set(\"docs\", \"service-address\", \"http://{}:{}\".format(etcd_host, etcd_port))\n    config.set(\"docs\", \"service-key\", \"http://{}:{}\".format(etcd_host, etcd_port))\n\n    config.set(\"log\", \"log-file\", \"/var/log/docs.log\")\n    config.set(\"log\", \"log-level\", \"info\")\n    config.set(\"log\", \"log-format\", \"%(message)s\")\n\n    return config\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"docs\": \"docs\",\n        \"log\": \"log\",\n        \"key\": {\n            \"tls\": True,\n            \"authentication\": True,\n            \"authorization\": True,\n            \"etcd\": True,\n            \"docs\": True,\n            \"log\": True,\n        },\n    }\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    conf = {\n        \"tls\": {\n            \"certFile\": None,\n            \"keyFile\": None,\n            \"caCerts\": {},\n            \"certChain\": \"\",\n            \"certChainCredentials\": None,\n        },\n        \"authentication\": {\n            \"username\": user,\n            \"etcd\": {\"host\": etcd_host, \"port\": etcd_port},\n            \"docs\": {\"host\": \"127.0.0.1\", \"port\": 8080, \"prefix\": \"/docs\"},\n        },\n        \"authorization\": {\n            \"username\": user,\n            \"etcd\": {\"host\": etcd_host, \"port\": etcd_port},\n            \"docs\": {\"host\": \"127.0.0.1\", \"port\": 8080, \"prefix\": \"/docs\"},\n        },\n        \"log\": {\n            \"level\": \"debug\",\n          ", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"etcd\": {\n            \"host\": etcd_host,\n            \"port\": etcd_port,\n        },\n        \"docs\": {\n            \"user\": user,\n            \"key\": {\n                \"tls\": False,\n                \"authentication\": False,\n                \"authorization\": False,\n                \"etcd\": {\n                    \"host\": etcd_host,\n                    \"port\": etcd_port,\n                },\n                \"log\": False,\n            },\n        },\n        \"log\": {\n            \"level\": logging.INFO,\n        },\n        \"tls\": {\n            \"host\": \"localhost\",\n            \"port\": etcd_port,\n        },\n ", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = {\n        'tls': True,\n        'authentication': {\n            'type': 'basic',\n            'username': user,\n            'keyfile': '/etc/etcd/keys/key.key'\n        },\n        'authorization': {\n            'type': 'basic',\n            'username': user,\n            'keyfile': '/etc/etcd/keys/key.key'\n        },\n        'docs': True,\n        'log': True,\n    }\n\n    if etcd_host:\n        config['docs']['etcd_host'] = etcd_host\n\n    if etcd_port:\n        config['docs']['etcd_port'] = etcd_port\n\n    return config\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"docs\": [\n            \"/\"\n        ],\n        \"log\": [\n            \"/\"\n        ],\n        \"tls\": [\n            \"none\"\n        ],\n        \"authentication\": {\n            \"certificate-authority\": \"/etc/ssl/certs/ca-certificates.crt\",\n            \"private-key\": \"/etc/ssl/private/ca-certificates.key\"\n        },\n        \"authorization\": {\n            \"certificate-authority\": \"/etc/ssl/certs/ca-certificates.crt\",\n            \"private-key\": \"/etc/ssl/private/ca-certificates.key\"\n        },\n        \"services\": {\n            \"dns\": {\n                \"host\": \"localhost\",\n           ", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = Config()\n    config.user = user\n    config.etcd_host = etcd_host\n    config.etcd_port = etcd_port\n    config.docs = {\"index\": {\"version\": 1}}\n    config.log = {\"index\": {\"version\": 1}}\n    return config\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = Configuration()\n    config.user = user\n    config.etcd_host = etcd_host\n    config.etcd_port = etcd_port\n    config.docs = \"\"\n    config.log = \"\"\n    config.key = {\n        \"tls\": {\n            \"type\": \"boolean\",\n            \"default\": False,\n        },\n        \"authentication\": {\n            \"type\": \"string\",\n            \"default\": \"password\",\n            \"minlen\": 5,\n            \"maxlen\": 200,\n        },\n        \"authorization\": {\n            \"type\": \"string\",\n            \"default\": \"password\",\n            \"minlen\": 5,\n            \"maxlen\": 200,\n        },\n        \"etcd\": {\n            \"type\": \"string\",\n            \"default\": \"/var/lib/etcd/\",\n            \"minlen\": 5,\n            \"max", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = Configuration()\n    config.user = user\n    config.etcd_host = etcd_host\n    config.etcd_port = etcd_port\n    config.log = \"\"\n    return config\n"], "level": "self_contained", "generate_results": [{"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    c = Configuration(user)\n    c.key_params[\"tls\"] = {\"key\": \"127.0.0.1:{}\".format(etcd_port)}\n    c.key_params[\"authentication\"] = {\"key\": \"{}:{}\".format(user, \"password\")}\n    c.key_params[\"authorization\"] = {\"key\": \"{}:{}\".format(user, \"token\")}\n    c.key_params[\"docs\"] = {\"key\": \"{}:{}\".format(user, \"docs\")}\n    c.key_params[\"log\"] = {\"key\": \"{}:{}\".format(user, \"log\")}\n\n    return c\n", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = Config()\n    for k in [\"tls\", \"authentication\", \"authorization\", \"etcd\", \"docs\", \"log\"]:\n        config.set(\"general\", k, \"{}\".format(k))\n\n    config.set(\"tls\", \"certificate-authority\", \"/etc/ssl/certs/ca-certificates.pem\")\n    config.set(\"tls\", \"key-file\", \"/etc/ssl/private/ca-certificates.pem\")\n    config.set(\"tls\", \"client-certificate\", \"/etc/ssl/certs/client-certificates.pem\")\n    config.set(\"tls\", \"client-key\", \"/etc/ssl/private/ca-certificates.pem\")\n\n    config.set(\"docs\", \"address\", \"http://{}:{}\".format(etcd_host, etcd_port))\n    config.set(\"docs\", \"service-address\", \"http://{}:{}\".format(etcd_host, etcd_port))\n    config.set(\"docs\", \"service-key\", \"http://{}:{}\".format(etcd_host, etcd_port))\n\n    config.set(\"log\", \"log-file\", \"/var/log/docs.log\")\n    config.set(\"log\", \"log-level\", \"info\")\n    config.set(\"log\", \"log-format\", \"%(message)s\")\n\n    return config\n", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"docs\": \"docs\",\n        \"log\": \"log\",\n        \"key\": {\n            \"tls\": True,\n            \"authentication\": True,\n            \"authorization\": True,\n            \"etcd\": True,\n            \"docs\": True,\n            \"log\": True,\n        },\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    conf = {\n        \"tls\": {\n            \"certFile\": None,\n            \"keyFile\": None,\n            \"caCerts\": {},\n            \"certChain\": \"\",\n            \"certChainCredentials\": None,\n        },\n        \"authentication\": {\n            \"username\": user,\n            \"etcd\": {\"host\": etcd_host, \"port\": etcd_port},\n            \"docs\": {\"host\": \"127.0.0.1\", \"port\": 8080, \"prefix\": \"/docs\"},\n        },\n        \"authorization\": {\n            \"username\": user,\n            \"etcd\": {\"host\": etcd_host, \"port\": etcd_port},\n            \"docs\": {\"host\": \"127.0.0.1\", \"port\": 8080, \"prefix\": \"/docs\"},\n        },\n        \"log\": {\n            \"level\": \"debug\",\n          ", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"etcd\": {\n            \"host\": etcd_host,\n            \"port\": etcd_port,\n        },\n        \"docs\": {\n            \"user\": user,\n            \"key\": {\n                \"tls\": False,\n                \"authentication\": False,\n                \"authorization\": False,\n                \"etcd\": {\n                    \"host\": etcd_host,\n                    \"port\": etcd_port,\n                },\n                \"log\": False,\n            },\n        },\n        \"log\": {\n            \"level\": logging.INFO,\n        },\n        \"tls\": {\n            \"host\": \"localhost\",\n            \"port\": etcd_port,\n        },\n ", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = {\n        'tls': True,\n        'authentication': {\n            'type': 'basic',\n            'username': user,\n            'keyfile': '/etc/etcd/keys/key.key'\n        },\n        'authorization': {\n            'type': 'basic',\n            'username': user,\n            'keyfile': '/etc/etcd/keys/key.key'\n        },\n        'docs': True,\n        'log': True,\n    }\n\n    if etcd_host:\n        config['docs']['etcd_host'] = etcd_host\n\n    if etcd_port:\n        config['docs']['etcd_port'] = etcd_port\n\n    return config\n", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"docs\": [\n            \"/\"\n        ],\n        \"log\": [\n            \"/\"\n        ],\n        \"tls\": [\n            \"none\"\n        ],\n        \"authentication\": {\n            \"certificate-authority\": \"/etc/ssl/certs/ca-certificates.crt\",\n            \"private-key\": \"/etc/ssl/private/ca-certificates.key\"\n        },\n        \"authorization\": {\n            \"certificate-authority\": \"/etc/ssl/certs/ca-certificates.crt\",\n            \"private-key\": \"/etc/ssl/private/ca-certificates.key\"\n        },\n        \"services\": {\n            \"dns\": {\n                \"host\": \"localhost\",\n           ", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = Config()\n    config.user = user\n    config.etcd_host = etcd_host\n    config.etcd_port = etcd_port\n    config.docs = {\"index\": {\"version\": 1}}\n    config.log = {\"index\": {\"version\": 1}}\n    return config\n", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = Configuration()\n    config.user = user\n    config.etcd_host = etcd_host\n    config.etcd_port = etcd_port\n    config.docs = \"\"\n    config.log = \"\"\n    config.key = {\n        \"tls\": {\n            \"type\": \"boolean\",\n            \"default\": False,\n        },\n        \"authentication\": {\n            \"type\": \"string\",\n            \"default\": \"password\",\n            \"minlen\": 5,\n            \"maxlen\": 200,\n        },\n        \"authorization\": {\n            \"type\": \"string\",\n            \"default\": \"password\",\n            \"minlen\": 5,\n            \"maxlen\": 200,\n        },\n        \"etcd\": {\n            \"type\": \"string\",\n            \"default\": \"/var/lib/etcd/\",\n            \"minlen\": 5,\n            \"max", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = Configuration()\n    config.user = user\n    config.etcd_host = etcd_host\n    config.etcd_port = etcd_port\n    config.log = \"\"\n    return config\n", "is_pass": false, "return_code": 1}]}
{"file_path": "dateutil/tz/_common.py", "project": "pexip/os-python-dateutil", "name": "_fromutc", "docstring": "Given a timezone-aware datetime in a given timezone, calculates a\ntimezone-aware datetime in a new timezone.\n\nSince this is the one time that we *know* we have an unambiguous\ndatetime object, we take this opportunity to determine whether the\ndatetime is ambiguous and in a \"fold\" state (e.g. if it's the first\noccurrence, chronologically, of the ambiguous datetime).\n\n:param dt:\n    A timezone-aware :class:`datetime.datetime` object.", "ques_id": "62b8a4a4755ee91dce50a3d2", "code": ["def _fromutc(self, dt):\n    if self._is_set is False:\n        raise ValueError()\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self)\n    else:\n        return dt.astimezone(self)\n", "def _fromutc(self, dt):\n    if self._isdst(dt):\n        return dt.replace(tzinfo=self)\n    else:\n        return dt.astimezone(self)\n", "def _fromutc(self, dt):\n    if self._is_set is False:\n        raise ValueError()\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self._default_tz)\n    else:\n        dt = dt.astimezone(self._default_tz)\n    return dt.replace(tzinfo=None)\n", "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self)\n    return dt.astimezone(self)\n", "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self.timezone)\n\n    if dt.tzinfo!= self.timezone:\n        dt = dt.astimezone(self.timezone)\n    return dt.replace(tzinfo=None)\n", "def _fromutc(self, dt):\n    if self._isdst(dt):\n        return dt + self._dst(dt)\n    else:\n        return dt + self._utc(dt)\n", "def _fromutc(self, dt):\n    if self._is_set is False:\n        raise ValueError()\n    if dt.tzinfo is None:\n        raise ValueError()\n\n    # TODO: Facilitate time zone handling\n    return dt.astimezone(self._tz)\n", "def _fromutc(self, dt):\n    if self._is_set is False:\n        raise ValueError()\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self)\n    return dt.astimezone(self)\n", "def _fromutc(self, dt):\n\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self.tz)\n\n    return dt.astimezone(self.tz)\n", "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self.__tz)\n\n    return dt.astimezone(self.__tz)\n"], "level": "self_contained", "generate_results": [{"generate_code": "def _fromutc(self, dt):\n    if self._is_set is False:\n        raise ValueError()\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self)\n    else:\n        return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if self._isdst(dt):\n        return dt.replace(tzinfo=self)\n    else:\n        return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if self._is_set is False:\n        raise ValueError()\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self._default_tz)\n    else:\n        dt = dt.astimezone(self._default_tz)\n    return dt.replace(tzinfo=None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self)\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self.timezone)\n\n    if dt.tzinfo!= self.timezone:\n        dt = dt.astimezone(self.timezone)\n    return dt.replace(tzinfo=None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if self._isdst(dt):\n        return dt + self._dst(dt)\n    else:\n        return dt + self._utc(dt)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if self._is_set is False:\n        raise ValueError()\n    if dt.tzinfo is None:\n        raise ValueError()\n\n    # TODO: Facilitate time zone handling\n    return dt.astimezone(self._tz)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if self._is_set is False:\n        raise ValueError()\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self)\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self.tz)\n\n    return dt.astimezone(self.tz)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self.__tz)\n\n    return dt.astimezone(self.__tz)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "dateutil/relativedelta.py", "project": "pexip/os-python-dateutil", "name": "normalized", "docstring": "Return a version of this object represented entirely using integer\nvalues for the relative attributes.\n\n>>> relativedelta(days=1.5, hours=2).normalized()\nrelativedelta(days=+1, hours=+14)\n\n:return:\n    Returns a :class:`dateutil.relativedelta.relativedelta` object.", "ques_id": "62b8982f755ee91dce50a241", "code": ["def normalized(self):\n    return self.__class__(self.value / self.unit)\n", "def normalized(self):\n    return self.__class__(self.value / self.unit)\n", "def normalized(self):\n    return self / self.units\n", "def normalized(self):\n    return self.__class__(*[int(num) for num in self])\n", "def normalized(self):\n    return self / self.units\n", "def normalized(self):\n    return self.__class__(self.value / self.unit)\n", "def normalized(self):\n    return self / self.units\n", "def normalized(self):\n    return self / self.duration\n", "def normalized(self):\n    return self.__class__(self.value / self.units)\n", "def normalized(self):\n    return self / self.units\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def normalized(self):\n    return self.__class__(self.value / self.unit)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return self.__class__(self.value / self.unit)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return self / self.units\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return self.__class__(*[int(num) for num in self])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return self / self.units\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return self.__class__(self.value / self.unit)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return self / self.units\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return self / self.duration\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return self.__class__(self.value / self.units)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return self / self.units\n", "is_pass": false, "return_code": 1}]}
{"file_path": "dateutil/tz/_common.py", "project": "pexip/os-python-dateutil", "name": "tzname_in_python2", "docstring": "Change unicode output into bytestrings in Python 2\n\ntzname() API changed in Python 3. It used to return bytes, but was changed\nto unicode strings", "ques_id": "62b89640755ee91dce50a114", "code": ["def tzname_in_python2(namefunc):\n\n    def wrapper(self, dt_arg, *args, **kwargs):\n        if six.PY2:\n            name = namefunc(self, dt_arg, *args, **kwargs)\n        else:\n            name = namefunc(self, dt_arg)\n        if name is not None:\n            dt_arg = dt_arg.replace(tzinfo=None)\n        return name, dt_arg\n\n    return wrapper\n", "def tzname_in_python2(namefunc):\n    def wrapper(self, dt_arg):\n        if isinstance(dt_arg, datetime.datetime):\n            # Python 2\n            dt_arg = dt_arg.astimezone(self.tz).replace(tzinfo=None)\n        return namefunc(self, dt_arg)\n    return wrapper\n", "def tzname_in_python2(namefunc):\n\n    @wraps(namefunc)\n    def wrapper(self, *args, **kwargs):\n        name = namefunc(self, *args, **kwargs)\n        if not IS_PY2:\n            name = name.encode('utf-8')\n        return name\n\n    return wrapper\n", "def tzname_in_python2(namefunc):\n    @wraps(namefunc)\n    def wrapper(self, tzinfo, *args, **kwargs):\n        return namefunc(self, datetime.datetime.now(tzinfo).encode(), *args, **kwargs)\n\n    return wrapper\n", "def tzname_in_python2(namefunc):\n\n    @functools.wraps(namefunc)\n    def wrapper(self, name):\n        name = namefunc(self, name)\n\n        if not PY3:\n            name = name.encode('utf-8')\n\n        return name\n\n    return wrapper\n", "def tzname_in_python2(namefunc):\n    if PY2:\n        @wraps(namefunc)\n        def wrapper(self, *args, **kwargs):\n            name = namefunc(self, *args, **kwargs)\n            if name is not None:\n                name = name.encode(self.encoding)\n            return name\n        return wrapper\n    else:\n        return namefunc\n", "def tzname_in_python2(namefunc):\n    def wrapper(self, dt_in_utc, *args, **kwargs):\n        dt_out_utc = namefunc(self, dt_in_utc, *args, **kwargs)\n        if six.PY2:\n            # Python 2 has no __str__ method\n            dt_out_utc = str(dt_out_utc)\n        return dt_out_utc\n    return wrapper\n", "def tzname_in_python2(namefunc):\n    \"Change unicode output into bytestrings in Python 2\"\n    @wraps(namefunc)\n    def wrapper(self, name, dtstart, dtend):\n        name = namefunc(self, name, dtstart, dtend)\n        if name is not None:\n            name = name.decode(\"utf-8\", errors=\"replace\")\n        return name\n    return wrapper\n", "def tzname_in_python2(namefunc):\n\n    @wraps(namefunc)\n    def wrapper(self, name, *args, **kwargs):\n        name = namefunc(self, name, *args, **kwargs)\n        if six.PY2:\n            name = name.encode('utf-8')\n\n        return name\n\n    return wrapper\n", "def tzname_in_python2(namefunc):\n\n    @wraps(namefunc)\n    def wrapper(self, name):\n        name = namefunc(self, name)\n        if sys.version_info < (3, 0):\n            if not isinstance(name, str):\n                raise ValueError(\n                    \"namefunc must return a string or bytes, not %r\" % name)\n            return name\n        else:\n            if not isinstance(name, bytes):\n                raise ValueError(\"namefunc must return a string or bytes, \"\n                                 \"not %r\" % name)\n            return name.decode(\"utf-8\", \"replace\")\n\n    return wrapper\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def tzname_in_python2(namefunc):\n\n    def wrapper(self, dt_arg, *args, **kwargs):\n        if six.PY2:\n            name = namefunc(self, dt_arg, *args, **kwargs)\n        else:\n            name = namefunc(self, dt_arg)\n        if name is not None:\n            dt_arg = dt_arg.replace(tzinfo=None)\n        return name, dt_arg\n\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n    def wrapper(self, dt_arg):\n        if isinstance(dt_arg, datetime.datetime):\n            # Python 2\n            dt_arg = dt_arg.astimezone(self.tz).replace(tzinfo=None)\n        return namefunc(self, dt_arg)\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n\n    @wraps(namefunc)\n    def wrapper(self, *args, **kwargs):\n        name = namefunc(self, *args, **kwargs)\n        if not IS_PY2:\n            name = name.encode('utf-8')\n        return name\n\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n    @wraps(namefunc)\n    def wrapper(self, tzinfo, *args, **kwargs):\n        return namefunc(self, datetime.datetime.now(tzinfo).encode(), *args, **kwargs)\n\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n\n    @functools.wraps(namefunc)\n    def wrapper(self, name):\n        name = namefunc(self, name)\n\n        if not PY3:\n            name = name.encode('utf-8')\n\n        return name\n\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n    if PY2:\n        @wraps(namefunc)\n        def wrapper(self, *args, **kwargs):\n            name = namefunc(self, *args, **kwargs)\n            if name is not None:\n                name = name.encode(self.encoding)\n            return name\n        return wrapper\n    else:\n        return namefunc\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n    def wrapper(self, dt_in_utc, *args, **kwargs):\n        dt_out_utc = namefunc(self, dt_in_utc, *args, **kwargs)\n        if six.PY2:\n            # Python 2 has no __str__ method\n            dt_out_utc = str(dt_out_utc)\n        return dt_out_utc\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n    \"Change unicode output into bytestrings in Python 2\"\n    @wraps(namefunc)\n    def wrapper(self, name, dtstart, dtend):\n        name = namefunc(self, name, dtstart, dtend)\n        if name is not None:\n            name = name.decode(\"utf-8\", errors=\"replace\")\n        return name\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n\n    @wraps(namefunc)\n    def wrapper(self, name, *args, **kwargs):\n        name = namefunc(self, name, *args, **kwargs)\n        if six.PY2:\n            name = name.encode('utf-8')\n\n        return name\n\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n\n    @wraps(namefunc)\n    def wrapper(self, name):\n        name = namefunc(self, name)\n        if sys.version_info < (3, 0):\n            if not isinstance(name, str):\n                raise ValueError(\n                    \"namefunc must return a string or bytes, not %r\" % name)\n            return name\n        else:\n            if not isinstance(name, bytes):\n                raise ValueError(\"namefunc must return a string or bytes, \"\n                                 \"not %r\" % name)\n            return name.decode(\"utf-8\", \"replace\")\n\n    return wrapper\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/prestoplot/_version.py", "project": "eykd/prestoplot", "name": "get_versions", "docstring": "Get version information or return default if unable to do so.", "ques_id": "62b87d24d292efb640a55670", "code": ["def get_versions():\n    try:\n        from django import VERSION as version\n    except ImportError:\n        from django.utils.version import get_complete_version\n\n        return get_complete_version('Django', '1.11')\n    return version\n", "def get_versions():\n    try:\n        from pkg_resources import get_distribution\n    except ImportError:\n        # PyPy didn't have get_distribution and version information could\n        # not be found.  We really don't want to bother to cache the\n        # version information if we get here.  It would be a pain to\n        # cache something else (e.g. importing setuptools).\n        return {}\n\n    return get_distribution().version\n", "def get_versions():\n    try:\n        from distutils.version import StrictVersion as Version\n    except ImportError:\n        # version wasn't found; could be installed or corrupted\n        return (0, 0, 0)\n    else:\n        return Version(*sys.version_info)\n", "def get_versions():\n    try:\n        from distutils.version import LooseVersion\n    except ImportError:\n        # version not available, return the default value\n        return (0, 0, 0)\n\n    # version information\n    version = LooseVersion('%s.%s.%s' % (__version__[0],\n                                        __version__[1],\n                                        __version__[2]))\n    update = LooseVersion('%s.%s' % (__update__[0], __update__[1]))\n    develop = LooseVersion('%s.%s.dev' % (__develop__[0], __develop__[1]))\n\n    return (version, update, develop)\n", "def get_versions():\n    try:\n        from zope.app.version.interfaces import IVersionInfo\n        return IVersionInfo(__version__)\n    except ImportError:\n        return __version__\n", "def get_versions():\n    try:\n        from django.conf import settings\n    except ImportError:\n        return {\"version\": \"0.0.0\", \"full-revisionid\": None,\n                \"dirty\": None,\n                \"error\": \"unable to find django.conf (is it installed?)\"}\n    else:\n        return get_versions_from_settings(settings)\n", "def get_versions():\n    try:\n        from pkg_resources import get_distribution\n    except ImportError:\n        # Distribution wasn't installed on system, fallback to the default\n        return {'version': '0.0.0', 'extras': set()}\n\n    dist = get_distribution()\n    if dist is not None:\n        # Distribution has been installed, return version information\n        return {'version': dist.version, 'extras': dist.extras}\n    # Distribution has not yet been installed, return the default value\n    return {'version': '0.0.0', 'extras': set()}\n", "def get_versions():\n    try:\n        from distutils.version import StrictVersion\n        return StrictVersion(pkg_resources.get_distribution('tornado').version)\n    except:\n        return pkg_resources.get_distribution('tornado').version\n", "def get_versions():\n    try:\n        from pkg_resources import parse_version\n    except ImportError:\n        # If pkg_resources is not installed, assume the default value is \n        # an empty tuple.\n        versions = ()\n    else:\n        versions = parse_version(DEFAULT_VERSION)\n    return versions\n", "def get_versions():\n    try:\n        from invenio_ext import get_versions\n    except ImportError:\n        return {\n            \"version\": \"0.0.1+unknown\",\n            \"author\": \"noreply@inveniosoftware.org\",\n            \"date\": \"\",\n        }\n    return get_versions()\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def get_versions():\n    try:\n        from django import VERSION as version\n    except ImportError:\n        from django.utils.version import get_complete_version\n\n        return get_complete_version('Django', '1.11')\n    return version\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from pkg_resources import get_distribution\n    except ImportError:\n        # PyPy didn't have get_distribution and version information could\n        # not be found.  We really don't want to bother to cache the\n        # version information if we get here.  It would be a pain to\n        # cache something else (e.g. importing setuptools).\n        return {}\n\n    return get_distribution().version\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from distutils.version import StrictVersion as Version\n    except ImportError:\n        # version wasn't found; could be installed or corrupted\n        return (0, 0, 0)\n    else:\n        return Version(*sys.version_info)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from distutils.version import LooseVersion\n    except ImportError:\n        # version not available, return the default value\n        return (0, 0, 0)\n\n    # version information\n    version = LooseVersion('%s.%s.%s' % (__version__[0],\n                                        __version__[1],\n                                        __version__[2]))\n    update = LooseVersion('%s.%s' % (__update__[0], __update__[1]))\n    develop = LooseVersion('%s.%s.dev' % (__develop__[0], __develop__[1]))\n\n    return (version, update, develop)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from zope.app.version.interfaces import IVersionInfo\n        return IVersionInfo(__version__)\n    except ImportError:\n        return __version__\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from django.conf import settings\n    except ImportError:\n        return {\"version\": \"0.0.0\", \"full-revisionid\": None,\n                \"dirty\": None,\n                \"error\": \"unable to find django.conf (is it installed?)\"}\n    else:\n        return get_versions_from_settings(settings)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from pkg_resources import get_distribution\n    except ImportError:\n        # Distribution wasn't installed on system, fallback to the default\n        return {'version': '0.0.0', 'extras': set()}\n\n    dist = get_distribution()\n    if dist is not None:\n        # Distribution has been installed, return version information\n        return {'version': dist.version, 'extras': dist.extras}\n    # Distribution has not yet been installed, return the default value\n    return {'version': '0.0.0', 'extras': set()}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from distutils.version import StrictVersion\n        return StrictVersion(pkg_resources.get_distribution('tornado').version)\n    except:\n        return pkg_resources.get_distribution('tornado').version\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from pkg_resources import parse_version\n    except ImportError:\n        # If pkg_resources is not installed, assume the default value is \n        # an empty tuple.\n        versions = ()\n    else:\n        versions = parse_version(DEFAULT_VERSION)\n    return versions\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from invenio_ext import get_versions\n    except ImportError:\n        return {\n            \"version\": \"0.0.1+unknown\",\n            \"author\": \"noreply@inveniosoftware.org\",\n            \"date\": \"\",\n        }\n    return get_versions()\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/prestoplot/_version.py", "project": "eykd/prestoplot", "name": "render", "docstring": "Render the given version pieces into the requested style.", "ques_id": "62b87d24d292efb640a5566f", "code": ["def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if not style or style == \"default\":\n        style = \"pep440\" if pieces[\"open\"] else \"pep440-pre\"\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"full-result\": rendered}\n", "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"version\": \"unknown\",\n                \"full-revisionid\": pieces.get(\"long\"),\n                \"dirty\": None,\n                \"error\": pieces[\"error\"],\n                \"date\": None}\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else", "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if pieces[\"style\"] == \"plain\":\n        return plain(pieces)\n    elif pieces[\"style\"] == \"html\":\n        return html(pieces)\n    elif pieces[\"style\"] == \"latex\":\n        return latex(pieces)\n    elif pieces[\"style\"] == \"svg\":\n        return svg(pieces)\n    elif pieces[\"style\"] == \"image\":\n        return image(pieces)\n    elif pieces[\"style\"] == \"jpeg\":\n        return jpeg(pieces)\n    elif pieces[\"style\"] == \"png\":\n        return png(pieces)\n    elif pieces[\"style\"] == \"svg-transparent\":\n        return svg_transparent(pieces)\n    elif pieces[\"style\"] == \"text\":\n        return text(pieces)\n    elif pieces[\"style\"] == \"svg-no-wrap\":\n        return svg_no_wrap(pieces)\n    el", "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if pieces[\"style\"] == \"default\":\n        style = \"pep440-pre\"\n\n    if pieces[\"style\"] == \"pep440-post\":\n        style = \"pep440-post-pre\"\n\n    if pieces[\"style\"] == \"pep440-old\":\n        style = \"pep440-old-pre\"\n\n    if pieces[\"style\"] == \"pep440-post-old\":\n        style = \"pep440-post-old-pre\"\n\n    return {\"full-result\": render_piece(pieces[\"piece\"], style),\n            \"error\": None}\n", "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if not style or style == \"default\":\n        style = \"pep440\" if pieces[\"revision\"] > 440 else \"pep440-pre\"\n\n    if style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"full-result\": rendered}\n", "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"full-result\": rendered}\n", "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": \"failure\"}\n\n    if style is None:\n        style = \"default\"\n\n    if style == \"default\":\n        rendered = render_default(pieces)\n    elif style == \"console\":\n        rendered = render_console(pieces)\n    elif style == \"stderr\":\n        rendered = render_stderr(pieces)\n    elif style == \"stdout\":\n        rendered = render_stdout(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"full-result\": rendered}\n", "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if style is None:\n        style = \"default\"\n\n    if style == \"default\":\n        rendered = render_pieces(pieces)\n    elif style == \"color\":\n        rendered = render_pieces_with_color(pieces)\n    elif style == \"color-no-bold\":\n        rendered = render_pieces_with_color_no_bold(pieces)\n    elif style == \"color-no-italic\":\n        rendered = render_pieces_with_color_no_italic(pieces)\n    elif style == \"color-no-underline\":\n        rendered = render_pieces_with_color_no_underline(pieces)\n    elif style == \"color-no-blink\":\n        rendered = render_pieces_with_color_no_blink(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"full-result\": rendered}\n", "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"full-result\": rendered}\n", "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if pieces[\"style\"] == \"plain\":\n        return plain(pieces)\n    elif pieces[\"style\"] == \"html\":\n        return html(pieces)\n    elif pieces[\"style\"] == \"latex\":\n        return latex(pieces)\n    else:\n        return {\"full-result\": \"unknown style '%s'\" % pieces[\"style\"]}\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if not style or style == \"default\":\n        style = \"pep440\" if pieces[\"open\"] else \"pep440-pre\"\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"full-result\": rendered}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"version\": \"unknown\",\n                \"full-revisionid\": pieces.get(\"long\"),\n                \"dirty\": None,\n                \"error\": pieces[\"error\"],\n                \"date\": None}\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if pieces[\"style\"] == \"plain\":\n        return plain(pieces)\n    elif pieces[\"style\"] == \"html\":\n        return html(pieces)\n    elif pieces[\"style\"] == \"latex\":\n        return latex(pieces)\n    elif pieces[\"style\"] == \"svg\":\n        return svg(pieces)\n    elif pieces[\"style\"] == \"image\":\n        return image(pieces)\n    elif pieces[\"style\"] == \"jpeg\":\n        return jpeg(pieces)\n    elif pieces[\"style\"] == \"png\":\n        return png(pieces)\n    elif pieces[\"style\"] == \"svg-transparent\":\n        return svg_transparent(pieces)\n    elif pieces[\"style\"] == \"text\":\n        return text(pieces)\n    elif pieces[\"style\"] == \"svg-no-wrap\":\n        return svg_no_wrap(pieces)\n    el", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if pieces[\"style\"] == \"default\":\n        style = \"pep440-pre\"\n\n    if pieces[\"style\"] == \"pep440-post\":\n        style = \"pep440-post-pre\"\n\n    if pieces[\"style\"] == \"pep440-old\":\n        style = \"pep440-old-pre\"\n\n    if pieces[\"style\"] == \"pep440-post-old\":\n        style = \"pep440-post-old-pre\"\n\n    return {\"full-result\": render_piece(pieces[\"piece\"], style),\n            \"error\": None}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if not style or style == \"default\":\n        style = \"pep440\" if pieces[\"revision\"] > 440 else \"pep440-pre\"\n\n    if style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"full-result\": rendered}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"full-result\": rendered}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": \"failure\"}\n\n    if style is None:\n        style = \"default\"\n\n    if style == \"default\":\n        rendered = render_default(pieces)\n    elif style == \"console\":\n        rendered = render_console(pieces)\n    elif style == \"stderr\":\n        rendered = render_stderr(pieces)\n    elif style == \"stdout\":\n        rendered = render_stdout(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"full-result\": rendered}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if style is None:\n        style = \"default\"\n\n    if style == \"default\":\n        rendered = render_pieces(pieces)\n    elif style == \"color\":\n        rendered = render_pieces_with_color(pieces)\n    elif style == \"color-no-bold\":\n        rendered = render_pieces_with_color_no_bold(pieces)\n    elif style == \"color-no-italic\":\n        rendered = render_pieces_with_color_no_italic(pieces)\n    elif style == \"color-no-underline\":\n        rendered = render_pieces_with_color_no_underline(pieces)\n    elif style == \"color-no-blink\":\n        rendered = render_pieces_with_color_no_blink(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"full-result\": rendered}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if not style or style == \"default\":\n        style = \"pep440\"  # the default\n\n    if style == \"pep440\":\n        rendered = render_pep440(pieces)\n    elif style == \"pep440-pre\":\n        rendered = render_pep440_pre(pieces)\n    elif style == \"pep440-post\":\n        rendered = render_pep440_post(pieces)\n    elif style == \"pep440-old\":\n        rendered = render_pep440_old(pieces)\n    elif style == \"git-describe\":\n        rendered = render_git_describe(pieces)\n    elif style == \"git-describe-long\":\n        rendered = render_git_describe_long(pieces)\n    else:\n        raise ValueError(\"unknown style '%s'\" % style)\n\n    return {\"full-result\": rendered}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    if pieces[\"error\"]:\n        return {\"full-result\": pieces[\"error\"]}\n\n    if pieces[\"style\"] == \"plain\":\n        return plain(pieces)\n    elif pieces[\"style\"] == \"html\":\n        return html(pieces)\n    elif pieces[\"style\"] == \"latex\":\n        return latex(pieces)\n    else:\n        return {\"full-result\": \"unknown style '%s'\" % pieces[\"style\"]}\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/prestoplot/_version.py", "project": "eykd/prestoplot", "name": "plus_or_dot", "docstring": "Return a + if we don't already have one, else return a .", "ques_id": "62b87d24d292efb640a5566d", "code": ["def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closet-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closet-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    closest_tag = closest_tag_piece(pieces)\n    if closest_tag and closest_tag in '+-':\n        return closest_tag\n    else:\n        return '.'\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closet-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closet-tag\", \"\"):\n        return \".\"\n    return \"+\"\n"], "level": "self_contained", "generate_results": [{"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closet-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closet-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    closest_tag = closest_tag_piece(pieces)\n    if closest_tag and closest_tag in '+-':\n        return closest_tag\n    else:\n        return '.'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closet-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closet-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}]}
{"file_path": "src/prestoplot/_version.py", "project": "eykd/prestoplot", "name": "run_command", "docstring": "Call the given command(s).", "ques_id": "62b87d23d292efb640a5566b", "code": ["def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/prestoplot/_version.py", "project": "eykd/prestoplot", "name": "get_config", "docstring": "Create, populate and return the VersioneerConfig() object.", "ques_id": "62b87d23d292efb640a55668", "code": ["def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"apertium/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/tornado/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/parse/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/py_miner/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"sequencer/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"etea/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"scatter3d/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"nodejs/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/twilio/twilio_pro_sms/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/separate_sequences/_version.py\"\n    cfg.verbose = False\n    return cfg\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"apertium/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/tornado/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/parse/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/py_miner/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"sequencer/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"etea/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"scatter3d/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"nodejs/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/twilio/twilio_pro_sms/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/separate_sequences/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/prestoplot/_version.py", "project": "eykd/prestoplot", "name": "register_vcs_handler", "docstring": "Create decorator to mark a method as the handler of a VCS.", "ques_id": "62b87d23d292efb640a55667", "code": ["def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\" Create decorator to mark a method as the handler of a object \"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\" Create decorator to mark a method as the handler of a object \"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n"], "level": "self_contained", "generate_results": [{"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\" Create decorator to mark a method as the handler of a object \"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\" Create decorator to mark a method as the handler of a object \"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a object\"\"\"\n    def decorate(f):\n        if vcs not in HANDLERS:\n            HANDLERS[vcs] = {}\n        HANDLERS[vcs][method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/store.py", "project": "zimeon/ocfl-py", "name": "validate_hierarchy", "docstring": "Validate storage root hierarchy.\n\nReturns:\n    num_objects - number of objects checked\n    good_objects - number of objects checked that were found to be valid", "ques_id": "62b45e945108cfac7f210a4a", "code": ["def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    num_objects, good_objects, found_objects = self._validate(\n        self.storage_root_path,\n        validate_objects=validate_objects,\n        check_digests=check_digests,\n        show_warnings=show_warnings\n    )\n\n    if found_objects and not found_objects % 2:\n        raise StorageError(\"Invalid object tree.\")\n\n    return num_objects, good_objects, found_objects\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    validation_errors = []\n    storage_roots = self.storage_roots\n    if validate_objects:\n        storage_roots = self.validate_objects(check_digests)\n\n    if check_digests:\n        self.validate_digests(storage_roots, show_warnings)\n\n    for storage_root in storage_roots:\n        if not storage_root.is_valid:\n            validation_errors.append(storage_root.path)\n\n    if validate_objects and len(validation_errors) > 0:\n        return len(validation_errors), validation_errors\n    else:\n        return 0, validation_errors\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    num_objects, good_objects = self._validate_storage_root(\n        self.storage_root, validate_objects=validate_objects,\n        check_digests=check_digests, show_warnings=show_warnings\n    )\n    return num_objects, good_objects\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    num_objects = 0\n    good_objects = 0\n    for storage_root in self.storage_roots:\n        num_objects += storage_root.validate_hierarchy(validate_objects=validate_objects, check_digests=check_digests, show_warnings=show_warnings)\n        if check_digests:\n            good_objects += len(storage_root.check_digests(validate_objects=validate_objects, show_warnings=show_warnings))\n    return num_objects, good_objects\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    validate_objects = self._validate_objects(validate_objects)\n    checked_objects = self._check_digests(check_digests)\n    found_to_be_valid = self._found_to_be_valid(validate_objects, checked_objects, show_warnings)\n    num_objects = len(found_to_be_valid)\n    return num_objects, found_to_be_valid, checked_objects\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if self.storage_root:\n        validation_results = self.storage_root.validate(\n            validate_objects=validate_objects,\n            check_digests=check_digests,\n            show_warnings=show_warnings\n        )\n\n        if validation_results.num_objects == 0:\n            return 0, 0\n        elif validation_results.num_objects > 0:\n            return validation_results.good_objects, validation_results.num_objects\n\n    return 0, 0\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if self.is_root:\n        return 0, []\n\n    results = self._validate_storage_root()\n    num_objects = len(results)\n    good_objects = 0\n    if validate_objects:\n        for storage_root in results:\n            good_objects += self._validate_storage_object(storage_root, check_digests)\n    if show_warnings:\n        for storage_root in results:\n            if storage_root.is_warning():\n                print(\"Warning: %s is a warning storage.\" % storage_root.name)\n                if check_digests:\n                    self._validate_digests(storage_root)\n    if check_digests:\n        for storage_root in results:\n            good_objects += self._validate_digests(storage_root)\n    return num_objects, good_objects\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if not validate_objects:\n        return 0, 0, 0\n    validated = 0\n    for object_path, root in self.store.items():\n        validated += self._validate_object(\n            object_path, root, check_digests=check_digests, show_warnings=show_warnings)\n    return validated, self.store.values(), validated / self.store.count()\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    self._validate_root_objects()\n    self._validate_storage_roots()\n    self._validate_root_digests()\n    self._validate_all_digests()\n    self._validate_objects_found()\n\n    if validate_objects:\n        self._validate_objects_checked(check_digests=check_digests, show_warnings=show_warnings)\n\n    return self.num_objects, self.good_objects, self.found_objects\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    num_objects = 0\n    good_objects = 0\n    for storage_root in self.storage_roots:\n        num_objects += self._validate_storage_root(storage_root, validate_objects, check_digests, show_warnings)\n        if validate_objects:\n            good_objects += len(storage_root.get_manifest().get_all_good_objects())\n    return num_objects, good_objects\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    num_objects, good_objects, found_objects = self._validate(\n        self.storage_root_path,\n        validate_objects=validate_objects,\n        check_digests=check_digests,\n        show_warnings=show_warnings\n    )\n\n    if found_objects and not found_objects % 2:\n        raise StorageError(\"Invalid object tree.\")\n\n    return num_objects, good_objects, found_objects\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    validation_errors = []\n    storage_roots = self.storage_roots\n    if validate_objects:\n        storage_roots = self.validate_objects(check_digests)\n\n    if check_digests:\n        self.validate_digests(storage_roots, show_warnings)\n\n    for storage_root in storage_roots:\n        if not storage_root.is_valid:\n            validation_errors.append(storage_root.path)\n\n    if validate_objects and len(validation_errors) > 0:\n        return len(validation_errors), validation_errors\n    else:\n        return 0, validation_errors\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    num_objects, good_objects = self._validate_storage_root(\n        self.storage_root, validate_objects=validate_objects,\n        check_digests=check_digests, show_warnings=show_warnings\n    )\n    return num_objects, good_objects\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    num_objects = 0\n    good_objects = 0\n    for storage_root in self.storage_roots:\n        num_objects += storage_root.validate_hierarchy(validate_objects=validate_objects, check_digests=check_digests, show_warnings=show_warnings)\n        if check_digests:\n            good_objects += len(storage_root.check_digests(validate_objects=validate_objects, show_warnings=show_warnings))\n    return num_objects, good_objects\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    validate_objects = self._validate_objects(validate_objects)\n    checked_objects = self._check_digests(check_digests)\n    found_to_be_valid = self._found_to_be_valid(validate_objects, checked_objects, show_warnings)\n    num_objects = len(found_to_be_valid)\n    return num_objects, found_to_be_valid, checked_objects\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if self.storage_root:\n        validation_results = self.storage_root.validate(\n            validate_objects=validate_objects,\n            check_digests=check_digests,\n            show_warnings=show_warnings\n        )\n\n        if validation_results.num_objects == 0:\n            return 0, 0\n        elif validation_results.num_objects > 0:\n            return validation_results.good_objects, validation_results.num_objects\n\n    return 0, 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if self.is_root:\n        return 0, []\n\n    results = self._validate_storage_root()\n    num_objects = len(results)\n    good_objects = 0\n    if validate_objects:\n        for storage_root in results:\n            good_objects += self._validate_storage_object(storage_root, check_digests)\n    if show_warnings:\n        for storage_root in results:\n            if storage_root.is_warning():\n                print(\"Warning: %s is a warning storage.\" % storage_root.name)\n                if check_digests:\n                    self._validate_digests(storage_root)\n    if check_digests:\n        for storage_root in results:\n            good_objects += self._validate_digests(storage_root)\n    return num_objects, good_objects\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if not validate_objects:\n        return 0, 0, 0\n    validated = 0\n    for object_path, root in self.store.items():\n        validated += self._validate_object(\n            object_path, root, check_digests=check_digests, show_warnings=show_warnings)\n    return validated, self.store.values(), validated / self.store.count()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    self._validate_root_objects()\n    self._validate_storage_roots()\n    self._validate_root_digests()\n    self._validate_all_digests()\n    self._validate_objects_found()\n\n    if validate_objects:\n        self._validate_objects_checked(check_digests=check_digests, show_warnings=show_warnings)\n\n    return self.num_objects, self.good_objects, self.found_objects\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    num_objects = 0\n    good_objects = 0\n    for storage_root in self.storage_roots:\n        num_objects += self._validate_storage_root(storage_root, validate_objects, check_digests, show_warnings)\n        if validate_objects:\n            good_objects += len(storage_root.get_manifest().get_all_good_objects())\n    return num_objects, good_objects\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/store.py", "project": "zimeon/ocfl-py", "name": "initialize", "docstring": "Create and initialize a new OCFL storage root.", "ques_id": "62b45e515108cfac7f210a3c", "code": ["def initialize(self):\n    self._storage_root = self._create_storage_root()\n", "def initialize(self):\n    self._create_storage_root()\n    self._initialize_object_store_backend()\n", "def initialize(self):\n    self._backend = _Backend(\n        self._name, self._type, self._length, self._block_size)\n    self._root = self._backend.root\n    self._tree = self._backend.tree\n", "def initialize(self):\n    super(OCFLStorageRoot, self).initialize()\n    self._storage_root = self._initialize_storage_root()\n", "def initialize(self):\n    self._storage_root = self._engine.create_storage_root(self._engine.get_storage_root())\n", "def initialize(self):\n    self._logger.debug(\"Initializing OCFL storage root '%s'\", self._root_name)\n\n    self._create_root()\n    self._set_root_schema(self._root_name, OCFL_SCHEMA_VERSION)\n    self._set_root_version(self._root_name, OCFL_ROOT_VERSION)\n    self._set_root_schema_version(self._root_name, OCFL_SCHEMA_VERSION)\n    self._set_root_db_version(self._root_name, OCFL_SCHEMA_VERSION)\n", "def initialize(self):\n    self._storage_root = OCFLStorageRoot(self)\n", "def initialize(self):\n    self._create_root()\n    self._initialize_storage_root()\n", "def initialize(self):\n    self._storage_root = self._create_storage_root()\n    self._write_roots(self._storage_root)\n", "def initialize(self):\n    self._create_storage_root()\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def initialize(self):\n    self._storage_root = self._create_storage_root()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    self._create_storage_root()\n    self._initialize_object_store_backend()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    self._backend = _Backend(\n        self._name, self._type, self._length, self._block_size)\n    self._root = self._backend.root\n    self._tree = self._backend.tree\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    super(OCFLStorageRoot, self).initialize()\n    self._storage_root = self._initialize_storage_root()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    self._storage_root = self._engine.create_storage_root(self._engine.get_storage_root())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    self._logger.debug(\"Initializing OCFL storage root '%s'\", self._root_name)\n\n    self._create_root()\n    self._set_root_schema(self._root_name, OCFL_SCHEMA_VERSION)\n    self._set_root_version(self._root_name, OCFL_ROOT_VERSION)\n    self._set_root_schema_version(self._root_name, OCFL_SCHEMA_VERSION)\n    self._set_root_db_version(self._root_name, OCFL_SCHEMA_VERSION)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    self._storage_root = OCFLStorageRoot(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    self._create_root()\n    self._initialize_storage_root()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    self._storage_root = self._create_storage_root()\n    self._write_roots(self._storage_root)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    self._create_storage_root()\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/object_utils.py", "project": "zimeon/ocfl-py", "name": "next_version", "docstring": "Next version identifier following existing pattern.\n\nMust deal with both zero-prefixed and non-zero prefixed versions.", "ques_id": "62b45e2eb89c9fd354170232", "code": ["def next_version(version):\n    parts = version.split('.')\n    while parts[-1] == '0':\n        parts.pop()\n    return '.'.join(parts)\n", "def next_version(version):\n    while version in versions:\n        version += 1\n    return version\n", "def next_version(version):\n    next = ''\n    while version:\n        next = str(int(version) + 1) + next\n        version = int(re.match(r'(\\d+)$', next).group(1))\n    return next\n", "def next_version(version):\n    # https://stackoverflow.com/questions/2279861/how-to-determine-whether-a-version-is-newer-than-an-existing-one\n    version_parts = version.split(\".\")\n    while len(version_parts) > 1:\n        try:\n            int(version_parts[-1])\n            return \".\".join(version_parts[:-1])\n        except ValueError:\n            version_parts.pop()\n    return version\n", "def next_version(version):\n    m = NEXT_VERSION_RE.search(version)\n    if m:\n        return version[:m.start(1)] + m.group(1) + version[m.end(1):]\n    else:\n        return version\n", "def next_version(version):\n    next_version = version\n    while True:\n        next_version += 1\n        if is_prerelease(next_version):\n            break\n    return next_version\n", "def next_version(version):\n    # find next 3 digits of next version\n    next_digits = ''\n    while len(version) > 3 and version[-3] not in ['.', '-']:\n        next_digits += version[-3]\n        version = version[:-3]\n\n    # find next 4 digits of next version\n    next_digits += version[-4:]\n    # convert next digits to int\n    next_digits = int(next_digits)\n\n    # check if next version is already in range\n    if (next_digits < 0 or next_digits > 999):\n        raise ValueError(\"Invalid next version %s\" % version)\n\n    return next_digits\n", "def next_version(version):\n    last = version\n    for x in range(1, 4):\n        m = int(version[-(x + 1):])\n        if (m <= int(version[:-(x + 1)])):\n            last = m\n            break\n    else:\n        last = 4\n    return str(last + 1)\n", "def next_version(version):\n    while True:\n        version += 1\n        if version > MAX_VERSION:\n            raise ValueError('Cannot generate new version!')\n        if not is_version_pattern(version):\n            raise ValueError('Not a valid version identifier!')\n        yield version\n", "def next_version(version):\n    parts = version.split('.')\n    while parts[-1] == '0':\n        parts.pop()\n    return '.'.join(parts)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def next_version(version):\n    parts = version.split('.')\n    while parts[-1] == '0':\n        parts.pop()\n    return '.'.join(parts)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    while version in versions:\n        version += 1\n    return version\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    next = ''\n    while version:\n        next = str(int(version) + 1) + next\n        version = int(re.match(r'(\\d+)$', next).group(1))\n    return next\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    # https://stackoverflow.com/questions/2279861/how-to-determine-whether-a-version-is-newer-than-an-existing-one\n    version_parts = version.split(\".\")\n    while len(version_parts) > 1:\n        try:\n            int(version_parts[-1])\n            return \".\".join(version_parts[:-1])\n        except ValueError:\n            version_parts.pop()\n    return version\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    m = NEXT_VERSION_RE.search(version)\n    if m:\n        return version[:m.start(1)] + m.group(1) + version[m.end(1):]\n    else:\n        return version\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    next_version = version\n    while True:\n        next_version += 1\n        if is_prerelease(next_version):\n            break\n    return next_version\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    # find next 3 digits of next version\n    next_digits = ''\n    while len(version) > 3 and version[-3] not in ['.', '-']:\n        next_digits += version[-3]\n        version = version[:-3]\n\n    # find next 4 digits of next version\n    next_digits += version[-4:]\n    # convert next digits to int\n    next_digits = int(next_digits)\n\n    # check if next version is already in range\n    if (next_digits < 0 or next_digits > 999):\n        raise ValueError(\"Invalid next version %s\" % version)\n\n    return next_digits\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    last = version\n    for x in range(1, 4):\n        m = int(version[-(x + 1):])\n        if (m <= int(version[:-(x + 1)])):\n            last = m\n            break\n    else:\n        last = 4\n    return str(last + 1)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    while True:\n        version += 1\n        if version > MAX_VERSION:\n            raise ValueError('Cannot generate new version!')\n        if not is_version_pattern(version):\n            raise ValueError('Not a valid version identifier!')\n        yield version\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    parts = version.split('.')\n    while parts[-1] == '0':\n        parts.pop()\n    return '.'.join(parts)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/validator.py", "project": "zimeon/ocfl-py", "name": "validate_version_inventories", "docstring": "Each version SHOULD have an inventory up to that point.\n\nAlso keep a record of any content digests different from those in the root inventory\nso that we can also check them when validating the content.\n\nversion_dirs is an array of version directory names and is assumed to be in\nversion sequence (1, 2, 3...).", "ques_id": "62b45e23e0d4551b0392c90a", "code": ["def validate_version_inventories(self, version_dirs):\n    pass\n", "def validate_version_inventories(self, version_dirs):\n    pass\n", "def validate_version_inventories(self, version_dirs):\n    pass\n", "def validate_version_inventories(self, version_dirs):\n    pass\n", "def validate_version_inventories(self, version_dirs):\n    # TODO: this method should be merged into the InventoryValidator\n    # validation and make it more dynamic.\n    for version_dir in version_dirs:\n        self._validate_version_inventories_in_dir(version_dir)\n", "def validate_version_inventories(self, version_dirs):\n    pass\n", "def validate_version_inventories(self, version_dirs):\n    inventory_filename = self.inventory_filename\n    if inventory_filename is None:\n        return\n\n    # If there's a single version directory, we should have a valid inventory\n    if len(version_dirs) == 1:\n        self.log.info(\"%s is already in an inventory\" % inventory_filename)\n        return\n\n    # The inventory is not valid if it's a single directory, but it's actually a list of version directories.\n    # If there is more than one version directory, then the list of version directories needs to be sorted before\n    # the inventory. This is because the inventory could be compared to a list of different version directories.\n    version_dirs = [os.path.relpath(d, version_dirs[0]) for d in version_dirs]\n\n    self.log.info(\"Validating inventory from %s\" % inventory_filename)\n    inventory = Inventory(inventory_filename)\n    self._validate_version_inventories_from_inventory(inventory, version_dirs)\n", "def validate_version_inventories(self, version_dirs):\n    pass\n", "def validate_version_inventories(self, version_dirs):\n    inventory_root = self.get_inventory_root()\n    if inventory_root is None:\n        return\n\n    for version_dir in version_dirs:\n        version_path = os.path.join(inventory_root, version_dir)\n        if not os.path.exists(version_path):\n            raise errors.CannotValidate(\n                'Inventory is out of date. '\n                'Expected a version in the root of the inventory. '\n                'Found {}'.format(version_path)\n            )\n\n        # Make sure the path is absolute.\n        if not os.path.isabs(version_path):\n            version_path = os.path.join(inventory_root, version_path)\n\n        # Check the digests in the contents of the path.\n        contents = self.read_inventory_file(version_path)\n        for digest in contents.get('__ALL__', []):\n            self.validate_digest(version_path, digest)\n", "def validate_version_inventories(self, version_dirs):\n    pass\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_version_inventories(self, version_dirs):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    # TODO: this method should be merged into the InventoryValidator\n    # validation and make it more dynamic.\n    for version_dir in version_dirs:\n        self._validate_version_inventories_in_dir(version_dir)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    inventory_filename = self.inventory_filename\n    if inventory_filename is None:\n        return\n\n    # If there's a single version directory, we should have a valid inventory\n    if len(version_dirs) == 1:\n        self.log.info(\"%s is already in an inventory\" % inventory_filename)\n        return\n\n    # The inventory is not valid if it's a single directory, but it's actually a list of version directories.\n    # If there is more than one version directory, then the list of version directories needs to be sorted before\n    # the inventory. This is because the inventory could be compared to a list of different version directories.\n    version_dirs = [os.path.relpath(d, version_dirs[0]) for d in version_dirs]\n\n    self.log.info(\"Validating inventory from %s\" % inventory_filename)\n    inventory = Inventory(inventory_filename)\n    self._validate_version_inventories_from_inventory(inventory, version_dirs)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    inventory_root = self.get_inventory_root()\n    if inventory_root is None:\n        return\n\n    for version_dir in version_dirs:\n        version_path = os.path.join(inventory_root, version_dir)\n        if not os.path.exists(version_path):\n            raise errors.CannotValidate(\n                'Inventory is out of date. '\n                'Expected a version in the root of the inventory. '\n                'Found {}'.format(version_path)\n            )\n\n        # Make sure the path is absolute.\n        if not os.path.isabs(version_path):\n            version_path = os.path.join(inventory_root, version_path)\n\n        # Check the digests in the contents of the path.\n        contents = self.read_inventory_file(version_path)\n        for digest in contents.get('__ALL__', []):\n            self.validate_digest(version_path, digest)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    pass\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/object_utils.py", "project": "zimeon/ocfl-py", "name": "find_path_type", "docstring": "Return a string indicating the type of thing at the given path.\n\nReturn values:\n    'root' - looks like an OCFL Storage Root\n    'object' - looks like an OCFL Object\n    'file' - a file, might be an inventory\n    other string explains error description\n\nLooks only at \"0=*\" Namaste files to determine the directory type.", "ques_id": "62b45e21e0d4551b0392c8ed", "code": ["def find_path_type(path):\n    path = os.path.abspath(path)\n\n    while path!= '/':\n        if os.path.isdir(os.path.join(path, '.git')):\n            return 'git'\n        elif os.path.isfile(os.path.join(path, '.hg')):\n            return 'hg'\n        path = os.path.dirname(path)\n\n    return ''\n", "def find_path_type(path):\n    if os.path.isfile(path):\n        return 'file'\n    elif os.path.isdir(path):\n        return 'dir'\n    else:\n        raise NotImplementedError('Unknown path type for \"%s\": \"%s\"' % (path, type(path)))\n", "def find_path_type(path):\n    types = []\n    for entry in os.scandir(path):\n        if entry.is_file() or entry.is_symlink():\n            types.append('file')\n        elif entry.is_dir():\n            types.append('dir')\n        elif entry.is_svn():\n            types.append('svn')\n        elif entry.is_git():\n            types.append('git')\n        elif entry.is_bzr():\n            types.append('bzr')\n        elif entry.is_hg():\n            types.append('hg')\n        elif entry.is_submodule():\n            types.append('submodule')\n        elif entry.is_svn_tree():\n            types.append('svn_tree')\n        elif entry.is_git_tree():\n            types.append('git_tree')\n        elif entry.is_git_url():\n    ", "def find_path_type(path):\n    if isinstance(path, (list, tuple)):\n        return 'array'\n    elif os.path.isfile(path):\n        return 'file'\n    elif os.path.isdir(path):\n        return 'directory'\n    else:\n        raise OSError(\n            \"Couldn't determine what type of file to process at {0}\".format(path))\n", "def find_path_type(path):\n    if is_file(path):\n        return 'file'\n    elif is_dir(path):\n        return 'directory'\n    else:\n        return 'unknown'\n", "def find_path_type(path):\n    f = sys._getframe()\n    while f.f_code.co_filename!= path:\n        f = f.f_back\n    return f.f_code.co_name\n", "def find_path_type(path):\n    if os.path.isfile(path):\n        return 'file'\n    if os.path.isdir(path):\n        return 'dir'\n    if os.path.islink(path):\n        return 'link'\n    return 'unknown'\n", "def find_path_type(path):\n    if isinstance(path, str):\n        path = [path]\n\n    type_, _ = splitext(basename(path[0]))\n\n    if type_ == '':\n        return 'directory'\n    elif type_ == '.svn':\n        return'svn'\n    elif type_ == '.git':\n        return 'git'\n    elif type_ == '.hg':\n        return 'hg'\n    elif type_ == '.gitignore':\n        return 'ignore'\n    elif type_ == '.svn.lock':\n        return 'lock'\n    elif type_ == '.svn'.startswith('.'):\n        return 'file'\n    elif '.' not in type_:\n        return 'file'\n    else:\n        return type_\n", "def find_path_type(path):\n    for thing in path:\n        if isinstance(thing, string_types):\n            return thing\n    return None\n", "def find_path_type(path):\n    if os.path.isdir(path):\n        return \"directory\"\n    if os.path.isfile(path):\n        return \"file\"\n    if os.path.islink(path):\n        return \"link\"\n    raise OSError(\"not a recognized path\")\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def find_path_type(path):\n    path = os.path.abspath(path)\n\n    while path!= '/':\n        if os.path.isdir(os.path.join(path, '.git')):\n            return 'git'\n        elif os.path.isfile(os.path.join(path, '.hg')):\n            return 'hg'\n        path = os.path.dirname(path)\n\n    return ''\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    if os.path.isfile(path):\n        return 'file'\n    elif os.path.isdir(path):\n        return 'dir'\n    else:\n        raise NotImplementedError('Unknown path type for \"%s\": \"%s\"' % (path, type(path)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    types = []\n    for entry in os.scandir(path):\n        if entry.is_file() or entry.is_symlink():\n            types.append('file')\n        elif entry.is_dir():\n            types.append('dir')\n        elif entry.is_svn():\n            types.append('svn')\n        elif entry.is_git():\n            types.append('git')\n        elif entry.is_bzr():\n            types.append('bzr')\n        elif entry.is_hg():\n            types.append('hg')\n        elif entry.is_submodule():\n            types.append('submodule')\n        elif entry.is_svn_tree():\n            types.append('svn_tree')\n        elif entry.is_git_tree():\n            types.append('git_tree')\n        elif entry.is_git_url():\n    ", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    if isinstance(path, (list, tuple)):\n        return 'array'\n    elif os.path.isfile(path):\n        return 'file'\n    elif os.path.isdir(path):\n        return 'directory'\n    else:\n        raise OSError(\n            \"Couldn't determine what type of file to process at {0}\".format(path))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    if is_file(path):\n        return 'file'\n    elif is_dir(path):\n        return 'directory'\n    else:\n        return 'unknown'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    f = sys._getframe()\n    while f.f_code.co_filename!= path:\n        f = f.f_back\n    return f.f_code.co_name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    if os.path.isfile(path):\n        return 'file'\n    if os.path.isdir(path):\n        return 'dir'\n    if os.path.islink(path):\n        return 'link'\n    return 'unknown'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    if isinstance(path, str):\n        path = [path]\n\n    type_, _ = splitext(basename(path[0]))\n\n    if type_ == '':\n        return 'directory'\n    elif type_ == '.svn':\n        return'svn'\n    elif type_ == '.git':\n        return 'git'\n    elif type_ == '.hg':\n        return 'hg'\n    elif type_ == '.gitignore':\n        return 'ignore'\n    elif type_ == '.svn.lock':\n        return 'lock'\n    elif type_ == '.svn'.startswith('.'):\n        return 'file'\n    elif '.' not in type_:\n        return 'file'\n    else:\n        return type_\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    for thing in path:\n        if isinstance(thing, string_types):\n            return thing\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    if os.path.isdir(path):\n        return \"directory\"\n    if os.path.isfile(path):\n        return \"file\"\n    if os.path.islink(path):\n        return \"link\"\n    raise OSError(\"not a recognized path\")\n", "is_pass": false, "return_code": 1}]}
{"file_path": "auto_nag/bzcleaner.py", "project": "mozilla/relman-auto-nag", "name": "amend_bzparams", "docstring": "Amend the Bugzilla params", "ques_id": "62b45b396decaeff903e1001", "code": ["def amend_bzparams(self, params, bug_ids):\n    if isinstance(bug_ids, int):\n        bug_ids = [bug_ids]\n    params['bugzilla_id'] = bug_ids\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    for bug_id in bug_ids:\n        params[\"bz_id\"] = bug_id\n        yield params\n", "def amend_bzparams(self, params, bug_ids):\n    for id in bug_ids:\n        params['id'] = id\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    if not params.get('bz_ids'):\n        return\n\n    for bz_id in bug_ids:\n        bz_params = params.copy()\n        bz_params['bz_id'] = bz_id\n\n        del bz_params['product_id']\n        del bz_params['product_name']\n        del bz_params['product_displayname']\n        del bz_params['product_version']\n        del bz_params['platform']\n\n        del bz_params['checked_in']\n        del bz_params['created_at']\n        del bz_params['updated_at']\n\n        del bz_params['status']\n\n        del bz_params['bug_id']\n        del bz_params['bz_ids']\n\n        params['bz_params'] = bz_params\n", "def amend_bzparams(self, params, bug_ids):\n    if not bug_ids:\n        return\n\n    if isinstance(bug_ids, list):\n        bug_ids = ';'.join(bug_ids)\n\n    params['ids'] = bug_ids\n\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    if isinstance(bug_ids, list):\n        bug_ids = ','.join(bug_ids)\n    if isinstance(params, dict):\n        params = params.copy()\n        params['bug_ids[]'] = bug_ids\n        return params\n", "def amend_bzparams(self, params, bug_ids):\n    if not bug_ids:\n        return\n\n    for id_ in bug_ids:\n        params['ids'].append(str(id_))\n", "def amend_bzparams(self, params, bug_ids):\n    if not bug_ids:\n        return\n    # If there are no bug_ids, we can just return\n    if not bug_ids:\n        return\n    # Make sure we have a list\n    if not isinstance(bug_ids, list):\n        bug_ids = [bug_ids]\n    # Now we can add the params\n    params['bug_id'] = bug_ids\n", "def amend_bzparams(self, params, bug_ids):\n    if params is None:\n        params = {}\n    params['ids'] = \",\".join(bug_ids)\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    if not bug_ids:\n        return\n\n    if isinstance(bug_ids, str):\n        bug_ids = [bug_ids]\n\n    for bug_id in bug_ids:\n        params['bugzilla_id'] = bug_id\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if isinstance(bug_ids, int):\n        bug_ids = [bug_ids]\n    params['bugzilla_id'] = bug_ids\n    return params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    for bug_id in bug_ids:\n        params[\"bz_id\"] = bug_id\n        yield params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    for id in bug_ids:\n        params['id'] = id\n    return params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if not params.get('bz_ids'):\n        return\n\n    for bz_id in bug_ids:\n        bz_params = params.copy()\n        bz_params['bz_id'] = bz_id\n\n        del bz_params['product_id']\n        del bz_params['product_name']\n        del bz_params['product_displayname']\n        del bz_params['product_version']\n        del bz_params['platform']\n\n        del bz_params['checked_in']\n        del bz_params['created_at']\n        del bz_params['updated_at']\n\n        del bz_params['status']\n\n        del bz_params['bug_id']\n        del bz_params['bz_ids']\n\n        params['bz_params'] = bz_params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if not bug_ids:\n        return\n\n    if isinstance(bug_ids, list):\n        bug_ids = ';'.join(bug_ids)\n\n    params['ids'] = bug_ids\n\n    return params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if isinstance(bug_ids, list):\n        bug_ids = ','.join(bug_ids)\n    if isinstance(params, dict):\n        params = params.copy()\n        params['bug_ids[]'] = bug_ids\n        return params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if not bug_ids:\n        return\n\n    for id_ in bug_ids:\n        params['ids'].append(str(id_))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if not bug_ids:\n        return\n    # If there are no bug_ids, we can just return\n    if not bug_ids:\n        return\n    # Make sure we have a list\n    if not isinstance(bug_ids, list):\n        bug_ids = [bug_ids]\n    # Now we can add the params\n    params['bug_id'] = bug_ids\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if params is None:\n        params = {}\n    params['ids'] = \",\".join(bug_ids)\n    return params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if not bug_ids:\n        return\n\n    if isinstance(bug_ids, str):\n        bug_ids = [bug_ids]\n\n    for bug_id in bug_ids:\n        params['bugzilla_id'] = bug_id\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/config/load.py", "project": "witten/atticmatic", "name": "deep_merge_nodes", "docstring": "Given a nested borgmatic configuration data structure as a list of tuples in the form of:\n\n    (\n        ruamel.yaml.nodes.ScalarNode as a key,\n        ruamel.yaml.nodes.MappingNode or other Node as a value,\n    ),\n\n... deep merge any node values corresponding to duplicate keys and return the result. If\nthere are colliding keys with non-MappingNode values (e.g., integers or strings), the last\nof the values wins.\n\nFor instance, given node values of:\n\n    [\n        (\n            ScalarNode(tag='tag:yaml.org,2002:str', value='retention'),\n            MappingNode(tag='tag:yaml.org,2002:map', value=[\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_hourly'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='24')\n                ),\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_daily'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='7')\n                ),\n            ]),\n        ),\n        (\n            ScalarNode(tag='tag:yaml.org,2002:str', value='retention'),\n            MappingNode(tag='tag:yaml.org,2002:map', value=[\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_daily'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='5')\n                ),\n            ]),\n        ),\n    ]\n\n... the returned result would be:\n\n    [\n        (\n            ScalarNode(tag='tag:yaml.org,2002:str', value='retention'),\n            MappingNode(tag='tag:yaml.org,2002:map', value=[\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_hourly'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='24')\n                ),\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_daily'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='5')\n                ),\n            ]),\n        ),\n    ]\n\nThe purpose of deep merging like this is to support, for instance, merging one borgmatic\nconfiguration file into another for reuse, such that a configuration section (\"retention\",\netc.) does not completely replace the corresponding section in a merged file.", "ques_id": "62b4567ed7d32e5b55cc83d9", "code": ["def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.value in result:\n                raise ValueError('Duplicate key: %r' % node.value)\n            result.append(node.value)\n        else:\n            result.append(node)\n    return result\n", "def deep_merge_nodes(nodes):\n    result = {}\n    for k, v in nodes.items():\n        if isinstance(v, MappingNode):\n            if k in result and isinstance(result[k], MappingNode):\n                if not is_same_type(result[k], v):\n                    raise ValueError('Duplicate mapping value for key {}'.format(k))\n            else:\n                result[k] = v\n        else:\n            result[k] = v\n    return result\n", "def deep_merge_nodes(nodes):\n    dupes = {}\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.value in dupes:\n                dupes[node.value].append(node)\n            else:\n                dupes[node.value] = [node]\n        else:\n            if node not in dupes:\n                dupes[node] = []\n            dupes[node].append(node)\n    result = []\n    for key, values in dupes.items():\n        if len(values) > 1:\n            last = values[-1]\n            for sub_value in values[:-1]:\n                if isinstance(last, MappingNode) and sub_value.value not in dupes:\n                    last.append(sub_value)\n                    break\n            else:\n         ", "def deep_merge_nodes(nodes):\n    result = nodes[-1]\n    for node in nodes[:-1]:\n        for key, value in node.items():\n            if isinstance(value, MappingNode):\n                if value == result:\n                    continue\n                else:\n                    result = value\n                    break\n        else:\n            result = node\n    return result\n", "def deep_merge_nodes(nodes):\n    duplicates = {}\n    for node in nodes:\n        if node.value in duplicates:\n            duplicates[node.value].append(node)\n        else:\n            duplicates[node.value] = [node]\n\n    # Remove duplicates\n    nodes = []\n    for key, values in duplicates.items():\n        if len(values) > 1:\n            nodes.append({key: values})\n        elif len(values) == 1:\n            nodes.append(values[0])\n\n    return nodes\n", "def deep_merge_nodes(nodes):\n    result = {}\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.value in result:\n                result[node.value].append(node)\n            else:\n                result[node.value] = [node]\n        else:\n            result[node] = node\n    return result\n", "def deep_merge_nodes(nodes):\n    result = {}\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.value in result:\n                result[node.value].append(node)\n            else:\n                result[node.value] = [node]\n        else:\n            if node not in result:\n                result[node] = []\n            result[node].append(node)\n    return result\n", "def deep_merge_nodes(nodes):\n    # type: (Iterable[MappingNode]) -> MappingNode\n    \"\"\"\n    Merge any node values corresponding to duplicate keys and return the result.\n\n    If there are colliding keys with non-MappingNode values, the last of the values\n    remains.\n    \"\"\"\n    nodes = list(nodes)\n    last = None\n    for node in nodes:\n        if node.value == '__last__':\n            if last:\n                node.value = last.value\n                last.prev_value = last.prev_node = node\n            else:\n                last = node\n        elif node.value!= node.prev_value and node.value!= node.prev_node.value:\n            node.value = node.prev_value\n            last.prev_value = node\n            last = node\n    return last\n", "def deep_merge_nodes(nodes):\n    def _deep_merge_nodes(nodes, new_node):\n        if isinstance(new_node, MappingNode):\n            for key in new_node.keys():\n                if key in nodes and nodes[key] is not None:\n                    if isinstance(nodes[key], MappingNode) and nodes[key].value == []:\n                        nodes[key] = nodes[key].value[-1]\n                    else:\n                        nodes[key].extend(_deep_merge_nodes(nodes[key], new_node.value[i]) for i in range(len(new_node.value)))\n                else:\n                    nodes[key] = new_node.value\n        else:\n            return new_node\n    return reduce(_deep_merge_nodes, nodes, None)\n", "def deep_merge_nodes(nodes):\n    def _deep_merge_node(node):\n        if isinstance(node, MappingNode):\n            mapping_keys = node.keys()\n            if len(mapping_keys) > 1:\n                key = mapping_keys[-1]\n                if isinstance(node[key], MappingNode):\n                    return _deep_merge_node(node[key])\n                else:\n                    return DeepMappingNode(key, node[key])\n            else:\n                return node\n        else:\n            return node\n\n    return reduce(_deep_merge_node, nodes, DeepMappingNode(None, None))\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.value in result:\n                raise ValueError('Duplicate key: %r' % node.value)\n            result.append(node.value)\n        else:\n            result.append(node)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = {}\n    for k, v in nodes.items():\n        if isinstance(v, MappingNode):\n            if k in result and isinstance(result[k], MappingNode):\n                if not is_same_type(result[k], v):\n                    raise ValueError('Duplicate mapping value for key {}'.format(k))\n            else:\n                result[k] = v\n        else:\n            result[k] = v\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    dupes = {}\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.value in dupes:\n                dupes[node.value].append(node)\n            else:\n                dupes[node.value] = [node]\n        else:\n            if node not in dupes:\n                dupes[node] = []\n            dupes[node].append(node)\n    result = []\n    for key, values in dupes.items():\n        if len(values) > 1:\n            last = values[-1]\n            for sub_value in values[:-1]:\n                if isinstance(last, MappingNode) and sub_value.value not in dupes:\n                    last.append(sub_value)\n                    break\n            else:\n         ", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = nodes[-1]\n    for node in nodes[:-1]:\n        for key, value in node.items():\n            if isinstance(value, MappingNode):\n                if value == result:\n                    continue\n                else:\n                    result = value\n                    break\n        else:\n            result = node\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    duplicates = {}\n    for node in nodes:\n        if node.value in duplicates:\n            duplicates[node.value].append(node)\n        else:\n            duplicates[node.value] = [node]\n\n    # Remove duplicates\n    nodes = []\n    for key, values in duplicates.items():\n        if len(values) > 1:\n            nodes.append({key: values})\n        elif len(values) == 1:\n            nodes.append(values[0])\n\n    return nodes\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = {}\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.value in result:\n                result[node.value].append(node)\n            else:\n                result[node.value] = [node]\n        else:\n            result[node] = node\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = {}\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.value in result:\n                result[node.value].append(node)\n            else:\n                result[node.value] = [node]\n        else:\n            if node not in result:\n                result[node] = []\n            result[node].append(node)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    # type: (Iterable[MappingNode]) -> MappingNode\n    \"\"\"\n    Merge any node values corresponding to duplicate keys and return the result.\n\n    If there are colliding keys with non-MappingNode values, the last of the values\n    remains.\n    \"\"\"\n    nodes = list(nodes)\n    last = None\n    for node in nodes:\n        if node.value == '__last__':\n            if last:\n                node.value = last.value\n                last.prev_value = last.prev_node = node\n            else:\n                last = node\n        elif node.value!= node.prev_value and node.value!= node.prev_node.value:\n            node.value = node.prev_value\n            last.prev_value = node\n            last = node\n    return last\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    def _deep_merge_nodes(nodes, new_node):\n        if isinstance(new_node, MappingNode):\n            for key in new_node.keys():\n                if key in nodes and nodes[key] is not None:\n                    if isinstance(nodes[key], MappingNode) and nodes[key].value == []:\n                        nodes[key] = nodes[key].value[-1]\n                    else:\n                        nodes[key].extend(_deep_merge_nodes(nodes[key], new_node.value[i]) for i in range(len(new_node.value)))\n                else:\n                    nodes[key] = new_node.value\n        else:\n            return new_node\n    return reduce(_deep_merge_nodes, nodes, None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    def _deep_merge_node(node):\n        if isinstance(node, MappingNode):\n            mapping_keys = node.keys()\n            if len(mapping_keys) > 1:\n                key = mapping_keys[-1]\n                if isinstance(node[key], MappingNode):\n                    return _deep_merge_node(node[key])\n                else:\n                    return DeepMappingNode(key, node[key])\n            else:\n                return node\n        else:\n            return node\n\n    return reduce(_deep_merge_node, nodes, DeepMappingNode(None, None))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/generate_config.py", "project": "witten/atticmatic", "name": "parse_arguments", "docstring": "Given command-line arguments with which this script was invoked, parse the arguments and return\nthem as an ArgumentParser instance.", "ques_id": "62b4567ad7d32e5b55cc83af", "code": ["def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for argument in arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for argument in arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Check that all required arguments are set',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    parser.add_argument('-v', '--version', action='version',\n                        version='%(prog)s'+ __version__)\n\n    for argument in arguments:\n        parser.add_argument(*argument.split('='), **argument_kwargs(argument))\n\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Command-line interface for Python scripts to be run through Python.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    parser.add_argument(\n        'file', metavar='PYTHON_FILE', nargs='?', type=argparse.FileType('r'),\n        help='The Python script to run'\n    )\n    parser.add_argument(\n        '-v', '--version', action='store_true', dest='print_version',\n        help='Show the version number of the program.'\n    )\n    parser.add_argument(\n        '-d', '--debug', action='store_true', dest='debug',\n        help='Print debugging information.'\n    )\n    parser.add_argument(\n        '-s', '--silent', action='store_true', dest='silent',\n        help='Silence the output.'\n    )\n    return parser\n", "def parse_arguments(*arguments):\n\n    parser = argparse.ArgumentParser(\n        description='Process Coverage output for package dependencies.')\n    parser.add_argument(\n        '--cover-erase', action='store_true',\n        help='Coverage erase files if they exist.')\n    parser.add_argument(\n        '--cover-branches', action='store_true',\n        help='Coverage branches if they exist.')\n    parser.add_argument(\n        '--cover-omit', action='append',\n        help='Coverage omit files from the coverage report.')\n    parser.add_argument(\n        '--cover-config', action='store',\n        help='Coverage configuration file (JSON)')\n    parser.add_argument(\n        '--no-colors', action='store_true',\n        help='Disable coloring of output')\n    parser.add_argument(\n        '--all', action='store_true',\n        help='List all tests that have been run in the coverage report.')\n    parser.ad", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for argument in arguments:\n        parser.add_argument(*argument)\n\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for arg in arguments:\n        parser.add_argument(*arg.split('='), **argparse.util.parse_qs(arg))\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for arg in arguments:\n        parser.add_argument(*arg.args, **arg.kwargs)\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for arg in arguments:\n        parser.add_argument(*arg.args, **arg.kwargs)\n\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for arg in arguments:\n        parser.add_argument(*arg.args, **arg.kwargs)\n    return parser\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for argument in arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for argument in arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Check that all required arguments are set',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    parser.add_argument('-v', '--version', action='version',\n                        version='%(prog)s'+ __version__)\n\n    for argument in arguments:\n        parser.add_argument(*argument.split('='), **argument_kwargs(argument))\n\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Command-line interface for Python scripts to be run through Python.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    parser.add_argument(\n        'file', metavar='PYTHON_FILE', nargs='?', type=argparse.FileType('r'),\n        help='The Python script to run'\n    )\n    parser.add_argument(\n        '-v', '--version', action='store_true', dest='print_version',\n        help='Show the version number of the program.'\n    )\n    parser.add_argument(\n        '-d', '--debug', action='store_true', dest='debug',\n        help='Print debugging information.'\n    )\n    parser.add_argument(\n        '-s', '--silent', action='store_true', dest='silent',\n        help='Silence the output.'\n    )\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n\n    parser = argparse.ArgumentParser(\n        description='Process Coverage output for package dependencies.')\n    parser.add_argument(\n        '--cover-erase', action='store_true',\n        help='Coverage erase files if they exist.')\n    parser.add_argument(\n        '--cover-branches', action='store_true',\n        help='Coverage branches if they exist.')\n    parser.add_argument(\n        '--cover-omit', action='append',\n        help='Coverage omit files from the coverage report.')\n    parser.add_argument(\n        '--cover-config', action='store',\n        help='Coverage configuration file (JSON)')\n    parser.add_argument(\n        '--no-colors', action='store_true',\n        help='Disable coloring of output')\n    parser.add_argument(\n        '--all', action='store_true',\n        help='List all tests that have been run in the coverage report.')\n    parser.ad", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for argument in arguments:\n        parser.add_argument(*argument)\n\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for arg in arguments:\n        parser.add_argument(*arg.split('='), **argparse.util.parse_qs(arg))\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for arg in arguments:\n        parser.add_argument(*arg.args, **arg.kwargs)\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for arg in arguments:\n        parser.add_argument(*arg.args, **arg.kwargs)\n\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for arg in arguments:\n        parser.add_argument(*arg.args, **arg.kwargs)\n    return parser\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/completion.py", "project": "witten/atticmatic", "name": "parser_flags", "docstring": "Given an argparse.ArgumentParser instance, return its argument flags in a space-separated\nstring.", "ques_id": "62b45679d7d32e5b55cc83a9", "code": ["def parser_flags(parser):\n    flags = ''\n    for flag in parser._action_groups:\n        flags +='' + flag._group_actions[0]._group_actions[1].option_strings[0]\n    return flags\n", "def parser_flags(parser):\n    flags = []\n    for arg in parser._actions:\n        if isinstance(arg, argparse.ArgumentParser):\n            flags.extend(arg.args)\n        else:\n            flags.append(arg)\n    return''.join(str(flag) for flag in flags)\n", "def parser_flags(parser):\n    flags = ''\n    for flag in parser._action_groups:\n        if flag._action_group_name == 'tornado.generator':\n            flags +='' + flag._action_flags\n    return flags\n", "def parser_flags(parser):\n    flags = ''\n    for flag in parser._action_groups['general']._group_actions:\n        if flag._action_group_name == 'examples':\n            flags +='-x {}'.format(flag._action_group_title)\n        else:\n            flags +='{}'.format(flag._action_group_title)\n    return flags\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        flags +='' + arg.flags\n    return flags\n", "def parser_flags(parser):\n    flags = ''\n    for flag in parser._action_groups:\n        if flag._group_name == '__flags__':\n            flags += flag._action_group_action\n    return flags\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        flags +='' + arg.flags\n    return flags\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.dest is None:\n            continue\n        flags +='{}'.format(arg.dest)\n    return flags\n", "def parser_flags(parser):\n    return''.join([str(flag) for flag in parser.flags])\n", "def parser_flags(parser):\n    return''.join(parser._flags)\n"], "level": "self_contained", "generate_results": [{"generate_code": "def parser_flags(parser):\n    flags = ''\n    for flag in parser._action_groups:\n        flags +='' + flag._group_actions[0]._group_actions[1].option_strings[0]\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = []\n    for arg in parser._actions:\n        if isinstance(arg, argparse.ArgumentParser):\n            flags.extend(arg.args)\n        else:\n            flags.append(arg)\n    return''.join(str(flag) for flag in flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for flag in parser._action_groups:\n        if flag._action_group_name == 'tornado.generator':\n            flags +='' + flag._action_flags\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for flag in parser._action_groups['general']._group_actions:\n        if flag._action_group_name == 'examples':\n            flags +='-x {}'.format(flag._action_group_title)\n        else:\n            flags +='{}'.format(flag._action_group_title)\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        flags +='' + arg.flags\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for flag in parser._action_groups:\n        if flag._group_name == '__flags__':\n            flags += flag._action_group_action\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        flags +='' + arg.flags\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.dest is None:\n            continue\n        flags +='{}'.format(arg.dest)\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join([str(flag) for flag in parser.flags])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(parser._flags)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/arguments.py", "project": "witten/atticmatic", "name": "parse_arguments", "docstring": "Given command-line arguments with which this script was invoked, parse the arguments and return\nthem as a dict mapping from subparser name (or \"global\") to an argparse.Namespace instance.", "ques_id": "62b45665d7d32e5b55cc8365", "code": ["def parse_arguments(*unparsed_arguments):\n    arguments = {}\n    for argument in unparsed_arguments:\n        try:\n            key, value = argument.split('=')\n            arguments[key] = value\n        except ValueError:\n            pass\n    return arguments\n", "def parse_arguments(*unparsed_arguments):\n    args = {}\n    for arg in unparsed_arguments:\n        arg = arg.split('=')\n        if len(arg) == 2:\n            args[arg[0]] = arg[1]\n    return args\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-i\", \"--input_file\", help=\"Input File\")\n    parser.add_argument(\"-o\", \"--output_file\", help=\"Output File\")\n    parser.add_argument(\"-f\", \"--force\", help=\"Force Mode\", action=\"store_true\")\n    parser.add_argument(\"-v\", \"--verbose\", help=\"Verbosity\", action=\"store_true\")\n    parser.add_argument(\"-a\", \"--address\", help=\"Address\", action=\"store\")\n    parser.add_argument(\"-s\", \"--sequence\", help=\"Sequence\", action=\"store\")\n    parser.add_argument(\"-t\", \"--type\", help=\"Type\", action=\"store\")\n    parser.add_argument(\"-d\", \"--debug\", help=\"Debug\", action=\"store_true\")\n\n    args = parser.parse_args()\n\n    return {\"input_file\": args.input_file, \"output_file\": args.output_file,\n            \"force\": args.force, \"verbose\": args.verbose, \"address\": args.address,\n            \"sequence\": args.sequence, \"type\": args.type, \"debug\": arg", "def parse_arguments(*unparsed_arguments):\n    return dict(map(parse_parameter, unparsed_arguments))\n", "def parse_arguments(*unparsed_arguments):\n    parsed_arguments = {}\n    for item in unparsed_arguments:\n        # Split argument by spaces\n        item = item.split(' ')\n\n        # Parse key/value pair\n        parsed_arguments[item[0]] = item[1]\n\n    return parsed_arguments\n", "def parse_arguments(*unparsed_arguments):\n    result = {}\n    for argument in unparsed_arguments:\n        try:\n            key, value = argument.split('=')\n        except ValueError:\n            raise ValueError('Unable to parse argument \"{}\".'.format(argument))\n        result[key] = value\n    return result\n", "def parse_arguments(*unparsed_arguments):\n    args = {}\n    for argument in unparsed_arguments:\n        try:\n            name, value = argument.split('=')\n        except ValueError:\n            name = argument\n            value = None\n        args[name] = value\n    return args\n", "def parse_arguments(*unparsed_arguments):\n    parsed_arguments = {}\n\n    for argument in unparsed_arguments:\n        key, value = argument.split('=')\n\n        parsed_arguments[key] = value\n\n    return parsed_arguments\n", "def parse_arguments(*unparsed_arguments):\n    parameters = dict()\n    for argument in unparsed_arguments:\n        key, value = argument.split('=', 1)\n        parameters[key] = value\n    return parameters\n", "def parse_arguments(*unparsed_arguments):\n    return dict(item.split(\"=\", 1) for item in unparsed_arguments)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def parse_arguments(*unparsed_arguments):\n    arguments = {}\n    for argument in unparsed_arguments:\n        try:\n            key, value = argument.split('=')\n            arguments[key] = value\n        except ValueError:\n            pass\n    return arguments\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    args = {}\n    for arg in unparsed_arguments:\n        arg = arg.split('=')\n        if len(arg) == 2:\n            args[arg[0]] = arg[1]\n    return args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-i\", \"--input_file\", help=\"Input File\")\n    parser.add_argument(\"-o\", \"--output_file\", help=\"Output File\")\n    parser.add_argument(\"-f\", \"--force\", help=\"Force Mode\", action=\"store_true\")\n    parser.add_argument(\"-v\", \"--verbose\", help=\"Verbosity\", action=\"store_true\")\n    parser.add_argument(\"-a\", \"--address\", help=\"Address\", action=\"store\")\n    parser.add_argument(\"-s\", \"--sequence\", help=\"Sequence\", action=\"store\")\n    parser.add_argument(\"-t\", \"--type\", help=\"Type\", action=\"store\")\n    parser.add_argument(\"-d\", \"--debug\", help=\"Debug\", action=\"store_true\")\n\n    args = parser.parse_args()\n\n    return {\"input_file\": args.input_file, \"output_file\": args.output_file,\n            \"force\": args.force, \"verbose\": args.verbose, \"address\": args.address,\n            \"sequence\": args.sequence, \"type\": args.type, \"debug\": arg", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    return dict(map(parse_parameter, unparsed_arguments))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parsed_arguments = {}\n    for item in unparsed_arguments:\n        # Split argument by spaces\n        item = item.split(' ')\n\n        # Parse key/value pair\n        parsed_arguments[item[0]] = item[1]\n\n    return parsed_arguments\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    result = {}\n    for argument in unparsed_arguments:\n        try:\n            key, value = argument.split('=')\n        except ValueError:\n            raise ValueError('Unable to parse argument \"{}\".'.format(argument))\n        result[key] = value\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    args = {}\n    for argument in unparsed_arguments:\n        try:\n            name, value = argument.split('=')\n        except ValueError:\n            name = argument\n            value = None\n        args[name] = value\n    return args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parsed_arguments = {}\n\n    for argument in unparsed_arguments:\n        key, value = argument.split('=')\n\n        parsed_arguments[key] = value\n\n    return parsed_arguments\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parameters = dict()\n    for argument in unparsed_arguments:\n        key, value = argument.split('=', 1)\n        parameters[key] = value\n    return parameters\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    return dict(item.split(\"=\", 1) for item in unparsed_arguments)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/arguments.py", "project": "witten/atticmatic", "name": "parse_subparser_arguments", "docstring": "Given a sequence of arguments and a dict from subparser name to argparse.ArgumentParser\ninstance, give each requested action's subparser a shot at parsing all arguments. This allows\ncommon arguments like \"--repository\" to be shared across multiple subparsers.\n\nReturn the result as a tuple of (a dict mapping from subparser name to a parsed namespace of\narguments, a list of remaining arguments not claimed by any subparser).", "ques_id": "62b45665d7d32e5b55cc8364", "code": ["def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    not_parsed_arguments = []\n    for subparser_name, subparser in six.iteritems(subparsers):\n        if subparser_name in unparsed_arguments:\n            parsed_arguments[subparser_name] = subparser.parse_args(unparsed_arguments[subparser_name])\n        else:\n            not_parsed_arguments.append(subparser_name)\n    return parsed_arguments, not_parsed_arguments\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for subparser_name, subparser in six.iteritems(subparsers):\n        parsed_arguments[subparser_name] = parse_argument_line(subparser,\n                                                             unparsed_arguments)\n        if parsed_arguments[subparser_name] is None:\n            remaining_arguments.append(subparser_name)\n\n    return parsed_arguments, remaining_arguments\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    unparsed_args = []\n    for argument in unparsed_arguments:\n        parsed_arguments[argument.name] = parse_argument(argument, subparsers)\n        if argument.name not in parsed_arguments:\n            unparsed_args.append(argument)\n    return parsed_arguments, unparsed_args\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parse_args = {}\n    not_parsed = []\n    for name, parser in subparsers.items():\n        try:\n            parser_args = parser.parse_args(unparsed_arguments)\n            parse_args.update(parser_args)\n            parse_args[name] = parser_args.pop(name)\n        except ArgumentParserError as e:\n            not_parsed.append(name)\n            e.parser = parser\n            e.arguments = []\n            e.parser_args = []\n            e.unparsed_arguments = unparsed_arguments\n            raise\n    return parse_args, not_parsed\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for subparser in subparsers._subparsers._actions:\n        args = unparsed_arguments.pop(0)\n        remaining_arguments.append(args)\n        arguments.update(subparser.parse_args(args))\n\n    return (arguments, remaining_arguments)\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for subparser in subparsers:\n        if subparser.name not in unparsed_arguments:\n            continue\n        args, _ = parse_args(unparsed_arguments[subparser.name], subparser)\n        arguments[subparser.name] = args\n        remaining_arguments.extend(args)\n    return (arguments, remaining_arguments)\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    unparsed_arguments = unparsed_arguments or []\n    for subparser_name in subparsers:\n        parser = subparsers[subparser_name]\n        arguments[subparser_name] = parser.parse_args(unparsed_arguments)\n        unparsed_arguments.pop(0)\n    return arguments, unparsed_arguments\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    unparsed_args = []\n    remaining_arguments = []\n    for arg in unparsed_arguments:\n        arg_parser = subparsers.add_parser(arg.replace('-', '_'))\n        arg_parser.set_defaults(**args_to_kwargs(arg))\n        parsed_arguments[arg] = arg_parser\n        remaining_arguments.append(arg_parser)\n        unparsed_args.append(arg)\n    for arg in unparsed_args:\n        arg_parser = subparsers.add_parser(arg.replace('-', '_'))\n        parsed_arguments[arg] = arg_parser\n        remaining_arguments.append(arg_parser)\n        unparsed_args.remove(arg)\n    return parsed_arguments, remaining_arguments\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_args = []\n    for parser in subparsers._actions:\n        parsed_arguments.update(parser.parse_args(unparsed_arguments))\n        if parsed_arguments[parser.dest] is None:\n            remaining_args.append(parser.dest)\n    return parsed_arguments, remaining_args\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    unparsed_args = []\n    for arg in unparsed_arguments:\n        if arg.name not in arguments:\n            arguments[arg.name] = parse_argparse_action(arg, subparsers)\n        else:\n            arguments[arg.name] = arguments[arg.name].parse(arg, subparsers)\n        unparsed_args.append(arguments[arg.name])\n    return (arguments, unparsed_args)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    not_parsed_arguments = []\n    for subparser_name, subparser in six.iteritems(subparsers):\n        if subparser_name in unparsed_arguments:\n            parsed_arguments[subparser_name] = subparser.parse_args(unparsed_arguments[subparser_name])\n        else:\n            not_parsed_arguments.append(subparser_name)\n    return parsed_arguments, not_parsed_arguments\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for subparser_name, subparser in six.iteritems(subparsers):\n        parsed_arguments[subparser_name] = parse_argument_line(subparser,\n                                                             unparsed_arguments)\n        if parsed_arguments[subparser_name] is None:\n            remaining_arguments.append(subparser_name)\n\n    return parsed_arguments, remaining_arguments\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    unparsed_args = []\n    for argument in unparsed_arguments:\n        parsed_arguments[argument.name] = parse_argument(argument, subparsers)\n        if argument.name not in parsed_arguments:\n            unparsed_args.append(argument)\n    return parsed_arguments, unparsed_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parse_args = {}\n    not_parsed = []\n    for name, parser in subparsers.items():\n        try:\n            parser_args = parser.parse_args(unparsed_arguments)\n            parse_args.update(parser_args)\n            parse_args[name] = parser_args.pop(name)\n        except ArgumentParserError as e:\n            not_parsed.append(name)\n            e.parser = parser\n            e.arguments = []\n            e.parser_args = []\n            e.unparsed_arguments = unparsed_arguments\n            raise\n    return parse_args, not_parsed\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for subparser in subparsers._subparsers._actions:\n        args = unparsed_arguments.pop(0)\n        remaining_arguments.append(args)\n        arguments.update(subparser.parse_args(args))\n\n    return (arguments, remaining_arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for subparser in subparsers:\n        if subparser.name not in unparsed_arguments:\n            continue\n        args, _ = parse_args(unparsed_arguments[subparser.name], subparser)\n        arguments[subparser.name] = args\n        remaining_arguments.extend(args)\n    return (arguments, remaining_arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    unparsed_arguments = unparsed_arguments or []\n    for subparser_name in subparsers:\n        parser = subparsers[subparser_name]\n        arguments[subparser_name] = parser.parse_args(unparsed_arguments)\n        unparsed_arguments.pop(0)\n    return arguments, unparsed_arguments\n", "is_pass": false, "return_code": 2}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    unparsed_args = []\n    remaining_arguments = []\n    for arg in unparsed_arguments:\n        arg_parser = subparsers.add_parser(arg.replace('-', '_'))\n        arg_parser.set_defaults(**args_to_kwargs(arg))\n        parsed_arguments[arg] = arg_parser\n        remaining_arguments.append(arg_parser)\n        unparsed_args.append(arg)\n    for arg in unparsed_args:\n        arg_parser = subparsers.add_parser(arg.replace('-', '_'))\n        parsed_arguments[arg] = arg_parser\n        remaining_arguments.append(arg_parser)\n        unparsed_args.remove(arg)\n    return parsed_arguments, remaining_arguments\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_args = []\n    for parser in subparsers._actions:\n        parsed_arguments.update(parser.parse_args(unparsed_arguments))\n        if parsed_arguments[parser.dest] is None:\n            remaining_args.append(parser.dest)\n    return parsed_arguments, remaining_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    unparsed_args = []\n    for arg in unparsed_arguments:\n        if arg.name not in arguments:\n            arguments[arg.name] = parse_argparse_action(arg, subparsers)\n        else:\n            arguments[arg.name] = arguments[arg.name].parse(arg, subparsers)\n        unparsed_args.append(arguments[arg.name])\n    return (arguments, unparsed_args)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/arguments.py", "project": "witten/atticmatic", "name": "make_parsers", "docstring": "Build a top-level parser and its subparsers and return them as a tuple.", "ques_id": "62b45665d7d32e5b55cc8363", "code": ["def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"Parse the results of a SMC analysis using the \"\n        \"'smc_results' file in the working directory.\"\n    )\n    subparsers = parser.add_subparsers()\n    add_results_parser(subparsers)\n    add_result_parser(subparsers)\n    add_debug_parser(subparsers)\n    add_error_parser(subparsers)\n    add_test_parser(subparsers)\n    add_profiles_parser(subparsers)\n    add_test_results_parser(subparsers)\n    add_junit_xml_parser(subparsers)\n    add_xunit_parser(subparsers)\n    add_coverage_parser(subparsers)\n    add_coverage_xml_parser(subparsers)\n    add_timeline_parser(subparsers)\n    add_test_xml_parser(subparsers)\n    add_timeline_xml_parser(subparsers)\n    add_test_table_parser(subparsers)\n    add_test_table_xml_parser(subparsers)\n    add_suite_xml_parser(subparsers)\n    add_suite_xml_xml_parser(subparsers)\n", "def make_parsers():\n    parser = argparse.ArgumentParser(description=\"Testing for docopt arguments\")\n    subparsers = parser.add_subparsers(dest=\"subcommand\")\n    for subcommand in [\"test\", \"run\", \"test-all\"]:\n        subparser = subparsers.add_parser(subcommand, help=\"Testing {} subcommand\".format(subcommand))\n        subparser.add_argument(\"--opt\", help=\"Test options\", action=\"store_true\")\n        subparser.add_argument(\"--val\", help=\"Test values\", action=\"store_true\")\n        subparser.add_argument(\"--flag\", help=\"Test flags\", action=\"store_true\")\n        subparser.add_argument(\"--no-flag\", help=\"Do not test flags\", action=\"store_false\")\n        subparser.add_argument(\"--no-opt\", help=\"Do not test options\", action=\"store_false\")\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Simple test command.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    subparsers = parser.add_subparsers(dest='command')\n    for command in COMMANDS:\n        subparser = subparsers.add_parser(\n            command['name'],\n            help=command['help'],\n            formatter_class=argparse.ArgumentDefaultsHelpFormatter\n        )\n        command['parser'](subparser)\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers()\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"Test that a command can be run with the --help flag.\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n\n    subparsers = parser.add_subparsers()\n    subparsers.required = True\n\n    test_cmd = subparsers.add_parser(\n        \"test\",\n        help=\"Test that a command can be run with the --help flag.\",\n    )\n    test_cmd.add_argument(\n        \"--test\",\n        action=\"store_true\",\n        help=\"Print test messages.\",\n    )\n    test_cmd.set_defaults(func=test_cmd_help)\n\n    return (parser, subparsers)\n", "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers()\n    build_data.build_parser(subparsers)\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser('build_cmakelists')\n    subparsers = parser.add_subparsers(dest='subcommand')\n\n    build_cmakelists.add_parser(subparsers)\n\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Test that the commands are working as expected.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    subparser = parser.add_subparsers(dest='command')\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n\n    return parser, subparser\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='A simple flake8 test suite.'\n    )\n    subparsers = parser.add_subparsers(dest='subcommand')\n    build_parser = subparsers.add_parser(\n        'build',\n        help='Build a Python file based on a single source file.'\n    )\n    build_parser.add_argument(\n        'file',\n        nargs='?',\n        type=str,\n        default='.',\n        help='The file to be built.'\n    )\n    run_parser = subparsers.add_parser(\n        'run',\n        help='Run the Python file based on a single source file.'\n    )\n    run_parser.add_argument(\n        'file',\n        nargs='?',\n        type=str,\n        default='.',\n        help='The file to be run.'\n    )\n    return (parser, subparsers)\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"A simple command-line tool to parse and transform \"\n        \"a JSON file into a Python dictionary.\")\n    parser.add_argument(\n        \"-v\", \"--version\", action=\"store_true\", help=\"Show the version number.\"\n    )\n    parser.add_argument(\n        \"input_file\", nargs=\"?\", help=\"The file to be parsed.\"\n    )\n    parser.add_argument(\n        \"-o\", \"--output\", default=\"-\", help=\"The file to be written to.\"\n    )\n    parser.add_argument(\n        \"-p\", \"--prefix\", default=\"\", help=\"The prefix of the resulting \"\n        \"dictionary.\"\n    )\n    return parser.parse_args()\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"Parse the results of a SMC analysis using the \"\n        \"'smc_results' file in the working directory.\"\n    )\n    subparsers = parser.add_subparsers()\n    add_results_parser(subparsers)\n    add_result_parser(subparsers)\n    add_debug_parser(subparsers)\n    add_error_parser(subparsers)\n    add_test_parser(subparsers)\n    add_profiles_parser(subparsers)\n    add_test_results_parser(subparsers)\n    add_junit_xml_parser(subparsers)\n    add_xunit_parser(subparsers)\n    add_coverage_parser(subparsers)\n    add_coverage_xml_parser(subparsers)\n    add_timeline_parser(subparsers)\n    add_test_xml_parser(subparsers)\n    add_timeline_xml_parser(subparsers)\n    add_test_table_parser(subparsers)\n    add_test_table_xml_parser(subparsers)\n    add_suite_xml_parser(subparsers)\n    add_suite_xml_xml_parser(subparsers)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(description=\"Testing for docopt arguments\")\n    subparsers = parser.add_subparsers(dest=\"subcommand\")\n    for subcommand in [\"test\", \"run\", \"test-all\"]:\n        subparser = subparsers.add_parser(subcommand, help=\"Testing {} subcommand\".format(subcommand))\n        subparser.add_argument(\"--opt\", help=\"Test options\", action=\"store_true\")\n        subparser.add_argument(\"--val\", help=\"Test values\", action=\"store_true\")\n        subparser.add_argument(\"--flag\", help=\"Test flags\", action=\"store_true\")\n        subparser.add_argument(\"--no-flag\", help=\"Do not test flags\", action=\"store_false\")\n        subparser.add_argument(\"--no-opt\", help=\"Do not test options\", action=\"store_false\")\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Simple test command.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    subparsers = parser.add_subparsers(dest='command')\n    for command in COMMANDS:\n        subparser = subparsers.add_parser(\n            command['name'],\n            help=command['help'],\n            formatter_class=argparse.ArgumentDefaultsHelpFormatter\n        )\n        command['parser'](subparser)\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers()\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"Test that a command can be run with the --help flag.\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n\n    subparsers = parser.add_subparsers()\n    subparsers.required = True\n\n    test_cmd = subparsers.add_parser(\n        \"test\",\n        help=\"Test that a command can be run with the --help flag.\",\n    )\n    test_cmd.add_argument(\n        \"--test\",\n        action=\"store_true\",\n        help=\"Print test messages.\",\n    )\n    test_cmd.set_defaults(func=test_cmd_help)\n\n    return (parser, subparsers)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers()\n    build_data.build_parser(subparsers)\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser('build_cmakelists')\n    subparsers = parser.add_subparsers(dest='subcommand')\n\n    build_cmakelists.add_parser(subparsers)\n\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Test that the commands are working as expected.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    subparser = parser.add_subparsers(dest='command')\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n    add_command(subparser)\n\n    return parser, subparser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='A simple flake8 test suite.'\n    )\n    subparsers = parser.add_subparsers(dest='subcommand')\n    build_parser = subparsers.add_parser(\n        'build',\n        help='Build a Python file based on a single source file.'\n    )\n    build_parser.add_argument(\n        'file',\n        nargs='?',\n        type=str,\n        default='.',\n        help='The file to be built.'\n    )\n    run_parser = subparsers.add_parser(\n        'run',\n        help='Run the Python file based on a single source file.'\n    )\n    run_parser.add_argument(\n        'file',\n        nargs='?',\n        type=str,\n        default='.',\n        help='The file to be run.'\n    )\n    return (parser, subparsers)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"A simple command-line tool to parse and transform \"\n        \"a JSON file into a Python dictionary.\")\n    parser.add_argument(\n        \"-v\", \"--version\", action=\"store_true\", help=\"Show the version number.\"\n    )\n    parser.add_argument(\n        \"input_file\", nargs=\"?\", help=\"The file to be parsed.\"\n    )\n    parser.add_argument(\n        \"-o\", \"--output\", default=\"-\", help=\"The file to be written to.\"\n    )\n    parser.add_argument(\n        \"-p\", \"--prefix\", default=\"\", help=\"The prefix of the resulting \"\n        \"dictionary.\"\n    )\n    return parser.parse_args()\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/config/load.py", "project": "witten/borgmatic", "name": "deep_merge_nodes", "docstring": "Given a nested borgmatic configuration data structure as a list of tuples in the form of:\n\n    (\n        ruamel.yaml.nodes.ScalarNode as a key,\n        ruamel.yaml.nodes.MappingNode or other Node as a value,\n    ),\n\n... deep merge any node values corresponding to duplicate keys and return the result. If\nthere are colliding keys with non-MappingNode values (e.g., integers or strings), the last\nof the values wins.\n\nFor instance, given node values of:\n\n    [\n        (\n            ScalarNode(tag='tag:yaml.org,2002:str', value='retention'),\n            MappingNode(tag='tag:yaml.org,2002:map', value=[\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_hourly'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='24')\n                ),\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_daily'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='7')\n                ),\n            ]),\n        ),\n        (\n            ScalarNode(tag='tag:yaml.org,2002:str', value='retention'),\n            MappingNode(tag='tag:yaml.org,2002:map', value=[\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_daily'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='5')\n                ),\n            ]),\n        ),\n    ]\n\n... the returned result would be:\n\n    [\n        (\n            ScalarNode(tag='tag:yaml.org,2002:str', value='retention'),\n            MappingNode(tag='tag:yaml.org,2002:map', value=[\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_hourly'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='24')\n                ),\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_daily'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='5')\n                ),\n            ]),\n        ),\n    ]\n\nThe purpose of deep merging like this is to support, for instance, merging one borgmatic\nconfiguration file into another for reuse, such that a configuration section (\"retention\",\netc.) does not completely replace the corresponding section in a merged file.", "ques_id": "62b438ba66fea644fe22cca2", "code": ["def deep_merge_nodes(nodes):\n    result = nodes[-1]\n    for node in nodes[:-1]:\n        for key, value in node.items():\n            if isinstance(value, MappingNode):\n                if value is not result:\n                    raise TypeError(\n                        \"Cannot merge values for non-MappingNode \"\n                        \"instances. Replace the last node value by \"\n                        \"the result of the replacement by a mapping value.\"\n                    )\n            else:\n                result[key] = value\n    return result\n", "def deep_merge_nodes(nodes):\n    # type: (Iterable[Node]) -> Dict[str, MappingNode]\n    \"\"\"\n    Merge any node values corresponding to duplicate keys and return the result.\n\n    If there are colliding keys with non-MappingNode values, the last of the values\n    remains.\n    \"\"\"\n    result = {}\n    for node in nodes:\n        if node not in result:\n            result[node] = MappingNode()\n        for key, value in node.items():\n            if key in result and isinstance(result[key], MappingNode):\n                if isinstance(value, MappingNode):\n                    result[key].merge(value)\n                else:\n                    result[key] = value\n            else:\n                result[key] = value\n    return result\n", "def deep_merge_nodes(nodes):\n    result = nodes[0]\n    for node in nodes[1:]:\n        for key, value in node.items():\n            if isinstance(value, MappingNode) and value.is_duplicate():\n                value = result[key]\n            setattr(result, key, value)\n    return result\n", "def deep_merge_nodes(nodes):\n    result = nodes[0]\n    for node in nodes[1:]:\n        for key, value in node.items():\n            if isinstance(value, MappingNode):\n                if key in result and isinstance(result[key], MappingNode):\n                    # merge values for colliding keys\n                    result[key].merge(value)\n                else:\n                    # append value to last node\n                    result[key] = value\n            else:\n                # keep last value unchanged\n                result[key] = value\n    return result\n", "def deep_merge_nodes(nodes):\n    nodes = list(nodes)\n    if not nodes:\n        return nodes\n    first = nodes[0]\n    for node in nodes[1:]:\n        if isinstance(node, MappingNode):\n            if node.value in first.value:\n                first = first.update(node.value)\n            else:\n                first = node.update({})\n        else:\n            first = node\n    return first\n", "def deep_merge_nodes(nodes):\n    result = nodes[0]\n    for node in nodes[1:]:\n        for key, value in node.items():\n            if key in result and isinstance(result[key], MappingNode) \\\n                    and isinstance(value, MappingNode):\n                result[key].update(value)\n            else:\n                result[key] = value\n    return result\n", "def deep_merge_nodes(nodes):\n    values = {}\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if values.get(node.value) is None:\n                values[node.value] = node\n            else:\n                raise ValueError('Duplicate key: %s' % node.value)\n        else:\n            yield node\n", "def deep_merge_nodes(nodes):\n    result = nodes[0]\n    for node in nodes[1:]:\n        for k, v in node.items():\n            if isinstance(v, MappingNode):\n                if v.value == result.value:\n                    # collide with non-MappingNode\n                    v.replace(result)\n                else:\n                    # duplicate value\n                    v.replace(result, deepcopy(last=True))\n                    # collide with non-MappingNode\n                    result = v\n            else:\n                result[k] = v\n    return result\n", "def deep_merge_nodes(nodes):\n    result = nodes[0]\n    for node in nodes[1:]:\n        if isinstance(result, MappingNode):\n            result = result.update(node)\n        else:\n            result = node\n    return result\n", "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.values()!= []:\n                result.append(node)\n            else:\n                result.pop()\n        else:\n            result.append(node)\n    return result\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def deep_merge_nodes(nodes):\n    result = nodes[-1]\n    for node in nodes[:-1]:\n        for key, value in node.items():\n            if isinstance(value, MappingNode):\n                if value is not result:\n                    raise TypeError(\n                        \"Cannot merge values for non-MappingNode \"\n                        \"instances. Replace the last node value by \"\n                        \"the result of the replacement by a mapping value.\"\n                    )\n            else:\n                result[key] = value\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    # type: (Iterable[Node]) -> Dict[str, MappingNode]\n    \"\"\"\n    Merge any node values corresponding to duplicate keys and return the result.\n\n    If there are colliding keys with non-MappingNode values, the last of the values\n    remains.\n    \"\"\"\n    result = {}\n    for node in nodes:\n        if node not in result:\n            result[node] = MappingNode()\n        for key, value in node.items():\n            if key in result and isinstance(result[key], MappingNode):\n                if isinstance(value, MappingNode):\n                    result[key].merge(value)\n                else:\n                    result[key] = value\n            else:\n                result[key] = value\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = nodes[0]\n    for node in nodes[1:]:\n        for key, value in node.items():\n            if isinstance(value, MappingNode) and value.is_duplicate():\n                value = result[key]\n            setattr(result, key, value)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = nodes[0]\n    for node in nodes[1:]:\n        for key, value in node.items():\n            if isinstance(value, MappingNode):\n                if key in result and isinstance(result[key], MappingNode):\n                    # merge values for colliding keys\n                    result[key].merge(value)\n                else:\n                    # append value to last node\n                    result[key] = value\n            else:\n                # keep last value unchanged\n                result[key] = value\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    nodes = list(nodes)\n    if not nodes:\n        return nodes\n    first = nodes[0]\n    for node in nodes[1:]:\n        if isinstance(node, MappingNode):\n            if node.value in first.value:\n                first = first.update(node.value)\n            else:\n                first = node.update({})\n        else:\n            first = node\n    return first\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = nodes[0]\n    for node in nodes[1:]:\n        for key, value in node.items():\n            if key in result and isinstance(result[key], MappingNode) \\\n                    and isinstance(value, MappingNode):\n                result[key].update(value)\n            else:\n                result[key] = value\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    values = {}\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if values.get(node.value) is None:\n                values[node.value] = node\n            else:\n                raise ValueError('Duplicate key: %s' % node.value)\n        else:\n            yield node\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = nodes[0]\n    for node in nodes[1:]:\n        for k, v in node.items():\n            if isinstance(v, MappingNode):\n                if v.value == result.value:\n                    # collide with non-MappingNode\n                    v.replace(result)\n                else:\n                    # duplicate value\n                    v.replace(result, deepcopy(last=True))\n                    # collide with non-MappingNode\n                    result = v\n            else:\n                result[k] = v\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = nodes[0]\n    for node in nodes[1:]:\n        if isinstance(result, MappingNode):\n            result = result.update(node)\n        else:\n            result = node\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.values()!= []:\n                result.append(node)\n            else:\n                result.pop()\n        else:\n            result.append(node)\n    return result\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/generate_config.py", "project": "witten/borgmatic", "name": "parse_arguments", "docstring": "Given command-line arguments with which this script was invoked, parse the arguments and return\nthem as an ArgumentParser instance.", "ques_id": "62b438b666fea644fe22cc78", "code": ["def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for argument in arguments:\n        if is_argument_instance(argument):\n            parser.add_argument(argument.get_name(), argument)\n        else:\n            parser.add_argument(argument)\n\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for argument in arguments:\n        parser.add_argument(argument)\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for arg in arguments:\n        parser.add_argument(*arg.args, **arg.kwargs)\n\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n\n    for arg in arguments:\n        parser.add_argument(*arg.args, **arg.kwargs)\n\n    return parser\n", "def parse_arguments(*arguments):\n\n    parser = argparse.ArgumentParser()\n    for argument in arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n\n    return parser\n", "def parse_arguments(*arguments):\n\n    # The \"--version\" option is the default short help for the program\n    parser = argparse.ArgumentParser(\n        description='A simple program that prints the version number',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    parser.add_argument(\n        '-v', '--version',\n        action='version',\n        version='%(prog)s {}'.format(os.path.basename(__file__))\n    )\n\n    for argument in arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description=\"\"\"\n            Common User Passwords Credential Script.\n            See https://github.com/miztiik/user-passwords for more info.\n        \"\"\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n\n    parser.add_argument(\n        \"-i\",\n        \"--interactive\",\n        action=\"store_true\",\n        help=\"Interactive mode (-i option for interactive mode).\",\n    )\n\n    parser.add_argument(\n        \"-d\",\n        \"--debug\",\n        action=\"store_true\",\n        help=\"Debug mode (-d option for debugging mode).\",\n    )\n\n    parser.add_argument(\n        \"-v\",\n        \"--version\",\n        action=\"store_true\",\n        help=\"Show the version number and exit.\",\n    )\n\n    parser.add_argument(\n        \"-c\",\n        \"--config\",\n        default=\".userpass.ym", "def parse_arguments(*arguments):\n\n    parser = argparse.ArgumentParser(\n        description=\"Just a Fibonnaci demonstration\")\n\n    for arg in arguments:\n        parser.add_argument(*arg[0], **arg[1])\n\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Just a Fibonnaci demonstration\")\n\n    parser.add_argument(\n        'n', type=int, help='The sum of the n most fibonnaci numbers')\n\n    return parser.parse_args(arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Test script for converting a PNG to JPEG',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    parser.add_argument(\n        '-o', '--output-file', required=True,\n        help='Output file to write the converted PNG to'\n    )\n\n    parser.add_argument(\n        'input-image', nargs='+', help='PNG input files'\n    )\n\n    parser.add_argument(\n        'output-image', nargs='+', help='JPEG output files'\n    )\n\n    return parser\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for argument in arguments:\n        if is_argument_instance(argument):\n            parser.add_argument(argument.get_name(), argument)\n        else:\n            parser.add_argument(argument)\n\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for argument in arguments:\n        parser.add_argument(argument)\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for arg in arguments:\n        parser.add_argument(*arg.args, **arg.kwargs)\n\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n\n    for arg in arguments:\n        parser.add_argument(*arg.args, **arg.kwargs)\n\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n\n    parser = argparse.ArgumentParser()\n    for argument in arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n\n    # The \"--version\" option is the default short help for the program\n    parser = argparse.ArgumentParser(\n        description='A simple program that prints the version number',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    parser.add_argument(\n        '-v', '--version',\n        action='version',\n        version='%(prog)s {}'.format(os.path.basename(__file__))\n    )\n\n    for argument in arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description=\"\"\"\n            Common User Passwords Credential Script.\n            See https://github.com/miztiik/user-passwords for more info.\n        \"\"\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n\n    parser.add_argument(\n        \"-i\",\n        \"--interactive\",\n        action=\"store_true\",\n        help=\"Interactive mode (-i option for interactive mode).\",\n    )\n\n    parser.add_argument(\n        \"-d\",\n        \"--debug\",\n        action=\"store_true\",\n        help=\"Debug mode (-d option for debugging mode).\",\n    )\n\n    parser.add_argument(\n        \"-v\",\n        \"--version\",\n        action=\"store_true\",\n        help=\"Show the version number and exit.\",\n    )\n\n    parser.add_argument(\n        \"-c\",\n        \"--config\",\n        default=\".userpass.ym", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n\n    parser = argparse.ArgumentParser(\n        description=\"Just a Fibonnaci demonstration\")\n\n    for arg in arguments:\n        parser.add_argument(*arg[0], **arg[1])\n\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Just a Fibonnaci demonstration\")\n\n    parser.add_argument(\n        'n', type=int, help='The sum of the n most fibonnaci numbers')\n\n    return parser.parse_args(arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Test script for converting a PNG to JPEG',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    parser.add_argument(\n        '-o', '--output-file', required=True,\n        help='Output file to write the converted PNG to'\n    )\n\n    parser.add_argument(\n        'input-image', nargs='+', help='PNG input files'\n    )\n\n    parser.add_argument(\n        'output-image', nargs='+', help='JPEG output files'\n    )\n\n    return parser\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/completion.py", "project": "witten/borgmatic", "name": "parser_flags", "docstring": "Given an argparse.ArgumentParser instance, return its argument flags in a space-separated\nstring.", "ques_id": "62b438b666fea644fe22cc72", "code": ["def parser_flags(parser):\n    return''.join(a.description for a in parser._actions)\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.dest is None:\n            flags +='{}'.format(arg.flags)\n        else:\n            flags +='{} {}'.format(arg.flags, arg.dest)\n    return flags\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.dest is None:\n            flags +=''\n        else:\n            flags += arg.dest +''\n    return flags\n", "def parser_flags(parser):\n    return''.join(v for v in vars(parser).values() if v)\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg._long_opts:\n            flags +='' + arg._long_opts[0]\n        if arg._opt_actions:\n            flags +='' + arg._opt_actions[0]\n    return flags\n", "def parser_flags(parser):\n    return''.join(str(f) for f in parser.flags)\n", "def parser_flags(parser):\n    flags = []\n    for arg in parser._actions:\n        if arg.dest is None:\n            flags.append(arg.default)\n        else:\n            flags.append(arg.takes_arg(arg.dest))\n    return''.join(flags)\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.nargs == 0:\n            flags +=''\n        else:\n            flags +='-'\n        flags += str(arg.default)\n    return flags\n", "def parser_flags(parser):\n    flags = ''\n    for flag in parser._action_groups:\n        if flag._group_name == '__flags':\n            flags ='' + flags\n    return flags\n", "def parser_flags(parser):\n    return''.join(str(f) for f in parser._flags)\n"], "level": "self_contained", "generate_results": [{"generate_code": "def parser_flags(parser):\n    return''.join(a.description for a in parser._actions)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.dest is None:\n            flags +='{}'.format(arg.flags)\n        else:\n            flags +='{} {}'.format(arg.flags, arg.dest)\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.dest is None:\n            flags +=''\n        else:\n            flags += arg.dest +''\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(v for v in vars(parser).values() if v)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg._long_opts:\n            flags +='' + arg._long_opts[0]\n        if arg._opt_actions:\n            flags +='' + arg._opt_actions[0]\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(str(f) for f in parser.flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = []\n    for arg in parser._actions:\n        if arg.dest is None:\n            flags.append(arg.default)\n        else:\n            flags.append(arg.takes_arg(arg.dest))\n    return''.join(flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.nargs == 0:\n            flags +=''\n        else:\n            flags +='-'\n        flags += str(arg.default)\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for flag in parser._action_groups:\n        if flag._group_name == '__flags':\n            flags ='' + flags\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(str(f) for f in parser._flags)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/completion.py", "project": "witten/borgmatic", "name": "bash_completion", "docstring": "Return a bash completion script for the borgmatic command. Produce this by introspecting\nborgmatic's command-line argument parsers.", "ques_id": "62b438b566fea644fe22cc70", "code": ["def bash_completion():\n    commands = {}\n    for command_name in _commands.keys():\n        try:\n            command_class = _commands[command_name]\n        except KeyError:\n            continue\n        args = command_class.get_bash_completion_args()\n        if args:\n            commands[command_name] = args\n    return commands\n", "def bash_completion():\n    commands = {}\n    for (action, args) in _command_parser._actions:\n        if args:\n            commands[action] = args\n    return commands.items()\n", "def bash_completion():\n    return '\\n'.join('  {}: {}'.format(k, v) for k, v in vars(bash).items() if k.startswith('COMMAND_'))\n", "def bash_completion():\n    cmd_list = []\n    for name, metadata in _commands.items():\n        parser = _get_bash_completion_parser(metadata)\n        cmd_list.append('{0} {1}'.format(name, parser.print_help))\n    return '\\n'.join(cmd_list)\n", "def bash_completion():\n    all_parser_names = ', '.join(p.__name__ for p in _get_command_parsers())\n    return '\\n'.join([\n        'bash -c \"echo -n \"{}\" > {}\"'.format(p, p) for p in all_parser_names\n    ])\n", "def bash_completion():\n    bash_completion = {}\n    for k, v in globals().items():\n        if k.startswith('BASH_COMMAND_'):\n            bash_completion[k[len('BASH_COMMAND_'):]] = v\n    return bash_completion\n", "def bash_completion():\n    bash_completion_dict = {}\n    for (name, parser) in _bash_completion_parsers.items():\n        bash_completion_dict[name] = parser.parse_args()\n    return bash_completion_dict\n", "def bash_completion():\n    commands = {}\n    for parser in BASH_COMMANDS:\n        # Get the name of the parser and its docstring\n        parser_name = parser.__name__.replace('_','').capitalize()\n        doc = inspect.cleandoc(parser.__doc__)\n        commands[parser_name] = (parser_name, doc)\n    return commands\n", "def bash_completion():\n    return '\\n'.join('  %s %s' % (k, v) for k, v in sorted(dict(argparse.__dict__).items()) if not k.startswith('_'))\n", "def bash_completion():\n    bash_completion = {'': []}\n\n    for group in bash_completion.values():\n        group.sort()\n        for item in group:\n            item.insert(0, '--')\n\n    return bash_completion\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def bash_completion():\n    commands = {}\n    for command_name in _commands.keys():\n        try:\n            command_class = _commands[command_name]\n        except KeyError:\n            continue\n        args = command_class.get_bash_completion_args()\n        if args:\n            commands[command_name] = args\n    return commands\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    commands = {}\n    for (action, args) in _command_parser._actions:\n        if args:\n            commands[action] = args\n    return commands.items()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    return '\\n'.join('  {}: {}'.format(k, v) for k, v in vars(bash).items() if k.startswith('COMMAND_'))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    cmd_list = []\n    for name, metadata in _commands.items():\n        parser = _get_bash_completion_parser(metadata)\n        cmd_list.append('{0} {1}'.format(name, parser.print_help))\n    return '\\n'.join(cmd_list)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    all_parser_names = ', '.join(p.__name__ for p in _get_command_parsers())\n    return '\\n'.join([\n        'bash -c \"echo -n \"{}\" > {}\"'.format(p, p) for p in all_parser_names\n    ])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    bash_completion = {}\n    for k, v in globals().items():\n        if k.startswith('BASH_COMMAND_'):\n            bash_completion[k[len('BASH_COMMAND_'):]] = v\n    return bash_completion\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    bash_completion_dict = {}\n    for (name, parser) in _bash_completion_parsers.items():\n        bash_completion_dict[name] = parser.parse_args()\n    return bash_completion_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    commands = {}\n    for parser in BASH_COMMANDS:\n        # Get the name of the parser and its docstring\n        parser_name = parser.__name__.replace('_','').capitalize()\n        doc = inspect.cleandoc(parser.__doc__)\n        commands[parser_name] = (parser_name, doc)\n    return commands\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    return '\\n'.join('  %s %s' % (k, v) for k, v in sorted(dict(argparse.__dict__).items()) if not k.startswith('_'))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    bash_completion = {'': []}\n\n    for group in bash_completion.values():\n        group.sort()\n        for item in group:\n            item.insert(0, '--')\n\n    return bash_completion\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/arguments.py", "project": "witten/borgmatic", "name": "parse_arguments", "docstring": "Given command-line arguments with which this script was invoked, parse the arguments and return\nthem as a dict mapping from subparser name (or \"global\") to an argparse.Namespace instance.", "ques_id": "62b438a266fea644fe22cc2e", "code": ["def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for unparsed_argument in unparsed_arguments:\n        parser.add_argument(*unparsed_argument.args, **unparsed_argument.kwargs)\n    return vars(parser.parse_args())\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for name, argument_list in unparsed_arguments:\n        for argument in argument_list:\n            parser.add_argument(*argument.args, **argument.kwargs)\n    return vars(parser.parse_args())\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Test the command line tool.\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n\n    parser.add_argument(\n        \"--test-path\",\n        default=\".\",\n        help=\"Path to the directory containing the test files. \"\n        \"Defaults to the directory containing the.helloworld \"\n        \"file, or the current directory if no directory is given.\",\n    )\n\n    parsed_arguments = parser.parse_args(*unparsed_arguments)\n\n    if parsed_arguments.test_path is None:\n        parsed_arguments.test_path = os.getcwd()\n\n    return {\n        \"test_path\": parsed_arguments.test_path,\n    }\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n    return vars(parser.parse_args())\n", "def parse_arguments(*unparsed_arguments):\n    parser = create_argument_parser()\n    return vars(parser.parse_args(unparsed_arguments))\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n\n    return vars(parser.parse_args())\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Test that the command line tool outputs the expected output.\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n    return vars(parser.parse_args(unparsed_arguments))\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Test that the --test-output-dir option works correctly\"\n    )\n    subparsers = parser.add_subparsers(dest=\"subcommand\")\n    for subcommand, subcommand_parser in six.iteritems(PARSERS):\n        parser = subparsers.add_parser(subcommand)\n        subcommand_parser.add_arguments(parser)\n    for argument in unparsed_arguments:\n        subparser_name = PARSERS[argument.command][\"subcommand\"]\n        parser_name = PARSERS[argument.command][\"global\"]\n        subparser = subparsers.add_parser(subparser_name)\n        parser.add_argument(*argument.args, **argument.kwargs)\n        parser.set_defaults(**parser_namespace(argument))\n    return {subcommand: parser.parse_args() for subcommand, parser in six.iteritems(PARSERS)}\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n    args = parser.parse_args()\n    return {arg.name: arg for arg in args.__args__}\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='subcommand')\n\n    for (subcommand, parser) in PARSERS:\n        parser = parser(\n            parents=[subparsers],\n            formatter_class=argparse.ArgumentDefaultsHelpFormatter\n        )\n        parser.add_argument('--%s' % subcommand, default=None, required=False)\n        parser.add_argument('--%s-args' % subcommand, default=None)\n\n    for argument in unparsed_arguments:\n        parser = parser.add_argument(\n            '--%s-args' % argument.replace('-', '_'), default=None)\n        parser.add_argument('--%s-kwargs' % argument.replace('-', '_'), default=None)\n\n    return dict((subcommand, parser.parse_args(*unparsed_arguments))\n                for subcommand, parser in PARSERS)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for unparsed_argument in unparsed_arguments:\n        parser.add_argument(*unparsed_argument.args, **unparsed_argument.kwargs)\n    return vars(parser.parse_args())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for name, argument_list in unparsed_arguments:\n        for argument in argument_list:\n            parser.add_argument(*argument.args, **argument.kwargs)\n    return vars(parser.parse_args())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Test the command line tool.\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n\n    parser.add_argument(\n        \"--test-path\",\n        default=\".\",\n        help=\"Path to the directory containing the test files. \"\n        \"Defaults to the directory containing the.helloworld \"\n        \"file, or the current directory if no directory is given.\",\n    )\n\n    parsed_arguments = parser.parse_args(*unparsed_arguments)\n\n    if parsed_arguments.test_path is None:\n        parsed_arguments.test_path = os.getcwd()\n\n    return {\n        \"test_path\": parsed_arguments.test_path,\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n    return vars(parser.parse_args())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = create_argument_parser()\n    return vars(parser.parse_args(unparsed_arguments))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n\n    return vars(parser.parse_args())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Test that the command line tool outputs the expected output.\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n    return vars(parser.parse_args(unparsed_arguments))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Test that the --test-output-dir option works correctly\"\n    )\n    subparsers = parser.add_subparsers(dest=\"subcommand\")\n    for subcommand, subcommand_parser in six.iteritems(PARSERS):\n        parser = subparsers.add_parser(subcommand)\n        subcommand_parser.add_arguments(parser)\n    for argument in unparsed_arguments:\n        subparser_name = PARSERS[argument.command][\"subcommand\"]\n        parser_name = PARSERS[argument.command][\"global\"]\n        subparser = subparsers.add_parser(subparser_name)\n        parser.add_argument(*argument.args, **argument.kwargs)\n        parser.set_defaults(**parser_namespace(argument))\n    return {subcommand: parser.parse_args() for subcommand, parser in six.iteritems(PARSERS)}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n    args = parser.parse_args()\n    return {arg.name: arg for arg in args.__args__}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='subcommand')\n\n    for (subcommand, parser) in PARSERS:\n        parser = parser(\n            parents=[subparsers],\n            formatter_class=argparse.ArgumentDefaultsHelpFormatter\n        )\n        parser.add_argument('--%s' % subcommand, default=None, required=False)\n        parser.add_argument('--%s-args' % subcommand, default=None)\n\n    for argument in unparsed_arguments:\n        parser = parser.add_argument(\n            '--%s-args' % argument.replace('-', '_'), default=None)\n        parser.add_argument('--%s-kwargs' % argument.replace('-', '_'), default=None)\n\n    return dict((subcommand, parser.parse_args(*unparsed_arguments))\n                for subcommand, parser in PARSERS)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/arguments.py", "project": "witten/borgmatic", "name": "parse_subparser_arguments", "docstring": "Given a sequence of arguments and a dict from subparser name to argparse.ArgumentParser\ninstance, give each requested action's subparser a shot at parsing all arguments. This allows\ncommon arguments like \"--repository\" to be shared across multiple subparsers.\n\nReturn the result as a tuple of (a dict mapping from subparser name to a parsed namespace of\narguments, a list of remaining arguments not claimed by any subparser).", "ques_id": "62b438a266fea644fe22cc2d", "code": ["def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    not_parsed_arguments = []\n    for subparser in subparsers.values():\n        try:\n            parsed_arguments = subparser.parse_args(unparsed_arguments)\n        except SystemExit:\n            raise\n        except Exception as exc:\n            not_parsed_arguments.append(subparser.name)\n            raise exc\n\n        if parsed_arguments is not None:\n            return (parsed_arguments, not_parsed_arguments)\n        else:\n            not_parsed_arguments.clear()\n    raise SystemExit(\n        \"Unable to parse arguments from arguments provided by subparsers: {}\"\n       .format(not_parsed_arguments)\n    )\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    unparsed_args = []\n    for subparser in subparsers:\n        parser = subparser.add_subparsers(dest=subparser.dest, help=subparser.help)\n        parsed_arguments[subparser.name] = parser\n        unparsed_args.extend(subparser.parse_args(unparsed_arguments))\n    return parsed_arguments, unparsed_args\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    unparsed_arguments.update(parsed_arguments)\n    remaining_arguments = []\n    unparsed_arguments.pop(\"--\", None)\n    for name, parser in subparsers.items():\n        parser_name = parser.name\n        parsed_arguments[name] = parser.parse_args(unparsed_arguments[name])\n        remaining_arguments.append(parsed_arguments[name])\n        if parser.description is not None:\n            parsed_arguments[name].description = parser.description\n        if parser.epilog is not None:\n            parsed_arguments[name].epilog = parser.epilog\n        if parser.formatter_class is not None:\n            parsed_arguments[name].formatter_class = parser.formatter_class\n        if parser.error_handler is not None:\n            parsed_arguments[name].error_handler = parser.error_handler\n        if parser.version is not None:\n            parsed_arguments[name].version = parse", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    unparsed_arguments = set(unparsed_arguments)\n\n    for namespace_parser in subparsers.values():\n        for name in unparsed_arguments:\n            arguments[name] = namespace_parser.parse_args(unparsed_arguments.pop(name))\n        if not unparsed_arguments:\n            break\n\n        remaining_arguments.append(namespace_parser)\n\n    for namespace_parser in remaining_arguments:\n        namespace_parser.parse_args(unparsed_arguments)\n\n    return arguments, remaining_arguments\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for arg in unparsed_arguments:\n        parser_name = \"--{}\".format(arg)\n        parser = subparsers[parser_name].add_argument_group(\n            description=arg,\n        )\n        arguments[arg] = parser.parse_args(unparsed_arguments[arg])\n        remaining_arguments.append(arguments[arg])\n        parser.set_defaults(**arguments[arg])\n    return (arguments, remaining_arguments)\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for subparser in subparsers._actions:\n        args = unparsed_arguments.pop(0)\n        if args:\n            subparser_name = \"--%s\" % subparser._dest\n            parser = subparsers._actions[subparser_name]\n            arguments[subparser_name] = parser.parse_args(args)\n            remaining_arguments.extend(unparsed_arguments)\n            unparsed_arguments.clear()\n        else:\n            unparsed_arguments.append(subparser)\n\n    return arguments, remaining_arguments\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for subparser_name, subparser in subparsers.items():\n        if subparser_name not in unparsed_arguments:\n            continue\n        args = unparsed_arguments[subparser_name]\n        args = subparser.parse_args(args)\n        parsed_arguments[subparser_name] = args\n        remaining_arguments.extend(args.args)\n    return parsed_arguments, remaining_arguments\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n\n    for arg in unparsed_arguments:\n        parser = subparsers.add_parser(arg.name, help=arg.help)\n        parser.set_defaults(func=partial(arg.func, arguments, remaining_arguments))\n        arguments[arg.name] = parser\n        remaining_arguments.append(arg)\n\n    return (arguments, remaining_arguments)\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    not_claimed_arguments = []\n    for name, parser in subparsers.items():\n        if name not in unparsed_arguments:\n            continue\n        parser_arguments = parser.parse_args(unparsed_arguments[name])\n        parsed_arguments.update(parser_arguments)\n        not_claimed_arguments.append(name)\n    return parsed_arguments, not_claimed_arguments\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    unparsed_arguments = list(unparsed_arguments)\n\n    while unparsed_arguments:\n        parser_name = unparsed_arguments.pop(0)\n        if parser_name in subparsers:\n            parser = subparsers[parser_name]\n            parsed_arguments = parser.parse_args(unparsed_arguments)\n            remaining_arguments.append(parsed_arguments)\n        else:\n            parsed_arguments = {}\n            for subparser_name in subparsers:\n                if subparser_name == parser_name:\n                    continue\n                parser = subparsers[subparser_name]\n                parsed_arguments = parser.parse_args(unparsed_arguments)\n                remaining_arguments.append(parsed_arguments)\n            unparsed_arguments = remaining_arguments\n  "], "level": "file_runnable", "generate_results": [{"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    not_parsed_arguments = []\n    for subparser in subparsers.values():\n        try:\n            parsed_arguments = subparser.parse_args(unparsed_arguments)\n        except SystemExit:\n            raise\n        except Exception as exc:\n            not_parsed_arguments.append(subparser.name)\n            raise exc\n\n        if parsed_arguments is not None:\n            return (parsed_arguments, not_parsed_arguments)\n        else:\n            not_parsed_arguments.clear()\n    raise SystemExit(\n        \"Unable to parse arguments from arguments provided by subparsers: {}\"\n       .format(not_parsed_arguments)\n    )\n", "is_pass": false, "return_code": 2}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    unparsed_args = []\n    for subparser in subparsers:\n        parser = subparser.add_subparsers(dest=subparser.dest, help=subparser.help)\n        parsed_arguments[subparser.name] = parser\n        unparsed_args.extend(subparser.parse_args(unparsed_arguments))\n    return parsed_arguments, unparsed_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    unparsed_arguments.update(parsed_arguments)\n    remaining_arguments = []\n    unparsed_arguments.pop(\"--\", None)\n    for name, parser in subparsers.items():\n        parser_name = parser.name\n        parsed_arguments[name] = parser.parse_args(unparsed_arguments[name])\n        remaining_arguments.append(parsed_arguments[name])\n        if parser.description is not None:\n            parsed_arguments[name].description = parser.description\n        if parser.epilog is not None:\n            parsed_arguments[name].epilog = parser.epilog\n        if parser.formatter_class is not None:\n            parsed_arguments[name].formatter_class = parser.formatter_class\n        if parser.error_handler is not None:\n            parsed_arguments[name].error_handler = parser.error_handler\n        if parser.version is not None:\n            parsed_arguments[name].version = parse", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    unparsed_arguments = set(unparsed_arguments)\n\n    for namespace_parser in subparsers.values():\n        for name in unparsed_arguments:\n            arguments[name] = namespace_parser.parse_args(unparsed_arguments.pop(name))\n        if not unparsed_arguments:\n            break\n\n        remaining_arguments.append(namespace_parser)\n\n    for namespace_parser in remaining_arguments:\n        namespace_parser.parse_args(unparsed_arguments)\n\n    return arguments, remaining_arguments\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for arg in unparsed_arguments:\n        parser_name = \"--{}\".format(arg)\n        parser = subparsers[parser_name].add_argument_group(\n            description=arg,\n        )\n        arguments[arg] = parser.parse_args(unparsed_arguments[arg])\n        remaining_arguments.append(arguments[arg])\n        parser.set_defaults(**arguments[arg])\n    return (arguments, remaining_arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for subparser in subparsers._actions:\n        args = unparsed_arguments.pop(0)\n        if args:\n            subparser_name = \"--%s\" % subparser._dest\n            parser = subparsers._actions[subparser_name]\n            arguments[subparser_name] = parser.parse_args(args)\n            remaining_arguments.extend(unparsed_arguments)\n            unparsed_arguments.clear()\n        else:\n            unparsed_arguments.append(subparser)\n\n    return arguments, remaining_arguments\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for subparser_name, subparser in subparsers.items():\n        if subparser_name not in unparsed_arguments:\n            continue\n        args = unparsed_arguments[subparser_name]\n        args = subparser.parse_args(args)\n        parsed_arguments[subparser_name] = args\n        remaining_arguments.extend(args.args)\n    return parsed_arguments, remaining_arguments\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n\n    for arg in unparsed_arguments:\n        parser = subparsers.add_parser(arg.name, help=arg.help)\n        parser.set_defaults(func=partial(arg.func, arguments, remaining_arguments))\n        arguments[arg.name] = parser\n        remaining_arguments.append(arg)\n\n    return (arguments, remaining_arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    not_claimed_arguments = []\n    for name, parser in subparsers.items():\n        if name not in unparsed_arguments:\n            continue\n        parser_arguments = parser.parse_args(unparsed_arguments[name])\n        parsed_arguments.update(parser_arguments)\n        not_claimed_arguments.append(name)\n    return parsed_arguments, not_claimed_arguments\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    unparsed_arguments = list(unparsed_arguments)\n\n    while unparsed_arguments:\n        parser_name = unparsed_arguments.pop(0)\n        if parser_name in subparsers:\n            parser = subparsers[parser_name]\n            parsed_arguments = parser.parse_args(unparsed_arguments)\n            remaining_arguments.append(parsed_arguments)\n        else:\n            parsed_arguments = {}\n            for subparser_name in subparsers:\n                if subparser_name == parser_name:\n                    continue\n                parser = subparsers[subparser_name]\n                parsed_arguments = parser.parse_args(unparsed_arguments)\n                remaining_arguments.append(parsed_arguments)\n            unparsed_arguments = remaining_arguments\n  ", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/arguments.py", "project": "witten/borgmatic", "name": "make_parsers", "docstring": "Build a top-level parser and its subparsers and return them as a tuple.", "ques_id": "62b438a266fea644fe22cc2c", "code": ["def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Test command line tool for generating test files.')\n    subparsers = parser.add_subparsers(dest='subcommand')\n\n    test_gen_parser = subparsers.add_parser(\n        'test-gen',\n        help='Generate test files for the given project.')\n    test_gen_parser.add_argument(\n        '--output-dir',\n        type=str,\n        default='./',\n        help='Directory to output generated files.')\n    test_gen_parser.add_argument(\n        '--source-dir',\n        type=str,\n        default='./',\n        help='Directory to load test source files.')\n    test_gen_parser.add_argument(\n        '--version',\n        action='store_true',\n        help='Print the version number and exit.')\n    test_gen_parser.set_defaults(func=gen_files)\n\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='A command line tool to parse and understand the '\n                    'GitHub API documentation.')\n\n    subparsers = parser.add_subparsers(dest='command')\n\n    parser_help = (\n        'A command line tool to parse and understand the '\n        'GitHub API documentation.'\n    )\n\n    subparser = subparsers.add_parser(\n        'help',\n        help=parser_help,\n        description='A command line tool to display the '\n                    'documentation of a command.'\n    )\n    subparser.add_argument(\n        'command',\n        metavar='COMMAND',\n        nargs='?',\n        help='The command to be documented.'\n    )\n\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Convert a CSV to YAML from a given JSON file.')\n    subparsers = parser.add_subparsers(dest='subcommand')\n\n    convert_to_yaml.add_parser(\n        subparsers, help='Convert a CSV to YAML from a given JSON file.')\n\n    split_args = parser.add_mutually_exclusive_group(required=False)\n    split_args.add_argument(\n        '-o', '--output', type=str, help='Output directory.',\n        required=False, default='.')\n    split_args.add_argument(\n        '-s', '--split', type=str, help='Split files by comma.',\n        required=False, default='')\n\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"Simple test to verify that the CLI works properly\")\n    subparsers = parser.add_subparsers(dest=\"command\")\n    add_data(parser, subparsers)\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser(description='Generate a new Test List.')\n    subparsers = parser.add_subparsers()\n    add_test_files(subparsers)\n    return (parser, subparsers)\n", "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers()\n\n    upload_parser = subparsers.add_parser(\n        'upload', description='Upload a new document to an existing '\n       'repository.')\n    upload_parser.add_argument(\n        '--repository', type=str, help='Repository to upload to.',\n        default='.', required=False)\n    upload_parser.add_argument(\n        '--schema', type=str, help='The schema file to use.', default=None,\n        required=False)\n\n    download_parser = subparsers.add_parser(\n        'download', description='Download a new document from an '\n        'existing repository.')\n    download_parser.add_argument(\n        '--repository', type=str, help='Repository to download from.',\n        default='.', required=False)\n    download_parser.add_argument(\n        '--schema', type=str, help='The schema file to use.', default=None,\n ", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"Test that subcommands can be called with argparse \"\n        \"options.\")\n    subparsers = parser.add_subparsers(dest=\"subcommand\")\n\n    for i in range(2):\n        subparser = subparsers.add_parser(\"subcommand-{}\".format(i))\n        subparser.add_argument(\"--arg1\", type=int)\n        subparser.add_argument(\"--arg2\", type=int)\n\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='command')\n\n    build_parser = subparsers.add_parser(\n        'build',\n        help='Build a single package'\n    )\n    build_parser.add_argument(\n        'package',\n        help='Package name to build'\n    )\n    build_parser.set_defaults(\n        func=build\n    )\n\n    clean_parser = subparsers.add_parser(\n        'clean',\n        help='Clean up the package'\n    )\n    clean_parser.add_argument(\n        'package',\n        help='Package name to clean'\n    )\n    clean_parser.set_defaults(\n        func=clean\n    )\n\n    install_parser = subparsers.add_parser(\n        'install',\n        help='Install a package'\n    )\n    install_parser.add_argument(\n        'package',\n        help='Package name to install'\n    )\n    install", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Commands related to a given project.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    subparsers = parser.add_subparsers(dest='subcommand')\n    subparsers.required = True\n    build_commands = subparsers.add_parser(\n        'build', help='Build the given project.'\n    )\n    build_commands.add_argument(\n        '--all', action='store_true', help='Build all packages.'\n    )\n    build_commands.add_argument(\n        '--skip-existing', action='store_true', help='Skip previous builds.'\n    )\n    build_commands.add_argument(\n        '--no-output', action='store_true', help='Do not print output to stdout.'\n    )\n    build_commands.set_defaults(func=build)\n    install_commands = subparsers.add_parser(\n        'install', help='Install the given project.'\n    )\n    install_commands.add_argument(\n        '--all', action=", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Program that parses JSON files from a given URL')\n    parser.add_argument('url', help='URL of the JSON file to parse')\n    subparsers = parser.add_subparsers(dest='subcommand')\n\n    parse = subparsers.add_parser('parse')\n    parse.add_argument('--json', dest='jsonfile', required=True,\n                        help='Name of the JSON file to parse')\n    parse.set_defaults(func=parse)\n\n    return parser, subparsers\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Test command line tool for generating test files.')\n    subparsers = parser.add_subparsers(dest='subcommand')\n\n    test_gen_parser = subparsers.add_parser(\n        'test-gen',\n        help='Generate test files for the given project.')\n    test_gen_parser.add_argument(\n        '--output-dir',\n        type=str,\n        default='./',\n        help='Directory to output generated files.')\n    test_gen_parser.add_argument(\n        '--source-dir',\n        type=str,\n        default='./',\n        help='Directory to load test source files.')\n    test_gen_parser.add_argument(\n        '--version',\n        action='store_true',\n        help='Print the version number and exit.')\n    test_gen_parser.set_defaults(func=gen_files)\n\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='A command line tool to parse and understand the '\n                    'GitHub API documentation.')\n\n    subparsers = parser.add_subparsers(dest='command')\n\n    parser_help = (\n        'A command line tool to parse and understand the '\n        'GitHub API documentation.'\n    )\n\n    subparser = subparsers.add_parser(\n        'help',\n        help=parser_help,\n        description='A command line tool to display the '\n                    'documentation of a command.'\n    )\n    subparser.add_argument(\n        'command',\n        metavar='COMMAND',\n        nargs='?',\n        help='The command to be documented.'\n    )\n\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Convert a CSV to YAML from a given JSON file.')\n    subparsers = parser.add_subparsers(dest='subcommand')\n\n    convert_to_yaml.add_parser(\n        subparsers, help='Convert a CSV to YAML from a given JSON file.')\n\n    split_args = parser.add_mutually_exclusive_group(required=False)\n    split_args.add_argument(\n        '-o', '--output', type=str, help='Output directory.',\n        required=False, default='.')\n    split_args.add_argument(\n        '-s', '--split', type=str, help='Split files by comma.',\n        required=False, default='')\n\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"Simple test to verify that the CLI works properly\")\n    subparsers = parser.add_subparsers(dest=\"command\")\n    add_data(parser, subparsers)\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(description='Generate a new Test List.')\n    subparsers = parser.add_subparsers()\n    add_test_files(subparsers)\n    return (parser, subparsers)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers()\n\n    upload_parser = subparsers.add_parser(\n        'upload', description='Upload a new document to an existing '\n       'repository.')\n    upload_parser.add_argument(\n        '--repository', type=str, help='Repository to upload to.',\n        default='.', required=False)\n    upload_parser.add_argument(\n        '--schema', type=str, help='The schema file to use.', default=None,\n        required=False)\n\n    download_parser = subparsers.add_parser(\n        'download', description='Download a new document from an '\n        'existing repository.')\n    download_parser.add_argument(\n        '--repository', type=str, help='Repository to download from.',\n        default='.', required=False)\n    download_parser.add_argument(\n        '--schema', type=str, help='The schema file to use.', default=None,\n ", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"Test that subcommands can be called with argparse \"\n        \"options.\")\n    subparsers = parser.add_subparsers(dest=\"subcommand\")\n\n    for i in range(2):\n        subparser = subparsers.add_parser(\"subcommand-{}\".format(i))\n        subparser.add_argument(\"--arg1\", type=int)\n        subparser.add_argument(\"--arg2\", type=int)\n\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='command')\n\n    build_parser = subparsers.add_parser(\n        'build',\n        help='Build a single package'\n    )\n    build_parser.add_argument(\n        'package',\n        help='Package name to build'\n    )\n    build_parser.set_defaults(\n        func=build\n    )\n\n    clean_parser = subparsers.add_parser(\n        'clean',\n        help='Clean up the package'\n    )\n    clean_parser.add_argument(\n        'package',\n        help='Package name to clean'\n    )\n    clean_parser.set_defaults(\n        func=clean\n    )\n\n    install_parser = subparsers.add_parser(\n        'install',\n        help='Install a package'\n    )\n    install_parser.add_argument(\n        'package',\n        help='Package name to install'\n    )\n    install", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Commands related to a given project.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    subparsers = parser.add_subparsers(dest='subcommand')\n    subparsers.required = True\n    build_commands = subparsers.add_parser(\n        'build', help='Build the given project.'\n    )\n    build_commands.add_argument(\n        '--all', action='store_true', help='Build all packages.'\n    )\n    build_commands.add_argument(\n        '--skip-existing', action='store_true', help='Skip previous builds.'\n    )\n    build_commands.add_argument(\n        '--no-output', action='store_true', help='Do not print output to stdout.'\n    )\n    build_commands.set_defaults(func=build)\n    install_commands = subparsers.add_parser(\n        'install', help='Install the given project.'\n    )\n    install_commands.add_argument(\n        '--all', action=", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Program that parses JSON files from a given URL')\n    parser.add_argument('url', help='URL of the JSON file to parse')\n    subparsers = parser.add_subparsers(dest='subcommand')\n\n    parse = subparsers.add_parser('parse')\n    parse.add_argument('--json', dest='jsonfile', required=True,\n                        help='Name of the JSON file to parse')\n    parse.set_defaults(func=parse)\n\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_10.py", "name": "paging", "docstring": "Returns WAPI response page by page\n\nArgs:\n    response (list): WAPI response.\n    max_results (int): Maximum number of objects to be returned in one page.\nReturns:\n    Generator object with WAPI response split page by page.", "ques_id": "62ece4982e6aefcf4aabbd5f", "code": ["def paging(response, max_results):\n\n    for item in response:\n        if len(item) > max_results:\n            yield item[:max_results]\n        else:\n            yield item\n", "def paging(response, max_results):\n    offset = 0\n    while offset < max_results:\n        for item in response:\n            yield item\n\n        offset += max_results\n", "def paging(response, max_results):\n    if response is None:\n        return\n\n    for item in response:\n        if item.get('meta', {}).get('total_count', 0) < max_results:\n            yield item\n", "def paging(response, max_results):\n\n    for item in response:\n        if len(item['results']) >= max_results:\n            yield item['results']\n            del item['results']\n            break\n        else:\n            yield item\n", "def paging(response, max_results):\n    return (response[i:i + max_results] for i in range(0, len(response), max_results))\n", "def paging(response, max_results):\n    return (response_page['value'] for response_page in utils.get_paging(response, max_results))\n", "def paging(response, max_results):\n\n    for i in range(0, len(response), max_results):\n        yield response[i:i + max_results]\n", "def paging(response, max_results):\n    for i in range(0, len(response), max_results):\n        yield response[i:i + max_results]\n", "def paging(response, max_results):\n    page = 1\n    while True:\n        for item in response['items']:\n            yield item\n        if page > max_results:\n            break\n        page += 1\n", "def paging(response, max_results):\n    if not response:\n        raise ValueError('Response is empty')\n\n    for result in response:\n        if len(result) >= max_results:\n            yield result\n\n            result = []\n\n        for page in range(1, min(int(math.ceil(len(result) / float(max_results))), max_results) + 1):\n            result.extend(result[page * max_results: (page + 1) * max_results])\n\n            if len(result) >= max_results:\n                yield result\n"], "level": "self_contained", "generate_results": [{"generate_code": "def paging(response, max_results):\n\n    for item in response:\n        if len(item) > max_results:\n            yield item[:max_results]\n        else:\n            yield item\n", "is_pass": false, "return_code": 1}, {"generate_code": "def paging(response, max_results):\n    offset = 0\n    while offset < max_results:\n        for item in response:\n            yield item\n\n        offset += max_results\n", "is_pass": false, "return_code": 1}, {"generate_code": "def paging(response, max_results):\n    if response is None:\n        return\n\n    for item in response:\n        if item.get('meta', {}).get('total_count', 0) < max_results:\n            yield item\n", "is_pass": false, "return_code": 1}, {"generate_code": "def paging(response, max_results):\n\n    for item in response:\n        if len(item['results']) >= max_results:\n            yield item['results']\n            del item['results']\n            break\n        else:\n            yield item\n", "is_pass": false, "return_code": 1}, {"generate_code": "def paging(response, max_results):\n    return (response[i:i + max_results] for i in range(0, len(response), max_results))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def paging(response, max_results):\n    return (response_page['value'] for response_page in utils.get_paging(response, max_results))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def paging(response, max_results):\n\n    for i in range(0, len(response), max_results):\n        yield response[i:i + max_results]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def paging(response, max_results):\n    for i in range(0, len(response), max_results):\n        yield response[i:i + max_results]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def paging(response, max_results):\n    page = 1\n    while True:\n        for item in response['items']:\n            yield item\n        if page > max_results:\n            break\n        page += 1\n", "is_pass": false, "return_code": 1}, {"generate_code": "def paging(response, max_results):\n    if not response:\n        raise ValueError('Response is empty')\n\n    for result in response:\n        if len(result) >= max_results:\n            yield result\n\n            result = []\n\n        for page in range(1, min(int(math.ceil(len(result) / float(max_results))), max_results) + 1):\n            result.extend(result[page * max_results: (page + 1) * max_results])\n\n            if len(result) >= max_results:\n                yield result\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_20.py", "name": "size_to_bytes", "docstring": "Convert human readable file size to bytes.\n\nResulting value is an approximation as input value is in most case rounded.\n\nArgs:\n    size: A string representing a human readable file size (eg: '500K')\n\nReturns:\n    A decimal representation of file size\n\n    Examples::\n\n        >>> size_to_bytes(\"500\")\n        500\n        >>> size_to_bytes(\"1K\")\n        1000", "ques_id": "62ece4982e6aefcf4aabbd60", "code": ["def size_to_bytes(size: str) -> int:\n    for x in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if size.endswith(x):\n            num = int(size.rstrip(x))\n            return num * (1024 ** x)\n    raise ValueError('Unknown file size \"{}\".'.format(size))\n", "def size_to_bytes(size: str) -> int:\n    for x in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if size.endswith(x):\n            num = int(size.rstrip(x))\n            return num * (1024 ** 2)\n    else:\n        raise ValueError('Unsupported file size {}'.format(size))\n", "def size_to_bytes(size: str) -> int:\n    match = re.match(r'^(\\d+)([KMGTPEZY]?)B?$', size)\n    if not match:\n        raise ValueError(\"Invalid file size format: %s\" % size)\n\n    num, unit = match.groups()\n    num = int(num)\n    if unit == \"B\":\n        return num * _BYTES_PER_BYTE\n    elif unit == \"K\":\n        return num * _BYTES_PER_KILOBYTE\n    elif unit == \"M\":\n        return num * _BYTES_PER_MEGABYTE\n    elif unit == \"G\":\n        return num * _BYTES_PER_GIGABYTE\n    elif unit == \"T\":\n        return num * _BYTES_PER_TERABYTE\n    else:\n        raise ValueError(\"Invalid file size format: %s\" % size)\n", "def size_to_bytes(size: str) -> int:\n    for x in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if size.endswith(x):\n            return int(float(size.rstrip(x)))\n\n    raise ValueError('Unknown file format')\n", "def size_to_bytes(size: str) -> int:\n    if size is None:\n        return None\n    size_map = {\n        'B': 1,\n        'KB': 1024 ** 3,\n        'MB': 1024 ** 2,\n        'GB': 1024 ** 1,\n        'TB': 1024\n    }\n    if size.endswith('B'):\n        return int(size[:-1])\n    elif size.endswith('KB'):\n        return int(size[:-3]) * size_map['KB']\n    elif size.endswith('MB'):\n        return int(size[:-4]) * size_map['MB']\n    elif size.endswith('GB'):\n        return int(size[:-4]) * size_map['GB']\n    elif size.endswith('TB'):\n        return int(size[:-4]) * size_map['TB']\n    else:\n        raise ValueError('Unknown file size format \"{}\"'.format(size))\n", "def size_to_bytes(size: str) -> int:\n    convert = {\n        'M': 1,\n        'G': 2,\n        'T': 3,\n        'P': 4,\n        'E': 5,\n        'Z': 6,\n        'Y': 7,\n    }\n    for key, value in convert.items():\n        if size.endswith(key):\n            size = size[:-len(key)]\n            return int(float(size) * value)\n    raise ValueError('Unknown file format {}'.format(size))\n", "def size_to_bytes(size: str) -> int:\n    for x in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if size.endswith(x):\n            return int(size.rstrip(x))\n    raise ValueError('Unknown file format: %s' % size)\n", "def size_to_bytes(size: str) -> int:\n    if not size:\n        return 0\n\n    size = size.replace('B', '')\n    try:\n        return int(size)\n    except ValueError:\n        pass\n\n    size = size.replace('kiB', '')\n    size = size.replace('M', '')\n    size = size.replace('G', '')\n    size = size.replace('T', '')\n\n    if 'T' in size:\n        size = int(size[:-1]) * 1000\n    elif 'G' in size:\n        size = int(size[:-1]) * 1000000\n    elif 'M' in size:\n        size = int(size[:-1]) * 1000000000\n\n    return size\n", "def size_to_bytes(size: str) -> int:\n    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n        if size.endswith(x):\n            size = size[:-len(x)]\n            return int(float(size))\n    raise ValueError('Unknown file format')\n", "def size_to_bytes(size: str) -> int:\n    for unit in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n        if size.endswith(unit):\n            size = size.replace(unit, '')\n            return int(float(size))\n    raise ValueError('Could not convert size {} to bytes'.format(size))\n"], "level": "self_contained", "generate_results": [{"generate_code": "def size_to_bytes(size: str) -> int:\n    for x in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if size.endswith(x):\n            num = int(size.rstrip(x))\n            return num * (1024 ** x)\n    raise ValueError('Unknown file size \"{}\".'.format(size))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    for x in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if size.endswith(x):\n            num = int(size.rstrip(x))\n            return num * (1024 ** 2)\n    else:\n        raise ValueError('Unsupported file size {}'.format(size))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    match = re.match(r'^(\\d+)([KMGTPEZY]?)B?$', size)\n    if not match:\n        raise ValueError(\"Invalid file size format: %s\" % size)\n\n    num, unit = match.groups()\n    num = int(num)\n    if unit == \"B\":\n        return num * _BYTES_PER_BYTE\n    elif unit == \"K\":\n        return num * _BYTES_PER_KILOBYTE\n    elif unit == \"M\":\n        return num * _BYTES_PER_MEGABYTE\n    elif unit == \"G\":\n        return num * _BYTES_PER_GIGABYTE\n    elif unit == \"T\":\n        return num * _BYTES_PER_TERABYTE\n    else:\n        raise ValueError(\"Invalid file size format: %s\" % size)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    for x in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if size.endswith(x):\n            return int(float(size.rstrip(x)))\n\n    raise ValueError('Unknown file format')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    if size is None:\n        return None\n    size_map = {\n        'B': 1,\n        'KB': 1024 ** 3,\n        'MB': 1024 ** 2,\n        'GB': 1024 ** 1,\n        'TB': 1024\n    }\n    if size.endswith('B'):\n        return int(size[:-1])\n    elif size.endswith('KB'):\n        return int(size[:-3]) * size_map['KB']\n    elif size.endswith('MB'):\n        return int(size[:-4]) * size_map['MB']\n    elif size.endswith('GB'):\n        return int(size[:-4]) * size_map['GB']\n    elif size.endswith('TB'):\n        return int(size[:-4]) * size_map['TB']\n    else:\n        raise ValueError('Unknown file size format \"{}\"'.format(size))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    convert = {\n        'M': 1,\n        'G': 2,\n        'T': 3,\n        'P': 4,\n        'E': 5,\n        'Z': 6,\n        'Y': 7,\n    }\n    for key, value in convert.items():\n        if size.endswith(key):\n            size = size[:-len(key)]\n            return int(float(size) * value)\n    raise ValueError('Unknown file format {}'.format(size))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    for x in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if size.endswith(x):\n            return int(size.rstrip(x))\n    raise ValueError('Unknown file format: %s' % size)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    if not size:\n        return 0\n\n    size = size.replace('B', '')\n    try:\n        return int(size)\n    except ValueError:\n        pass\n\n    size = size.replace('kiB', '')\n    size = size.replace('M', '')\n    size = size.replace('G', '')\n    size = size.replace('T', '')\n\n    if 'T' in size:\n        size = int(size[:-1]) * 1000\n    elif 'G' in size:\n        size = int(size[:-1]) * 1000000\n    elif 'M' in size:\n        size = int(size[:-1]) * 1000000000\n\n    return size\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n        if size.endswith(x):\n            size = size[:-len(x)]\n            return int(float(size))\n    raise ValueError('Unknown file format')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    for unit in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n        if size.endswith(unit):\n            size = size.replace(unit, '')\n            return int(float(size))\n    raise ValueError('Could not convert size {} to bytes'.format(size))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_14.py", "name": "_dictsum", "docstring": "Combine values of the dictionaries supplied by iterable dicts.\n\n>>> _dictsum([{'a': 1, 'b': 2}, {'a': 5, 'b': 0}])\n{'a': 6, 'b': 2}", "ques_id": "62ece4982e6aefcf4aabbd61", "code": ["def _dictsum(dicts):\n    result = copy.deepcopy(dicts[0])\n    for d in dicts[1:]:\n        for key in d:\n            result[key] += d[key]\n    return result\n", "def _dictsum(dicts):\n    keys = list(dicts.keys())\n    values = list(dicts.values())\n    total = sum(values, [])\n    result = {}\n    for key in keys:\n        result[key] = total[0]\n        total = total[1:]\n    for key in keys:\n        result[key] += sum(values, [])\n    return result\n", "def _dictsum(dicts):\n\n    new_dict = {}\n    for key, value in dicts.items():\n        new_dict[key] = value + new_dict.get(key, 0)\n    return new_dict\n", "def _dictsum(dicts):\n    result = {}\n    for k, v in dicts.items():\n        result[k] = result.get(k, 0) + v\n    return result\n", "def _dictsum(dicts):\n\n    dic = dicts[0]\n    for i in dicts[1:]:\n        dic = dict_add(dic, i)\n    return dic\n", "def _dictsum(dicts):\n    result = {}\n    for key in dicts:\n        value = dicts[key]\n        if value not in result:\n            result[value] = 0\n        result[value] += 1\n    return result\n", "def _dictsum(dicts):\n    result = copy.deepcopy(dicts[0])\n    for dict in dicts[1:]:\n        for key in dict:\n            result[key] += dict[key]\n    return result\n", "def _dictsum(dicts):\n    return {key: dicts[key] for key in dicts if key in dicts}\n", "def _dictsum(dicts):\n    if not dicts:\n        return {}\n    keys = dicts[0].keys()\n    total = {}\n    for d in dicts:\n        for k in keys:\n            if k in d:\n                total[k] = total.get(k, 0) + d[k]\n    return total\n", "def _dictsum(dicts):\n    result = {}\n    for key in dicts:\n        value = dicts[key]\n        if value not in result:\n            result[value] = 0\n        result[value] += 1\n    return result\n"], "level": "self_contained", "generate_results": [{"generate_code": "def _dictsum(dicts):\n    result = copy.deepcopy(dicts[0])\n    for d in dicts[1:]:\n        for key in d:\n            result[key] += d[key]\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    keys = list(dicts.keys())\n    values = list(dicts.values())\n    total = sum(values, [])\n    result = {}\n    for key in keys:\n        result[key] = total[0]\n        total = total[1:]\n    for key in keys:\n        result[key] += sum(values, [])\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n\n    new_dict = {}\n    for key, value in dicts.items():\n        new_dict[key] = value + new_dict.get(key, 0)\n    return new_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    result = {}\n    for k, v in dicts.items():\n        result[k] = result.get(k, 0) + v\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n\n    dic = dicts[0]\n    for i in dicts[1:]:\n        dic = dict_add(dic, i)\n    return dic\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    result = {}\n    for key in dicts:\n        value = dicts[key]\n        if value not in result:\n            result[value] = 0\n        result[value] += 1\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    result = copy.deepcopy(dicts[0])\n    for dict in dicts[1:]:\n        for key in dict:\n            result[key] += dict[key]\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    return {key: dicts[key] for key in dicts if key in dicts}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    if not dicts:\n        return {}\n    keys = dicts[0].keys()\n    total = {}\n    for d in dicts:\n        for k in keys:\n            if k in d:\n                total[k] = total.get(k, 0) + d[k]\n    return total\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _dictsum(dicts):\n    result = {}\n    for key in dicts:\n        value = dicts[key]\n        if value not in result:\n            result[value] = 0\n        result[value] += 1\n    return result\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_15.py", "name": "_replace_url_args", "docstring": "Replace any custom string URL items with values in args", "ques_id": "62ece4982e6aefcf4aabbd62", "code": ["def _replace_url_args(url, url_args):\n    if url_args:\n        for k, v in url_args.items():\n            url = url.replace('{{{0}}}'.format(k), v)\n    return url\n", "def _replace_url_args(url, url_args):\n    if url_args:\n        for k, v in url_args.items():\n            url = url.replace('{{' + k + '}}', v)\n    return url\n", "def _replace_url_args(url, url_args):\n    for k, v in url_args.items():\n        url = re.sub('{{{}}}'.format(k), str(v), url)\n    return url\n", "def _replace_url_args(url, url_args):\n    for k, v in url_args.items():\n        url = url.replace('{{{}}}'.format(k), v)\n    return url\n", "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        if value:\n            url = url.replace('{{' + key + '}}', value)\n    return url\n", "def _replace_url_args(url, url_args):\n    for k, v in url_args.items():\n        if v:\n            url = url.replace('{{{}}}'.format(k), str(v))\n    return url\n", "def _replace_url_args(url, url_args):\n    if url_args:\n        for k, v in url_args.items():\n            url = url.replace('{{{}}}'.format(k), v)\n    return url\n", "def _replace_url_args(url, url_args):\n    for k, v in url_args.items():\n        if v is not None:\n            url = url.replace('{{' + k + '}}', v)\n\n    return url\n", "def _replace_url_args(url, url_args):\n    for k, v in url_args.items():\n        if v:\n            url = url.replace('{{{}}}'.format(k), v)\n    return url\n", "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        if value:\n            url = url.replace('{{{}}}'.format(key), value)\n    return url\n"], "level": "self_contained", "generate_results": [{"generate_code": "def _replace_url_args(url, url_args):\n    if url_args:\n        for k, v in url_args.items():\n            url = url.replace('{{{0}}}'.format(k), v)\n    return url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    if url_args:\n        for k, v in url_args.items():\n            url = url.replace('{{' + k + '}}', v)\n    return url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    for k, v in url_args.items():\n        url = re.sub('{{{}}}'.format(k), str(v), url)\n    return url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    for k, v in url_args.items():\n        url = url.replace('{{{}}}'.format(k), v)\n    return url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        if value:\n            url = url.replace('{{' + key + '}}', value)\n    return url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    for k, v in url_args.items():\n        if v:\n            url = url.replace('{{{}}}'.format(k), str(v))\n    return url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    if url_args:\n        for k, v in url_args.items():\n            url = url.replace('{{{}}}'.format(k), v)\n    return url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    for k, v in url_args.items():\n        if v is not None:\n            url = url.replace('{{' + k + '}}', v)\n\n    return url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    for k, v in url_args.items():\n        if v:\n            url = url.replace('{{{}}}'.format(k), v)\n    return url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        if value:\n            url = url.replace('{{{}}}'.format(key), value)\n    return url\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_5.py", "name": "is_none_string", "docstring": "Check if a string represents a None value.", "ques_id": "62ece4982e6aefcf4aabbd63", "code": ["def is_none_string(val: any) -> bool:\n    if not isinstance(val, str):\n        return False\n    return val.lower() == 'none'\n", "def is_none_string(val: any) -> bool:\n    return is_string(val) and val.lower() == 'none'\n", "def is_none_string(val: any) -> bool:\n    return isinstance(val, str) and val.lower() == 'none'\n", "def is_none_string(val: any) -> bool:\n    return type(val) is str and val.lower() == 'none'\n", "def is_none_string(val: any) -> bool:\n    if not is_string(val):\n        return False\n    return val.lower() == 'none'\n", "def is_none_string(val: any) -> bool:\n    return isinstance(val, str) and val.lower() == 'none'\n", "def is_none_string(val: any) -> bool:\n    return (isinstance(val, str) and val.lower() == 'none')\n", "def is_none_string(val: any) -> bool:\n    return isinstance(val, str) and val.lower() == 'none'\n", "def is_none_string(val: any) -> bool:\n    return isinstance(val, str) and val.lower() == 'none'\n", "def is_none_string(val: any) -> bool:\n    return is_string(val) and val.lower() == 'none'\n"], "level": "self_contained", "generate_results": [{"generate_code": "def is_none_string(val: any) -> bool:\n    if not isinstance(val, str):\n        return False\n    return val.lower() == 'none'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_none_string(val: any) -> bool:\n    return is_string(val) and val.lower() == 'none'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_none_string(val: any) -> bool:\n    return isinstance(val, str) and val.lower() == 'none'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_none_string(val: any) -> bool:\n    return type(val) is str and val.lower() == 'none'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_none_string(val: any) -> bool:\n    if not is_string(val):\n        return False\n    return val.lower() == 'none'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_none_string(val: any) -> bool:\n    return isinstance(val, str) and val.lower() == 'none'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_none_string(val: any) -> bool:\n    return (isinstance(val, str) and val.lower() == 'none')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_none_string(val: any) -> bool:\n    return isinstance(val, str) and val.lower() == 'none'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_none_string(val: any) -> bool:\n    return isinstance(val, str) and val.lower() == 'none'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_none_string(val: any) -> bool:\n    return is_string(val) and val.lower() == 'none'\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_1.py", "name": "strip_root", "docstring": "Remove root from path, throw exception on failure.", "ques_id": "62ece4982e6aefcf4aabbd64", "code": ["def strip_root(path, root):\n    if not root:\n        return path\n\n    return path.replace(root, '')\n", "def strip_root(path, root):\n    if not root:\n        raise Exception(\"You must provide a root for stripping\")\n    if path == root:\n        return path\n    elif path.startswith(root + os.sep):\n        return path[len(root) + 1:]\n    else:\n        return path\n", "def strip_root(path, root):\n    if not root:\n        return path\n\n    return path[len(root):]\n", "def strip_root(path, root):\n    if not root:\n        raise Exception('A root must be specified for the path')\n\n    if path == root:\n        raise Exception('A path must not have the same root as the path')\n\n    return path[len(root):]\n", "def strip_root(path, root):\n    try:\n        return path[len(root):]\n    except IndexError:\n        raise Exception(\"Invalid path\")\n", "def strip_root(path, root):\n    if path.startswith(root):\n        return path[len(root):]\n    else:\n        raise Exception('Not in root')\n", "def strip_root(path, root):\n    if not root:\n        return path\n    else:\n        return path[len(root):]\n", "def strip_root(path, root):\n\n    if not root:\n        return path\n\n    if path == root:\n        raise NoRootError(\"Path cannot be the root of a tree\")\n\n    return path[len(root):]\n", "def strip_root(path, root):\n    if not root:\n        return path\n\n    if path == root:\n        raise Exception(\"Cannot strip root from %s\" % path)\n\n    return path[len(root):]\n", "def strip_root(path, root):\n    if not root:\n        raise Exception('Invalid path')\n    elif path == root:\n        return path\n    elif path == root.strip('/'):\n        return ''\n    else:\n        return path.rsplit('/', 1)[0]\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def strip_root(path, root):\n    if not root:\n        return path\n\n    return path.replace(root, '')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if not root:\n        raise Exception(\"You must provide a root for stripping\")\n    if path == root:\n        return path\n    elif path.startswith(root + os.sep):\n        return path[len(root) + 1:]\n    else:\n        return path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if not root:\n        return path\n\n    return path[len(root):]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if not root:\n        raise Exception('A root must be specified for the path')\n\n    if path == root:\n        raise Exception('A path must not have the same root as the path')\n\n    return path[len(root):]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    try:\n        return path[len(root):]\n    except IndexError:\n        raise Exception(\"Invalid path\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if path.startswith(root):\n        return path[len(root):]\n    else:\n        raise Exception('Not in root')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if not root:\n        return path\n    else:\n        return path[len(root):]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n\n    if not root:\n        return path\n\n    if path == root:\n        raise NoRootError(\"Path cannot be the root of a tree\")\n\n    return path[len(root):]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if not root:\n        return path\n\n    if path == root:\n        raise Exception(\"Cannot strip root from %s\" % path)\n\n    return path[len(root):]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if not root:\n        raise Exception('Invalid path')\n    elif path == root:\n        return path\n    elif path == root.strip('/'):\n        return ''\n    else:\n        return path.rsplit('/', 1)[0]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_8.py", "name": "parser_flags", "docstring": "Given an argparse.ArgumentParser instance, return its argument flags in a space-separated\nstring.", "ques_id": "62ece4982e6aefcf4aabbd65", "code": ["def parser_flags(parser):\n    flags = ''\n    for flag in parser._actions:\n        if flag.nargs == 0:\n            flags +=''\n        flags += flag.dest +''\n    return flags\n", "def parser_flags(parser):\n    flags = []\n    for arg in parser._actions:\n        if arg.dest is None:\n            flags.append('-' + arg.action.__name__)\n        else:\n            flags.append('-' + arg.action.__name__ + '=' + arg.dest)\n    return''.join(flags)\n", "def parser_flags(parser):\n    flags = []\n    for flag in parser._actions:\n        if isinstance(flag, argparse._StoreTrueAction):\n            flags.append('--{}'.format(flag.dest))\n        elif isinstance(flag, argparse._StoreFalseAction):\n            flags.append('-{}'.format(flag.dest))\n        else:\n            flags.append(flag.default)\n    return''.join(flags)\n", "def parser_flags(parser):\n    flags = []\n    for flag in parser._actions:\n        if flag.nargs == 0:\n            flags.append('-')\n        else:\n            flags.append('--')\n            flags.append(flag.dest)\n    return''.join(flags)\n", "def parser_flags(parser):\n    flags = []\n    for flag in parser._actions:\n        if flag.dest is None:\n            continue\n        flags.append('{} {}'.format(flag.nargs, flag.dest))\n    return''.join(flags)\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.dest is None:\n            continue\n        if arg.default is not None and arg.default is not False:\n            flags +=''\n        if arg.default is True:\n            flags += '--%s' % arg.dest\n        else:\n            flags +='-%s' % arg.dest\n\n    return flags\n", "def parser_flags(parser):\n    return''.join([flag.replace('-', '_') for flag in parser.flags])\n", "def parser_flags(parser):\n    flags = []\n    for flag in parser._actions:\n        if flag.nargs == argparse.REMAINDER:\n            flags.extend(flag.choices)\n        else:\n            flags.append(flag.default)\n    return''.join(flags)\n", "def parser_flags(parser):\n    return''.join(flag.replace('-', '_') for flag in parser.flags)\n", "def parser_flags(parser):\n    flags = []\n    for arg in parser._actions:\n        if arg.dest is None:\n            continue\n        if arg.default is not None and arg.default is not False:\n            flags.append('{}={}'.format(arg.dest, arg.default))\n        else:\n            flags.append('{}'.format(arg.dest))\n    return''.join(flags)\n"], "level": "self_contained", "generate_results": [{"generate_code": "def parser_flags(parser):\n    flags = ''\n    for flag in parser._actions:\n        if flag.nargs == 0:\n            flags +=''\n        flags += flag.dest +''\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = []\n    for arg in parser._actions:\n        if arg.dest is None:\n            flags.append('-' + arg.action.__name__)\n        else:\n            flags.append('-' + arg.action.__name__ + '=' + arg.dest)\n    return''.join(flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = []\n    for flag in parser._actions:\n        if isinstance(flag, argparse._StoreTrueAction):\n            flags.append('--{}'.format(flag.dest))\n        elif isinstance(flag, argparse._StoreFalseAction):\n            flags.append('-{}'.format(flag.dest))\n        else:\n            flags.append(flag.default)\n    return''.join(flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = []\n    for flag in parser._actions:\n        if flag.nargs == 0:\n            flags.append('-')\n        else:\n            flags.append('--')\n            flags.append(flag.dest)\n    return''.join(flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = []\n    for flag in parser._actions:\n        if flag.dest is None:\n            continue\n        flags.append('{} {}'.format(flag.nargs, flag.dest))\n    return''.join(flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.dest is None:\n            continue\n        if arg.default is not None and arg.default is not False:\n            flags +=''\n        if arg.default is True:\n            flags += '--%s' % arg.dest\n        else:\n            flags +='-%s' % arg.dest\n\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join([flag.replace('-', '_') for flag in parser.flags])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = []\n    for flag in parser._actions:\n        if flag.nargs == argparse.REMAINDER:\n            flags.extend(flag.choices)\n        else:\n            flags.append(flag.default)\n    return''.join(flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(flag.replace('-', '_') for flag in parser.flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = []\n    for arg in parser._actions:\n        if arg.dest is None:\n            continue\n        if arg.default is not None and arg.default is not False:\n            flags.append('{}={}'.format(arg.dest, arg.default))\n        else:\n            flags.append('{}'.format(arg.dest))\n    return''.join(flags)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_19.py", "name": "was_processed", "docstring": "Check if a file or directory has already been processed.\n\nTo prevent recursion, expand the path name to an absolution path\ncall this function with a set that will store all the entries and\nthe entry to test. If the entry is already in the set, report the issue\nand return ``True``. Otherwise, add the entry to the set and return\n``False`` to allow the path to be processed.\n\nArgs:\n    processed: Set to store processed pathnames\n    path_name: Path to a directory or file\n    verbose: True if verbose output is requested\n\nReturns:\n    True if it's already in the set. False if not.", "ques_id": "62ece4982e6aefcf4aabbd66", "code": ["def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"ERROR: '%s' already processed. It will be overwritten.\" % path_name)\n        return False\n    else:\n        processed.add(path_name)\n        if verbose:\n            print(\"Adding %s to processed set.\" % path_name)\n        if os.path.isdir(path_name):\n            if verbose:\n                print(\"Adding directory to processed set.\")\n            for entry in os.listdir(path_name):\n                was_processed(processed, os.path.join(path_name, entry), verbose)\n        elif os.path.isfile(path_name):\n            if verbose:\n                print(\"Adding file to processed set.\")\n            if os.path.islink(path_name):\n                if verbose:\n                    print(\"Linking file to processed set.\")\n    ", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print('{0} already processed {1}'.format(path_name, processed))\n        return True\n\n    processed.add(path_name)\n    if os.path.isdir(path_name):\n        if verbose:\n            print('{0} already processed {1}'.format(path_name, processed))\n        return True\n\n    if verbose:\n        print('Adding {0} to processed set'.format(path_name))\n\n    if os.path.isfile(path_name):\n        if verbose:\n            print('{0} already processed {1}'.format(path_name, processed))\n        return False\n\n    processed.add(os.path.join(path_name, os.path.basename(path_name)))\n    if verbose:\n        print('Adding {0} to processed set'.format(os.path.join(path_name, os.path.basename(path_name))))\n\n    if os.path.isdir(path_name):\n        if verbose:\n            print('{0} already", "def was_processed(processed, path_name, verbose):\n    if processed.get(path_name):\n        if verbose:\n            print(\"Skipping due to recursion.\")\n        return False\n    processed[path_name] = True\n    if verbose:\n        print(\"Processing:\", path_name)\n    if os.path.isdir(path_name):\n        for entry in os.listdir(path_name):\n            was_processed(processed, os.path.join(path_name, entry), verbose)\n    elif os.path.isfile(path_name):\n        if verbose:\n            print(\"Skipping entry:\", path_name)\n        return False\n    return True\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"{} already processed. Returning False\".format(path_name))\n        return False\n    if os.path.isdir(path_name):\n        if verbose:\n            print(\"{} already processed. Returning False\".format(path_name))\n        return False\n    processed.add(path_name)\n    if verbose:\n        print(\"Adding {} to processed\".format(path_name))\n    return True\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        return True\n    else:\n        processed.add(path_name)\n        if verbose:\n            print(f\"Adding {path_name} to processed set\")\n        return False\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"WARNING: It seems that the file \"\n                  \"'{}' already exists and is being processed.\".format(\n                      path_name))\n        return True\n    processed.add(path_name)\n    if verbose:\n        print(\"Adding {} to the set.\".format(path_name))\n    if os.path.isdir(path_name):\n        if verbose:\n            print(\"WARNING: It seems that the directory \"\n                  \"'{}' already exists and is being processed.\".format(\n                      path_name))\n        return False\n    if verbose:\n        print(\"Adding {} to the set.\".format(path_name))\n    processed.add(os.path.join(path_name, os.path.basename(path_name)))\n    if verbose:\n        print(\"Returning True if it's already in the set.\")\n    return True", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"Skipping {0} because it already exists\".format(path_name))\n        return True\n    if os.path.isdir(path_name):\n        if verbose:\n            print(\"Skipping {0} because it is a directory\".format(path_name))\n        return True\n    if os.path.isfile(path_name):\n        if verbose:\n            print(\"Skipping {0} because it already exists\".format(path_name))\n        return True\n    processed.add(path_name)\n    if verbose:\n        print(\"Adding {0} to the set\".format(path_name))\n    return False\n", "def was_processed(processed, path_name, verbose):\n    # Get the path to the entry\n    entry = get_entry_path(path_name, verbose)\n\n    # If the entry isn't in the set, add it\n    if entry not in processed:\n        processed.add(entry)\n        if verbose:\n            print(\"Adding\", entry)\n\n        # Try to expand the path name to an abssolution path call so that\n        # the absolute paths return the same values for every entry\n        expanded_path_name = os.path.expanduser(entry)\n\n        # Try to add the entry to the set\n        if expanded_path_name not in processed:\n            processed.add(expanded_path_name)\n            if verbose:\n                print(\"Adding\", expanded_path_name)\n\n    return True\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"The file '{}' already in the set.\".format(path_name))\n        return False\n    else:\n        processed.add(path_name)\n        if verbose:\n            print(\"Adding the file '{}' to the set.\".format(path_name))\n        return True\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"File already processed: %s\" % path_name)\n        return True\n    processed.add(path_name)\n    if verbose:\n        print(\"Adding file: %s\" % path_name)\n    try:\n        if os.path.isdir(path_name):\n            for entry in os.listdir(path_name):\n                was_processed(processed, os.path.join(path_name, entry), verbose)\n        else:\n            if os.path.isfile(path_name):\n                processed.add(path_name)\n    except OSError:\n        print(\"Error occured when processing file: %s\" % path_name)\n        if verbose:\n            print(\"Error message: %s\" % sys.exc_info()[1])\n    return False\n"], "level": "self_contained", "generate_results": [{"generate_code": "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"ERROR: '%s' already processed. It will be overwritten.\" % path_name)\n        return False\n    else:\n        processed.add(path_name)\n        if verbose:\n            print(\"Adding %s to processed set.\" % path_name)\n        if os.path.isdir(path_name):\n            if verbose:\n                print(\"Adding directory to processed set.\")\n            for entry in os.listdir(path_name):\n                was_processed(processed, os.path.join(path_name, entry), verbose)\n        elif os.path.isfile(path_name):\n            if verbose:\n                print(\"Adding file to processed set.\")\n            if os.path.islink(path_name):\n                if verbose:\n                    print(\"Linking file to processed set.\")\n    ", "is_pass": false, "return_code": 1}, {"generate_code": "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print('{0} already processed {1}'.format(path_name, processed))\n        return True\n\n    processed.add(path_name)\n    if os.path.isdir(path_name):\n        if verbose:\n            print('{0} already processed {1}'.format(path_name, processed))\n        return True\n\n    if verbose:\n        print('Adding {0} to processed set'.format(path_name))\n\n    if os.path.isfile(path_name):\n        if verbose:\n            print('{0} already processed {1}'.format(path_name, processed))\n        return False\n\n    processed.add(os.path.join(path_name, os.path.basename(path_name)))\n    if verbose:\n        print('Adding {0} to processed set'.format(os.path.join(path_name, os.path.basename(path_name))))\n\n    if os.path.isdir(path_name):\n        if verbose:\n            print('{0} already", "is_pass": false, "return_code": 1}, {"generate_code": "def was_processed(processed, path_name, verbose):\n    if processed.get(path_name):\n        if verbose:\n            print(\"Skipping due to recursion.\")\n        return False\n    processed[path_name] = True\n    if verbose:\n        print(\"Processing:\", path_name)\n    if os.path.isdir(path_name):\n        for entry in os.listdir(path_name):\n            was_processed(processed, os.path.join(path_name, entry), verbose)\n    elif os.path.isfile(path_name):\n        if verbose:\n            print(\"Skipping entry:\", path_name)\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"{} already processed. Returning False\".format(path_name))\n        return False\n    if os.path.isdir(path_name):\n        if verbose:\n            print(\"{} already processed. Returning False\".format(path_name))\n        return False\n    processed.add(path_name)\n    if verbose:\n        print(\"Adding {} to processed\".format(path_name))\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        return True\n    else:\n        processed.add(path_name)\n        if verbose:\n            print(f\"Adding {path_name} to processed set\")\n        return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"WARNING: It seems that the file \"\n                  \"'{}' already exists and is being processed.\".format(\n                      path_name))\n        return True\n    processed.add(path_name)\n    if verbose:\n        print(\"Adding {} to the set.\".format(path_name))\n    if os.path.isdir(path_name):\n        if verbose:\n            print(\"WARNING: It seems that the directory \"\n                  \"'{}' already exists and is being processed.\".format(\n                      path_name))\n        return False\n    if verbose:\n        print(\"Adding {} to the set.\".format(path_name))\n    processed.add(os.path.join(path_name, os.path.basename(path_name)))\n    if verbose:\n        print(\"Returning True if it's already in the set.\")\n    return True", "is_pass": false, "return_code": 1}, {"generate_code": "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"Skipping {0} because it already exists\".format(path_name))\n        return True\n    if os.path.isdir(path_name):\n        if verbose:\n            print(\"Skipping {0} because it is a directory\".format(path_name))\n        return True\n    if os.path.isfile(path_name):\n        if verbose:\n            print(\"Skipping {0} because it already exists\".format(path_name))\n        return True\n    processed.add(path_name)\n    if verbose:\n        print(\"Adding {0} to the set\".format(path_name))\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def was_processed(processed, path_name, verbose):\n    # Get the path to the entry\n    entry = get_entry_path(path_name, verbose)\n\n    # If the entry isn't in the set, add it\n    if entry not in processed:\n        processed.add(entry)\n        if verbose:\n            print(\"Adding\", entry)\n\n        # Try to expand the path name to an abssolution path call so that\n        # the absolute paths return the same values for every entry\n        expanded_path_name = os.path.expanduser(entry)\n\n        # Try to add the entry to the set\n        if expanded_path_name not in processed:\n            processed.add(expanded_path_name)\n            if verbose:\n                print(\"Adding\", expanded_path_name)\n\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"The file '{}' already in the set.\".format(path_name))\n        return False\n    else:\n        processed.add(path_name)\n        if verbose:\n            print(\"Adding the file '{}' to the set.\".format(path_name))\n        return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"File already processed: %s\" % path_name)\n        return True\n    processed.add(path_name)\n    if verbose:\n        print(\"Adding file: %s\" % path_name)\n    try:\n        if os.path.isdir(path_name):\n            for entry in os.listdir(path_name):\n                was_processed(processed, os.path.join(path_name, entry), verbose)\n        else:\n            if os.path.isfile(path_name):\n                processed.add(path_name)\n    except OSError:\n        print(\"Error occured when processing file: %s\" % path_name)\n        if verbose:\n            print(\"Error message: %s\" % sys.exc_info()[1])\n    return False\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_9.py", "name": "vertex3tuple", "docstring": "return 3 points for each vertex of the polygon. This will include the vertex and the 2 points on both sides of the vertex::\n\npolygon with vertices ABCD\nWill return\nDAB, ABC, BCD, CDA -> returns 3tuples\n#A    B    C    D  -> of vertices", "ques_id": "62ece4982e6aefcf4aabbd67", "code": ["def vertex3tuple(vertices):\n    vertices = np.asarray(vertices)\n    if vertices.ndim == 1:\n        vertices = vertices.reshape((-1, 2))\n\n    if vertices.shape[1]!= 2:\n        raise ValueError('vertices must be a single tuple of length 2')\n\n    # Get the points on the triangle\n    triangle_vertices = triangle(vertices)\n    triangle_vertices = np.concatenate((vertices[:, 0], triangle_vertices), axis=1)\n    triangle_points = np.concatenate((vertices[:, 1], triangle_vertices), axis=1)\n\n    # Get the points outside the triangle\n    outside_vertices = np.inf\n    for i, vertex in enumerate(triangle_vertices):\n        if vertex[0] > vertices[i, 0] or vertex[1] > vertices[i, 1]:\n            outside_vertices = i\n    vertices = np.delete(vertices, outside_vertices, 1)\n\n    return vertices\n", "def vertex3tuple(vertices):\n    vertices = np.array(vertices)\n    if vertices.ndim == 1:\n        vertices = vertices.T\n    vertices = vertices.tolist()\n    vertices.sort()\n    tuple_vertices = []\n    for i, vertex in enumerate(vertices):\n        if i == 0:\n            tuple_vertices.append(vertex)\n        elif i == len(vertices)-1:\n            tuple_vertices.append(vertex[::-1])\n        else:\n            tuple_vertices.append((vertex[0], vertex[1], vertex[2]))\n    return tuple_vertices\n", "def vertex3tuple(vertices):\n\n    vertices = np.array(vertices)\n\n    if vertices.ndim!= 2:\n        raise ValueError('vertices must be a 2D array')\n\n    if vertices.shape[1]!= 3:\n        raise ValueError('vertices must be a 3-dimensional array')\n\n    if vertices.dtype!= np.int:\n        raise TypeError('vertices must be a 1-dimensional array')\n\n    if vertices.max() > vertices.min():\n        raise ValueError('vertices must be in a strict range')\n\n    if vertices.shape[0] < 3:\n        raise ValueError('vertices must be in a strict range')\n\n    if vertices.shape[1] == 2:\n        vertices = np.array([vertices, vertices])\n\n    return list(zip(vertices[:, 0], vertices[:, 1], vertices[:, 2]))\n", "def vertex3tuple(vertices):\n    vertices = np.array(vertices)\n    if vertices.shape[0] < 3:\n        return [vertices]\n    vertices[:, 0] -= vertices[:, 2]\n    vertices[:, 1] -= vertices[:, 0]\n    vertices[:, 2] = vertices[:, 0] + vertices[:, 1]\n    return vertices.tolist()\n", "def vertex3tuple(vertices):\n    return list(vertex2tuple(vertices))\n", "def vertex3tuple(vertices):\n    vertices = np.array(vertices)\n    vertices = vertices[:, [1, 0]]\n    vertices[:, 0] = vertices[:, 0] - vertices[:, 2]\n    vertices = vertices[np.isfinite(vertices)]\n    return vertices\n", "def vertex3tuple(vertices):\n    return [vertices[0], vertices[1], vertices[2]]\n", "def vertex3tuple(vertices):\n    return list(zip(vertices[0::3], vertices[1::3], vertices[2::3]))\n", "def vertex3tuple(vertices):\n\n    if len(vertices) < 3:\n        return [vertices]\n\n    vertices = list(vertices)\n    vertices.sort()\n\n    outside = vertices[0]\n    for i in range(1, len(vertices)):\n        if vertices[i] > outside:\n            outside = vertices[i]\n\n    inside = vertices[-1]\n    for i in range(len(vertices) - 2, -1, -1):\n        if vertices[i] < inside:\n            inside = vertices[i]\n\n    return [(vertices[i], vertices[i + 1], vertices[i + 2]) for i in range(3)]\n", "def vertex3tuple(vertices):\n    vertices = np.array(vertices)\n    vertices = np.insert(vertices, 0, [0, 0, 0])\n    vertices = np.insert(vertices, 0, [0, 0, 0])\n    vertices = np.insert(vertices, 0, vertices[:, 0])\n    vertices = np.insert(vertices, 0, vertices[:, 1])\n    vertices = np.insert(vertices, 0, vertices[:, 2])\n    return vertices\n"], "level": "self_contained", "generate_results": [{"generate_code": "def vertex3tuple(vertices):\n    vertices = np.asarray(vertices)\n    if vertices.ndim == 1:\n        vertices = vertices.reshape((-1, 2))\n\n    if vertices.shape[1]!= 2:\n        raise ValueError('vertices must be a single tuple of length 2')\n\n    # Get the points on the triangle\n    triangle_vertices = triangle(vertices)\n    triangle_vertices = np.concatenate((vertices[:, 0], triangle_vertices), axis=1)\n    triangle_points = np.concatenate((vertices[:, 1], triangle_vertices), axis=1)\n\n    # Get the points outside the triangle\n    outside_vertices = np.inf\n    for i, vertex in enumerate(triangle_vertices):\n        if vertex[0] > vertices[i, 0] or vertex[1] > vertices[i, 1]:\n            outside_vertices = i\n    vertices = np.delete(vertices, outside_vertices, 1)\n\n    return vertices\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n    vertices = np.array(vertices)\n    if vertices.ndim == 1:\n        vertices = vertices.T\n    vertices = vertices.tolist()\n    vertices.sort()\n    tuple_vertices = []\n    for i, vertex in enumerate(vertices):\n        if i == 0:\n            tuple_vertices.append(vertex)\n        elif i == len(vertices)-1:\n            tuple_vertices.append(vertex[::-1])\n        else:\n            tuple_vertices.append((vertex[0], vertex[1], vertex[2]))\n    return tuple_vertices\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n\n    vertices = np.array(vertices)\n\n    if vertices.ndim!= 2:\n        raise ValueError('vertices must be a 2D array')\n\n    if vertices.shape[1]!= 3:\n        raise ValueError('vertices must be a 3-dimensional array')\n\n    if vertices.dtype!= np.int:\n        raise TypeError('vertices must be a 1-dimensional array')\n\n    if vertices.max() > vertices.min():\n        raise ValueError('vertices must be in a strict range')\n\n    if vertices.shape[0] < 3:\n        raise ValueError('vertices must be in a strict range')\n\n    if vertices.shape[1] == 2:\n        vertices = np.array([vertices, vertices])\n\n    return list(zip(vertices[:, 0], vertices[:, 1], vertices[:, 2]))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n    vertices = np.array(vertices)\n    if vertices.shape[0] < 3:\n        return [vertices]\n    vertices[:, 0] -= vertices[:, 2]\n    vertices[:, 1] -= vertices[:, 0]\n    vertices[:, 2] = vertices[:, 0] + vertices[:, 1]\n    return vertices.tolist()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n    return list(vertex2tuple(vertices))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n    vertices = np.array(vertices)\n    vertices = vertices[:, [1, 0]]\n    vertices[:, 0] = vertices[:, 0] - vertices[:, 2]\n    vertices = vertices[np.isfinite(vertices)]\n    return vertices\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n    return [vertices[0], vertices[1], vertices[2]]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n    return list(zip(vertices[0::3], vertices[1::3], vertices[2::3]))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n\n    if len(vertices) < 3:\n        return [vertices]\n\n    vertices = list(vertices)\n    vertices.sort()\n\n    outside = vertices[0]\n    for i in range(1, len(vertices)):\n        if vertices[i] > outside:\n            outside = vertices[i]\n\n    inside = vertices[-1]\n    for i in range(len(vertices) - 2, -1, -1):\n        if vertices[i] < inside:\n            inside = vertices[i]\n\n    return [(vertices[i], vertices[i + 1], vertices[i + 2]) for i in range(3)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n    vertices = np.array(vertices)\n    vertices = np.insert(vertices, 0, [0, 0, 0])\n    vertices = np.insert(vertices, 0, [0, 0, 0])\n    vertices = np.insert(vertices, 0, vertices[:, 0])\n    vertices = np.insert(vertices, 0, vertices[:, 1])\n    vertices = np.insert(vertices, 0, vertices[:, 2])\n    return vertices\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_6.py", "name": "int_to_string", "docstring": "Convert a number to a string, using the given alphabet.\n\nThe output has the most significant digit first.", "ques_id": "62ece4982e6aefcf4aabbd68", "code": ["def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    padding = padding or 0\n    result = []\n    while number > 0:\n        number, mod = divmod(number, len(alphabet))\n        result.append(alphabet[mod])\n    result.reverse()\n    result.extend(['0' * padding] * (len(result) - len(result) % padding))\n    return ''.join(result)\n", "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    pad_len = len(str(padding))\n    padded = \"{:0\" + str(pad_len) + \"}\"\n    result = padded.format(number).upper()\n    if padding is not None:\n        result = result[-padding - 1 :]\n    return result\n", "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    str_number = ''.join([alphabet[number % len(alphabet)]] * (padding or len(alphabet) - 1))\n    return str_number\n", "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    if number == 0:\n        return \"0\"\n\n    padded_number = number_to_string(number, alphabet, padding)\n    return alphabet[(padded_number - 1) % len(alphabet)] + padded_number\n", "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    padding = padding or 0\n    result = ''\n    while number > 0:\n        result = alphabet[number % len(alphabet)] + result\n        number //= len(alphabet)\n    return '0' * padding + result\n", "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    if padding is None:\n        padding = 0\n    number_string = str(number)\n    padding_string = \"0\" * (padding + 1)\n    if len(number_string) % 2:\n        number_string = f\"0{padding_string}{number_string}\"\n    if padding > 0:\n        number_string = f\"{number_string}{padding_string}\"\n    return number_string\n", "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    string = \"\"\n    while number!= 0:\n        number, mod = divmod(number, len(alphabet))\n        string = alphabet[mod] + string\n    if padding is not None:\n        for i in range(padding):\n            string += \"0\"\n    return string\n", "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    str_number = str(number)\n    if padding is not None:\n        str_number = str_number[-padding:]\n    for i, letter in enumerate(alphabet):\n        str_number = str_number.replace(letter, alphabet[i])\n    return str_number\n", "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    if padding is None:\n        padding = 0\n\n    base = len(alphabet)\n    output = []\n    while number > 0:\n        output.append(alphabet[number % base])\n        number //= base\n\n    if padding > 0:\n        output.extend(['0'] * (padding - len(output)))\n\n    return ''.join(reversed(output))\n", "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    if number == 0:\n        return \"0\"\n    if padding is None:\n        padding = len(alphabet) - len(alphabet.index(\"0\"))\n    result = []\n    while number!= 0:\n        result.append(alphabet[number % len(alphabet)])\n        number //= len(alphabet)\n    result.reverse()\n    return \"\".join(result)[-padding:]\n"], "level": "self_contained", "generate_results": [{"generate_code": "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    padding = padding or 0\n    result = []\n    while number > 0:\n        number, mod = divmod(number, len(alphabet))\n        result.append(alphabet[mod])\n    result.reverse()\n    result.extend(['0' * padding] * (len(result) - len(result) % padding))\n    return ''.join(result)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    pad_len = len(str(padding))\n    padded = \"{:0\" + str(pad_len) + \"}\"\n    result = padded.format(number).upper()\n    if padding is not None:\n        result = result[-padding - 1 :]\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    str_number = ''.join([alphabet[number % len(alphabet)]] * (padding or len(alphabet) - 1))\n    return str_number\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    if number == 0:\n        return \"0\"\n\n    padded_number = number_to_string(number, alphabet, padding)\n    return alphabet[(padded_number - 1) % len(alphabet)] + padded_number\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    padding = padding or 0\n    result = ''\n    while number > 0:\n        result = alphabet[number % len(alphabet)] + result\n        number //= len(alphabet)\n    return '0' * padding + result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    if padding is None:\n        padding = 0\n    number_string = str(number)\n    padding_string = \"0\" * (padding + 1)\n    if len(number_string) % 2:\n        number_string = f\"0{padding_string}{number_string}\"\n    if padding > 0:\n        number_string = f\"{number_string}{padding_string}\"\n    return number_string\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    string = \"\"\n    while number!= 0:\n        number, mod = divmod(number, len(alphabet))\n        string = alphabet[mod] + string\n    if padding is not None:\n        for i in range(padding):\n            string += \"0\"\n    return string\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    str_number = str(number)\n    if padding is not None:\n        str_number = str_number[-padding:]\n    for i, letter in enumerate(alphabet):\n        str_number = str_number.replace(letter, alphabet[i])\n    return str_number\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    if padding is None:\n        padding = 0\n\n    base = len(alphabet)\n    output = []\n    while number > 0:\n        output.append(alphabet[number % base])\n        number //= base\n\n    if padding > 0:\n        output.extend(['0'] * (padding - len(output)))\n\n    return ''.join(reversed(output))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: List[str], padding: Optional[int] = None) -> str:\n    if number == 0:\n        return \"0\"\n    if padding is None:\n        padding = len(alphabet) - len(alphabet.index(\"0\"))\n    result = []\n    while number!= 0:\n        result.append(alphabet[number % len(alphabet)])\n        number //= len(alphabet)\n    result.reverse()\n    return \"\".join(result)[-padding:]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_12.py", "name": "_replace_register", "docstring": "Replace value from flows to given register number\n\n'register_value' key in dictionary will be replaced by register number\ngiven by 'register_number'\n\n:param flow_params: Dictionary containing defined flows\n:param register_number: The number of register where value will be stored\n:param register_value: Key to be replaced by register number", "ques_id": "62ece4982e6aefcf4aabbd69", "code": ["def _replace_register(flow_params, register_number, register_value):\n    del flow_params[register_number]\n    flow_params[register_value] = None\n", "def _replace_register(flow_params, register_number, register_value):\n    del flow_params[register_number]\n    flow_params[register_value] = None\n", "def _replace_register(flow_params, register_number, register_value):\n    if register_value in flow_params:\n        flow_params[register_number] = flow_params[register_value]\n        del flow_params[register_value]\n", "def _replace_register(flow_params, register_number, register_value):\n    del flow_params[register_number]\n    flow_params[register_value] = None\n", "def _replace_register(flow_params, register_number, register_value):\n    if register_value in flow_params:\n        flow_params[register_value] = flow_params[register_number]\n        del flow_params[register_number]\n", "def _replace_register(flow_params, register_number, register_value):\n    flow_params[register_number] = flow_params[register_value]\n    del flow_params[register_value]\n", "def _replace_register(flow_params, register_number, register_value):\n\n    del flow_params[register_number]\n    flow_params[register_value] = None\n", "def _replace_register(flow_params, register_number, register_value):\n    flow_params[register_number] = flow_params[register_value]\n    del flow_params[register_value]\n", "def _replace_register(flow_params, register_number, register_value):\n    del flow_params[register_number]\n    flow_params[register_value] = None\n", "def _replace_register(flow_params, register_number, register_value):\n    if register_value in flow_params:\n        flow_params[register_value] = flow_params[register_number]\n        del flow_params[register_number]\n    else:\n        raise KeyError(\n            \"register {} is not present in the flow parameters\".format(register_number)\n        )\n"], "level": "self_contained", "generate_results": [{"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    del flow_params[register_number]\n    flow_params[register_value] = None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    del flow_params[register_number]\n    flow_params[register_value] = None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    if register_value in flow_params:\n        flow_params[register_number] = flow_params[register_value]\n        del flow_params[register_value]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    del flow_params[register_number]\n    flow_params[register_value] = None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    if register_value in flow_params:\n        flow_params[register_value] = flow_params[register_number]\n        del flow_params[register_number]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    flow_params[register_number] = flow_params[register_value]\n    del flow_params[register_value]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n\n    del flow_params[register_number]\n    flow_params[register_value] = None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    flow_params[register_number] = flow_params[register_value]\n    del flow_params[register_value]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    del flow_params[register_number]\n    flow_params[register_value] = None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    if register_value in flow_params:\n        flow_params[register_value] = flow_params[register_number]\n        del flow_params[register_number]\n    else:\n        raise KeyError(\n            \"register {} is not present in the flow parameters\".format(register_number)\n        )\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_2.py", "name": "replace_dots", "docstring": "Replaces all values of '.' to arg from the given string", "ques_id": "62ece4982e6aefcf4aabbd6a", "code": ["def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n"], "level": "self_contained", "generate_results": [{"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "self_contained/test_3.py", "name": "subclasses", "docstring": "Return all subclasses of a class, recursively", "ques_id": "62ece4982e6aefcf4aabbd6b", "code": ["def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield from subclasses(subclass)\n    yield cls\n", "def subclasses(cls):\n    for subcls in cls.__subclasses__():\n        yield subcls\n        yield from subclasses(subcls)\n", "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__() for g in subclasses(s)]\n", "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield subclass\n        yield from subclasses(subclass)\n", "def subclasses(cls):\n    for subcls in cls.__subclasses__():\n        yield subcls\n        yield from subclasses(subcls)\n", "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield from subclasses(subclass)\n    yield cls\n", "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield subclass\n        yield from subclasses(subclass)\n", "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield from subclasses(subclass)\n    yield cls\n", "def subclasses(cls):\n    for subcls in cls.__subclasses__():\n        yield subcls\n        yield from subclasses(subcls)\n", "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield from subclasses(subclass)\n    yield cls\n"], "level": "self_contained", "generate_results": [{"generate_code": "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield from subclasses(subclass)\n    yield cls\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    for subcls in cls.__subclasses__():\n        yield subcls\n        yield from subclasses(subcls)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__() for g in subclasses(s)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield subclass\n        yield from subclasses(subclass)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    for subcls in cls.__subclasses__():\n        yield subcls\n        yield from subclasses(subcls)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield from subclasses(subclass)\n    yield cls\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield subclass\n        yield from subclasses(subclass)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield from subclasses(subclass)\n    yield cls\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    for subcls in cls.__subclasses__():\n        yield subcls\n        yield from subclasses(subcls)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield from subclasses(subclass)\n    yield cls\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_7.py", "name": "string_to_int", "docstring": "Convert a string to a number, using the given alphabet.\n\nThe input is assumed to have the most significant digit first.", "ques_id": "62ece4982e6aefcf4aabbd6d", "code": ["def string_to_int(string: str, alphabet: List[str]) -> int:\n    result = 0\n    for i in range(len(string)):\n        result += alphabet.index(string[i]) * (26 ** i)\n    return result\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    int_value = 0\n    for letter in string:\n        int_value *= len(alphabet)\n        int_value += alphabet.index(letter)\n    return int_value\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    number = 0\n    for letter in string:\n        number *= len(alphabet)\n        number += alphabet.index(letter)\n    return number\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    if len(string) == 0:\n        raise ValueError(\"Can't convert empty string.\")\n    if len(string) == 1:\n        return alphabet[0][string[0]]\n\n    result = 0\n    for i in range(len(string)):\n        result += alphabet[ord(string[i]) - ord('a')][i]\n    return result\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    num = 0\n    for letter in string:\n        if letter in alphabet:\n            num += 1\n    return num\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    if len(string) == 0:\n        return -1\n    result = 0\n    for letter in string:\n        result = result * len(alphabet) + alphabet.index(letter)\n    return result\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    return sum([ALPHABET_TO_INT[letter] for letter in string])\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    if not alphabet:\n        return -1\n    if len(alphabet) == 1 and not string:\n        return 0\n    if len(alphabet) == 2 and not string[0] and not string[1]:\n        return 0\n    if len(alphabet) == 3 and not string[0] and string[1]:\n        return 1\n    result = 0\n    for i in range(len(string)):\n        result += alphabet.index(string[i]) * (len(alphabet) - i - 1)\n    return result\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    result = 0\n    for i in range(len(string)):\n        result += alphabet.index(string[i]) * (len(alphabet) ** (len(string) - i - 1))\n    return result\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    return sum([ALPHABET_TO_INT[letter] for letter in string]) * len(alphabet)\n"], "level": "self_contained", "generate_results": [{"generate_code": "def string_to_int(string: str, alphabet: List[str]) -> int:\n    result = 0\n    for i in range(len(string)):\n        result += alphabet.index(string[i]) * (26 ** i)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def string_to_int(string: str, alphabet: List[str]) -> int:\n    int_value = 0\n    for letter in string:\n        int_value *= len(alphabet)\n        int_value += alphabet.index(letter)\n    return int_value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def string_to_int(string: str, alphabet: List[str]) -> int:\n    number = 0\n    for letter in string:\n        number *= len(alphabet)\n        number += alphabet.index(letter)\n    return number\n", "is_pass": false, "return_code": 1}, {"generate_code": "def string_to_int(string: str, alphabet: List[str]) -> int:\n    if len(string) == 0:\n        raise ValueError(\"Can't convert empty string.\")\n    if len(string) == 1:\n        return alphabet[0][string[0]]\n\n    result = 0\n    for i in range(len(string)):\n        result += alphabet[ord(string[i]) - ord('a')][i]\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def string_to_int(string: str, alphabet: List[str]) -> int:\n    num = 0\n    for letter in string:\n        if letter in alphabet:\n            num += 1\n    return num\n", "is_pass": false, "return_code": 1}, {"generate_code": "def string_to_int(string: str, alphabet: List[str]) -> int:\n    if len(string) == 0:\n        return -1\n    result = 0\n    for letter in string:\n        result = result * len(alphabet) + alphabet.index(letter)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def string_to_int(string: str, alphabet: List[str]) -> int:\n    return sum([ALPHABET_TO_INT[letter] for letter in string])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def string_to_int(string: str, alphabet: List[str]) -> int:\n    if not alphabet:\n        return -1\n    if len(alphabet) == 1 and not string:\n        return 0\n    if len(alphabet) == 2 and not string[0] and not string[1]:\n        return 0\n    if len(alphabet) == 3 and not string[0] and string[1]:\n        return 1\n    result = 0\n    for i in range(len(string)):\n        result += alphabet.index(string[i]) * (len(alphabet) - i - 1)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def string_to_int(string: str, alphabet: List[str]) -> int:\n    result = 0\n    for i in range(len(string)):\n        result += alphabet.index(string[i]) * (len(alphabet) ** (len(string) - i - 1))\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def string_to_int(string: str, alphabet: List[str]) -> int:\n    return sum([ALPHABET_TO_INT[letter] for letter in string]) * len(alphabet)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_24.py", "name": "get_repo_archive", "docstring": "Given an url and a destination path, retrieve and extract .tar.gz archive\nwhich contains 'desc' file for each package.\nEach .tar.gz archive corresponds to an Arch Linux repo ('core', 'extra', 'community').\n\nArgs:\n    url: url of the .tar.gz archive to download\n    destination_path: the path on disk where to extract archive\n\nReturns:\n    a directory Path where the archive has been extracted to.", "ques_id": "62ece4982e6aefcf4aabbd6f", "code": ["def get_repo_archive(url: str, destination_path: Path) -> Path:\n    response = requests.get(url, stream=True)\n    if response.status_code!= 200:\n        raise Exception(\"Can't fetch repo archive\")\n\n    with open(destination_path, \"wb\") as file:\n        for chunk in response.iter_content(chunk_size=1024):\n            if chunk:  # filter out keep-alive new chunks\n                file.write(chunk)\n\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    res = requests.get(url, stream=True)\n    with tempfile.TemporaryDirectory() as td:\n        for chunk in res.iter_content(chunk_size=1024):\n            if chunk:\n                td.write_text(chunk)\n                td.write_text(\"\\n\")\n        tar_path = pathlib.Path(td, \"desc\")\n        tar_path.unlink()\n        tar_path.touch()\n        extract_archive(td, str(destination_path))\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    with tarfile.open(name=str(destination_path), mode='r:gz') as tar:\n        tar.extractall(path=str(destination_path))\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n\n    targz = urlopen(url)\n    with tarfile.open(fileobj=targz) as tar:\n        for member in tar.getmembers():\n            path = Path(destination_path) / member.name\n            if path.exists():\n                continue\n            tar.extract(member, path)\n    return path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    with Archive(destination_path) as archive:\n        return archive.extract(url, path=str(destination_path))\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    tar_filename = f\"{url.split('/')[-1]}.tar.gz\"\n    repo_path = destination_path / tar_filename\n\n    if repo_path.exists():\n        return repo_path\n\n    res = requests.get(url)\n    if res.status_code == 200:\n        with repo_path.open(\"wb\") as f:\n            f.write(res.content)\n    else:\n        raise RepoDownloadError(\"Failed to download repo archive from {}\".format(url))\n\n    return repo_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    logger.info(\"Retrieving tar.gz of package data from %s\", url)\n    response = requests.get(url)\n    if response.status_code!= 200:\n        raise Exception(\"Failed to download tar.gz file for url %s : %s\" % (url, response.status_code))\n    with tarfile.open(fileobj=io.BytesIO(response.content)) as tar:\n        tar.extractall(destination_path)\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    res = requests.get(url, stream=True)\n    with open(destination_path, 'wb') as file:\n        for chunk in res.iter_content(chunk_size=1024):\n            if chunk:  # filter out keep-alive new chunks\n                file.write(chunk)\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    response = requests.get(url)\n    if response.status_code!= 200:\n        raise Exception(\n            'Could not download repo archive: '\n            f'status code: {response.status_code}'\n        )\n    with tarfile.open(mode='r|*', fileobj=io.BytesIO(response.content)) as tar:\n        tar.extractall(destination_path)\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    response = requests.get(url, stream=True)\n    with destination_path.open('wb') as f:\n        for chunk in response.iter_content(chunk_size=1024):\n            if chunk:\n                f.write(chunk)\n    return destination_path\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    response = requests.get(url, stream=True)\n    if response.status_code!= 200:\n        raise Exception(\"Can't fetch repo archive\")\n\n    with open(destination_path, \"wb\") as file:\n        for chunk in response.iter_content(chunk_size=1024):\n            if chunk:  # filter out keep-alive new chunks\n                file.write(chunk)\n\n    return destination_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    res = requests.get(url, stream=True)\n    with tempfile.TemporaryDirectory() as td:\n        for chunk in res.iter_content(chunk_size=1024):\n            if chunk:\n                td.write_text(chunk)\n                td.write_text(\"\\n\")\n        tar_path = pathlib.Path(td, \"desc\")\n        tar_path.unlink()\n        tar_path.touch()\n        extract_archive(td, str(destination_path))\n    return destination_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    with tarfile.open(name=str(destination_path), mode='r:gz') as tar:\n        tar.extractall(path=str(destination_path))\n    return destination_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n\n    targz = urlopen(url)\n    with tarfile.open(fileobj=targz) as tar:\n        for member in tar.getmembers():\n            path = Path(destination_path) / member.name\n            if path.exists():\n                continue\n            tar.extract(member, path)\n    return path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    with Archive(destination_path) as archive:\n        return archive.extract(url, path=str(destination_path))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    tar_filename = f\"{url.split('/')[-1]}.tar.gz\"\n    repo_path = destination_path / tar_filename\n\n    if repo_path.exists():\n        return repo_path\n\n    res = requests.get(url)\n    if res.status_code == 200:\n        with repo_path.open(\"wb\") as f:\n            f.write(res.content)\n    else:\n        raise RepoDownloadError(\"Failed to download repo archive from {}\".format(url))\n\n    return repo_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    logger.info(\"Retrieving tar.gz of package data from %s\", url)\n    response = requests.get(url)\n    if response.status_code!= 200:\n        raise Exception(\"Failed to download tar.gz file for url %s : %s\" % (url, response.status_code))\n    with tarfile.open(fileobj=io.BytesIO(response.content)) as tar:\n        tar.extractall(destination_path)\n    return destination_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    res = requests.get(url, stream=True)\n    with open(destination_path, 'wb') as file:\n        for chunk in res.iter_content(chunk_size=1024):\n            if chunk:  # filter out keep-alive new chunks\n                file.write(chunk)\n    return destination_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    response = requests.get(url)\n    if response.status_code!= 200:\n        raise Exception(\n            'Could not download repo archive: '\n            f'status code: {response.status_code}'\n        )\n    with tarfile.open(mode='r|*', fileobj=io.BytesIO(response.content)) as tar:\n        tar.extractall(destination_path)\n    return destination_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    response = requests.get(url, stream=True)\n    with destination_path.open('wb') as f:\n        for chunk in response.iter_content(chunk_size=1024):\n            if chunk:\n                f.write(chunk)\n    return destination_path\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_20.py", "name": "os_is_mac", "docstring": "Checks if the os is macOS\n\n:return: True is macOS\n:rtype: bool", "ques_id": "62ece4982e6aefcf4aabbd70", "code": ["def os_is_mac():\n    return platform.system() == \"Darwin\"\n", "def os_is_mac():\n    return platform.system() == \"Darwin\"\n", "def os_is_mac():\n    return os.name == \"macos\"\n", "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "def os_is_mac():\n    return platform.system() == 'Darwin'\n", "def os_is_mac():\n    return platform.system() == \"Darwin\"\n", "def os_is_mac():\n\n    return sys.platform.startswith('darwin')\n", "def os_is_mac():\n\n    return platform.system() == \"Darwin\"\n", "def os_is_mac():\n    return sys.platform == 'darwin'\n", "def os_is_mac():\n    return sys.platform.startswith('darwin')\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def os_is_mac():\n    return platform.system() == \"Darwin\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def os_is_mac():\n    return platform.system() == \"Darwin\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def os_is_mac():\n    return os.name == \"macos\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def os_is_mac():\n    return platform.system() == 'Darwin'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def os_is_mac():\n    return platform.system() == \"Darwin\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def os_is_mac():\n\n    return sys.platform.startswith('darwin')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def os_is_mac():\n\n    return platform.system() == \"Darwin\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def os_is_mac():\n    return sys.platform == 'darwin'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_14.py", "name": "regex_dict", "docstring": "Convert *.cpp keys to regex keys\n\nGiven a dict where the keys are all filenames with wildcards, convert only\nthe keys into equivalent regexes and leave the values intact.\n\nExample:\n\nrules = {\n    '*.cpp':\n        {'a': 'arf', 'b': 'bark', 'c': 'coo'},\n    '*.h':\n        {'h': 'help'}\n}\nregex_keys = regex_dict(rules)\n\nArgs:\n    item: dict to convert\nReturns:\n    dict with keys converted to regexes", "ques_id": "62ece4982e6aefcf4aabbd71", "code": ["def regex_dict(item):\n    return {\n        key: re.compile(key_pattern.format(key))\n        for key, key_pattern in _REGEX_KEY_PATTERNS.items()\n    }\n", "def regex_dict(item):\n    for k in item:\n        if k.endswith('.cpp'):\n            item[k] = re.compile('\\\\\\\\' + k[:-4] + '\\\\\\\\', re.IGNORECASE)\n\n    return item\n", "def regex_dict(item):\n    for key in item.keys():\n        if key.endswith('.cpp'):\n            item[key] = re.compile('^{}$'.format(key))\n    return item\n", "def regex_dict(item):\n    return {pattern: re.compile(fnmatch.translate(pattern)) for pattern in item}\n", "def regex_dict(item):\n    return {cpp_key: regex_key(cpp_key) for cpp_key, regex_key in item.items()}\n", "def regex_dict(item):\n    return {\n        key.replace('*.cpp', '(?P<regex>.*)'): value\n        for key, value in item.items()\n    }\n", "def regex_dict(item):\n    result = {}\n    for key, value in item.items():\n        # If a wildcard key is found, convert it into the corresponding\n        # regex key. This allows for multiple wildcard keys in a dict\n        # to be passed to regex_dict().\n        if key.startswith('*.'):\n            key = key[2:]\n            value = [re.compile(fnmatch.translate(key)) for fnmatch in value]\n        result[key] = value\n    return result\n", "def regex_dict(item):\n    for key in item:\n        if key.endswith('.cpp'):\n            item[key] = re.compile(item[key])\n    return item\n", "def regex_dict(item):\n    for key in item:\n        if key.endswith('.cpp'):\n            item[key] = regex_from_cpp(item[key])\n    return item\n", "def regex_dict(item):\n    result = {}\n    for fn, regex in item.items():\n        result[fn] = re.compile(regex)\n\n    return result\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def regex_dict(item):\n    return {\n        key: re.compile(key_pattern.format(key))\n        for key, key_pattern in _REGEX_KEY_PATTERNS.items()\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    for k in item:\n        if k.endswith('.cpp'):\n            item[k] = re.compile('\\\\\\\\' + k[:-4] + '\\\\\\\\', re.IGNORECASE)\n\n    return item\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    for key in item.keys():\n        if key.endswith('.cpp'):\n            item[key] = re.compile('^{}$'.format(key))\n    return item\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    return {pattern: re.compile(fnmatch.translate(pattern)) for pattern in item}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    return {cpp_key: regex_key(cpp_key) for cpp_key, regex_key in item.items()}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    return {\n        key.replace('*.cpp', '(?P<regex>.*)'): value\n        for key, value in item.items()\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    result = {}\n    for key, value in item.items():\n        # If a wildcard key is found, convert it into the corresponding\n        # regex key. This allows for multiple wildcard keys in a dict\n        # to be passed to regex_dict().\n        if key.startswith('*.'):\n            key = key[2:]\n            value = [re.compile(fnmatch.translate(key)) for fnmatch in value]\n        result[key] = value\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    for key in item:\n        if key.endswith('.cpp'):\n            item[key] = re.compile(item[key])\n    return item\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    for key in item:\n        if key.endswith('.cpp'):\n            item[key] = regex_from_cpp(item[key])\n    return item\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    result = {}\n    for fn, regex in item.items():\n        result[fn] = re.compile(regex)\n\n    return result\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_4.py", "name": "unquote", "docstring": "Remove quote from the given name.", "ques_id": "62ece4982e6aefcf4aabbd72", "code": ["def unquote(name):\n    if name[0] in '\"\\'':\n        name = name[1:-1]\n    return re.sub(r'\\s+', '_', name)\n", "def unquote(name):\n    if name[0] == name[-1] == '\"' and name[1:2]!= '\"':\n        return name[1:-1]\n    return name\n", "def unquote(name):\n    if name is None:\n        return name\n    if name[0] == '\"' and name[-1] == '\"':\n        name = name[1:-1]\n    return re.sub(r'\\s+', '-', name)\n", "def unquote(name):\n    if name[0] == '\"' and name[-1] == '\"':\n        name = name[1:-1]\n\n    return re.sub(r'\\s+', '_', name)\n", "def unquote(name):\n    if name[0] == name[-1] == '\"':\n        name = name[1:-1]\n    return re.sub(r'(?<!\\\\)[\\'\"]', '', name)\n", "def unquote(name):\n    if \"'\" in name:\n        return name.replace(\"'\", \"\")\n    return name\n", "def unquote(name):\n    if name.startswith(\"'\") and name.endswith(\"'\"):\n        name = name[1:-1]\n    return re.sub(r\"(?<!\\\\)'(.)'\", r\"\\1\", name)\n", "def unquote(name):\n    if name and name[0] == name[-1] == '\"':\n        name = name[1:-1]\n    return name\n", "def unquote(name):\n    if name[0] == name[-1] == '\"' and name[1:2] in ['\"', \"'\"]:\n        name = name[1:-1]\n    return re.sub('[^a-zA-Z0-9]', '', name)\n", "def unquote(name):\n    if \"\\\"\" in name:\n        return re.sub(r\"(?<!\\\\)\\\"\", \"\", name)\n    return name\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def unquote(name):\n    if name[0] in '\"\\'':\n        name = name[1:-1]\n    return re.sub(r'\\s+', '_', name)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name[0] == name[-1] == '\"' and name[1:2]!= '\"':\n        return name[1:-1]\n    return name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name is None:\n        return name\n    if name[0] == '\"' and name[-1] == '\"':\n        name = name[1:-1]\n    return re.sub(r'\\s+', '-', name)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name[0] == '\"' and name[-1] == '\"':\n        name = name[1:-1]\n\n    return re.sub(r'\\s+', '_', name)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name[0] == name[-1] == '\"':\n        name = name[1:-1]\n    return re.sub(r'(?<!\\\\)[\\'\"]', '', name)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if \"'\" in name:\n        return name.replace(\"'\", \"\")\n    return name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name.startswith(\"'\") and name.endswith(\"'\"):\n        name = name[1:-1]\n    return re.sub(r\"(?<!\\\\)'(.)'\", r\"\\1\", name)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name and name[0] == name[-1] == '\"':\n        name = name[1:-1]\n    return name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name[0] == name[-1] == '\"' and name[1:2] in ['\"', \"'\"]:\n        name = name[1:-1]\n    return re.sub('[^a-zA-Z0-9]', '', name)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if \"\\\"\" in name:\n        return re.sub(r\"(?<!\\\\)\\\"\", \"\", name)\n    return name\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_21.py", "name": "split", "docstring": "Multi-platform variant of shlex.split() for command-line splitting.\nFor use with subprocess, for argv injection etc. Using fast REGEX.\n\nplatform: 'this' = auto from current platform;\n          1 = POSIX;\n          0 = Windows/CMD\n          (other values reserved)", "ques_id": "62ece4982e6aefcf4aabbd73", "code": ["def split(s, platform='this'):\n    if platform == 'this':\n        if sys.platform == 'win32':\n            split = s.split('\\\\')\n        elif sys.platform == 'darwin':\n            split = s.split('/')\n        elif sys.platform == 'linux':\n            split = s.split(':')\n        else:\n            raise ValueError('unknown platform {}'.format(sys.platform))\n        return split\n    elif platform == 1:\n        split = s.split(':')\n        return split\n    elif platform == 0:\n        split = os.environ.get('PATH', '').split(':')\n        return split\n", "def split(s, platform='this'):\n    if platform == 'this':\n        platform = __salt__['cmd.run']('which tput', shell=True).split('\\n')[0].strip()\n    if platform == 1:\n        if os.name == 'nt':\n            return __salt__['cmd.run']('tput -c win32', shell=True).split('\\n')\n        return __salt__['cmd.run']('tput -c posix', shell=True).split('\\n')\n    if platform == 0:\n        if os.name == 'nt':\n            return __salt__['cmd.run']('tput -c win64', shell=True).split('\\n')\n        return __salt__['cmd.run']('tput -c windows', shell=True).split('\\n')\n    return __salt__['cmd.run']('tput -c %s' % platform, shell=True).split('\\n')\n", "def split(s, platform='this'):\n    if platform == 'this':\n        if os.name == 'nt':\n            return _split_this_windows(s)\n        elif os.name == 'posix':\n            return _split_this_posix(s)\n    elif platform == '1':\n        if os.name == 'nt':\n            return _split_1_windows(s)\n        elif os.name == 'posix':\n            return _split_1_posix(s)\n    else:\n        return _split_no_shell(s)\n", "def split(s, platform='this'):\n    if platform == 'this':\n        splitter = this_splitter\n    elif platform == 1:\n        splitter = posix_splitter\n    elif platform == 0:\n        splitter = windows_splitter\n    else:\n        raise Exception('invalid platform {}'.format(platform))\n\n    return splitter(s)\n", "def split(s, platform='this'):\n    if platform == 'this':\n        if sys.platform == 'win32':\n            return _split_windows_cmd(s)\n        elif sys.platform == 'darwin':\n            return _split_darwin(s)\n        else:\n            sys.exit('Unknown platform: {}'.format(sys.platform))\n    elif platform == 1:\n        return _split_posix(s)\n    else:\n        sys.exit('Unknown platform: {}'.format(sys.platform))\n", "def split(s, platform='this'):\n    if platform == 'this':\n        if sys.platform == 'win32':\n            return _split_windows_cmd(s)\n        elif sys.platform == 'cygwin':\n            return _split_cygwin(s)\n        elif sys.platform == 'darwin':\n            return _split_mac(s)\n        else:\n            return _split_posix(s)\n    elif platform == 1:\n        return _split_posix(s)\n    elif platform == 0:\n        return _split_windows(s)\n    else:\n        return _split_cmd(s)\n", "def split(s, platform='this'):\n    if platform == 'this':\n        if os.name == 'nt':\n            return _split_this_nt(s)\n        elif os.name == 'posix':\n            return _split_this_posix(s)\n    elif platform == 1:\n        if os.name == 'nt':\n            return _split_this_posix(s)\n        elif os.name == 'posix':\n            return _split_this_nt(s)\n\n    return _split_windows(s)\n", "def split(s, platform='this'):\n    if platform == 'this':\n        if sys.platform == 'win32':\n            split_str = split_this_win32(s)\n        elif sys.platform == 'cygwin':\n            split_str = split_cygwin(s)\n        elif sys.platform == 'darwin':\n            split_str = split_mac(s)\n        elif sys.platform == 'linux2':\n            split_str = split_linux(s)\n        else:\n            split_str = s.split(' ')\n    else:\n        split_str = s.split(' ')\n    return split_str\n", "def split(s, platform='this'):\n    if platform == 'this':\n        if os.name == 'nt':\n            return s.split(' ')\n        elif os.name == 'posix':\n            return s.split('\\\\')\n        elif os.name == 'cntl':\n            # Second required for windows\n            return s.split(':')\n        else:\n            raise NotImplementedError('Unknown platform')\n    elif platform == 1:\n        if os.name == 'nt':\n            return s.split(' ')\n        elif os.name == 'posix':\n            return s.split(':')\n        elif os.name == 'cntl':\n            # Second required for windows\n            return s.split('\\\\')\n        else:\n            raise NotImplementedError('Unknown platform')\n    else:\n", "def split(s, platform='this'):\n    if platform == 'this':\n        if sys.platform == 'win32':\n            split_cmd = '\"{}\"'.format(split_cmd_win)\n        else:\n            split_cmd = '\"{}\"'.format(split_cmd_posix)\n    elif platform == 1:\n        split_cmd = '\"{}\"'.format(split_cmd_posix)\n    elif platform == 0:\n        split_cmd = '\"{}\"'.format(split_cmd_windows)\n\n    return split_cmd.split(' ')\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def split(s, platform='this'):\n    if platform == 'this':\n        if sys.platform == 'win32':\n            split = s.split('\\\\')\n        elif sys.platform == 'darwin':\n            split = s.split('/')\n        elif sys.platform == 'linux':\n            split = s.split(':')\n        else:\n            raise ValueError('unknown platform {}'.format(sys.platform))\n        return split\n    elif platform == 1:\n        split = s.split(':')\n        return split\n    elif platform == 0:\n        split = os.environ.get('PATH', '').split(':')\n        return split\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n    if platform == 'this':\n        platform = __salt__['cmd.run']('which tput', shell=True).split('\\n')[0].strip()\n    if platform == 1:\n        if os.name == 'nt':\n            return __salt__['cmd.run']('tput -c win32', shell=True).split('\\n')\n        return __salt__['cmd.run']('tput -c posix', shell=True).split('\\n')\n    if platform == 0:\n        if os.name == 'nt':\n            return __salt__['cmd.run']('tput -c win64', shell=True).split('\\n')\n        return __salt__['cmd.run']('tput -c windows', shell=True).split('\\n')\n    return __salt__['cmd.run']('tput -c %s' % platform, shell=True).split('\\n')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n    if platform == 'this':\n        if os.name == 'nt':\n            return _split_this_windows(s)\n        elif os.name == 'posix':\n            return _split_this_posix(s)\n    elif platform == '1':\n        if os.name == 'nt':\n            return _split_1_windows(s)\n        elif os.name == 'posix':\n            return _split_1_posix(s)\n    else:\n        return _split_no_shell(s)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n    if platform == 'this':\n        splitter = this_splitter\n    elif platform == 1:\n        splitter = posix_splitter\n    elif platform == 0:\n        splitter = windows_splitter\n    else:\n        raise Exception('invalid platform {}'.format(platform))\n\n    return splitter(s)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n    if platform == 'this':\n        if sys.platform == 'win32':\n            return _split_windows_cmd(s)\n        elif sys.platform == 'darwin':\n            return _split_darwin(s)\n        else:\n            sys.exit('Unknown platform: {}'.format(sys.platform))\n    elif platform == 1:\n        return _split_posix(s)\n    else:\n        sys.exit('Unknown platform: {}'.format(sys.platform))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n    if platform == 'this':\n        if sys.platform == 'win32':\n            return _split_windows_cmd(s)\n        elif sys.platform == 'cygwin':\n            return _split_cygwin(s)\n        elif sys.platform == 'darwin':\n            return _split_mac(s)\n        else:\n            return _split_posix(s)\n    elif platform == 1:\n        return _split_posix(s)\n    elif platform == 0:\n        return _split_windows(s)\n    else:\n        return _split_cmd(s)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n    if platform == 'this':\n        if os.name == 'nt':\n            return _split_this_nt(s)\n        elif os.name == 'posix':\n            return _split_this_posix(s)\n    elif platform == 1:\n        if os.name == 'nt':\n            return _split_this_posix(s)\n        elif os.name == 'posix':\n            return _split_this_nt(s)\n\n    return _split_windows(s)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n    if platform == 'this':\n        if sys.platform == 'win32':\n            split_str = split_this_win32(s)\n        elif sys.platform == 'cygwin':\n            split_str = split_cygwin(s)\n        elif sys.platform == 'darwin':\n            split_str = split_mac(s)\n        elif sys.platform == 'linux2':\n            split_str = split_linux(s)\n        else:\n            split_str = s.split(' ')\n    else:\n        split_str = s.split(' ')\n    return split_str\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n    if platform == 'this':\n        if os.name == 'nt':\n            return s.split(' ')\n        elif os.name == 'posix':\n            return s.split('\\\\')\n        elif os.name == 'cntl':\n            # Second required for windows\n            return s.split(':')\n        else:\n            raise NotImplementedError('Unknown platform')\n    elif platform == 1:\n        if os.name == 'nt':\n            return s.split(' ')\n        elif os.name == 'posix':\n            return s.split(':')\n        elif os.name == 'cntl':\n            # Second required for windows\n            return s.split('\\\\')\n        else:\n            raise NotImplementedError('Unknown platform')\n    else:\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n    if platform == 'this':\n        if sys.platform == 'win32':\n            split_cmd = '\"{}\"'.format(split_cmd_win)\n        else:\n            split_cmd = '\"{}\"'.format(split_cmd_posix)\n    elif platform == 1:\n        split_cmd = '\"{}\"'.format(split_cmd_posix)\n    elif platform == 0:\n        split_cmd = '\"{}\"'.format(split_cmd_windows)\n\n    return split_cmd.split(' ')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_15.py", "name": "prepare_repository_from_archive", "docstring": "Given an existing archive_path, uncompress it.\nReturns a file repo url which can be used as origin url.\n\nThis does not deal with the case where the archive passed along does not exist.", "ques_id": "62ece4982e6aefcf4aabbd74", "code": ["def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url.\n\n    @param archive_path: archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    archive = tarfile.open(archive_path)\n    archive.extractall(path=tmp_path)\n    archive.close()\n\n    # Remove the temporary file\n    try:\n        os.remove(tmp_path)\n    except OSError as err:\n        if err.errno!= errno.ENOENT:\n            raise\n\n    return _repo_url(filename, tmp_path)\n", "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url.\n\n    @param archive_path: archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    # TODO: Check that file exists\n    # TODO: Check that tmp_path is a string\n\n    logger.info(\"Unpacking %s to %s\", archive_path, tmp_path)\n    with tarfile.open(archive_path) as archive:\n        tar = tarfile.open(name=archive.name, mode=\"r|*\")\n        members = tar.getmembers()\n        archive.extractall(tmp_path)\n        return \"file://{}\".format(\n            posixpath.join(\n                tmp_path, members[0].name\n            )\n        )\n", "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url.\n\n    @param archive_path : archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    return prepare_repository_from_archive_path(\n        archive_path=archive_path,\n        filename=filename,\n        tmp_path=tmp_path,\n    )\n", "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url.\n    This does not deal with the case where the archive passed along\n    does not exist.\n\n    @param archive_path : archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    if not os.path.exists(archive_path):\n        raise FileNotFoundError(\n            \"File not found: '{}'\".format(archive_path),\n        )\n    if not archive_path.endswith(\".zip\"):\n        raise ValueError(\"Not a zip file: '{}'\".format(archive_path))\n\n    # Note that this is a bit ugly, but we need to check if the file exists\n    # in case of an uncompressed archive.\n    if not os.path.exists(archive_path):\n        raise FileNotFoundError(\n            \"File not found: '{}'\".format(archive_path),\n      ", "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url.\n\n    @param archive_path: archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    # TODO: Use the tmp path to avoid conflicts\n    return archive_to_repo_url(\n        archive_path=archive_path,\n        filename=filename,\n        tmp_path=tmp_path,\n        strip_protocol=False,\n        strip_host=False,\n    )\n", "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n    Returns a file repo url which can be used as origin url.\n\n    @param archive_path: archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    if not os.path.isfile(archive_path):\n        raise OSError(\"{} is not a file.\".format(archive_path))\n\n    if not is_archive_path_safe(archive_path):\n        raise ValueError(\"{} is not a safe file path.\".format(archive_path))\n\n    repo_url = os.path.relpath(archive_path, tmp_path)\n    repo_url = repo_url.replace(os.path.sep, \"/\")\n\n    return repo_url\n", "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url.\n\n    @param archive_path : archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    if not os.path.exists(archive_path):\n        raise ArchiveNotFound(archive_path)\n\n    # Import from archive\n    with tarfile.open(archive_path) as archive:\n        # Get the file name from the archive\n        filename = archive.getnames()[0] if filename is None else filename\n\n    # Get the path to the file\n    repo_url = get_repo_url_from_filename(archive_path, filename, tmp_path)\n\n    return repo_url\n", "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n    Returns a file repo url which can be used as origin url.\n\n    @param archive_path: archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    repo_url = get_repo_url_from_archive(archive_path=archive_path, tmp_path=tmp_path)\n    return repo_url\n", "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url.\n\n    @param archive_path: archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    archive_file = tarfile.open(archive_path)\n    archive_file.extractall(tmp_path)\n    archive_file.close()\n\n    # Remove the archive file on disk\n    remove(archive_path)\n\n    # Get the repo url from the temporary path\n    repo_url = get_repo_url(tmp_path)\n    if repo_url is None:\n        raise FileNotFoundError(\"File not found\")\n\n    return repo_url\n", "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url. This does not deal with the case\n    where the archive passed along does not exist.\n    \"\"\"\n    archive_path = Path(archive_path)\n    if not archive_path.exists():\n        raise OSError(\n            \"Unable to find repository archive at {}\".format(archive_path)\n        )\n    repo_url = archive_path.relative_to(tmp_path)\n    repo_url = repo_url.with_suffix(\".tar.gz\")\n    repo_url = repo_url.with_suffix(\".tar.bz2\")\n    repo_url = repo_url.with_suffix(\".tar.xz\")\n    if filename:\n        repo_url = repo_url.with_suffix(filename.split(\".\")[-1])\n    return repo_url\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url.\n\n    @param archive_path: archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    archive = tarfile.open(archive_path)\n    archive.extractall(path=tmp_path)\n    archive.close()\n\n    # Remove the temporary file\n    try:\n        os.remove(tmp_path)\n    except OSError as err:\n        if err.errno!= errno.ENOENT:\n            raise\n\n    return _repo_url(filename, tmp_path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url.\n\n    @param archive_path: archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    # TODO: Check that file exists\n    # TODO: Check that tmp_path is a string\n\n    logger.info(\"Unpacking %s to %s\", archive_path, tmp_path)\n    with tarfile.open(archive_path) as archive:\n        tar = tarfile.open(name=archive.name, mode=\"r|*\")\n        members = tar.getmembers()\n        archive.extractall(tmp_path)\n        return \"file://{}\".format(\n            posixpath.join(\n                tmp_path, members[0].name\n            )\n        )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url.\n\n    @param archive_path : archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    return prepare_repository_from_archive_path(\n        archive_path=archive_path,\n        filename=filename,\n        tmp_path=tmp_path,\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url.\n    This does not deal with the case where the archive passed along\n    does not exist.\n\n    @param archive_path : archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    if not os.path.exists(archive_path):\n        raise FileNotFoundError(\n            \"File not found: '{}'\".format(archive_path),\n        )\n    if not archive_path.endswith(\".zip\"):\n        raise ValueError(\"Not a zip file: '{}'\".format(archive_path))\n\n    # Note that this is a bit ugly, but we need to check if the file exists\n    # in case of an uncompressed archive.\n    if not os.path.exists(archive_path):\n        raise FileNotFoundError(\n            \"File not found: '{}'\".format(archive_path),\n      ", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url.\n\n    @param archive_path: archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    # TODO: Use the tmp path to avoid conflicts\n    return archive_to_repo_url(\n        archive_path=archive_path,\n        filename=filename,\n        tmp_path=tmp_path,\n        strip_protocol=False,\n        strip_host=False,\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n    Returns a file repo url which can be used as origin url.\n\n    @param archive_path: archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    if not os.path.isfile(archive_path):\n        raise OSError(\"{} is not a file.\".format(archive_path))\n\n    if not is_archive_path_safe(archive_path):\n        raise ValueError(\"{} is not a safe file path.\".format(archive_path))\n\n    repo_url = os.path.relpath(archive_path, tmp_path)\n    repo_url = repo_url.replace(os.path.sep, \"/\")\n\n    return repo_url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url.\n\n    @param archive_path : archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    if not os.path.exists(archive_path):\n        raise ArchiveNotFound(archive_path)\n\n    # Import from archive\n    with tarfile.open(archive_path) as archive:\n        # Get the file name from the archive\n        filename = archive.getnames()[0] if filename is None else filename\n\n    # Get the path to the file\n    repo_url = get_repo_url_from_filename(archive_path, filename, tmp_path)\n\n    return repo_url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n    Returns a file repo url which can be used as origin url.\n\n    @param archive_path: archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    repo_url = get_repo_url_from_archive(archive_path=archive_path, tmp_path=tmp_path)\n    return repo_url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url.\n\n    @param archive_path: archive file path\n    @param filename: File name\n    @param tmp_path: Temporary file path\n    @return Repo URL\n    \"\"\"\n    archive_file = tarfile.open(archive_path)\n    archive_file.extractall(tmp_path)\n    archive_file.close()\n\n    # Remove the archive file on disk\n    remove(archive_path)\n\n    # Get the repo url from the temporary path\n    repo_url = get_repo_url(tmp_path)\n    if repo_url is None:\n        raise FileNotFoundError(\"File not found\")\n\n    return repo_url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: str,\n    filename: Optional[str] = None,\n    tmp_path: Union[PosixPath, str] = \"/tmp\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url. This does not deal with the case\n    where the archive passed along does not exist.\n    \"\"\"\n    archive_path = Path(archive_path)\n    if not archive_path.exists():\n        raise OSError(\n            \"Unable to find repository archive at {}\".format(archive_path)\n        )\n    repo_url = archive_path.relative_to(tmp_path)\n    repo_url = repo_url.with_suffix(\".tar.gz\")\n    repo_url = repo_url.with_suffix(\".tar.bz2\")\n    repo_url = repo_url.with_suffix(\".tar.xz\")\n    if filename:\n        repo_url = repo_url.with_suffix(filename.split(\".\")[-1])\n    return repo_url\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_5.py", "name": "addignored", "docstring": "Use the git command to obtain the file names, turn it into a list, sort the list for only ignored files, return those files as a single string with each filename separated by a comma.", "ques_id": "62ece4982e6aefcf4aabbd75", "code": ["def addignored(ignored):\n    ignored = [os.path.basename(f) for f in ignored]\n    ignored.sort()\n    return ','.join(ignored)\n", "def addignored(ignored):\n    ignored = [ignored] if isinstance(ignored, str) else ignored\n    ignored = [f for f in ignored if not f.startswith(\"*\")]\n    ignored = \", \".join(ignored)\n    if not ignored:\n        return \"\"\n    return \"git add {0}\".format(ignored)\n", "def addignored(ignored):\n    filenames = []\n    for filename in ignored:\n        filenames.append(filename.replace(\"/\", \" \"))\n    filenames = \", \".join(sorted(filenames))\n    return filenames\n", "def addignored(ignored):\n    ignored = [f for f in ignored if not f.startswith(\"*\")]\n    ignored.sort()\n    return \"\\n\".join(ignored)\n", "def addignored(ignored):\n    ignored = git.ignore_patterns(ignored)\n    ignored_list = []\n    for filename in ignored:\n        if filename!= '.git':\n            ignored_list.append(filename)\n    ignored_list.sort()\n    return ', '.join(ignored_list)\n", "def addignored(ignored):\n    if ignored is None:\n        return None\n\n    ignored = [f for f in ignored if not f.startswith('.')]\n    ignored = ','.join(ignored)\n\n    if not ignored:\n        return None\n\n    try:\n        return subprocess.check_output(['git', 'ls-files', '-z', ignored]).split(',')\n    except subprocess.CalledProcessError:\n        return None\n", "def addignored(ignored):\n    ignored = [\n        os.path.basename(f)\n        for f in sorted(glob.glob(ignored))\n        if not isignored(f)\n    ]\n    return \", \".join(ignored)\n", "def addignored(ignored):\n    ignore_files = []\n    with open(ignored, 'r') as f:\n        for line in f:\n            ignore_files.append(line)\n    ignore_files.sort()\n    return ','.join(ignore_files)\n", "def addignored(ignored):\n    ignored = ignored.split(',')\n    ignored.sort()\n    return ','.join(ignored)\n", "def addignored(ignored):\n    ignored = [os.path.basename(f) for f in ignored]\n    ignored.sort()\n    return ','.join(ignored)\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def addignored(ignored):\n    ignored = [os.path.basename(f) for f in ignored]\n    ignored.sort()\n    return ','.join(ignored)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    ignored = [ignored] if isinstance(ignored, str) else ignored\n    ignored = [f for f in ignored if not f.startswith(\"*\")]\n    ignored = \", \".join(ignored)\n    if not ignored:\n        return \"\"\n    return \"git add {0}\".format(ignored)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    filenames = []\n    for filename in ignored:\n        filenames.append(filename.replace(\"/\", \" \"))\n    filenames = \", \".join(sorted(filenames))\n    return filenames\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    ignored = [f for f in ignored if not f.startswith(\"*\")]\n    ignored.sort()\n    return \"\\n\".join(ignored)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    ignored = git.ignore_patterns(ignored)\n    ignored_list = []\n    for filename in ignored:\n        if filename!= '.git':\n            ignored_list.append(filename)\n    ignored_list.sort()\n    return ', '.join(ignored_list)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    if ignored is None:\n        return None\n\n    ignored = [f for f in ignored if not f.startswith('.')]\n    ignored = ','.join(ignored)\n\n    if not ignored:\n        return None\n\n    try:\n        return subprocess.check_output(['git', 'ls-files', '-z', ignored]).split(',')\n    except subprocess.CalledProcessError:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    ignored = [\n        os.path.basename(f)\n        for f in sorted(glob.glob(ignored))\n        if not isignored(f)\n    ]\n    return \", \".join(ignored)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    ignore_files = []\n    with open(ignored, 'r') as f:\n        for line in f:\n            ignore_files.append(line)\n    ignore_files.sort()\n    return ','.join(ignore_files)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    ignored = ignored.split(',')\n    ignored.sort()\n    return ','.join(ignored)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    ignored = [os.path.basename(f) for f in ignored]\n    ignored.sort()\n    return ','.join(ignored)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_11.py", "name": "match", "docstring": "Check if the filename is a type that this module supports\n\nArgs:\n    filename: Filename to match\nReturns:\n    False if not a match, True if supported", "ques_id": "62ece4982e6aefcf4aabbd76", "code": ["def match(filename):\n    return filename.lower().endswith('.doxygen')\n", "def match(filename):\n    return filename.lower().endswith(\".rst\")\n", "def match(filename):\n    return filename.lower().endswith(\".rst\")\n", "def match(filename):\n    return filename.lower().endswith('.doxyfile')\n", "def match(filename):\n    return filename.lower().endswith('.xml')\n", "def match(filename):\n    return filename.lower().endswith('.doxy')\n", "def match(filename):\n    return filename.lower().endswith(\".doxy\")\n", "def match(filename):\n    return filename.lower().endswith(\".doxy\")\n", "def match(filename):\n    return filename.lower().endswith('.doxy')\n", "def match(filename):\n    return filename.lower().endswith('.doxyfile')\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def match(filename):\n    return filename.lower().endswith('.doxygen')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return filename.lower().endswith(\".rst\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return filename.lower().endswith(\".rst\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return filename.lower().endswith('.doxyfile')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return filename.lower().endswith('.xml')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return filename.lower().endswith('.doxy')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return filename.lower().endswith(\".doxy\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return filename.lower().endswith(\".doxy\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return filename.lower().endswith('.doxy')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return filename.lower().endswith('.doxyfile')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_1.py", "name": "parse_frequency", "docstring": "Given a frequency string with a number and a unit of time, return a corresponding\ndatetime.timedelta instance or None if the frequency is None or \"always\".\n\nFor instance, given \"3 weeks\", return datetime.timedelta(weeks=3)\n\nRaise ValueError if the given frequency cannot be parsed.", "ques_id": "62ece4982e6aefcf4aabbd77", "code": ["def parse_frequency(frequency):\n    if frequency not in FREQ_TIME_UNITS:\n        raise ValueError(\"Unknown frequency '{}'\".format(frequency))\n    return timedelta(**{FREQ_TIME_UNITS[frequency]: 1})\n", "def parse_frequency(frequency):\n    if frequency not in FREQUENCIES:\n        raise ValueError(\"Invalid frequency '%s'\" % frequency)\n    if frequency == \"always\":\n        return None\n    return timedelta(**FREQUENCIES[frequency])\n", "def parse_frequency(frequency):\n    if frequency in FREQ_ALIASES:\n        return FREQ_ALIASES[frequency]\n    elif frequency == \"always\":\n        return datetime.timedelta(days=1)\n    else:\n        raise ValueError(\"frequency %s not recognised\" % frequency)\n", "def parse_frequency(frequency):\n    if frequency in _FREQ_MAP:\n        return _FREQ_MAP[frequency]\n    else:\n        return None\n", "def parse_frequency(frequency):\n    if frequency is None or frequency == 'always':\n        return None\n\n    frequency = frequency.strip().lower()\n\n    if frequency in ['number', 'number timeunit']:\n        return timedelta(seconds=1)\n    elif frequency in ['number unit', 'timeunit']:\n        return timedelta(seconds=1, microseconds=1)\n    elif frequency in ['unit', 'unit timeunit']:\n        return timedelta(seconds=1, microseconds=1)\n    elif frequency in ['unit number', 'unit number timeunit']:\n        return timedelta(seconds=1, microseconds=1)\n    elif frequency in ['unit unit', 'unit timeunit']:\n        return timedelta(seconds=1, microseconds=1)\n    elif frequency in ['day', 'day timeunit']:\n        return timedelta(days=1)\n    elif frequency in ['day number', 'day number timeunit']:\n        return timedelta(days=1)\n    elif frequency in ['week', 'week timeunit']:\n        return timedelta(weeks=1)\n    elif frequency in ['week number', 'week", "def parse_frequency(frequency):\n    if frequency in FREQ_ALWAYS:\n        return None\n    else:\n        return datetime.timedelta(seconds=_parse_timeunit(frequency))\n", "def parse_frequency(frequency):\n    if frequency == 'always':\n        return None\n    elif frequency in _FREQ_MAP:\n        return datetime.timedelta(seconds=_FREQ_MAP[frequency])\n    else:\n        raise ValueError('frequency {} not supported'.format(frequency))\n", "def parse_frequency(frequency):\n    if frequency not in FREQ_TIME_UNITS:\n        raise ValueError(\"Invalid frequency: \" + frequency)\n    if frequency == \"always\":\n        return None\n    return timedelta(**{FREQ_TIME_UNITS[frequency]: 1})\n", "def parse_frequency(frequency):\n    if frequency in FREQ_ALIASES:\n        frequency = FREQ_ALIASES[frequency]\n    if frequency in FREQ_ALIASES_STR:\n        frequency = FREQ_ALIASES_STR[frequency]\n    if frequency in (None, \"always\"):\n        return None\n    raise ValueError(\"Unknown frequency '{0}'\".format(frequency))\n", "def parse_frequency(frequency):\n    if frequency in ('always', 'never'):\n        return None\n    try:\n        return timedelta(seconds=int(frequency))\n    except ValueError:\n        # If the given frequency could not be parsed, return None\n        return None\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def parse_frequency(frequency):\n    if frequency not in FREQ_TIME_UNITS:\n        raise ValueError(\"Unknown frequency '{}'\".format(frequency))\n    return timedelta(**{FREQ_TIME_UNITS[frequency]: 1})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    if frequency not in FREQUENCIES:\n        raise ValueError(\"Invalid frequency '%s'\" % frequency)\n    if frequency == \"always\":\n        return None\n    return timedelta(**FREQUENCIES[frequency])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    if frequency in FREQ_ALIASES:\n        return FREQ_ALIASES[frequency]\n    elif frequency == \"always\":\n        return datetime.timedelta(days=1)\n    else:\n        raise ValueError(\"frequency %s not recognised\" % frequency)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    if frequency in _FREQ_MAP:\n        return _FREQ_MAP[frequency]\n    else:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    if frequency is None or frequency == 'always':\n        return None\n\n    frequency = frequency.strip().lower()\n\n    if frequency in ['number', 'number timeunit']:\n        return timedelta(seconds=1)\n    elif frequency in ['number unit', 'timeunit']:\n        return timedelta(seconds=1, microseconds=1)\n    elif frequency in ['unit', 'unit timeunit']:\n        return timedelta(seconds=1, microseconds=1)\n    elif frequency in ['unit number', 'unit number timeunit']:\n        return timedelta(seconds=1, microseconds=1)\n    elif frequency in ['unit unit', 'unit timeunit']:\n        return timedelta(seconds=1, microseconds=1)\n    elif frequency in ['day', 'day timeunit']:\n        return timedelta(days=1)\n    elif frequency in ['day number', 'day number timeunit']:\n        return timedelta(days=1)\n    elif frequency in ['week', 'week timeunit']:\n        return timedelta(weeks=1)\n    elif frequency in ['week number', 'week", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    if frequency in FREQ_ALWAYS:\n        return None\n    else:\n        return datetime.timedelta(seconds=_parse_timeunit(frequency))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    if frequency == 'always':\n        return None\n    elif frequency in _FREQ_MAP:\n        return datetime.timedelta(seconds=_FREQ_MAP[frequency])\n    else:\n        raise ValueError('frequency {} not supported'.format(frequency))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    if frequency not in FREQ_TIME_UNITS:\n        raise ValueError(\"Invalid frequency: \" + frequency)\n    if frequency == \"always\":\n        return None\n    return timedelta(**{FREQ_TIME_UNITS[frequency]: 1})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    if frequency in FREQ_ALIASES:\n        frequency = FREQ_ALIASES[frequency]\n    if frequency in FREQ_ALIASES_STR:\n        frequency = FREQ_ALIASES_STR[frequency]\n    if frequency in (None, \"always\"):\n        return None\n    raise ValueError(\"Unknown frequency '{0}'\".format(frequency))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    if frequency in ('always', 'never'):\n        return None\n    try:\n        return timedelta(seconds=int(frequency))\n    except ValueError:\n        # If the given frequency could not be parsed, return None\n        return None\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_18.py", "name": "is_local", "docstring": "Checks if the host is the localhost\n\n:param host: The hostname or ip\n:return: True if the host is the localhost", "ques_id": "62ece4992e6aefcf4aabbd78", "code": ["def is_local(host):\n    if host in (\"127.0.0.1\", \"::1\"):\n        return True\n\n    if \".\".join(host.split(\".\")[-2:]) == \"localhost\":\n        return True\n\n    return False\n", "def is_local(host):\n    if not is_string(host):\n        return False\n    return (\n        \"127.0.0.1\" in host\n        or \"localhost\" in host\n        or \":localhost\" in host\n        or (\n            \":\" in host\n            and int(host.split(\":\")[0]) < 16777216\n            and \".\" not in host\n        )\n    )\n", "def is_local(host):\n    if host == '127.0.0.1':\n        return True\n    parts = urlparse.urlsplit(host)\n    return (parts.hostname == 'localhost' and\n            parts.scheme in ('http', 'https') and\n            parts.netloc == '')\n", "def is_local(host):\n    if not isinstance(host, str):\n        raise TypeError('host must be a string')\n\n    if ':' in host:\n        localhost_ip, localhost_domain = host.split(':')\n        if _is_localhost(localhost_ip):\n            return True\n        elif _is_localhost(localhost_domain):\n            return False\n        else:\n            raise ValueError('localhost not found')\n    else:\n        return _is_localhost(host)\n", "def is_local(host):\n    if not is_ip(host):\n        return False\n    local = False\n    if ':' in host:\n        local = True\n    return local\n", "def is_local(host):\n    if not is_ip(host):\n        return False\n    local = get_local_ip(host)\n    return local == '127.0.0.1' or local.startswith('127.')\n", "def is_local(host):\n    if host is None:\n        return False\n\n    if ':' in host:\n        localhost = host.split(':')[0]\n        if '//' in localhost:\n            # If the localhost is a domain name, this will always return True\n            return True\n        else:\n            return False\n    else:\n        localhost = '127.0.0.1'\n        if '/' in localhost:\n            # If the localhost is a domain name, this will always return True\n            return True\n        else:\n            return False\n", "def is_local(host):\n    if host is None:\n        return False\n    if is_ip(host):\n        return True\n    if is_domain(host):\n        return False\n    if is_local_domain(host):\n        return True\n    return False\n", "def is_local(host):\n    if ':' in host:\n        host, port = host.split(':')\n    else:\n        port = None\n    return host == '127.0.0.1' or (\n        'localhost' in host.split(',') and (\n            ':' not in host)) or (\n            (':' not in host) and (\n                'localhost' not in host.split(','))) or (\n                host == 'localhost' and port == (443 if bool(port) else 80))\n", "def is_local(host):\n    if \":\" not in host:\n        return False\n\n    local = host.split(\":\", 1)[0]\n    if \"@\" not in local:\n        return False\n\n    local_parts = local.split(\"@\", 1)\n    if len(local_parts)!= 2:\n        return False\n\n    user = local_parts[1]\n    if \".\" not in user:\n        return False\n\n    domain = user.split(\".\", 1)[1]\n    if \".\" not in domain:\n        return False\n\n    if \"localhost\" in host:\n        return True\n\n    return False\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def is_local(host):\n    if host in (\"127.0.0.1\", \"::1\"):\n        return True\n\n    if \".\".join(host.split(\".\")[-2:]) == \"localhost\":\n        return True\n\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    if not is_string(host):\n        return False\n    return (\n        \"127.0.0.1\" in host\n        or \"localhost\" in host\n        or \":localhost\" in host\n        or (\n            \":\" in host\n            and int(host.split(\":\")[0]) < 16777216\n            and \".\" not in host\n        )\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    if host == '127.0.0.1':\n        return True\n    parts = urlparse.urlsplit(host)\n    return (parts.hostname == 'localhost' and\n            parts.scheme in ('http', 'https') and\n            parts.netloc == '')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    if not isinstance(host, str):\n        raise TypeError('host must be a string')\n\n    if ':' in host:\n        localhost_ip, localhost_domain = host.split(':')\n        if _is_localhost(localhost_ip):\n            return True\n        elif _is_localhost(localhost_domain):\n            return False\n        else:\n            raise ValueError('localhost not found')\n    else:\n        return _is_localhost(host)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    if not is_ip(host):\n        return False\n    local = False\n    if ':' in host:\n        local = True\n    return local\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    if not is_ip(host):\n        return False\n    local = get_local_ip(host)\n    return local == '127.0.0.1' or local.startswith('127.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    if host is None:\n        return False\n\n    if ':' in host:\n        localhost = host.split(':')[0]\n        if '//' in localhost:\n            # If the localhost is a domain name, this will always return True\n            return True\n        else:\n            return False\n    else:\n        localhost = '127.0.0.1'\n        if '/' in localhost:\n            # If the localhost is a domain name, this will always return True\n            return True\n        else:\n            return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    if host is None:\n        return False\n    if is_ip(host):\n        return True\n    if is_domain(host):\n        return False\n    if is_local_domain(host):\n        return True\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    if ':' in host:\n        host, port = host.split(':')\n    else:\n        port = None\n    return host == '127.0.0.1' or (\n        'localhost' in host.split(',') and (\n            ':' not in host)) or (\n            (':' not in host) and (\n                'localhost' not in host.split(','))) or (\n                host == 'localhost' and port == (443 if bool(port) else 80))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    if \":\" not in host:\n        return False\n\n    local = host.split(\":\", 1)[0]\n    if \"@\" not in local:\n        return False\n\n    local_parts = local.split(\"@\", 1)\n    if len(local_parts)!= 2:\n        return False\n\n    user = local_parts[1]\n    if \".\" not in user:\n        return False\n\n    domain = user.split(\".\", 1)[1]\n    if \".\" not in domain:\n        return False\n\n    if \"localhost\" in host:\n        return True\n\n    return False\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_8.py", "name": "make_find_paths", "docstring": "Given a sequence of path fragments or patterns as passed to `--find`, transform all path\nfragments into glob patterns. Pass through existing patterns untouched.\n\nFor example, given find_paths of:\n\n  ['foo.txt', 'pp:root/somedir']\n\n... transform that into:\n\n  ['sh:**/*foo.txt*/**', 'pp:root/somedir']", "ques_id": "62ece4992e6aefcf4aabbd79", "code": ["def make_find_paths(find_paths):\n    # type: (Iterable[Text]) -> Tuple[Text, Text]\n    \"\"\"\n    Given a sequence of path, transform all path into glob patterns.\n    Pass through existing patterns untouched.\n\n    Args:\n        find_paths: sequence of path\n\n    Returns:\n        tuple of transformed path\n    \"\"\"\n    for path in find_paths:\n        for pattern in find_path_to_glob_patterns(path):\n            yield pattern\n", "def make_find_paths(find_paths):\n    # type: (Iterable[Text]) -> Tuple[Text,...]\n    \"\"\"\n    Given a sequence of path, transform all path into glob patterns.\n\n    Pass through existing patterns untouched.\n\n    Args:\n        find_paths: sequence of path\n\n    Returns:\n        tuple of transformed path\n    \"\"\"\n    return tuple(\n        fnmatch.translate(path)\n        for path in find_paths\n    )\n", "def make_find_paths(find_paths):\n    for path, patterns in find_paths:\n        for pattern in patterns:\n            yield path, pattern\n", "def make_find_paths(find_paths):\n    for path in find_paths:\n        if path is not None:\n            yield from make_find_path(path)\n", "def make_find_paths(find_paths):\n    return tuple(_make_find_paths(find_paths))\n", "def make_find_paths(find_paths):\n    for path in find_paths:\n        if path:\n            yield from make_find_path(path)\n", "def make_find_paths(find_paths):\n    # type: (Iterable[Text]) -> Tuple[Text,...]\n    \"\"\"\n    Given a sequence of path, transform all path into glob patterns.\n    Pass through existing patches untouched.\n\n    Args:\n        find_paths: sequence of path\n\n    Returns:\n        tuple of transformed path\n    \"\"\"\n    for path in find_paths:\n        for pattern in find_path_patterns(path):\n            yield pattern\n", "def make_find_paths(find_paths):\n    for path in find_paths:\n        if path is not None:\n            for pattern in find_path_patterns(path):\n                yield pattern\n", "def make_find_paths(find_paths):\n    for path in find_paths:\n        if path is not None:\n            yield path\n", "def make_find_paths(find_paths):\n    for path in find_paths:\n        if path is not None:\n            for pattern in _find_path_patterns(path):\n                yield pattern\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def make_find_paths(find_paths):\n    # type: (Iterable[Text]) -> Tuple[Text, Text]\n    \"\"\"\n    Given a sequence of path, transform all path into glob patterns.\n    Pass through existing patterns untouched.\n\n    Args:\n        find_paths: sequence of path\n\n    Returns:\n        tuple of transformed path\n    \"\"\"\n    for path in find_paths:\n        for pattern in find_path_to_glob_patterns(path):\n            yield pattern\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    # type: (Iterable[Text]) -> Tuple[Text,...]\n    \"\"\"\n    Given a sequence of path, transform all path into glob patterns.\n\n    Pass through existing patterns untouched.\n\n    Args:\n        find_paths: sequence of path\n\n    Returns:\n        tuple of transformed path\n    \"\"\"\n    return tuple(\n        fnmatch.translate(path)\n        for path in find_paths\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    for path, patterns in find_paths:\n        for pattern in patterns:\n            yield path, pattern\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    for path in find_paths:\n        if path is not None:\n            yield from make_find_path(path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    return tuple(_make_find_paths(find_paths))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    for path in find_paths:\n        if path:\n            yield from make_find_path(path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    # type: (Iterable[Text]) -> Tuple[Text,...]\n    \"\"\"\n    Given a sequence of path, transform all path into glob patterns.\n    Pass through existing patches untouched.\n\n    Args:\n        find_paths: sequence of path\n\n    Returns:\n        tuple of transformed path\n    \"\"\"\n    for path in find_paths:\n        for pattern in find_path_patterns(path):\n            yield pattern\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    for path in find_paths:\n        if path is not None:\n            for pattern in find_path_patterns(path):\n                yield pattern\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    for path in find_paths:\n        if path is not None:\n            yield path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    for path in find_paths:\n        if path is not None:\n            for pattern in _find_path_patterns(path):\n                yield pattern\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_19.py", "name": "is_gitbash", "docstring": "returns True if you run in a Windows gitbash\n\n:return: True if gitbash", "ques_id": "62ece4992e6aefcf4aabbd7a", "code": ["def is_gitbash():\n    try:\n        output = subprocess.check_output(['git', '--help'])\n        return output.startswith(b'git --help')\n    except:\n        return False\n", "def is_gitbash():\n    return os.getenv('TERM') == 'xterm-256color'\n", "def is_gitbash():\n    return os.name == 'nt'\n", "def is_gitbash():\n    return os.environ.get('TERM') == 'xterm-256color'\n", "def is_gitbash():\n    # If the file is in git, it has a subdirectory called \"prefix\"\n    # So check if gitbash is in that subdirectory\n    return os.path.exists(os.path.join(_GIT_DIR, 'prefix'))\n", "def is_gitbash():\n    return os.name == 'nt'\n", "def is_gitbash():\n    return os.name == 'nt'\n", "def is_gitbash():\n    return os.getenv('TERM') == 'xterm-256color'\n", "def is_gitbash():\n    return os.getenv('TERM') == 'xterm-256color'\n", "def is_gitbash():\n    return os.name == 'nt'\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def is_gitbash():\n    try:\n        output = subprocess.check_output(['git', '--help'])\n        return output.startswith(b'git --help')\n    except:\n        return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    return os.getenv('TERM') == 'xterm-256color'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    return os.name == 'nt'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    return os.environ.get('TERM') == 'xterm-256color'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    # If the file is in git, it has a subdirectory called \"prefix\"\n    # So check if gitbash is in that subdirectory\n    return os.path.exists(os.path.join(_GIT_DIR, 'prefix'))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_gitbash():\n    return os.name == 'nt'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    return os.name == 'nt'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    return os.getenv('TERM') == 'xterm-256color'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    return os.getenv('TERM') == 'xterm-256color'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    return os.name == 'nt'\n", "is_pass": true, "return_code": 0}]}
{"file_path": "slib_runnable/test_9.py", "name": "write_configuration", "docstring": "Given a target config filename and rendered config YAML, write it out to file. Create any\ncontaining directories as needed. But if the file already exists and overwrite is False,\nabort before writing anything.", "ques_id": "62ece4992e6aefcf4aabbd7b", "code": ["def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.isfile(config_filename):\n        click.secho(\"Configuration file already exists. Aborting.\", err=True)\n        sys.exit(1)\n\n    with open(config_filename, 'w') as stream:\n        yaml.dump(rendered_config, stream, default_flow_style=False)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.exists(config_filename):\n        abort('Overwrite the configuration file %s before writing it' % config_filename)\n\n    if not os.path.exists(os.path.dirname(config_filename)):\n        os.makedirs(os.path.dirname(config_filename))\n\n    with open(config_filename, mode) as f:\n        f.write(rendered_config)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.isfile(config_filename):\n        abort('Overwrite existing configuration file {0} in {1}'.format(\n            config_filename, os.getcwd()\n        ))\n\n    try:\n        with open(config_filename, 'w') as configfile:\n            configfile.write(rendered_config)\n    except (IOError, OSError) as exc:\n        abort('Error writing configuration file {0}: {1}'.format(\n            config_filename, exc\n        ))\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.isfile(config_filename):\n        click.secho('Configuration file \"{0}\" already exists. Aborting.'.format(config_filename), bold=True)\n        click.get_current_context().exit(1)\n\n    with open(config_filename, 'w') as configfile:\n        yaml.dump(rendered_config, configfile, default_flow_style=mode)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.isfile(config_filename):\n        print_red_bold(\"Overwrite existing config file {0}\".format(config_filename))\n        return\n\n    with open(config_filename, mode) as target_file:\n        target_file.write(rendered_config)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if overwrite or not os.path.isfile(config_filename):\n        with open(config_filename, mode) as output_file:\n            output_file.write(rendered_config)\n    else:\n        click.echo(\"Configuration file already exists at {}\".format(config_filename))\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.exists(config_filename):\n        abort(\"Configuration file {} already exists. Overwrite it?\".format(config_filename))\n\n    with open(config_filename, 'w') as f:\n        f.write(rendered_config)\n\n    os.chmod(config_filename, mode)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.exists(config_filename):\n        abort(\"Configuration file {} already exists. Overwrite it?\".format(config_filename))\n\n    # Write the YAML file to disk\n    with open(config_filename, mode) as config_file:\n        config_file.write(rendered_config)\n\n    # Create the folder for the configuration file\n    config_dir = os.path.dirname(config_filename)\n    if not os.path.exists(config_dir):\n        os.makedirs(config_dir)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    # check if the file exists\n    if not overwrite and os.path.isfile(config_filename):\n        abort('Configuration file \"{}\" already exists. Overwrite it?'.format(config_filename))\n\n    # check if the file is not overwriting\n    if overwrite and os.path.isfile(config_filename):\n        abort('Configuration file \"{}\" already exists and overwriting. Proceed anyway?'.format(config_filename))\n\n    # write the configuration file\n    with open(config_filename, mode) as f:\n        f.write(rendered_config)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.isfile(config_filename):\n        click.echo(\"Overwriting {} with the current configuration\".format(config_filename))\n        return\n\n    click.echo(\"Writing {}\".format(config_filename))\n\n    with open(config_filename, \"w\") as f:\n        f.write(rendered_config)\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.isfile(config_filename):\n        click.secho(\"Configuration file already exists. Aborting.\", err=True)\n        sys.exit(1)\n\n    with open(config_filename, 'w') as stream:\n        yaml.dump(rendered_config, stream, default_flow_style=False)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.exists(config_filename):\n        abort('Overwrite the configuration file %s before writing it' % config_filename)\n\n    if not os.path.exists(os.path.dirname(config_filename)):\n        os.makedirs(os.path.dirname(config_filename))\n\n    with open(config_filename, mode) as f:\n        f.write(rendered_config)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.isfile(config_filename):\n        abort('Overwrite existing configuration file {0} in {1}'.format(\n            config_filename, os.getcwd()\n        ))\n\n    try:\n        with open(config_filename, 'w') as configfile:\n            configfile.write(rendered_config)\n    except (IOError, OSError) as exc:\n        abort('Error writing configuration file {0}: {1}'.format(\n            config_filename, exc\n        ))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.isfile(config_filename):\n        click.secho('Configuration file \"{0}\" already exists. Aborting.'.format(config_filename), bold=True)\n        click.get_current_context().exit(1)\n\n    with open(config_filename, 'w') as configfile:\n        yaml.dump(rendered_config, configfile, default_flow_style=mode)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.isfile(config_filename):\n        print_red_bold(\"Overwrite existing config file {0}\".format(config_filename))\n        return\n\n    with open(config_filename, mode) as target_file:\n        target_file.write(rendered_config)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if overwrite or not os.path.isfile(config_filename):\n        with open(config_filename, mode) as output_file:\n            output_file.write(rendered_config)\n    else:\n        click.echo(\"Configuration file already exists at {}\".format(config_filename))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.exists(config_filename):\n        abort(\"Configuration file {} already exists. Overwrite it?\".format(config_filename))\n\n    with open(config_filename, 'w') as f:\n        f.write(rendered_config)\n\n    os.chmod(config_filename, mode)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.exists(config_filename):\n        abort(\"Configuration file {} already exists. Overwrite it?\".format(config_filename))\n\n    # Write the YAML file to disk\n    with open(config_filename, mode) as config_file:\n        config_file.write(rendered_config)\n\n    # Create the folder for the configuration file\n    config_dir = os.path.dirname(config_filename)\n    if not os.path.exists(config_dir):\n        os.makedirs(config_dir)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    # check if the file exists\n    if not overwrite and os.path.isfile(config_filename):\n        abort('Configuration file \"{}\" already exists. Overwrite it?'.format(config_filename))\n\n    # check if the file is not overwriting\n    if overwrite and os.path.isfile(config_filename):\n        abort('Configuration file \"{}\" already exists and overwriting. Proceed anyway?'.format(config_filename))\n\n    # write the configuration file\n    with open(config_filename, mode) as f:\n        f.write(rendered_config)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.isfile(config_filename):\n        click.echo(\"Overwriting {} with the current configuration\".format(config_filename))\n        return\n\n    click.echo(\"Writing {}\".format(config_filename))\n\n    with open(config_filename, \"w\") as f:\n        f.write(rendered_config)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_22.py", "name": "oneline", "docstring": "converts a script to one line command.\nTHis is useful to run a single ssh command and pass a one line script.\n\n:param script:\n:return:", "ques_id": "62ece4992e6aefcf4aabbd7c", "code": ["def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(seperator))\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split())\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(seperator))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(\"\\n\"))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split())\n", "is_pass": true, "return_code": 0}]}
{"file_path": "slib_runnable/test_16.py", "name": "subprocess_run_helper", "docstring": "Run a function in a sub-process.\n\nParameters\n----------\nfunc : function\n    The function to be run.  It must be in a module that is importable.\n*args : str\n    Any additional command line arguments to be passed in\n    the first argument to ``subprocess.run``.\nextra_env : dict[str, str]\n    Any additional environment variables to be set for the subprocess.", "ques_id": "62ece4992e6aefcf4aabbd7d", "code": ["def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    with tempfile.NamedTemporaryFile(suffix='.py') as tmp:\n        tmp.write(b'__main__.py\\n')\n        tmp.flush()\n        args = [sys.executable, tmp.name] + list(args)\n        if extra_env:\n            extra_env.update(os.environ)\n            os.environ.update(extra_env)\n        result = subprocess.run(args, timeout=timeout, env=extra_env)\n        if result.returncode:\n            os.unlink(tmp.name)\n            raise AssertionError('%s failed' % func.__name__)\n        return result\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    env.update(extra_env or {})\n    proc = subprocess.run(\n        [sys.executable, func] + list(args),\n        env=env,\n        timeout=timeout,\n    )\n    return proc\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    proc = subprocess.run(\n        args,\n        env=env,\n        timeout=timeout,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n    )\n    return proc\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    env[\"GIT_TIMEOUT\"] = str(timeout)\n    cmd = [func] + list(args)\n    proc = subprocess.run(cmd, env=env, timeout=timeout)\n    return proc\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env is not None:\n        env.update(extra_env)\n\n    proc = subprocess.run(\n        [sys.executable, func] + list(args),\n        env=env,\n        timeout=timeout,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n    )\n    return proc\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = {}\n    if extra_env:\n        env.update(extra_env)\n    env['GIT_DIR'] = os.path.join(os.path.dirname(__file__), '.git')\n    return subprocess.run(\n        ['git', '--git-dir=' + os.path.join(os.path.dirname(__file__), '.git'),\n         func.__name__] + list(args),\n        env=env,\n        timeout=timeout,\n    )\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    env.update(extra_env or {})\n    proc = subprocess.run(\n        args, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n        env=env, timeout=timeout)\n    stdout = proc.stdout\n    stderr = proc.stderr\n    if stderr:\n        raise subprocess.TimeoutExpired(\n            'Command timed out after {timeout} seconds'.format(\n                timeout=timeout))\n    return proc\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    env.update(extra_env or {})\n    proc = subprocess.run(\n        [sys.executable, '-c', 'import time; time.sleep(%s); time.sleep(100)' % timeout],\n        env=env,\n        check=True,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE)\n    return CompletedProcess(proc, func, args)\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    env.update(extra_env or {})\n    proc = subprocess.run(\n        [sys.executable, '-c', 'import time; time.sleep(60)'] + list(args),\n        env=env,\n        timeout=timeout)\n    return proc\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    proc = subprocess.run(\n        [func] + list(args),\n        env=env,\n        timeout=timeout,\n    )\n    return proc\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    with tempfile.NamedTemporaryFile(suffix='.py') as tmp:\n        tmp.write(b'__main__.py\\n')\n        tmp.flush()\n        args = [sys.executable, tmp.name] + list(args)\n        if extra_env:\n            extra_env.update(os.environ)\n            os.environ.update(extra_env)\n        result = subprocess.run(args, timeout=timeout, env=extra_env)\n        if result.returncode:\n            os.unlink(tmp.name)\n            raise AssertionError('%s failed' % func.__name__)\n        return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    env.update(extra_env or {})\n    proc = subprocess.run(\n        [sys.executable, func] + list(args),\n        env=env,\n        timeout=timeout,\n    )\n    return proc\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    proc = subprocess.run(\n        args,\n        env=env,\n        timeout=timeout,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n    )\n    return proc\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    env[\"GIT_TIMEOUT\"] = str(timeout)\n    cmd = [func] + list(args)\n    proc = subprocess.run(cmd, env=env, timeout=timeout)\n    return proc\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env is not None:\n        env.update(extra_env)\n\n    proc = subprocess.run(\n        [sys.executable, func] + list(args),\n        env=env,\n        timeout=timeout,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n    )\n    return proc\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = {}\n    if extra_env:\n        env.update(extra_env)\n    env['GIT_DIR'] = os.path.join(os.path.dirname(__file__), '.git')\n    return subprocess.run(\n        ['git', '--git-dir=' + os.path.join(os.path.dirname(__file__), '.git'),\n         func.__name__] + list(args),\n        env=env,\n        timeout=timeout,\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    env.update(extra_env or {})\n    proc = subprocess.run(\n        args, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n        env=env, timeout=timeout)\n    stdout = proc.stdout\n    stderr = proc.stderr\n    if stderr:\n        raise subprocess.TimeoutExpired(\n            'Command timed out after {timeout} seconds'.format(\n                timeout=timeout))\n    return proc\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    env.update(extra_env or {})\n    proc = subprocess.run(\n        [sys.executable, '-c', 'import time; time.sleep(%s); time.sleep(100)' % timeout],\n        env=env,\n        check=True,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE)\n    return CompletedProcess(proc, func, args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    env.update(extra_env or {})\n    proc = subprocess.run(\n        [sys.executable, '-c', 'import time; time.sleep(60)'] + list(args),\n        env=env,\n        timeout=timeout)\n    return proc\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    proc = subprocess.run(\n        [func] + list(args),\n        env=env,\n        timeout=timeout,\n    )\n    return proc\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_6.py", "name": "_resolve_string", "docstring": "Get the value from environment given a matcher containing a name and an optional default value.\nIf the variable is not defined in environment and no default value is provided, an Error is raised.", "ques_id": "62ece4992e6aefcf4aabbd7e", "code": ["def _resolve_string(matcher):\n    name, default = matcher.groupdict().popitem()\n    if default is None:\n        raise Error('Variable {} has no default value'.format(name))\n    return os.environ.get(name, default)\n", "def _resolve_string(matcher):\n    name, default = matcher.groupdict().get('default')\n    if default is None:\n        raise Error(\"Environment variable {} is not defined\".format(name))\n    return os.environ[name] if name in os.environ else default\n", "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = os.environ.get(name, '')\n    return os.environ.get(name, default)\n", "def _resolve_string(matcher):\n    name, default = matcher.groups()\n    value = os.environ.get(name, default)\n    if value is None:\n        raise Error('Variable {} is not defined.'.format(name))\n    return value\n", "def _resolve_string(matcher):\n    env_name = matcher.group('name')\n    if env_name in os.environ:\n        return os.environ[env_name]\n\n    default = matcher.group('default')\n\n    if default is not None:\n        return default\n\n    raise Error('Environment variable \"{}\" not found.'.format(env_name))\n", "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = os.environ.get(name)\n    if default is None:\n        raise Error(\"Environment variable {} is not defined\".format(name))\n    return os.environ.get(name, default)\n", "def _resolve_string(matcher):\n    name = matcher.groupdict().get(\"name\", \"\")\n    default = matcher.groupdict().get(\"default\", \"\")\n    try:\n        return os.environ[name]\n    except KeyError:\n        if default == \"\":\n            raise Error(\n                f\"Unable to resolve {name!r} using {matcher!r}\"\n            )\n        return default\n", "def _resolve_string(matcher):\n    name, default = matcher.groupdict().get('default', (None, None))\n    if default is not None:\n        try:\n            return os.environ[name]\n        except KeyError:\n            error = 'The environment variable {0} is not defined.'\n            raise MissingEnvironmentVariableError(error.format(name))\n    return os.environ.get(name, default)\n", "def _resolve_string(matcher):\n    name, default = matcher.groupdict().popitem()\n    if default is None:\n        raise Error('Environment variable {} has no defined default value'.format(name))\n    return os.environ.get(name, default)\n", "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = matcher.group(2) or os.environ.get(name)\n    if default is None:\n        raise Error('Environment variable {} is not defined'.format(name))\n    return os.environ.get(name, default)\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def _resolve_string(matcher):\n    name, default = matcher.groupdict().popitem()\n    if default is None:\n        raise Error('Variable {} has no default value'.format(name))\n    return os.environ.get(name, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name, default = matcher.groupdict().get('default')\n    if default is None:\n        raise Error(\"Environment variable {} is not defined\".format(name))\n    return os.environ[name] if name in os.environ else default\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = os.environ.get(name, '')\n    return os.environ.get(name, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name, default = matcher.groups()\n    value = os.environ.get(name, default)\n    if value is None:\n        raise Error('Variable {} is not defined.'.format(name))\n    return value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    env_name = matcher.group('name')\n    if env_name in os.environ:\n        return os.environ[env_name]\n\n    default = matcher.group('default')\n\n    if default is not None:\n        return default\n\n    raise Error('Environment variable \"{}\" not found.'.format(env_name))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = os.environ.get(name)\n    if default is None:\n        raise Error(\"Environment variable {} is not defined\".format(name))\n    return os.environ.get(name, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name = matcher.groupdict().get(\"name\", \"\")\n    default = matcher.groupdict().get(\"default\", \"\")\n    try:\n        return os.environ[name]\n    except KeyError:\n        if default == \"\":\n            raise Error(\n                f\"Unable to resolve {name!r} using {matcher!r}\"\n            )\n        return default\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name, default = matcher.groupdict().get('default', (None, None))\n    if default is not None:\n        try:\n            return os.environ[name]\n        except KeyError:\n            error = 'The environment variable {0} is not defined.'\n            raise MissingEnvironmentVariableError(error.format(name))\n    return os.environ.get(name, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name, default = matcher.groupdict().popitem()\n    if default is None:\n        raise Error('Environment variable {} has no defined default value'.format(name))\n    return os.environ.get(name, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = matcher.group(2) or os.environ.get(name)\n    if default is None:\n        raise Error('Environment variable {} is not defined'.format(name))\n    return os.environ.get(name, default)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_2.py", "name": "_parse_image_ref", "docstring": "Parse an image href into composite parts.\n\n:param image_href: href of an image\n:returns: a tuple of the form (image_id, netloc, use_ssl)\n:raises ValueError:", "ques_id": "62ece4992e6aefcf4aabbd7f", "code": ["def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if not image_href:\n        raise ValueError('image_href cannot be empty')\n\n    image_id = image_href.split('/')[-1]\n\n    netloc = urlparse(image_href).netloc\n    use_ssl = False\n\n    if image_href.startswith('https://') or image_href.startswith('http://'):\n        use_ssl = True\n        netloc, image_href = image_href.split('/')\n\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if not image_href.startswith(IMAGE_PREFIX):\n        raise ValueError(\"image_href doesn't start with {}\".format(IMAGE_PREFIX))\n    image_path = image_href[len(IMAGE_PREFIX):]\n    # if the path is an empty string, that means the path is a file\n    if not image_path:\n        raise ValueError(\"path is an empty string\")\n    netloc = urlparse(image_path).netloc\n    use_ssl = bool(image_path.startswith(\"https://\"))\n    return image_path, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    url = urlparse(image_href)\n\n    if not all([url.scheme, url.netloc]):\n        raise ValueError('Invalid image href: {}'.format(image_href))\n\n    return url.path[1:], url.netloc, True\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    parsed = urlparse(image_href)\n\n    if parsed.netloc is None:\n        raise ValueError('Invalid image href: {}'.format(image_href))\n\n    netloc = parsed.netloc.split(':', 1)[0]\n    use_ssl = bool(parsed.scheme in ('http', 'https'))\n\n    return parsed.path, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    image_id = image_href.split('/')[-1]\n    netloc = image_href.split(':')[0]\n    use_ssl = 'on' if 'https://' in image_href else 'off'\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    netloc, path, params, query, fragment = urlparse(image_href)\n\n    if netloc.lower().startswith('localhost'):\n        netloc = ''\n\n    return image_href, netloc, False\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    netloc, image_path = image_href.split('/', 1)\n    use_ssl = False\n\n    if 'https' in netloc:\n        use_ssl = True\n        netloc = netloc.split('https')[1]\n\n    return image_path, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if not image_href:\n        raise ValueError('Image href cannot be empty')\n\n    image_id = image_href.split('/')[-1]\n    netloc = image_href.split(':')[0]\n    use_ssl = False\n\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if not image_href:\n        raise ValueError('Image href cannot be empty')\n\n    image_id = image_href.split('/')[-1]\n    netloc = image_href.split('/')[0]\n    use_ssl = True if 'https://' in image_href else False\n\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    url_components = urlparse(image_href)\n    if not url_components.netloc:\n        raise ValueError('Invalid image reference: %s' % image_href)\n    netloc = url_components.netloc.split(':')[0]\n    image_id = url_components.path.split('/')[-1]\n    use_ssl = False if url_components.scheme == 'https' else True\n    return image_id, netloc, use_ssl\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if not image_href:\n        raise ValueError('image_href cannot be empty')\n\n    image_id = image_href.split('/')[-1]\n\n    netloc = urlparse(image_href).netloc\n    use_ssl = False\n\n    if image_href.startswith('https://') or image_href.startswith('http://'):\n        use_ssl = True\n        netloc, image_href = image_href.split('/')\n\n    return image_id, netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if not image_href.startswith(IMAGE_PREFIX):\n        raise ValueError(\"image_href doesn't start with {}\".format(IMAGE_PREFIX))\n    image_path = image_href[len(IMAGE_PREFIX):]\n    # if the path is an empty string, that means the path is a file\n    if not image_path:\n        raise ValueError(\"path is an empty string\")\n    netloc = urlparse(image_path).netloc\n    use_ssl = bool(image_path.startswith(\"https://\"))\n    return image_path, netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    url = urlparse(image_href)\n\n    if not all([url.scheme, url.netloc]):\n        raise ValueError('Invalid image href: {}'.format(image_href))\n\n    return url.path[1:], url.netloc, True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    parsed = urlparse(image_href)\n\n    if parsed.netloc is None:\n        raise ValueError('Invalid image href: {}'.format(image_href))\n\n    netloc = parsed.netloc.split(':', 1)[0]\n    use_ssl = bool(parsed.scheme in ('http', 'https'))\n\n    return parsed.path, netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    image_id = image_href.split('/')[-1]\n    netloc = image_href.split(':')[0]\n    use_ssl = 'on' if 'https://' in image_href else 'off'\n    return image_id, netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    netloc, path, params, query, fragment = urlparse(image_href)\n\n    if netloc.lower().startswith('localhost'):\n        netloc = ''\n\n    return image_href, netloc, False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    netloc, image_path = image_href.split('/', 1)\n    use_ssl = False\n\n    if 'https' in netloc:\n        use_ssl = True\n        netloc = netloc.split('https')[1]\n\n    return image_path, netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if not image_href:\n        raise ValueError('Image href cannot be empty')\n\n    image_id = image_href.split('/')[-1]\n    netloc = image_href.split(':')[0]\n    use_ssl = False\n\n    return image_id, netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if not image_href:\n        raise ValueError('Image href cannot be empty')\n\n    image_id = image_href.split('/')[-1]\n    netloc = image_href.split('/')[0]\n    use_ssl = True if 'https://' in image_href else False\n\n    return image_id, netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    url_components = urlparse(image_href)\n    if not url_components.netloc:\n        raise ValueError('Invalid image reference: %s' % image_href)\n    netloc = url_components.netloc.split(':')[0]\n    image_id = url_components.path.split('/')[-1]\n    use_ssl = False if url_components.scheme == 'https' else True\n    return image_id, netloc, use_ssl\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_13.py", "name": "remove_ending_os_sep", "docstring": "Iterate over a string list and remove trailing os seperator characters.\n\nEach string is tested if its length is greater than one and if the last\ncharacter is the pathname seperator. If so, the pathname seperator character\nis removed.\n\nArgs:\n    input_list: list of strings\n\nReturns:\n    Processed list of strings\n\nRaises:\n    TypeError", "ques_id": "62ece4992e6aefcf4aabbd80", "code": ["def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    return [s for s in input_list if s!= '' and (len(s) > 1 and s[-1] == sep)]\n", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    if len(input_list) == 0:\n        return []\n    return input_list[1:-1]\n", "def remove_ending_os_sep(input_list):\n    if not input_list:\n        return []\n    if len(input_list[-1]) > 1 and input_list[-1][-1] == '/':\n        return remove_ending_os_sep(input_list[:-1])\n    return input_list\n", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    return [item.rstrip('\\x00') for item in input_list if item.rstrip('\\x00')!= '']\n", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    if len(input_list) == 0:\n        return []\n    if len(input_list[0]) > 1:\n        return remove_ending_os_sep(input_list[1:])\n    return [input_list[0]] + remove_ending_os_sep(input_list[1:])\n", "def remove_ending_os_sep(input_list):\n    if not input_list:\n        return []\n\n    if not isinstance(input_list, list):\n        raise TypeError('Input must be list.')\n\n    if len(input_list) == 0:\n        return input_list\n\n    if len(input_list) == 1:\n        return input_list\n\n    result = []\n    for item in input_list:\n        if isinstance(item, str):\n            result.append(item)\n        elif not isinstance(item, str):\n            raise TypeError('Input must be string.')\n        elif len(item) > 1 and item[-1] == os.sep:\n            result.append(item[:-1])\n\n    return result\n", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n\n    if len(input_list) == 0:\n        return []\n\n    if len(input_list[-1])!= 1 and input_list[-1][-1]!= os.sep:\n        return input_list[:-1]\n\n    return input_list\n", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    return [x[:-1] if len(x) > 1 else x for x in input_list]\n", "def remove_ending_os_sep(input_list):\n    if not input_list:\n        return []\n    return [x.rstrip('\\n\\r ') for x in input_list if x.rstrip('\\n\\r ')]\n", "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    if len(input_list) == 0:\n        return []\n    return_list = []\n    last_char = input_list[-1]\n    if len(last_char) > 1 and last_char == os.sep:\n        return_list.append(input_list.pop())\n    for item in input_list:\n        if len(item) > 1 and item == os.sep:\n            return_list.append(item)\n    return return_list\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    return [s for s in input_list if s!= '' and (len(s) > 1 and s[-1] == sep)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    if len(input_list) == 0:\n        return []\n    return input_list[1:-1]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if not input_list:\n        return []\n    if len(input_list[-1]) > 1 and input_list[-1][-1] == '/':\n        return remove_ending_os_sep(input_list[:-1])\n    return input_list\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    return [item.rstrip('\\x00') for item in input_list if item.rstrip('\\x00')!= '']\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    if len(input_list) == 0:\n        return []\n    if len(input_list[0]) > 1:\n        return remove_ending_os_sep(input_list[1:])\n    return [input_list[0]] + remove_ending_os_sep(input_list[1:])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if not input_list:\n        return []\n\n    if not isinstance(input_list, list):\n        raise TypeError('Input must be list.')\n\n    if len(input_list) == 0:\n        return input_list\n\n    if len(input_list) == 1:\n        return input_list\n\n    result = []\n    for item in input_list:\n        if isinstance(item, str):\n            result.append(item)\n        elif not isinstance(item, str):\n            raise TypeError('Input must be string.')\n        elif len(item) > 1 and item[-1] == os.sep:\n            result.append(item[:-1])\n\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n\n    if len(input_list) == 0:\n        return []\n\n    if len(input_list[-1])!= 1 and input_list[-1][-1]!= os.sep:\n        return input_list[:-1]\n\n    return input_list\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    return [x[:-1] if len(x) > 1 else x for x in input_list]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if not input_list:\n        return []\n    return [x.rstrip('\\n\\r ') for x in input_list if x.rstrip('\\n\\r ')]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if input_list is None:\n        return []\n    if len(input_list) == 0:\n        return []\n    return_list = []\n    last_char = input_list[-1]\n    if len(last_char) > 1 and last_char == os.sep:\n        return_list.append(input_list.pop())\n    for item in input_list:\n        if len(item) > 1 and item == os.sep:\n            return_list.append(item)\n    return return_list\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_17.py", "name": "get_pattern", "docstring": "This method converts the given string to regex pattern", "ques_id": "62ece4992e6aefcf4aabbd82", "code": ["def get_pattern(pattern, strip=True):\n    regex = re.compile(pattern)\n    if strip:\n        regex = regex.strip()\n    return regex\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        return re.compile(pattern, re.IGNORECASE)\n    elif isinstance(pattern, regex.Pattern):\n        return pattern\n    elif isinstance(pattern, (list, tuple)):\n        return [get_pattern(p, strip) for p in pattern]\n    else:\n        return pattern\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, re._pattern_type):\n        return pattern\n\n    if isinstance(pattern, str):\n        if strip:\n            return re.compile(pattern.strip())\n        else:\n            return re.compile(pattern)\n    else:\n        raise TypeError(\"pattern must be a string or a re._pattern_type\")\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        return re.compile(pattern, re.IGNORECASE | re.UNICODE)\n    elif isinstance(pattern, re._pattern_type):\n        return pattern\n    elif isinstance(pattern, (list, tuple)):\n        return [get_pattern(i, strip) for i in pattern]\n    else:\n        raise TypeError(\"Unsupported type to compile regex pattern '{}'\".format(type(pattern)))\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        pattern = re.compile(pattern, re.IGNORECASE)\n\n        if strip:\n            return strip_spaces(pattern)\n        else:\n            return pattern\n    else:\n        return pattern\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        return re.compile(pattern, re.VERBOSE if strip else 0)\n    elif isinstance(pattern, re._pattern_type):\n        return pattern\n    else:\n        raise TypeError('Input must be str or re._pattern_type')\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        if pattern == '':\n            pattern = None\n        else:\n            pattern = re.compile(pattern)\n            if strip:\n                pattern.strip(' ')\n    return pattern\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        pattern = re.compile(pattern)\n    elif isinstance(pattern, re._pattern_type):\n        pass\n    elif isinstance(pattern, regex._pattern_type):\n        pass\n    else:\n        raise TypeError(\"Invalid type to convert to regex pattern object\")\n\n    if strip:\n        pattern = pattern.strip()\n\n    return pattern\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, (str, bytes)):\n        return re.compile(pattern, re.UNICODE if strip else re.I)\n    elif isinstance(pattern, re._pattern_type):\n        return pattern\n    elif isinstance(pattern, (list, tuple)):\n        return [get_pattern(s, strip) for s in pattern]\n    else:\n        raise ValueError(\"Pattern must be string or regex pattern object\")\n", "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        return re.compile(pattern, re.UNICODE if strip else re.DOTALL)\n    elif isinstance(pattern, re._pattern_type):\n        return pattern\n    else:\n        raise TypeError(\"pattern must be str or re._pattern_type\")\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def get_pattern(pattern, strip=True):\n    regex = re.compile(pattern)\n    if strip:\n        regex = regex.strip()\n    return regex\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        return re.compile(pattern, re.IGNORECASE)\n    elif isinstance(pattern, regex.Pattern):\n        return pattern\n    elif isinstance(pattern, (list, tuple)):\n        return [get_pattern(p, strip) for p in pattern]\n    else:\n        return pattern\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, re._pattern_type):\n        return pattern\n\n    if isinstance(pattern, str):\n        if strip:\n            return re.compile(pattern.strip())\n        else:\n            return re.compile(pattern)\n    else:\n        raise TypeError(\"pattern must be a string or a re._pattern_type\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        return re.compile(pattern, re.IGNORECASE | re.UNICODE)\n    elif isinstance(pattern, re._pattern_type):\n        return pattern\n    elif isinstance(pattern, (list, tuple)):\n        return [get_pattern(i, strip) for i in pattern]\n    else:\n        raise TypeError(\"Unsupported type to compile regex pattern '{}'\".format(type(pattern)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        pattern = re.compile(pattern, re.IGNORECASE)\n\n        if strip:\n            return strip_spaces(pattern)\n        else:\n            return pattern\n    else:\n        return pattern\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        return re.compile(pattern, re.VERBOSE if strip else 0)\n    elif isinstance(pattern, re._pattern_type):\n        return pattern\n    else:\n        raise TypeError('Input must be str or re._pattern_type')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        if pattern == '':\n            pattern = None\n        else:\n            pattern = re.compile(pattern)\n            if strip:\n                pattern.strip(' ')\n    return pattern\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        pattern = re.compile(pattern)\n    elif isinstance(pattern, re._pattern_type):\n        pass\n    elif isinstance(pattern, regex._pattern_type):\n        pass\n    else:\n        raise TypeError(\"Invalid type to convert to regex pattern object\")\n\n    if strip:\n        pattern = pattern.strip()\n\n    return pattern\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, (str, bytes)):\n        return re.compile(pattern, re.UNICODE if strip else re.I)\n    elif isinstance(pattern, re._pattern_type):\n        return pattern\n    elif isinstance(pattern, (list, tuple)):\n        return [get_pattern(s, strip) for s in pattern]\n    else:\n        raise ValueError(\"Pattern must be string or regex pattern object\")\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get_pattern(pattern, strip=True):\n    if isinstance(pattern, str):\n        return re.compile(pattern, re.UNICODE if strip else re.DOTALL)\n    elif isinstance(pattern, re._pattern_type):\n        return pattern\n    else:\n        raise TypeError(\"pattern must be str or re._pattern_type\")\n", "is_pass": true, "return_code": 0}]}
{"file_path": "slib_runnable/test_7.py", "name": "run_command", "docstring": "Call the given command(s).", "ques_id": "62ece4992e6aefcf4aabbd83", "code": ["def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n                print(e", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    if env is None: env = os.environ\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                stdout=subprocess.PIPE, stderr=(subprocess.PIPE if hide_stderr\n                    else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    if not isinstance(commands, list):\n        commands = [commands]\n\n    # put the arguments in a list so that if we run this multiple times,\n    # we will not trigger an error when trying to run the same command\n    args = list(args)\n\n    if env is None:\n        env = os.environ.copy()\n\n    if verbose:\n        print(\"Running %d %s %s\" % (len(args), \" \".join(commands), \"with arguments: %s\" % (\" \".join([pipes.quote(a) for a in args]))))\n\n    p = None\n    for c in commands:\n        p = Popen(c, args=args, cwd=cwd, env=env)\n        stdout, stderr = p.communicate()\n        if stderr:\n            if hide_stderr:\n                sys.stderr.write(stderr)\n            return None, p.returncode\n    return stdout, p.returncode\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    assert isinstance(args, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                          else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                prin", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    if isinstance(commands, str):\n        commands = [commands]\n    return run_commands(commands, args, cwd=cwd, verbose=verbose, hide_stderr=hide_stderr, env=env)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    if env is None:\n        env = os.environ.copy()\n    if cwd is None:\n        cwd = os.getcwd()\n    p = None\n    for c in commands:\n        try:\n            p = subprocess.Popen(\n                c, args=args, stdout=subprocess.PIPE, stderr=(subprocess.PIPE if hide_stderr else None)\n                # env=env,\n                cwd=cwd,\n                env=env,\n            )\n            break\n        except OSError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % c)\n                print(e)\n            return None, None\n   "], "level": "slib_runnable", "generate_results": [{"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n                print(e", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    if env is None: env = os.environ\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                stdout=subprocess.PIPE, stderr=(subprocess.PIPE if hide_stderr\n                    else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n                print(e)\n            return None, None\n    else:\n        if verbose:\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    if not isinstance(commands, list):\n        commands = [commands]\n\n    # put the arguments in a list so that if we run this multiple times,\n    # we will not trigger an error when trying to run the same command\n    args = list(args)\n\n    if env is None:\n        env = os.environ.copy()\n\n    if verbose:\n        print(\"Running %d %s %s\" % (len(args), \" \".join(commands), \"with arguments: %s\" % (\" \".join([pipes.quote(a) for a in args]))))\n\n    p = None\n    for c in commands:\n        p = Popen(c, args=args, cwd=cwd, env=env)\n        stdout, stderr = p.communicate()\n        if stderr:\n            if hide_stderr:\n                sys.stderr.write(stderr)\n            return None, p.returncode\n    return stdout, p.returncode\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    assert isinstance(args, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                          else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                prin", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    if isinstance(commands, str):\n        commands = [commands]\n    return run_commands(commands, args, cwd=cwd, verbose=verbose, hide_stderr=hide_stderr, env=env)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    if env is None:\n        env = os.environ.copy()\n    if cwd is None:\n        cwd = os.getcwd()\n    p = None\n    for c in commands:\n        try:\n            p = subprocess.Popen(\n                c, args=args, stdout=subprocess.PIPE, stderr=(subprocess.PIPE if hide_stderr else None)\n                # env=env,\n                cwd=cwd,\n                env=env,\n            )\n            break\n        except OSError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % c)\n                print(e)\n            return None, None\n   ", "is_pass": false, "return_code": 1}]}
{"file_path": "plib_runnable/test_4.py", "name": "is_ipv4", "docstring": "Test if IPv4 address or not\n    ", "ques_id": "62ece4992e6aefcf4aabbd84", "code": ["def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}]}
{"file_path": "plib_runnable/test_11.py", "name": "find_roots", "docstring": "Find the roots in some sort of transitive hierarchy.\n\nfind_roots(graph, rdflib.RDFS.subClassOf)\nwill return a set of all roots of the sub-class hierarchy\n\nAssumes triple of the form (child, prop, parent), i.e. the direction of\nRDFS.subClassOf or SKOS.broader", "ques_id": "62ece4992e6aefcf4aabbd85", "code": ["def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form\n\n    (child, prop, parent), i.e. the direction of RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef Class\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n\n    for _, _, c in graph.triples((prop, RDFS.subClassOf, None)):\n        if c is None:\n            continue\n        if isinstance(c, set):\n            for r in c:\n                roots.add(r)\n        else:\n            roots.add(c)\n\n    return roots\n", "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef Class\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if not roots:\n        roots = set()\n    for triple in graph.objects(prop, RDFS.subClassOf):\n        if triple[0] not in roots:\n            roots.add(triple[0])\n        if triple[1] not in roots:\n            roots.add(triple[1])\n    return roots\n", "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of\n    the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of RDFS.subClassOf\n    or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef\n        roots: Optional[Set[\"Node\"]]\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n    for p, o in graph.objects(subject=prop, predicate=SKOS.broader):\n        if p == root:\n            continue\n        # p is a predicate of SKOS.broader\n        # o is the predicate of RDFS.subClassOf\n        if is_subclass(o, root):\n            roots.add(p)\n            continue\n        if is_superclass(o, root):\n    ", "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class Object\n        prop: URIRef Class\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n\n    for triple in graph.triples((prop, RDFS.subClassOf, None)):\n        root = triple[2]\n        if isinstance(root, BNode):\n            roots.add(root)\n\n    return roots\n", "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n\n    for p, o in graph.triples((prop, RDFS.subClassOf, None)):\n        if p not in roots:\n            roots.add(p)\n            roots |= find_roots(graph, o, roots)\n    return roots\n", "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef Class\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n    for pred, obj in graph.triples((prop, RDFS.subClassOf, None)):\n        if pred == SKOS.node:\n            roots.add(obj)\n        elif pred == RDFS.comment:\n            for sub in obj.labels():\n                roots.add(sub)\n    return roots\n", "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of the\n    sub-class hierarchy\n\n    Assumes triple of the form\n    (child, prop, parent), i.e. the direction of RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef Class\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n    for p, o in graph.objects(subject=prop, predicate=RDFS.subClassOf):\n        if o is None:\n            continue\n        if o in roots:\n            continue\n        roots.add(o)\n        find_roots(graph, o, roots)\n    return roots\n", "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of\n    the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class Object\n        prop: URIRef Class\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n    for child in graph.objects(\n        subject=prop, predicate=RDFS.subClassOf\n    ):\n        root = find_root(graph, child, roots)\n        if root:\n            roots.add(root)\n    return roots\n", "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of RDFS.subClassOf\n    or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n\n    for sub in graph.objects(\n        subject=prop, predicate=RDFS.subClassOf\n    ):\n        # Get the direct parent of the sub-class\n        parent = sub.superClass()\n\n        if parent is not None:\n            # Check to see if we have a triple of the form (child, prop, parent)\n            if isinstance(parent, set):\n                # Two roots in a", "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n\n    for p, o in graph.objects(subject=prop, predicate=RDFS.subClassOf):\n        if isinstance(o, SKOS.broader):\n            for r in o.broader:\n                roots.add(r)\n        elif isinstance(o, RDFS.subClassOf):\n            roots.add(o)\n        elif isinstance(o, RDFS.RDFClass):\n            for r in o.instances"], "level": "plib_runnable", "generate_results": [{"generate_code": "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form\n\n    (child, prop, parent), i.e. the direction of RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef Class\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n\n    for _, _, c in graph.triples((prop, RDFS.subClassOf, None)):\n        if c is None:\n            continue\n        if isinstance(c, set):\n            for r in c:\n                roots.add(r)\n        else:\n            roots.add(c)\n\n    return roots\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef Class\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if not roots:\n        roots = set()\n    for triple in graph.objects(prop, RDFS.subClassOf):\n        if triple[0] not in roots:\n            roots.add(triple[0])\n        if triple[1] not in roots:\n            roots.add(triple[1])\n    return roots\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of\n    the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of RDFS.subClassOf\n    or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef\n        roots: Optional[Set[\"Node\"]]\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n    for p, o in graph.objects(subject=prop, predicate=SKOS.broader):\n        if p == root:\n            continue\n        # p is a predicate of SKOS.broader\n        # o is the predicate of RDFS.subClassOf\n        if is_subclass(o, root):\n            roots.add(p)\n            continue\n        if is_superclass(o, root):\n    ", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class Object\n        prop: URIRef Class\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n\n    for triple in graph.triples((prop, RDFS.subClassOf, None)):\n        root = triple[2]\n        if isinstance(root, BNode):\n            roots.add(root)\n\n    return roots\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n\n    for p, o in graph.triples((prop, RDFS.subClassOf, None)):\n        if p not in roots:\n            roots.add(p)\n            roots |= find_roots(graph, o, roots)\n    return roots\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef Class\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n    for pred, obj in graph.triples((prop, RDFS.subClassOf, None)):\n        if pred == SKOS.node:\n            roots.add(obj)\n        elif pred == RDFS.comment:\n            for sub in obj.labels():\n                roots.add(sub)\n    return roots\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of the\n    sub-class hierarchy\n\n    Assumes triple of the form\n    (child, prop, parent), i.e. the direction of RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef Class\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n    for p, o in graph.objects(subject=prop, predicate=RDFS.subClassOf):\n        if o is None:\n            continue\n        if o in roots:\n            continue\n        roots.add(o)\n        find_roots(graph, o, roots)\n    return roots\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of\n    the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class Object\n        prop: URIRef Class\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n    for child in graph.objects(\n        subject=prop, predicate=RDFS.subClassOf\n    ):\n        root = find_root(graph, child, roots)\n        if root:\n            roots.add(root)\n    return roots\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of RDFS.subClassOf\n    or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n\n    for sub in graph.objects(\n        subject=prop, predicate=RDFS.subClassOf\n    ):\n        # Get the direct parent of the sub-class\n        parent = sub.superClass()\n\n        if parent is not None:\n            # Check to see if we have a triple of the form (child, prop, parent)\n            if isinstance(parent, set):\n                # Two roots in a", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: \"Graph\", prop: \"URIRef\", roots: Optional[Set[\"Node\"]] = None\n) -> Set[\"Node\"]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n\n    Args:\n        graph: Graph Class\n        prop: URIRef\n        roots: Optional list with set type\n\n    Return:\n        roots: a set with nodes\n    \"\"\"\n    if roots is None:\n        roots = set()\n\n    for p, o in graph.objects(subject=prop, predicate=RDFS.subClassOf):\n        if isinstance(o, SKOS.broader):\n            for r in o.broader:\n                roots.add(r)\n        elif isinstance(o, RDFS.subClassOf):\n            roots.add(o)\n        elif isinstance(o, RDFS.RDFClass):\n            for r in o.instances", "is_pass": false, "return_code": 1}]}
{"file_path": "plib_runnable/test_1.py", "name": "_dump_string", "docstring": "Dump to a py2-unicode or py3-string", "ques_id": "62ece4992e6aefcf4aabbd86", "code": ["def _dump_string(obj, dumper=None):\n    return dumper or yaml.SafeDumper\n", "def _dump_string(obj, dumper=None):\n    return dumper or yaml.representer.SafeRepresenter().represent_mapping(\n        u'tag:yaml.org,2002:str', obj)\n", "def _dump_string(obj, dumper=None):\n    return yaml.dump(\n        obj,\n        default_flow_style=False,\n        Dumper=dumper,\n        allow_unicode=True,\n        allow_system_keys=True,\n        default_flow_style=False,\n    )\n", "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = yaml.SafeDumper\n    return dumper.dump(obj)\n", "def _dump_string(obj, dumper=None):\n    return dumper or yaml.SafeDumper\n", "def _dump_string(obj, dumper=None):\n    return dumper or yaml.SafeDumper\n", "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = yaml.SafeDumper\n    return dumper.represent_scalar('tag:yaml.org,2002:str', str(obj))\n", "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = yaml.SafeDumper\n    return dumper.represent_mapping(u'tag:yaml.org,2002:str', obj)\n", "def _dump_string(obj, dumper=None):\n    return yaml.dump(\n        obj, Dumper=dumper,\n        default_flow_style=False, allow_unicode=True\n    )\n", "def _dump_string(obj, dumper=None):\n    return dumper or yaml.SafeDumper\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def _dump_string(obj, dumper=None):\n    return dumper or yaml.SafeDumper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    return dumper or yaml.representer.SafeRepresenter().represent_mapping(\n        u'tag:yaml.org,2002:str', obj)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    return yaml.dump(\n        obj,\n        default_flow_style=False,\n        Dumper=dumper,\n        allow_unicode=True,\n        allow_system_keys=True,\n        default_flow_style=False,\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = yaml.SafeDumper\n    return dumper.dump(obj)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    return dumper or yaml.SafeDumper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    return dumper or yaml.SafeDumper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = yaml.SafeDumper\n    return dumper.represent_scalar('tag:yaml.org,2002:str', str(obj))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = yaml.SafeDumper\n    return dumper.represent_mapping(u'tag:yaml.org,2002:str', obj)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    return yaml.dump(\n        obj, Dumper=dumper,\n        default_flow_style=False, allow_unicode=True\n    )\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _dump_string(obj, dumper=None):\n    return dumper or yaml.SafeDumper\n", "is_pass": false, "return_code": 1}]}
{"file_path": "plib_runnable/test_8.py", "name": "build_app_logger", "docstring": "General purpose application logger. Useful mainly for debugging", "ques_id": "62ece4992e6aefcf4aabbd87", "code": ["def build_app_logger(name='app', logfile='app.log', debug=True):\n    # Create logger\n    logger = logging.getLogger(name)\n    # Set log file name\n    log_file_name = \"%s.log\" % logfile\n    log_file_path = os.path.join(os.path.dirname(__file__), log_file_name)\n    # Set log level\n    logger.setLevel(logging.INFO)\n    # Log file handler\n    log_handler = logging.FileHandler(log_file_path)\n    # Log format\n    log_handler.setFormatter(\n        logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n    # Log handler\n    logger.addHandler(log_handler)\n    if debug:\n        logger.setLevel(logging.DEBUG)\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    app_logger = logging.getLogger(name)\n    app_logger.setLevel(logging.INFO)\n\n    # create console handler and set level to debug\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.DEBUG)\n\n    # create formatter\n    formatter = logging.Formatter(fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    # add formatter to ch\n    ch.setFormatter(formatter)\n\n    # add ch to logger\n    app_logger.addHandler(ch)\n\n    # add formatter to app_logger\n    app_logger.addHandler(formatter)\n\n    if debug:\n        app_logger.setLevel(logging.DEBUG)\n\n    return app_logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n\n    # create console handler and set level to debug\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.DEBUG)\n\n    # create formatter\n    formatter = logging.Formatter(\n        fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    )\n\n    # add formatter to ch\n    ch.setFormatter(formatter)\n\n    # add ch to logger\n    logger.addHandler(ch)\n\n    if debug:\n        logger.debug('logging initialized')\n    else:\n        logger.info('logging initialized')\n\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n\n    # create console handler and set level to debug\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.DEBUG)\n\n    # create formatter\n    formatter = logging.Formatter(\n        fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n        datefmt='%Y-%m-%d %H:%M:%S')\n\n    # add formatter to ch\n    ch.setFormatter(formatter)\n\n    # add ch to logger\n    logger.addHandler(ch)\n\n    if debug:\n        logger.debug('set debug mode')\n\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.INFO)\n\n    if debug:\n        handler.setLevel(logging.DEBUG)\n\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler.setFormatter(formatter)\n\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n    logger.addHandler(handler)\n\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    # Create logger\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n\n    # Configure file handler\n    handler = logging.FileHandler(logfile, 'w')\n    handler.setLevel(logging.INFO)\n\n    # Configure console handler\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.INFO)\n\n    # Add formatter\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    # Add formatter to handler\n    handler.setFormatter(formatter)\n    console_handler.setFormatter(formatter)\n\n    # Add handlers to logger\n    logger.addHandler(handler)\n    logger.addHandler(console_handler)\n\n    # Logger format\n    logger.info('Logger started')\n\n    if debug:\n        logger.setLevel(logging.DEBUG)\n\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    log_format = '%(asctime)s - %(levelname)s - %(message)s'\n    log_date_format = '%Y-%m-%d %H:%M:%S'\n\n    log_level = logging.INFO\n\n    if debug:\n        log_level = logging.DEBUG\n\n    handler = logging.FileHandler(logfile, mode='w')\n    handler.setFormatter(logging.Formatter(log_format))\n\n    logger = logging.getLogger(name)\n    logger.setLevel(log_level)\n    logger.addHandler(handler)\n\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    if debug:\n        logger.setLevel(logging.DEBUG)\n\n    # create console handler and set level to debug\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.DEBUG)\n\n    # create formatter\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    # add formatter to ch\n    ch.setFormatter(formatter)\n\n    # add ch to logger\n    logger.addHandler(ch)\n\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logformat = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n    logdatefmt = '%m/%d/%Y %I:%M:%S %p'\n    handler = logging.StreamHandler()\n    handler.setFormatter(logging.Formatter(logformat, logdatefmt))\n\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n    logger.addHandler(handler)\n\n    if debug:\n        logger.addHandler(logging.NullHandler())\n\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n\n    # create console handler and set level to debug\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.DEBUG)\n\n    # create formatter\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    # add formatter to ch\n    ch.setFormatter(formatter)\n\n    # add ch to logger\n    logger.addHandler(ch)\n\n    # add logger to debug mode\n    if debug:\n        logger.setLevel(logging.DEBUG)\n\n    return logger\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    # Create logger\n    logger = logging.getLogger(name)\n    # Set log file name\n    log_file_name = \"%s.log\" % logfile\n    log_file_path = os.path.join(os.path.dirname(__file__), log_file_name)\n    # Set log level\n    logger.setLevel(logging.INFO)\n    # Log file handler\n    log_handler = logging.FileHandler(log_file_path)\n    # Log format\n    log_handler.setFormatter(\n        logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n    # Log handler\n    logger.addHandler(log_handler)\n    if debug:\n        logger.setLevel(logging.DEBUG)\n    return logger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    app_logger = logging.getLogger(name)\n    app_logger.setLevel(logging.INFO)\n\n    # create console handler and set level to debug\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.DEBUG)\n\n    # create formatter\n    formatter = logging.Formatter(fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    # add formatter to ch\n    ch.setFormatter(formatter)\n\n    # add ch to logger\n    app_logger.addHandler(ch)\n\n    # add formatter to app_logger\n    app_logger.addHandler(formatter)\n\n    if debug:\n        app_logger.setLevel(logging.DEBUG)\n\n    return app_logger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n\n    # create console handler and set level to debug\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.DEBUG)\n\n    # create formatter\n    formatter = logging.Formatter(\n        fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    )\n\n    # add formatter to ch\n    ch.setFormatter(formatter)\n\n    # add ch to logger\n    logger.addHandler(ch)\n\n    if debug:\n        logger.debug('logging initialized')\n    else:\n        logger.info('logging initialized')\n\n    return logger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n\n    # create console handler and set level to debug\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.DEBUG)\n\n    # create formatter\n    formatter = logging.Formatter(\n        fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n        datefmt='%Y-%m-%d %H:%M:%S')\n\n    # add formatter to ch\n    ch.setFormatter(formatter)\n\n    # add ch to logger\n    logger.addHandler(ch)\n\n    if debug:\n        logger.debug('set debug mode')\n\n    return logger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.INFO)\n\n    if debug:\n        handler.setLevel(logging.DEBUG)\n\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler.setFormatter(formatter)\n\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n    logger.addHandler(handler)\n\n    return logger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    # Create logger\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n\n    # Configure file handler\n    handler = logging.FileHandler(logfile, 'w')\n    handler.setLevel(logging.INFO)\n\n    # Configure console handler\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.INFO)\n\n    # Add formatter\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    # Add formatter to handler\n    handler.setFormatter(formatter)\n    console_handler.setFormatter(formatter)\n\n    # Add handlers to logger\n    logger.addHandler(handler)\n    logger.addHandler(console_handler)\n\n    # Logger format\n    logger.info('Logger started')\n\n    if debug:\n        logger.setLevel(logging.DEBUG)\n\n    return logger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    log_format = '%(asctime)s - %(levelname)s - %(message)s'\n    log_date_format = '%Y-%m-%d %H:%M:%S'\n\n    log_level = logging.INFO\n\n    if debug:\n        log_level = logging.DEBUG\n\n    handler = logging.FileHandler(logfile, mode='w')\n    handler.setFormatter(logging.Formatter(log_format))\n\n    logger = logging.getLogger(name)\n    logger.setLevel(log_level)\n    logger.addHandler(handler)\n\n    return logger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    if debug:\n        logger.setLevel(logging.DEBUG)\n\n    # create console handler and set level to debug\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.DEBUG)\n\n    # create formatter\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    # add formatter to ch\n    ch.setFormatter(formatter)\n\n    # add ch to logger\n    logger.addHandler(ch)\n\n    return logger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logformat = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n    logdatefmt = '%m/%d/%Y %I:%M:%S %p'\n    handler = logging.StreamHandler()\n    handler.setFormatter(logging.Formatter(logformat, logdatefmt))\n\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n    logger.addHandler(handler)\n\n    if debug:\n        logger.addHandler(logging.NullHandler())\n\n    return logger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n\n    # create console handler and set level to debug\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.DEBUG)\n\n    # create formatter\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    # add formatter to ch\n    ch.setFormatter(formatter)\n\n    # add ch to logger\n    logger.addHandler(ch)\n\n    # add logger to debug mode\n    if debug:\n        logger.setLevel(logging.DEBUG)\n\n    return logger\n", "is_pass": false, "return_code": 1}]}
{"file_path": "plib_runnable/test_6.py", "name": "make_array", "docstring": "Function to create an array with shape and dtype.\n\nParameters\n----------\nshape : tuple\n    shape of the array to create\ndtype : `numpy.dtype`\n    data-type of the array to create", "ques_id": "62ece4992e6aefcf4aabbd88", "code": ["def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0, dtype=dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0, dtype=dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0, dtype=dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0, dtype=dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0.0, dtype=dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0, dtype=dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0.0, dtype=dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, 0.0, dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0.0, dtype=dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0, dtype=dtype)\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0, dtype=dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0, dtype=dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0, dtype=dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0, dtype=dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0.0, dtype=dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0, dtype=dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0.0, dtype=dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, 0.0, dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0.0, dtype=dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.full(shape, fill_value=0, dtype=dtype)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "plib_runnable/test_2.py", "name": "gaussian", "docstring": "Gaussian centered around 0.2 with a sigma of 0.1.", "ques_id": "62ece4992e6aefcf4aabbd89", "code": ["def gaussian(x):\n    return np.exp(-(x ** 2) / (2 * sigma ** 2))\n", "def gaussian(x):\n    return np.exp(-np.power(x-0.2, 2)/(2*np.power(10, 6))) * np.exp(-np.power(x-0.1, 2)/(2*np.power(10, 6)))\n", "def gaussian(x):\n    return np.exp(-(x**2)/(2*0.2**2)) / (2*np.pi*0.2**2)\n", "def gaussian(x):\n    return np.exp(-(x**2)/(2*0.2**2)) / np.sqrt(2*np.pi*0.2**2)\n", "def gaussian(x):\n    return np.exp(-(x - 0.2)**2 / (2 * 0.1**2))\n", "def gaussian(x):\n    return np.exp(-np.power(x-0.2, 2)/(2*np.power(10, 2))) * np.exp(-np.power(x-0.1, 2)/(2*np.power(10, 2)))\n", "def gaussian(x):\n    return np.exp(-(x**2) / (2*(2*np.pi)**2)) / np.sqrt(2*np.pi)\n", "def gaussian(x):\n    return np.exp(-(x**2)/(2*0.2**2)) / (2*np.pi*0.2**2)\n", "def gaussian(x):\n    return np.exp(-(x**2) / (2*0.2**2)) / np.sqrt(2*np.pi*0.2**2)\n", "def gaussian(x):\n    return np.exp(-np.power(x-0.2, 2)/(2*np.power(10, 2))) / np.sqrt(2*np.pi*10)\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def gaussian(x):\n    return np.exp(-(x ** 2) / (2 * sigma ** 2))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def gaussian(x):\n    return np.exp(-np.power(x-0.2, 2)/(2*np.power(10, 6))) * np.exp(-np.power(x-0.1, 2)/(2*np.power(10, 6)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def gaussian(x):\n    return np.exp(-(x**2)/(2*0.2**2)) / (2*np.pi*0.2**2)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def gaussian(x):\n    return np.exp(-(x**2)/(2*0.2**2)) / np.sqrt(2*np.pi*0.2**2)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def gaussian(x):\n    return np.exp(-(x - 0.2)**2 / (2 * 0.1**2))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def gaussian(x):\n    return np.exp(-np.power(x-0.2, 2)/(2*np.power(10, 2))) * np.exp(-np.power(x-0.1, 2)/(2*np.power(10, 2)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def gaussian(x):\n    return np.exp(-(x**2) / (2*(2*np.pi)**2)) / np.sqrt(2*np.pi)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def gaussian(x):\n    return np.exp(-(x**2)/(2*0.2**2)) / (2*np.pi*0.2**2)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def gaussian(x):\n    return np.exp(-(x**2) / (2*0.2**2)) / np.sqrt(2*np.pi*0.2**2)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def gaussian(x):\n    return np.exp(-np.power(x-0.2, 2)/(2*np.power(10, 2))) / np.sqrt(2*np.pi*10)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "plib_runnable/test_13.py", "name": "load_configurations", "docstring": "Given a sequence of configuration filenames, load and validate each configuration file. Return\nthe results as a tuple of: dict of configuration filename to corresponding parsed configuration,\nand sequence of logging.LogRecord instances containing any parse errors.", "ques_id": "62ece4992e6aefcf4aabbd8a", "code": ["def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    try:\n        return load_configurations_from_files(config_filenames,\n                                              overrides,\n                                              resolve_env)\n    except (ConfigurationError, UnknownConfigurationError) as e:\n        return _handle_config_errors(e)\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = _load_configurations(config_filenames, overrides, resolve_env)\n\n    errors = {}\n    for filename, config in six.iteritems(configs):\n        try:\n            config.validate()\n        except config.parser.ParseError as e:\n            errors[filename] = e\n\n    if errors:\n        for filename, exception in six.iteritems(errors):\n            logger.error('%s: %s', filename, exception)\n        raise ConfigurationError(errors)\n\n    return configs, errors\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = load_config_files(config_filenames, resolve_env=resolve_env)\n\n    for config in configs:\n        validate_configuration(config, overrides)\n\n    return configs, configs.errors\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = load_configs(config_filenames, resolve_env=resolve_env)\n    parsers = _get_parsers(configs)\n    logging.basicConfig()\n    for config in configs:\n        results = _parse_configuration(config, parsers)\n        if results is not None:\n            logging.info('Parsed configuration %s', config)\n            yield results\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    return load_configs(config_filenames,\n                        overrides=overrides,\n                        resolve_env=resolve_env)\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = []\n    for config_filename in config_filenames:\n        try:\n            with open(config_filename, 'r') as f:\n                configs.append(load_config(f, overrides=overrides,\n                                          resolve_env=resolve_env))\n        except Exception:\n            # Skip over any config errors\n            pass\n    return configs, [err for err in validate_configurations(configs)]\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = load_config_files(config_filenames, resolve_env=resolve_env)\n\n    errors = []\n    for config_filename, config in configs.items():\n        try:\n            config.validate()\n        except InvalidConfigError as e:\n            errors.append(e.args[0])\n            continue\n\n        # Skip validation if the parser cannot parse the configuration file\n        if not config.is_valid():\n            errors.append(\"Configuration file is not valid: %s\" % config_filename)\n            continue\n\n        result = parse_configuration(config, overrides)\n        result['filename'] = config_filename\n        yield result\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = load_configuration_files(config_filenames, resolve_env)\n    return _validate_and_return_configs(configs, overrides)\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    # type: (Sequence[Text], Optional[Mapping[Text, Mapping[Text, Text]]], bool) -> Tuple[Mapping[Text, Mapping[Text, Text]], Iterable[logging.LogRecord]]\n    \"\"\"\n    Given a sequence of configuration filenames, load and validate each configuration file.\n    If the configuration file cannot be read due to insufficient permissions or error parsing\n    configuration file, the error log will be recorded. Otherwise, return the results as a\n    tuple of: dict of configuration filename to corresponding parsed configuration, and sequence\n    of logging.LogRecords containing any parse errors.\n    \"\"\"\n    error_log = logging.getLogger(__name__)\n\n    for filename in config_filenames:\n        config = load_configuration(filename, overrides, resolve_env)\n        if not config:\n            error_log.error(\"Configuration file %s could not be loaded\", filename)\n            continue\n\n        parsed_config, records = config_parser.parse_configuration(config)\n        if not records:\n       ", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = []\n    for config_filename in config_filenames:\n        try:\n            config = load_configuration(config_filename, overrides,\n                                        resolve_env)\n        except IOError:\n            config = {}\n        except Exception as e:\n            record_error(e, config_filename)\n            config['error'] = True\n        else:\n            configs.append(config)\n        if not config.get('error'):\n            return configs, config_filename\n\n    return configs, None\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    try:\n        return load_configurations_from_files(config_filenames,\n                                              overrides,\n                                              resolve_env)\n    except (ConfigurationError, UnknownConfigurationError) as e:\n        return _handle_config_errors(e)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = _load_configurations(config_filenames, overrides, resolve_env)\n\n    errors = {}\n    for filename, config in six.iteritems(configs):\n        try:\n            config.validate()\n        except config.parser.ParseError as e:\n            errors[filename] = e\n\n    if errors:\n        for filename, exception in six.iteritems(errors):\n            logger.error('%s: %s', filename, exception)\n        raise ConfigurationError(errors)\n\n    return configs, errors\n", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = load_config_files(config_filenames, resolve_env=resolve_env)\n\n    for config in configs:\n        validate_configuration(config, overrides)\n\n    return configs, configs.errors\n", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = load_configs(config_filenames, resolve_env=resolve_env)\n    parsers = _get_parsers(configs)\n    logging.basicConfig()\n    for config in configs:\n        results = _parse_configuration(config, parsers)\n        if results is not None:\n            logging.info('Parsed configuration %s', config)\n            yield results\n", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    return load_configs(config_filenames,\n                        overrides=overrides,\n                        resolve_env=resolve_env)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = []\n    for config_filename in config_filenames:\n        try:\n            with open(config_filename, 'r') as f:\n                configs.append(load_config(f, overrides=overrides,\n                                          resolve_env=resolve_env))\n        except Exception:\n            # Skip over any config errors\n            pass\n    return configs, [err for err in validate_configurations(configs)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = load_config_files(config_filenames, resolve_env=resolve_env)\n\n    errors = []\n    for config_filename, config in configs.items():\n        try:\n            config.validate()\n        except InvalidConfigError as e:\n            errors.append(e.args[0])\n            continue\n\n        # Skip validation if the parser cannot parse the configuration file\n        if not config.is_valid():\n            errors.append(\"Configuration file is not valid: %s\" % config_filename)\n            continue\n\n        result = parse_configuration(config, overrides)\n        result['filename'] = config_filename\n        yield result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = load_configuration_files(config_filenames, resolve_env)\n    return _validate_and_return_configs(configs, overrides)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    # type: (Sequence[Text], Optional[Mapping[Text, Mapping[Text, Text]]], bool) -> Tuple[Mapping[Text, Mapping[Text, Text]], Iterable[logging.LogRecord]]\n    \"\"\"\n    Given a sequence of configuration filenames, load and validate each configuration file.\n    If the configuration file cannot be read due to insufficient permissions or error parsing\n    configuration file, the error log will be recorded. Otherwise, return the results as a\n    tuple of: dict of configuration filename to corresponding parsed configuration, and sequence\n    of logging.LogRecords containing any parse errors.\n    \"\"\"\n    error_log = logging.getLogger(__name__)\n\n    for filename in config_filenames:\n        config = load_configuration(filename, overrides, resolve_env)\n        if not config:\n            error_log.error(\"Configuration file %s could not be loaded\", filename)\n            continue\n\n        parsed_config, records = config_parser.parse_configuration(config)\n        if not records:\n       ", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = []\n    for config_filename in config_filenames:\n        try:\n            config = load_configuration(config_filename, overrides,\n                                        resolve_env)\n        except IOError:\n            config = {}\n        except Exception as e:\n            record_error(e, config_filename)\n            config['error'] = True\n        else:\n            configs.append(config)\n        if not config.get('error'):\n            return configs, config_filename\n\n    return configs, None\n", "is_pass": false, "return_code": 1}]}
{"file_path": "plib_runnable/test_3.py", "name": "force_string", "docstring": "This function returns the bytes object corresponding to ``obj``\nin case it is a string using UTF-8. ", "ques_id": "62ece4992e6aefcf4aabbd8b", "code": ["def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode(\"utf-8\")\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode(\"utf-8\")\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode(\"utf-8\")\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "is_pass": true, "return_code": 0}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "is_pass": true, "return_code": 0}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "is_pass": true, "return_code": 0}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode(\"utf-8\")\n    return obj\n", "is_pass": true, "return_code": 0}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "is_pass": true, "return_code": 0}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "is_pass": true, "return_code": 0}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode(\"utf-8\")\n    return obj\n", "is_pass": true, "return_code": 0}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "is_pass": true, "return_code": 0}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode(\"utf-8\")\n    return obj\n", "is_pass": true, "return_code": 0}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj.decode('utf-8')\n    return obj\n", "is_pass": true, "return_code": 0}]}
{"file_path": "neo4j/time/__init__.py", "project": "neo4j/neo4j-python-driver", "name": "from_ticks", "docstring": "Create a time from ticks (nanoseconds since midnight).\n\n:param ticks: nanoseconds since midnight\n:type ticks: int\n:param tz: optional timezone\n:type tz: datetime.tzinfo\n\n:rtype: Time\n\n:raises ValueError: if ticks is out of bounds\n    (0 <= ticks < 86400000000000)", "ques_id": "62e60723d76274f8a4026b76", "code": ["def from_ticks(cls, ticks, tz=None):\n    return cls._from_time(\n        _time.mktime(_time.gmtime(ticks)[:6] + (0,)), tz)\n", "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError(\"ticks must be >= 0\")\n    if ticks > 86400000000000:\n        raise ValueError(\"ticks must be <= 86400000000000\")\n\n    if tz is None:\n        tz = dateutil_tz.tzlocal()\n\n    return cls(tz.localize(ticks * 1e-9, is_dst=None))\n", "def from_ticks(cls, ticks, tz=None):\n    return cls.from_datetime(datetime.utcfromtimestamp(ticks), tz)\n", "def from_ticks(cls, ticks, tz=None):\n    if not 0 <= ticks < 86400000000:\n        raise ValueError(\"ticks out of bounds (0 <= ticks < 86400000000)\")\n\n    return cls._from_time_struct(_time_from_ticks(ticks, tz))\n", "def from_ticks(cls, ticks, tz=None):\n    if not 0 <= ticks < 86400000000:\n        raise ValueError(\"ticks out of bounds (0 <= ticks < 86400000000000)\")\n\n    return cls._from_time(\n        time.gmtime(ticks * 1000000000), tz=tz)\n", "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError('ticks must be greater than zero')\n    if ticks > (86400000000 * 1000):\n        raise ValueError('ticks must be less than 86400000000000')\n\n    if tz is None:\n        tz = _get_timezone()\n\n    return cls(tz.localize(datetime.time(ticks // 1000, ticks % 1000)))\n", "def from_ticks(cls, ticks, tz=None):\n    if not 0 <= ticks < 86400000000:\n        raise ValueError('ticks out of bounds (0 <= ticks < 86400000000)')\n\n    if tz is None:\n        tz = _get_timezone('UTC')\n\n    dt = datetime.datetime.utcfromtimestamp(ticks / 1000000000)\n    return cls.from_datetime(dt, tz)\n", "def from_ticks(cls, ticks, tz=None):\n    if not 0 <= ticks < 86400000000:\n        raise ValueError(\"ticks out of bounds (0 <= ticks < 86400000000)\")\n\n    return cls._from_time(\n        Time.from_ns(ticks, tz),\n        tz\n    )\n", "def from_ticks(cls, ticks, tz=None):\n    tz = tz or dateutil_tz.tzlocal()\n    return cls(ticks * 1000000000, tz)\n", "def from_ticks(cls, ticks, tz=None):\n    return cls._from_timestamp(*time.gmtime(ticks * 1e3 / 1000000000, tz))\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def from_ticks(cls, ticks, tz=None):\n    return cls._from_time(\n        _time.mktime(_time.gmtime(ticks)[:6] + (0,)), tz)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError(\"ticks must be >= 0\")\n    if ticks > 86400000000000:\n        raise ValueError(\"ticks must be <= 86400000000000\")\n\n    if tz is None:\n        tz = dateutil_tz.tzlocal()\n\n    return cls(tz.localize(ticks * 1e-9, is_dst=None))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    return cls.from_datetime(datetime.utcfromtimestamp(ticks), tz)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if not 0 <= ticks < 86400000000:\n        raise ValueError(\"ticks out of bounds (0 <= ticks < 86400000000)\")\n\n    return cls._from_time_struct(_time_from_ticks(ticks, tz))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if not 0 <= ticks < 86400000000:\n        raise ValueError(\"ticks out of bounds (0 <= ticks < 86400000000000)\")\n\n    return cls._from_time(\n        time.gmtime(ticks * 1000000000), tz=tz)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError('ticks must be greater than zero')\n    if ticks > (86400000000 * 1000):\n        raise ValueError('ticks must be less than 86400000000000')\n\n    if tz is None:\n        tz = _get_timezone()\n\n    return cls(tz.localize(datetime.time(ticks // 1000, ticks % 1000)))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if not 0 <= ticks < 86400000000:\n        raise ValueError('ticks out of bounds (0 <= ticks < 86400000000)')\n\n    if tz is None:\n        tz = _get_timezone('UTC')\n\n    dt = datetime.datetime.utcfromtimestamp(ticks / 1000000000)\n    return cls.from_datetime(dt, tz)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if not 0 <= ticks < 86400000000:\n        raise ValueError(\"ticks out of bounds (0 <= ticks < 86400000000)\")\n\n    return cls._from_time(\n        Time.from_ns(ticks, tz),\n        tz\n    )\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    tz = tz or dateutil_tz.tzlocal()\n    return cls(ticks * 1000000000, tz)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    return cls._from_timestamp(*time.gmtime(ticks * 1e3 / 1000000000, tz))\n", "is_pass": true, "return_code": 0}]}
{"file_path": "neo4j/_async/io/_bolt.py", "project": "neo4j/neo4j-python-driver", "name": "protocol_handlers", "docstring": "Return a dictionary of available Bolt protocol handlers,\nkeyed by version tuple. If an explicit protocol version is\nprovided, the dictionary will contain either zero or one items,\ndepending on whether that version is supported. If no protocol\nversion is provided, all available versions will be returned.\n\n:param protocol_version: tuple identifying a specific protocol\n    version (e.g. (3, 5)) or None\n:return: dictionary of version tuple to handler class for all\n    relevant and supported protocol versions\n:raise TypeError: if protocol version is not passed in a tuple", "ques_id": "62e60873d76274f8a4026bd8", "code": ["def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        versions = cls.VERSIONS\n    else:\n        versions = [protocol_version] + list(protocol_version)\n\n    return {version: cls.handler_for_version(version) for version in versions}\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        versions = cls._protocol_versions\n        return {v: k for k, v in versions.items()}\n    else:\n        v = protocol_version\n        if not isinstance(v, tuple):\n            raise TypeError(\n                'protocol_version must be a tuple or None; got {!r}'.format(v))\n        return {v[0]: k for k, v in versions.items() if v[1] == v[2]}\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n    elif protocol_version in cls._protocol_handlers:\n        return cls._protocol_handlers[protocol_version]\n    else:\n        raise TypeError(\n            'protocol_version {} not supported by {}'.format(\n                protocol_version, cls.__name__))\n", "def protocol_handlers(cls, protocol_version=None):\n    version_tuples = _protocol_version_to_handlers.get(protocol_version, None)\n    if version_tuples is None:\n        version_tuples = _protocol_version_to_handlers[protocol_version] = {}\n    return version_tuples\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        versions = cls._VERSIONS\n    else:\n        versions = [protocol_version] + list(cls._VERSIONS)\n\n    handlers = {}\n    for version in versions:\n        handlers[version] = getattr(BoltHandler, 'protocol_' + str(version))\n\n    return handlers\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n    else:\n        return cls._protocol_handlers.get(protocol_version, {})\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        versions = cls._protocol_versions\n    else:\n        versions = [protocol_version] + cls._protocol_versions\n\n    return {version: cls._handler_for_version(version) for version in versions}\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return _protocol_handlers\n\n    return {\n        version: protocol_handler\n        for version, protocol_handler in _protocol_handlers.items()\n        if version >= protocol_version\n    }\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return _protocol_handlers\n    elif not isinstance(protocol_version, tuple):\n        raise TypeError(\n            'protocol_version must be a tuple or None, not {}'.format(\n                protocol_version))\n    return {\n        version: getattr(Bolt, 'handle_{}'.format(version))\n        for version in _protocol_handlers\n        if (version in protocol_version)\n    }\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return _PROTOCOL_HANDLER_CLASSES\n    else:\n        try:\n            return {\n                version: getattr(BoltProtocol, 'handle_{}'.format(version))\n                for version in _PROTOCOL_HANDLER_CLASSES[protocol_version]\n            }\n        except KeyError:\n            raise TypeError(\n                'protocol_version {} is not supported'.format(protocol_version))\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        versions = cls.VERSIONS\n    else:\n        versions = [protocol_version] + list(protocol_version)\n\n    return {version: cls.handler_for_version(version) for version in versions}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        versions = cls._protocol_versions\n        return {v: k for k, v in versions.items()}\n    else:\n        v = protocol_version\n        if not isinstance(v, tuple):\n            raise TypeError(\n                'protocol_version must be a tuple or None; got {!r}'.format(v))\n        return {v[0]: k for k, v in versions.items() if v[1] == v[2]}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n    elif protocol_version in cls._protocol_handlers:\n        return cls._protocol_handlers[protocol_version]\n    else:\n        raise TypeError(\n            'protocol_version {} not supported by {}'.format(\n                protocol_version, cls.__name__))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    version_tuples = _protocol_version_to_handlers.get(protocol_version, None)\n    if version_tuples is None:\n        version_tuples = _protocol_version_to_handlers[protocol_version] = {}\n    return version_tuples\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        versions = cls._VERSIONS\n    else:\n        versions = [protocol_version] + list(cls._VERSIONS)\n\n    handlers = {}\n    for version in versions:\n        handlers[version] = getattr(BoltHandler, 'protocol_' + str(version))\n\n    return handlers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n    else:\n        return cls._protocol_handlers.get(protocol_version, {})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        versions = cls._protocol_versions\n    else:\n        versions = [protocol_version] + cls._protocol_versions\n\n    return {version: cls._handler_for_version(version) for version in versions}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return _protocol_handlers\n\n    return {\n        version: protocol_handler\n        for version, protocol_handler in _protocol_handlers.items()\n        if version >= protocol_version\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return _protocol_handlers\n    elif not isinstance(protocol_version, tuple):\n        raise TypeError(\n            'protocol_version must be a tuple or None, not {}'.format(\n                protocol_version))\n    return {\n        version: getattr(Bolt, 'handle_{}'.format(version))\n        for version in _protocol_handlers\n        if (version in protocol_version)\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return _PROTOCOL_HANDLER_CLASSES\n    else:\n        try:\n            return {\n                version: getattr(BoltProtocol, 'handle_{}'.format(version))\n                for version in _PROTOCOL_HANDLER_CLASSES[protocol_version]\n            }\n        except KeyError:\n            raise TypeError(\n                'protocol_version {} is not supported'.format(protocol_version))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/api.py", "project": "neo4j/neo4j-python-driver", "name": "from_raw_values", "docstring": "Create a Bookmarks object from a list of raw bookmark string values.\n\nYou should not need to use this method unless you want to deserialize\nbookmarks.\n\n:param values: ASCII string values (raw bookmarks)\n:type values: Iterable[str]", "ques_id": "62e60e3bd76274f8a4026d1a", "code": ["def from_raw_values(cls, values):\n    return cls([values[x] for x in cls._fields])\n", "def from_raw_values(cls, values):\n    return cls(values)\n", "def from_raw_values(cls, values):\n    return cls(values)\n", "def from_raw_values(cls, values):\n    return cls([b.strip() for b in values.split(\",\")])\n", "def from_raw_values(cls, values):\n    return cls(values)\n", "def from_raw_values(cls, values):\n    return cls([values])\n", "def from_raw_values(cls, values):\n    return cls(values[0], values[1], values[2], values[3])\n", "def from_raw_values(cls, values):\n    return cls(None, values)\n", "def from_raw_values(cls, values):\n    return cls(values)\n", "def from_raw_values(cls, values):\n    return cls([value.strip() for value in values.split(\",\")])\n"], "level": "self_contained", "generate_results": [{"generate_code": "def from_raw_values(cls, values):\n    return cls([values[x] for x in cls._fields])\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(values)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(values)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls([b.strip() for b in values.split(\",\")])\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(values)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls([values])\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(values[0], values[1], values[2], values[3])\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(None, values)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(values)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls([value.strip() for value in values.split(\",\")])\n", "is_pass": true, "return_code": 0}]}
{"file_path": "lena/core/split.py", "project": "ynikitenko/lena", "name": "_get_seq_with_type", "docstring": "Return a (sequence, type) pair.\nSequence is derived from *seq*\n(or is *seq*, if that is of a sequence type).", "ques_id": "62b87b199a0c4fa8b80b354c", "code": ["def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = sys.getsizeof(seq)\n        seq = seq.__class__, bufsize\n    else:\n        seq = seq, bufsize\n    return seq\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        # This is already a sequence, return it directly.\n        return seq, seq._type\n    if isinstance(seq, type):\n        # This is a type, return it as-is.\n        return seq, seq\n    if isinstance(seq, basestring):\n        # This is a string instead, so just return it.\n        return seq, seq\n    if bufsize is None:\n        bufsize = sys.getsizeof(seq)\n    if not isinstance(seq, (list, tuple)):\n        raise TypeError(\"'seq' must be a sequence, not %r\" % seq)\n    if len(seq) < bufsize:\n        raise ValueError(\"'seq' must have at least %d elements, not %d\"\n                         % (bufsize, len(seq)))\n    # This is a bit of a mess: we create a new list of the right size\n    ", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is not None:\n            return seq._get_typed_seq(bufsize)\n        else:\n            return seq\n    else:\n        return (seq, type(seq))\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = sys.getsizeof(seq)\n        return (_get_seq_as_str(seq), _get_seq_as_type(seq, bufsize))\n    elif isinstance(seq, (str, bytes, bytearray)):\n        return (_get_seq_as_str(seq), _get_seq_as_type(seq, bufsize))\n    else:\n        raise TypeError('seq must be a string or bytes, bytearray, '\n                        'or Sequence, not %r' % seq)\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = sys.getsizeof(seq)\n        return (seq.__class__, (type(seq),) + _get_seq_with_type(seq.__class__, bufsize))\n    else:\n        return (seq, type(seq))\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        # if we were given an iterator then we need to convert it into a\n        # tuple containing the underlying data.  This avoids having\n        # to make an empty tuple for something else than an iterator.\n        if isinstance(seq, Iterator):\n            seq = tuple(seq)\n        return seq, type(seq)\n    else:\n        if bufsize is None:\n            bufsize = sys.getsizeof(seq)\n        return seq, type(seq)\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = sys.getrefcount(seq)\n        t = _SequenceType\n    else:\n        t = _GenericType\n\n    if hasattr(seq, '__len__'):\n        if bufsize is None:\n            bufsize = sys.getrefcount(seq)\n        return tuple(_get_seq_with_type(i, bufsize) for i in seq)\n    else:\n        return (t(seq), t)\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, type):\n        return seq, seq.__name__\n    elif isinstance(seq, Sequence):\n        return seq, type(seq).__name__\n    elif isinstance(seq, type) and issubclass(seq, BaseException):\n        return seq, 'exception'\n    else:\n        return seq, 'generic'\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = sys.getsizeof(seq)\n        return (seq.__class__, type(seq))\n    else:\n        return (type(seq), type(seq))\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence) or isinstance(seq, Mapping):\n        if bufsize is None:\n            bufsize = sys.getsizeof(seq)\n        return (tuple(seq), type(seq))\n    else:\n        return (seq, type(seq))\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = sys.getsizeof(seq)\n        seq = seq.__class__, bufsize\n    else:\n        seq = seq, bufsize\n    return seq\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        # This is already a sequence, return it directly.\n        return seq, seq._type\n    if isinstance(seq, type):\n        # This is a type, return it as-is.\n        return seq, seq\n    if isinstance(seq, basestring):\n        # This is a string instead, so just return it.\n        return seq, seq\n    if bufsize is None:\n        bufsize = sys.getsizeof(seq)\n    if not isinstance(seq, (list, tuple)):\n        raise TypeError(\"'seq' must be a sequence, not %r\" % seq)\n    if len(seq) < bufsize:\n        raise ValueError(\"'seq' must have at least %d elements, not %d\"\n                         % (bufsize, len(seq)))\n    # This is a bit of a mess: we create a new list of the right size\n    ", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is not None:\n            return seq._get_typed_seq(bufsize)\n        else:\n            return seq\n    else:\n        return (seq, type(seq))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = sys.getsizeof(seq)\n        return (_get_seq_as_str(seq), _get_seq_as_type(seq, bufsize))\n    elif isinstance(seq, (str, bytes, bytearray)):\n        return (_get_seq_as_str(seq), _get_seq_as_type(seq, bufsize))\n    else:\n        raise TypeError('seq must be a string or bytes, bytearray, '\n                        'or Sequence, not %r' % seq)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = sys.getsizeof(seq)\n        return (seq.__class__, (type(seq),) + _get_seq_with_type(seq.__class__, bufsize))\n    else:\n        return (seq, type(seq))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        # if we were given an iterator then we need to convert it into a\n        # tuple containing the underlying data.  This avoids having\n        # to make an empty tuple for something else than an iterator.\n        if isinstance(seq, Iterator):\n            seq = tuple(seq)\n        return seq, type(seq)\n    else:\n        if bufsize is None:\n            bufsize = sys.getsizeof(seq)\n        return seq, type(seq)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = sys.getrefcount(seq)\n        t = _SequenceType\n    else:\n        t = _GenericType\n\n    if hasattr(seq, '__len__'):\n        if bufsize is None:\n            bufsize = sys.getrefcount(seq)\n        return tuple(_get_seq_with_type(i, bufsize) for i in seq)\n    else:\n        return (t(seq), t)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, type):\n        return seq, seq.__name__\n    elif isinstance(seq, Sequence):\n        return seq, type(seq).__name__\n    elif isinstance(seq, type) and issubclass(seq, BaseException):\n        return seq, 'exception'\n    else:\n        return seq, 'generic'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = sys.getsizeof(seq)\n        return (seq.__class__, type(seq))\n    else:\n        return (type(seq), type(seq))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence) or isinstance(seq, Mapping):\n        if bufsize is None:\n            bufsize = sys.getsizeof(seq)\n        return (tuple(seq), type(seq))\n    else:\n        return (seq, type(seq))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/histogram.py", "project": "ynikitenko/lena", "name": "scale", "docstring": "Compute or set scale (integral of the histogram).\n\nIf *other* is ``None``, return scale of this histogram.\nIf its scale was not computed before,\nit is computed and stored for subsequent use\n(unless explicitly asked to *recompute*).\nNote that after changing (filling) the histogram\none must explicitly recompute the scale\nif it was computed before.\n\nIf a float *other* is provided, rescale self to *other*.\n\nHistograms with scale equal to zero can't be rescaled.\n:exc:`.LenaValueError` is raised if one tries to do that.", "ques_id": "62b87b4f9a0c4fa8b80b3581", "code": ["def scale(self, other=None, recompute=False):\n\n    if self._scale is not None and not recompute:\n        if other is None:\n            other = self._scale\n        else:\n            try:\n                self._scale = other / self._count\n            except ZeroDivisionError:\n                raise LenaValueError(\"scale of %s cannot be recomputed\" % (self,))\n\n    self._count = 0\n    self._sum = 0\n\n    if self._scale is not None:\n        self._update_scale(other)\n", "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        other = self._hist.scale\n    elif not isinstance(other, numbers.Number):\n        raise LenaHistError(\n            \"Attempted to rescale histogram with a non-numerical value\")\n\n    if self._scale is not None and other!= self._scale:\n        if recompute:\n            self.recompute()\n        else:\n            raise LenaHistError(\n                \"Histogram scale was not set properly after changing (filling)\")\n\n    self._scale = other\n", "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        # compute scale of the histogram\n        try:\n            scale = self._hist.scale()\n        except AttributeError:\n            scale = 0.0\n        else:\n            if recompute:\n                self.recompute()\n                scale = self._hist.scale()\n\n        return scale\n    else:\n        # set scale of the histogram\n        self._hist.scale(other)\n\n        # update scale if necessary\n        if recompute:\n            self.recompute()\n", "def scale(self, other=None, recompute=False):\n\n    if self._scale is not None and not recompute and other is not None:\n        raise LenaHistoError(\"Scale of histo already computed!\")\n\n    if self._scale is None and other is not None:\n        self._scale = self._compute_scale(other)\n    elif self._scale is None and recompute and other is None:\n        self.recompute(fill=False)\n\n    return self._scale\n", "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        if self.scale is not None:\n            return\n        other = self.new()\n\n    # if scale is not computed, compute it\n    if not self.scale:\n        self._compute_scale(other)\n\n    # otherwise, set scale of self to the provided value\n    else:\n        self._scale = other\n        if recompute:\n            self.recompute()\n", "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        # compute from the size of the histogram\n        return self._hist.scale(recompute)\n\n    # otherwise, we can scale the histogram with the given other\n    # (unless explicitly asked to recompute)\n    else:\n        if not recompute:\n            return self._hist.scale(other)\n\n        # otherwise, compute the scale of the histogram with the same\n        # parameters as the other histogram and store the scale in the\n        # scale attribute\n        self._hist.scale(other, recompute)\n        self.setScale(other.getScale())\n", "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        if not self.is_scaled:\n            self.scale_to_zero()\n            recompute = True\n    else:\n        if not self.is_scaled:\n            self.set_scale(other)\n            recompute = True\n\n    return recompute\n", "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        scale = self._scale\n    else:\n        if self._scale is not None and other is not None:\n            raise LenaError(\"Histograms with scale equal to zero cannot be rescaled\")\n        else:\n            self._scale = other\n            if recompute:\n                self.recompute()\n", "def scale(self, other=None, recompute=False):\n\n    # check if scale was not computed yet\n    if self._scale is None and other is not None:\n        if recompute:\n            self._scale = self._compute_scale(other)\n        else:\n            self._scale = other\n    else:\n        if recompute:\n            self._scale = 0.0\n\n    return self._scale\n", "def scale(self, other=None, recompute=False):\n\n    if other is not None:\n        if self._scale is not None and self._scale!= other:\n            raise LenaHistogramError(\"Histograms with scale equal to zero cannot be rescaled\")\n        self._scale = other\n        self._update_scale(recompute)\n    else:\n        return self._scale\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def scale(self, other=None, recompute=False):\n\n    if self._scale is not None and not recompute:\n        if other is None:\n            other = self._scale\n        else:\n            try:\n                self._scale = other / self._count\n            except ZeroDivisionError:\n                raise LenaValueError(\"scale of %s cannot be recomputed\" % (self,))\n\n    self._count = 0\n    self._sum = 0\n\n    if self._scale is not None:\n        self._update_scale(other)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        other = self._hist.scale\n    elif not isinstance(other, numbers.Number):\n        raise LenaHistError(\n            \"Attempted to rescale histogram with a non-numerical value\")\n\n    if self._scale is not None and other!= self._scale:\n        if recompute:\n            self.recompute()\n        else:\n            raise LenaHistError(\n                \"Histogram scale was not set properly after changing (filling)\")\n\n    self._scale = other\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        # compute scale of the histogram\n        try:\n            scale = self._hist.scale()\n        except AttributeError:\n            scale = 0.0\n        else:\n            if recompute:\n                self.recompute()\n                scale = self._hist.scale()\n\n        return scale\n    else:\n        # set scale of the histogram\n        self._hist.scale(other)\n\n        # update scale if necessary\n        if recompute:\n            self.recompute()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if self._scale is not None and not recompute and other is not None:\n        raise LenaHistoError(\"Scale of histo already computed!\")\n\n    if self._scale is None and other is not None:\n        self._scale = self._compute_scale(other)\n    elif self._scale is None and recompute and other is None:\n        self.recompute(fill=False)\n\n    return self._scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        if self.scale is not None:\n            return\n        other = self.new()\n\n    # if scale is not computed, compute it\n    if not self.scale:\n        self._compute_scale(other)\n\n    # otherwise, set scale of self to the provided value\n    else:\n        self._scale = other\n        if recompute:\n            self.recompute()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        # compute from the size of the histogram\n        return self._hist.scale(recompute)\n\n    # otherwise, we can scale the histogram with the given other\n    # (unless explicitly asked to recompute)\n    else:\n        if not recompute:\n            return self._hist.scale(other)\n\n        # otherwise, compute the scale of the histogram with the same\n        # parameters as the other histogram and store the scale in the\n        # scale attribute\n        self._hist.scale(other, recompute)\n        self.setScale(other.getScale())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        if not self.is_scaled:\n            self.scale_to_zero()\n            recompute = True\n    else:\n        if not self.is_scaled:\n            self.set_scale(other)\n            recompute = True\n\n    return recompute\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        scale = self._scale\n    else:\n        if self._scale is not None and other is not None:\n            raise LenaError(\"Histograms with scale equal to zero cannot be rescaled\")\n        else:\n            self._scale = other\n            if recompute:\n                self.recompute()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    # check if scale was not computed yet\n    if self._scale is None and other is not None:\n        if recompute:\n            self._scale = self._compute_scale(other)\n        else:\n            self._scale = other\n    else:\n        if recompute:\n            self._scale = 0.0\n\n    return self._scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is not None:\n        if self._scale is not None and self._scale!= other:\n            raise LenaHistogramError(\"Histograms with scale equal to zero cannot be rescaled\")\n        self._scale = other\n        self._update_scale(recompute)\n    else:\n        return self._scale\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/graph.py", "project": "ynikitenko/lena", "name": "scale", "docstring": "Get or set the scale of the graph.\n\nIf *other* is ``None``, return the scale of this graph.\n\nIf a numeric *other* is provided, rescale to that value.\nIf the graph has unknown or zero scale,\nrescaling that will raise :exc:`~.LenaValueError`.\n\nTo get meaningful results, graph's fields are used.\nOnly the last coordinate is rescaled.\nFor example, if the graph has *x* and *y* coordinates,\nthen *y* will be rescaled, and for a 3-dimensional graph\n*z* will be rescaled.\nAll errors are rescaled together with their coordinate.", "ques_id": "62b87b519a0c4fa8b80b3583", "code": ["def scale(self, other=None):\n    if other is None:\n        return self._scale\n    else:\n        if isinstance(other, (int, float)):\n            self._scale = other\n        else:\n            try:\n                self._scale = float(other)\n            except ValueError:\n                raise LenaError(\n                    \"Unrecognized scale '%s' for graph '%s'.\" % (other, self.name)\n                )\n", "def scale(self, other=None):\n    if other is not None:\n        if isinstance(other, Lena):\n            other = other.to_lena()\n        elif not isinstance(other, Lena):\n            raise TypeError('unsupported type to scale graph with')\n        self._lena.scale(other)\n        self.rescale_graph_fields()\n    return self._lena.scale\n", "def scale(self, other=None):\n    if other is not None:\n        self._check_other_coord(other)\n        self._check_scale(other)\n        self._scale = other\n        self._check_rescaling()\n    return self._scale\n", "def scale(self, other=None):\n    if other is not None:\n        if not isinstance(other, Lena):\n            other = self.__class__(other)\n        self._rescale(other)\n    return self._scale\n", "def scale(self, other=None):\n    if other:\n        self._rescale(other, scale=True)\n    return self._scale\n", "def scale(self, other=None):\n    if other:\n        if not isinstance(other, Lena):\n            other = self.__class__(other)\n        if self.__class__ is other.__class__:\n            if self.__dict__ == other.__dict__:\n                return self.__dict__\n            else:\n                self.__dict__ = other.__dict__\n                self.__init__()\n        else:\n            raise TypeError(\n                \"Graphics can only scale the coordinates of other \"\n                \"Lena objects (not {})\".format(self.__class__))\n    else:\n        self.__init__()\n        self.__scale = self.__last\n    return self.__scale\n", "def scale(self, other=None):\n    if other is not None:\n        other = self._check_other_coord(other)\n        self._update_scale(other)\n    return self._scale\n", "def scale(self, other=None):\n    if other is not None:\n        self._check_other_coord(other)\n        self._rescale(other)\n    return self._scale\n", "def scale(self, other=None):\n    if other is not None:\n        if not isinstance(other, numbers.Number):\n            raise TypeError('Graph.scale requires number arguments')\n        if other < 0:\n            other = self._nodes[-1][1] * -1\n        elif other >= self._nodes[-1][1]:\n            other = self._nodes[-1][1]\n        self._check_scale(other)\n    self._set_scale(self._nodes, other)\n", "def scale(self, other=None):\n    if other:\n        if not isinstance(other, Lena):\n            other = Lena(other)\n        self._check_dimensions(other)\n        self._check_same_lena()\n        self._check_valid()\n        self._scale = other._scale\n        self._last = other._last\n    else:\n        return self._scale\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def scale(self, other=None):\n    if other is None:\n        return self._scale\n    else:\n        if isinstance(other, (int, float)):\n            self._scale = other\n        else:\n            try:\n                self._scale = float(other)\n            except ValueError:\n                raise LenaError(\n                    \"Unrecognized scale '%s' for graph '%s'.\" % (other, self.name)\n                )\n", "is_pass": true, "return_code": 0}, {"generate_code": "def scale(self, other=None):\n    if other is not None:\n        if isinstance(other, Lena):\n            other = other.to_lena()\n        elif not isinstance(other, Lena):\n            raise TypeError('unsupported type to scale graph with')\n        self._lena.scale(other)\n        self.rescale_graph_fields()\n    return self._lena.scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other is not None:\n        self._check_other_coord(other)\n        self._check_scale(other)\n        self._scale = other\n        self._check_rescaling()\n    return self._scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other is not None:\n        if not isinstance(other, Lena):\n            other = self.__class__(other)\n        self._rescale(other)\n    return self._scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other:\n        self._rescale(other, scale=True)\n    return self._scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other:\n        if not isinstance(other, Lena):\n            other = self.__class__(other)\n        if self.__class__ is other.__class__:\n            if self.__dict__ == other.__dict__:\n                return self.__dict__\n            else:\n                self.__dict__ = other.__dict__\n                self.__init__()\n        else:\n            raise TypeError(\n                \"Graphics can only scale the coordinates of other \"\n                \"Lena objects (not {})\".format(self.__class__))\n    else:\n        self.__init__()\n        self.__scale = self.__last\n    return self.__scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other is not None:\n        other = self._check_other_coord(other)\n        self._update_scale(other)\n    return self._scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other is not None:\n        self._check_other_coord(other)\n        self._rescale(other)\n    return self._scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other is not None:\n        if not isinstance(other, numbers.Number):\n            raise TypeError('Graph.scale requires number arguments')\n        if other < 0:\n            other = self._nodes[-1][1] * -1\n        elif other >= self._nodes[-1][1]:\n            other = self._nodes[-1][1]\n        self._check_scale(other)\n    self._set_scale(self._nodes, other)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other:\n        if not isinstance(other, Lena):\n            other = Lena(other)\n        self._check_dimensions(other)\n        self._check_same_lena()\n        self._check_valid()\n        self._scale = other._scale\n        self._last = other._last\n    else:\n        return self._scale\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/hist_functions.py", "project": "ynikitenko/lena", "name": "hist_to_graph", "docstring": "Convert a :class:`.histogram` to a :class:`.graph`.\n\n*make_value* is a function to set the value of a graph's point.\nBy default it is bin content.\n*make_value* accepts a single value (bin content) without context.\n\nThis option could be used to create graph's error bars.\nFor example, to create a graph with errors\nfrom a histogram where bins contain\na named tuple with fields *mean*, *mean_error* and a context\none could use\n\n>>> make_value = lambda bin_: (bin_.mean, bin_.mean_error)\n\n*get_coordinate* defines what the coordinate\nof a graph point created from a histogram bin will be.\nIt can be \"left\" (default), \"right\" and \"middle\".\n\n*field_names* set field names of the graph. Their number\nmust be the same as the dimension of the result.\nFor a *make_value* above they would be\n*(\"x\", \"y_mean\", \"y_mean_error\")*.\n\n*scale* becomes the graph's scale (unknown by default).\nIf it is ``True``, it uses the histogram scale.\n\n*hist* must contain only numeric bins (without context)\nor *make_value* must remove context when creating a numeric graph.\n\nReturn the resulting graph.", "ques_id": "62b87b869a0c4fa8b80b35e1", "code": ["def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example,\n    to create a graph with errors from a histogram where bins contain\n    a named tuple with fields *mean*, *mean_error` and a context one would\n    use.\n\n    For example, to create a graph with errors from a histogram where\n    bins contain named tuple with fields *mean*, *mean_error* and a context\n    one would use.\n\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) *get_coordinate* scale\n    >>> make_value = lambda bin_: (\"x\", \"y_mean\", \"y_mean_error\")\n    >>> get_coordinate = lambda bin_: \"middle\"\n    >>> field_names = (\"x\", \"y\")\n    >>> scale = lam", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example, to create\n    a graph with errors from a histogram where bins contain a named tuple with\n    fields *mean*, *mean_error` and a context one would be.\n\n    For example, to create a graph with errors from a histogram where bins contain\n    named tuple with fields *mean*, *mean_error* and a context one would be.\n\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) *get_coordinate* define what the\n    coordinate of a graph point created from a histogram bin will be.\n    >>> make_value = lambda bin_: (\"x\", \"y_mean\", \"y_mean_error\")\n    >>> field_names = (\"x\", \"y\")\n    >>> scale = None", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example,\n    to create a graph with errors from a histogram where bins contain\n    a named tuple with fields *mean*, *mean_error` and a context one would\n    use.\n\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) *get_coordinate* defines what the coordinate of a graph\n    >>> make_value = lambda bin_: (\"left\", \"right\")\n    >>> field_names = (\"mean\", \"mean_error\")\n    >>> scale = None\n    >>> hist.make_value = make_value\n    >>> hist.get_coordinate = make_value\n    >>> graph = hist_to_graph(hist, make_value=make_value, get_coordinate=get_coordinate, field_names=field_names, scale=scale)\n    >>>", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example,\n    to create a graph with errors from a histogram where bins contain\n    a named tuple with fields *mean*, *mean_error` and a context one would\n    be.\n\n    For example, to create a graph with errors from a histogram where\n    bins contain named tuples without context.  This option could be\n    used to create a numeric graph.\n\n    *field_names* set field names of the graph.\n\n    The number must be the same as the dimension of the result.  For a\n    *make_value* above it would be *(\"x\", \"y_mean\", \"y_mean_error\")*.  This\n    can be used to create a numeric graph's scale (unknown by default).\n\n    >>> make_value ", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example,\n    to create a graph with errors from a histogram where bins contain\n    a named tuple with fields *mean*, *mean_error` and a context one would be.\n\n    For example, to create a graph with errors from a histogram where\n    bins contain named tuple with fields *mean*, *mean_error* and a context\n    one would be.\n\n    *field_names* set field names of the graph.\n\n    Though it can be \"left\" (default), \"right\" and \"middle\". *field_names*\n    set field names of the graph.\n\n    We can use *scale* to set the scale of the graph when created a numeric\n    graph.\n\n    Return the resulting graph.\n    \"\"\"\n    return hist_to", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example,\n    to create a graph with errors from a histogram where bins contain\n    a named tuple with fields *mean*, *mean_error` and a context one would\n    use.\n\n    For example, to create a graph with errors from a histogram where\n    bins contain named tuple with fields *mean*, *mean_error* and a context\n    one would use.\n\n    *field_names* set field names of the graph.\n\n    This can be used to create the graph's scale (unknown by default).\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) *get_coordinate* defines\n                                                   ", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example,\n    to create a graph with errors from a histogram where bins contain\n    a named tuple with fields *mean*, *mean_error` and a context one would\n    use.\n\n    For example, to create a graph with errors from a histogram where\n    bins contain a named tuple with fields *mean*, *mean_error`.\n\n    This option could be used to create a numeric graph.\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate* defines what the coordinate of a graph point created from a histogram bin will be. It can be \"left\" (default), \"right\" and \"middle\".\n\n    >>> make_value = lambda bin_: (\"x\", \"y_mean\",", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For\n    example, to create a graph with errors from a histogram where bins\n    contain a named tuple with fields *mean*, *mean_error` and a context\n    one would use.\n\n    For example, to create a graph with errors from a histogram where bins\n    contain named tuples without context. This can be used to create a\n    numeric graph.\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) *get_coordinate*                                                                                                                         ", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example, to\n    create a graph with errors from a histogram where bins contain\n    a named tuple with fields *mean*, *mean_error` and a context one would\n    use.\n\n    For example, to create a graph with errors from a histogram where\n    bins contain named tuple with fields *mean*, *mean_error` and a context\n    one would use.\n\n\n    *field_names* set field names of the graph. The number must be the same\n    as the dimension of the result. For a *make_value* above they would be\n    *(\"x\", \"y_mean\", \"y_mean_error\")*. *scale* behaves the same as the\n    histogram scale. If it is ``True``, it uses the ", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n    This option could be used to create graph's error bars.\n\n    For example, to create a graph with errors from a histogram where\n    bins contain a named tuple with fields *mean*, *mean_error` and\n    a context one would be.\n\n    *field_names* set field names of the graph.\n\n    The number must be the same as the dimension of the result. For a\n    *make_value* above they would be.    *scale* behaves the same as the\n    graph's scale.    *hist* must contain only numeric bins (without context).\n\n    Return the resulting graph.\n    \"\"\"\n    if scale is None:\n        scale = get_coordinate(hist)\n\n    result = {}\n    for key in field_names:\n        resu"], "level": "project_runnable", "generate_results": [{"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example,\n    to create a graph with errors from a histogram where bins contain\n    a named tuple with fields *mean*, *mean_error` and a context one would\n    use.\n\n    For example, to create a graph with errors from a histogram where\n    bins contain named tuple with fields *mean*, *mean_error* and a context\n    one would use.\n\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) *get_coordinate* scale\n    >>> make_value = lambda bin_: (\"x\", \"y_mean\", \"y_mean_error\")\n    >>> get_coordinate = lambda bin_: \"middle\"\n    >>> field_names = (\"x\", \"y\")\n    >>> scale = lam", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example, to create\n    a graph with errors from a histogram where bins contain a named tuple with\n    fields *mean*, *mean_error` and a context one would be.\n\n    For example, to create a graph with errors from a histogram where bins contain\n    named tuple with fields *mean*, *mean_error* and a context one would be.\n\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) *get_coordinate* define what the\n    coordinate of a graph point created from a histogram bin will be.\n    >>> make_value = lambda bin_: (\"x\", \"y_mean\", \"y_mean_error\")\n    >>> field_names = (\"x\", \"y\")\n    >>> scale = None", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example,\n    to create a graph with errors from a histogram where bins contain\n    a named tuple with fields *mean*, *mean_error` and a context one would\n    use.\n\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) *get_coordinate* defines what the coordinate of a graph\n    >>> make_value = lambda bin_: (\"left\", \"right\")\n    >>> field_names = (\"mean\", \"mean_error\")\n    >>> scale = None\n    >>> hist.make_value = make_value\n    >>> hist.get_coordinate = make_value\n    >>> graph = hist_to_graph(hist, make_value=make_value, get_coordinate=get_coordinate, field_names=field_names, scale=scale)\n    >>>", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example,\n    to create a graph with errors from a histogram where bins contain\n    a named tuple with fields *mean*, *mean_error` and a context one would\n    be.\n\n    For example, to create a graph with errors from a histogram where\n    bins contain named tuples without context.  This option could be\n    used to create a numeric graph.\n\n    *field_names* set field names of the graph.\n\n    The number must be the same as the dimension of the result.  For a\n    *make_value* above it would be *(\"x\", \"y_mean\", \"y_mean_error\")*.  This\n    can be used to create a numeric graph's scale (unknown by default).\n\n    >>> make_value ", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example,\n    to create a graph with errors from a histogram where bins contain\n    a named tuple with fields *mean*, *mean_error` and a context one would be.\n\n    For example, to create a graph with errors from a histogram where\n    bins contain named tuple with fields *mean*, *mean_error* and a context\n    one would be.\n\n    *field_names* set field names of the graph.\n\n    Though it can be \"left\" (default), \"right\" and \"middle\". *field_names*\n    set field names of the graph.\n\n    We can use *scale* to set the scale of the graph when created a numeric\n    graph.\n\n    Return the resulting graph.\n    \"\"\"\n    return hist_to", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example,\n    to create a graph with errors from a histogram where bins contain\n    a named tuple with fields *mean*, *mean_error` and a context one would\n    use.\n\n    For example, to create a graph with errors from a histogram where\n    bins contain named tuple with fields *mean*, *mean_error* and a context\n    one would use.\n\n    *field_names* set field names of the graph.\n\n    This can be used to create the graph's scale (unknown by default).\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) *get_coordinate* defines\n                                                   ", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example,\n    to create a graph with errors from a histogram where bins contain\n    a named tuple with fields *mean*, *mean_error` and a context one would\n    use.\n\n    For example, to create a graph with errors from a histogram where\n    bins contain a named tuple with fields *mean*, *mean_error`.\n\n    This option could be used to create a numeric graph.\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate* defines what the coordinate of a graph point created from a histogram bin will be. It can be \"left\" (default), \"right\" and \"middle\".\n\n    >>> make_value = lambda bin_: (\"x\", \"y_mean\",", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For\n    example, to create a graph with errors from a histogram where bins\n    contain a named tuple with fields *mean*, *mean_error` and a context\n    one would use.\n\n    For example, to create a graph with errors from a histogram where bins\n    contain named tuples without context. This can be used to create a\n    numeric graph.\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) *get_coordinate*                                                                                                                         ", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For example, to\n    create a graph with errors from a histogram where bins contain\n    a named tuple with fields *mean*, *mean_error` and a context one would\n    use.\n\n    For example, to create a graph with errors from a histogram where\n    bins contain named tuple with fields *mean*, *mean_error` and a context\n    one would use.\n\n\n    *field_names* set field names of the graph. The number must be the same\n    as the dimension of the result. For a *make_value* above they would be\n    *(\"x\", \"y_mean\", \"y_mean_error\")*. *scale* behaves the same as the\n    histogram scale. If it is ``True``, it uses the ", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n    This option could be used to create graph's error bars.\n\n    For example, to create a graph with errors from a histogram where\n    bins contain a named tuple with fields *mean*, *mean_error` and\n    a context one would be.\n\n    *field_names* set field names of the graph.\n\n    The number must be the same as the dimension of the result. For a\n    *make_value* above they would be.    *scale* behaves the same as the\n    graph's scale.    *hist* must contain only numeric bins (without context).\n\n    Return the resulting graph.\n    \"\"\"\n    if scale is None:\n        scale = get_coordinate(hist)\n\n    result = {}\n    for key in field_names:\n        resu", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/verify.py", "project": "pexip/os-zope", "name": "_verify", "docstring": "Verify that *candidate* might correctly provide *iface*.\n\nThis involves:\n\n- Making sure the candidate claims that it provides the\n  interface using ``iface.providedBy`` (unless *tentative* is `True`,\n  in which case this step is skipped). This means that the candidate's class\n  declares that it `implements <zope.interface.implementer>` the interface,\n  or the candidate itself declares that it `provides <zope.interface.provider>`\n  the interface\n\n- Making sure the candidate defines all the necessary methods\n\n- Making sure the methods have the correct signature (to the\n  extent possible)\n\n- Making sure the candidate defines all the necessary attributes\n\n:return bool: Returns a true value if everything that could be\n   checked passed.\n:raises zope.interface.Invalid: If any of the previous\n   conditions does not hold.\n\n.. versionchanged:: 5.0\n    If multiple methods or attributes are invalid, all such errors\n    are collected and reported. Previously, only the first error was reported.\n    As a special case, if only one such error is present, it is raised\n    alone, like before.", "ques_id": "62b8b4baeb7e40a82d2d1136", "code": ["def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is None:\n        vtype = iface.providedBy(candidate)\n\n    if not tentative and vtype is not IType:\n        raise zope.interface.Invalid(\"Candidate must provide %s\" % iface.__name__)\n\n    if not hasattr(candidate, 'providedBy'):\n        raise zope.interface.Invalid(\"Candidate must provide %s\" % iface.__name__)\n\n    if vtype is IType:\n        if not hasattr(candidate, 'implements'):\n            raise zope.interface.Invalid(\"Candidate doesn't provide %s\" % iface.__name__)\n\n        if not candidate.implements(iface):\n            raise zope.interface.Invalid(\"Candidate doesn't provide %s\" % iface.__name__)\n\n    if not hasattr(candidate, '__call__'):\n        raise zope.interface.Invalid(\"Candidate must provide %s\" % iface.__name__)\n\n    if vtype is IType:\n        if not hasattr(candidate, 'validate'):\n            raise", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is None:\n        vtype = candidate.type\n    if not issubclass(vtype, InterfaceClass):\n        return False\n    if tentative:\n        return False\n    if iface.providedBy(candidate) is False:\n        return False\n    if iface.providedBy(candidate) is True:\n        return True\n    if not hasattr(candidate, '__call__'):\n        return False\n    if not hasattr(candidate, '__getitem__'):\n        return False\n    if vtype is InterfaceClass:\n        # Only allow claim of a class\n        # We don't want to expose the claim to the implementer, so we can't just test that\n        # it doesn't get passed in as an attribute.\n        return False\n    if iface.providedBy(candidate.__call__) is False:\n        return False\n    if iface.providedBy(candidate.__call__) is True:\n        return True\n", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if not tentative:\n        if not hasattr(candidate, 'providedBy'):\n            if vtype is None:\n                raise zope.interface.Invalid(\n                    \"{} does not provide {}\".format(candidate, iface.__name__))\n            else:\n                raise zope.interface.Invalid(\n                    \"{} does not provide {} with type {}\".format(\n                        candidate, iface.__name__, vtype.__name__))\n\n    return True\n", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if not candidate.providedBy(iface):\n        return False\n\n    # The candidate's class declares that it `implements` the interface, or\n    # itself declares that it `provides` it.  The candidate declares all\n    # the necessary methods, then reported.\n    if not tentative:\n        # Check if the candidate's `provides` method has the correct signature\n        # and reported all the necessary attributes\n        verifyClass(iface, iface.providedBy)\n\n        # Check if the candidate defines all the required attributes\n        for name, type_ in iface.__dict__.items():\n            verifyAttribute(iface, name, type_)\n\n    # The candidate has the correct signature and has no extra methods (already\n    # verified), so we check if the candidate actually provides the interface.\n    if not iface.providedBy(candidate):\n        return False\n\n    return True\n", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is not None:\n        if vtype not in iface.providedBy:\n            raise zope.interface.Invalid(\n                u'%s not in %s' % (vtype, iface.providedBy))\n        return True\n\n    if tentative or candidate.providedBy(iface):\n        return True\n\n    if not hasattr(candidate, '__call__'):\n        raise zope.interface.Invalid(\n            u'%s should be callable' % iface.__name__)\n\n    # Check for an explicit ``provides`` attribute\n    if hasattr(iface, 'provides'):\n        try:\n            iface.provides(iface.provides)\n        except zope.interface.Invalid as ex:\n            if not ex.args[0].startswith('Unexpected interface '):\n                raise\n\n    # Check for an implementation claim on the class\n    if hasattr(iface, '__call__'):\n        try:\n            iface(ifac", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if not candidate.providedBy(iface):\n        return False\n    if tentative:\n        raise zope.interface.Invalid(\n            'Candidate claims must be provided by %s' % iface)\n    if vtype is None:\n        vtype = iface.__class__\n    if hasattr(iface, 'providedBy'):\n        return vtype.providedBy(candidate)\n    if hasattr(candidate, 'providedBy'):\n        return vtype.providedBy(iface)\n    raise zope.interface.Invalid(\n        'Candidate claims must provide %s or %s' % (iface, candidate))\n", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if tentative and hasattr(candidate, 'providedBy'):\n        return True\n\n    if hasattr(candidate, 'provides') and not tentative:\n        if not candidate.provides(iface):\n            raise zope.interface.Invalid(\n                \"Candidate %s does not provide %s\" % (\n                    candidate, iface))\n\n    # Make sure the candidate's class declares that it `implements` the\n    # interface, or that it `provides` it (if it `implements`)\n\n    if hasattr(candidate, 'provides'):\n        iface = candidate.provides(iface)\n\n    # Make sure the candidate has the correct signature\n    if not hasattr(candidate, 'provides'):\n        if vtype is None:\n            vtype = type(candidate)\n        if not hasattr(candidate, 'provides')(vtype):\n            raise zope.interface.Invalid(\n                \"Candidate %s does not provide ", "def _verify(iface, candidate, tentative=False, vtype=None):\n    # If the candidate has an implementation, check that it provides the\n    # interface\n    if candidate.__implementation__ is not None:\n        # Make sure the candidate claims that it provides the interface\n        if not iface.providedBy(candidate):\n            raise zope.interface.Invalid(\n                \"%s claims the interface %r, but the candidate doesn't \"\n                \"provide it.\" % (iface, candidate))\n        # Make sure the candidate declares the interface\n        if not iface.providedBy(candidate.__implementation__):\n            raise zope.interface.Invalid(\n                \"%s claims the interface %r, but the candidate doesn't \"\n                \"declare it.\" % (iface, candidate))\n\n    # Make sure the candidate defines all the necessary methods\n    if not hasattr(candidate, '__providedBy__'):\n        raise zope.interface.Invalid(\n", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if tentative:\n        if hasattr(candidate, 'providedBy'):\n            return False\n        if hasattr(candidate, 'provides'):\n            return False\n        if hasattr(candidate, '__call__') and not callable(candidate):\n            return False\n        return True\n    return _verify_interface(iface, candidate, vtype=vtype)\n", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if tentative:\n        return True\n    if vtype is None:\n        vtype = iface.providedBy(candidate)\n    if not vtype:\n        return True\n    if iface.providedBy(candidate) is False:\n        raise zope.interface.Invalid(\n            \"Candidate claim must provide %s %s\" % (vtype, iface.name))\n    if not iface.providedBy(candidate):\n        raise zope.interface.Invalid(\n            \"Candidate claim must declare %s %s\" % (vtype, iface.name))\n    if not hasattr(candidate, 'providedBy'):\n        raise zope.interface.Invalid(\n            \"Candidate claim must declare %s %s\" % (vtype, iface.name))\n    return True\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is None:\n        vtype = iface.providedBy(candidate)\n\n    if not tentative and vtype is not IType:\n        raise zope.interface.Invalid(\"Candidate must provide %s\" % iface.__name__)\n\n    if not hasattr(candidate, 'providedBy'):\n        raise zope.interface.Invalid(\"Candidate must provide %s\" % iface.__name__)\n\n    if vtype is IType:\n        if not hasattr(candidate, 'implements'):\n            raise zope.interface.Invalid(\"Candidate doesn't provide %s\" % iface.__name__)\n\n        if not candidate.implements(iface):\n            raise zope.interface.Invalid(\"Candidate doesn't provide %s\" % iface.__name__)\n\n    if not hasattr(candidate, '__call__'):\n        raise zope.interface.Invalid(\"Candidate must provide %s\" % iface.__name__)\n\n    if vtype is IType:\n        if not hasattr(candidate, 'validate'):\n            raise", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is None:\n        vtype = candidate.type\n    if not issubclass(vtype, InterfaceClass):\n        return False\n    if tentative:\n        return False\n    if iface.providedBy(candidate) is False:\n        return False\n    if iface.providedBy(candidate) is True:\n        return True\n    if not hasattr(candidate, '__call__'):\n        return False\n    if not hasattr(candidate, '__getitem__'):\n        return False\n    if vtype is InterfaceClass:\n        # Only allow claim of a class\n        # We don't want to expose the claim to the implementer, so we can't just test that\n        # it doesn't get passed in as an attribute.\n        return False\n    if iface.providedBy(candidate.__call__) is False:\n        return False\n    if iface.providedBy(candidate.__call__) is True:\n        return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if not tentative:\n        if not hasattr(candidate, 'providedBy'):\n            if vtype is None:\n                raise zope.interface.Invalid(\n                    \"{} does not provide {}\".format(candidate, iface.__name__))\n            else:\n                raise zope.interface.Invalid(\n                    \"{} does not provide {} with type {}\".format(\n                        candidate, iface.__name__, vtype.__name__))\n\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if not candidate.providedBy(iface):\n        return False\n\n    # The candidate's class declares that it `implements` the interface, or\n    # itself declares that it `provides` it.  The candidate declares all\n    # the necessary methods, then reported.\n    if not tentative:\n        # Check if the candidate's `provides` method has the correct signature\n        # and reported all the necessary attributes\n        verifyClass(iface, iface.providedBy)\n\n        # Check if the candidate defines all the required attributes\n        for name, type_ in iface.__dict__.items():\n            verifyAttribute(iface, name, type_)\n\n    # The candidate has the correct signature and has no extra methods (already\n    # verified), so we check if the candidate actually provides the interface.\n    if not iface.providedBy(candidate):\n        return False\n\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is not None:\n        if vtype not in iface.providedBy:\n            raise zope.interface.Invalid(\n                u'%s not in %s' % (vtype, iface.providedBy))\n        return True\n\n    if tentative or candidate.providedBy(iface):\n        return True\n\n    if not hasattr(candidate, '__call__'):\n        raise zope.interface.Invalid(\n            u'%s should be callable' % iface.__name__)\n\n    # Check for an explicit ``provides`` attribute\n    if hasattr(iface, 'provides'):\n        try:\n            iface.provides(iface.provides)\n        except zope.interface.Invalid as ex:\n            if not ex.args[0].startswith('Unexpected interface '):\n                raise\n\n    # Check for an implementation claim on the class\n    if hasattr(iface, '__call__'):\n        try:\n            iface(ifac", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if not candidate.providedBy(iface):\n        return False\n    if tentative:\n        raise zope.interface.Invalid(\n            'Candidate claims must be provided by %s' % iface)\n    if vtype is None:\n        vtype = iface.__class__\n    if hasattr(iface, 'providedBy'):\n        return vtype.providedBy(candidate)\n    if hasattr(candidate, 'providedBy'):\n        return vtype.providedBy(iface)\n    raise zope.interface.Invalid(\n        'Candidate claims must provide %s or %s' % (iface, candidate))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if tentative and hasattr(candidate, 'providedBy'):\n        return True\n\n    if hasattr(candidate, 'provides') and not tentative:\n        if not candidate.provides(iface):\n            raise zope.interface.Invalid(\n                \"Candidate %s does not provide %s\" % (\n                    candidate, iface))\n\n    # Make sure the candidate's class declares that it `implements` the\n    # interface, or that it `provides` it (if it `implements`)\n\n    if hasattr(candidate, 'provides'):\n        iface = candidate.provides(iface)\n\n    # Make sure the candidate has the correct signature\n    if not hasattr(candidate, 'provides'):\n        if vtype is None:\n            vtype = type(candidate)\n        if not hasattr(candidate, 'provides')(vtype):\n            raise zope.interface.Invalid(\n                \"Candidate %s does not provide ", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    # If the candidate has an implementation, check that it provides the\n    # interface\n    if candidate.__implementation__ is not None:\n        # Make sure the candidate claims that it provides the interface\n        if not iface.providedBy(candidate):\n            raise zope.interface.Invalid(\n                \"%s claims the interface %r, but the candidate doesn't \"\n                \"provide it.\" % (iface, candidate))\n        # Make sure the candidate declares the interface\n        if not iface.providedBy(candidate.__implementation__):\n            raise zope.interface.Invalid(\n                \"%s claims the interface %r, but the candidate doesn't \"\n                \"declare it.\" % (iface, candidate))\n\n    # Make sure the candidate defines all the necessary methods\n    if not hasattr(candidate, '__providedBy__'):\n        raise zope.interface.Invalid(\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if tentative:\n        if hasattr(candidate, 'providedBy'):\n            return False\n        if hasattr(candidate, 'provides'):\n            return False\n        if hasattr(candidate, '__call__') and not callable(candidate):\n            return False\n        return True\n    return _verify_interface(iface, candidate, vtype=vtype)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if tentative:\n        return True\n    if vtype is None:\n        vtype = iface.providedBy(candidate)\n    if not vtype:\n        return True\n    if iface.providedBy(candidate) is False:\n        raise zope.interface.Invalid(\n            \"Candidate claim must provide %s %s\" % (vtype, iface.name))\n    if not iface.providedBy(candidate):\n        raise zope.interface.Invalid(\n            \"Candidate claim must declare %s %s\" % (vtype, iface.name))\n    if not hasattr(candidate, 'providedBy'):\n        raise zope.interface.Invalid(\n            \"Candidate claim must declare %s %s\" % (vtype, iface.name))\n    return True\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/verify.py", "project": "pexip/os-zope", "name": "verifyObject", "docstring": "Verify that *candidate* might correctly provide *iface*.\n\nThis involves:\n\n- Making sure the candidate claims that it provides the\n  interface using ``iface.providedBy`` (unless *tentative* is `True`,\n  in which case this step is skipped). This means that the candidate's class\n  declares that it `implements <zope.interface.implementer>` the interface,\n  or the candidate itself declares that it `provides <zope.interface.provider>`\n  the interface\n\n- Making sure the candidate defines all the necessary methods\n\n- Making sure the methods have the correct signature (to the\n  extent possible)\n\n- Making sure the candidate defines all the necessary attributes\n\n:return bool: Returns a true value if everything that could be\n   checked passed.\n:raises zope.interface.Invalid: If any of the previous\n   conditions does not hold.\n\n.. versionchanged:: 5.0\n    If multiple methods or attributes are invalid, all such errors\n    are collected and reported. Previously, only the first error was reported.\n    As a special case, if only one such error is present, it is raised\n    alone, like before.", "ques_id": "62b8b4baeb7e40a82d2d1137", "code": ["def verifyObject(iface, candidate, tentative=False):\n    if candidate.__class__ is not iface:\n        return False\n    if tentative:\n        # This is a tentative check, nothing to verify\n        return True\n    if hasattr(candidate, 'providedBy'):\n        verifyObject(iface, candidate.providedBy, tentative=True)\n    elif hasattr(candidate, 'provides'):\n        verifyObject(iface, candidate.provides, tentative=True)\n    elif hasattr(candidate, 'implements'):\n        verifyObject(iface, candidate.implements, tentative=True)\n    else:\n        # This is a check for an attribute that doesn't exist\n        if hasattr(candidate, '__call__'):\n            return False\n        if not tentative:\n            raise TypeError(\n                '%s is not a valid class or attribute of %s' %\n                (candidate, iface))\n    return True\n", "def verifyObject(iface, candidate, tentative=False):\n    # XXX: We might want to check for invalid claims, not just the interface\n    #       claims, and if the claim fails or the interface is not valid.  That\n    #       way, we can simply log the claim failure and raise the error.\n    claim = verifyClaim(iface, candidate)\n    if claim is False:\n        return False\n    if not tentative:\n        try:\n            iface.providedBy(claim)\n        except ComponentLookupError:\n            return False\n    return True\n", "def verifyObject(iface, candidate, tentative=False):\n    if tentative:\n        return True\n    if hasattr(candidate, 'providedBy'):\n        return verifyObject(iface, candidate.providedBy(iface), False)\n    if hasattr(candidate, 'provides'):\n        try:\n            verifyObject(iface, candidate.provides(iface), False)\n        except KeyError:\n            if tentative:\n                raise\n            return False\n    return True\n", "def verifyObject(iface, candidate, tentative=False):\n    if tentative and hasattr(candidate, 'providedBy'):\n        # In this case the previous condition checks for the provided\n        # interface to be true (i.e. it means that the candidate is\n        # explicitly provided by the context of an object).  This is\n        # performed by the candidate declaration step, so the first\n        # error reported is propagated.\n        return True\n    # All other errors are propagated immediately.\n    return zope.interface.verify.verifyObject(iface, candidate, True)\n", "def verifyObject(iface, candidate, tentative=False):\n    if not hasattr(candidate, 'providedBy'):\n        return False\n    if tentative or not hasattr(candidate, 'provides'):\n        return True\n    if iface.providedBy(candidate):\n        return True\n    if not hasattr(candidate, 'provides'):\n        return False\n    for name, method in inspect.getmembers(candidate):\n        if not hasattr(method, 'provides'):\n            return False\n        verifyObject(method, getattr(candidate, name), tentative=True)\n    return True\n", "def verifyObject(iface, candidate, tentative=False):\n    if not candidate.implementedBy(iface):\n        return False\n    if tentative and hasattr(candidate, 'providedBy'):\n        if not candidate.providedBy(iface):\n            raise zope.interface.Invalid(\n                \"%s does not provide %r\" % (candidate, iface))\n        return False\n    return True\n", "def verifyObject(iface, candidate, tentative=False):\n    if not isinstance(candidate, Candidate):\n        return False\n    if not tentative:\n        try:\n            verifyObject(iface.providedBy, candidate, False)\n        except zope.interface.Invalid:\n            return False\n    try:\n        verifyObject(iface.providedBy, candidate, True)\n    except zope.interface.Invalid:\n        return False\n    return True\n", "def verifyObject(iface, candidate, tentative=False):\n    if not candidate.providedBy(iface):\n        return False\n\n    if tentative:\n        # Check that the candidate declares the interface\n        # rather than the candidate itself.\n        providedBy = iface.providedBy\n        if providedBy is None:\n            return False\n        if not providedBy(candidate):\n            raise Invalid(\n                u\"%s claims %s which is not provided by %s\" % (\n                    iface.__name__, candidate.__name__,\n                    providedBy.__name__))\n\n    # Make sure the candidate has the correct signature\n    verifyObjectSignature(iface, candidate, iface.providedBy)\n\n    # Make sure the candidate defines all the required attributes\n    verifyObjectAttributes(iface, candidate)\n\n    return True\n", "def verifyObject(iface, candidate, tentative=False):\n    if not hasattr(candidate, 'providedBy'):\n        return False\n    if tentative or candidate.providedBy(iface):\n        return True\n    errors = []\n    for name, result in getattr(candidate, '__provides__', {}).items():\n        try:\n            result(iface)\n        except TypeError:\n            errors.append(\n                \"%r instance of %r has an invalid type %r\" %\n                (name, iface, type(iface)))\n    if errors:\n        raise Invalid(\n            \"Multiple %s claims %r of %r\" %\n            (candidate.__class__.__name__, iface, iface.__class__))\n    return True\n", "def verifyObject(iface, candidate, tentative=False):\n    if candidate.__providedBy__ is None:\n        if tentative:\n            raise zope.interface.Invalid(\"%r does not provide %r\" % (candidate, iface))\n        return False\n\n    # Make sure the candidate claims that it provides the interface\n    if not iface.providedBy(candidate):\n        raise zope.interface.Invalid(\n            \"%r does not provide %r\" % (candidate, iface))\n\n    # Make sure the candidate declares all the necessary methods\n    for name, method in inspect.getmembers(candidate):\n        if not hasattr(method, '__call__'):\n            raise zope.interface.Invalid(\n                \"%r does not declare method %r\" % (candidate, name))\n\n    return True\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if candidate.__class__ is not iface:\n        return False\n    if tentative:\n        # This is a tentative check, nothing to verify\n        return True\n    if hasattr(candidate, 'providedBy'):\n        verifyObject(iface, candidate.providedBy, tentative=True)\n    elif hasattr(candidate, 'provides'):\n        verifyObject(iface, candidate.provides, tentative=True)\n    elif hasattr(candidate, 'implements'):\n        verifyObject(iface, candidate.implements, tentative=True)\n    else:\n        # This is a check for an attribute that doesn't exist\n        if hasattr(candidate, '__call__'):\n            return False\n        if not tentative:\n            raise TypeError(\n                '%s is not a valid class or attribute of %s' %\n                (candidate, iface))\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    # XXX: We might want to check for invalid claims, not just the interface\n    #       claims, and if the claim fails or the interface is not valid.  That\n    #       way, we can simply log the claim failure and raise the error.\n    claim = verifyClaim(iface, candidate)\n    if claim is False:\n        return False\n    if not tentative:\n        try:\n            iface.providedBy(claim)\n        except ComponentLookupError:\n            return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if tentative:\n        return True\n    if hasattr(candidate, 'providedBy'):\n        return verifyObject(iface, candidate.providedBy(iface), False)\n    if hasattr(candidate, 'provides'):\n        try:\n            verifyObject(iface, candidate.provides(iface), False)\n        except KeyError:\n            if tentative:\n                raise\n            return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if tentative and hasattr(candidate, 'providedBy'):\n        # In this case the previous condition checks for the provided\n        # interface to be true (i.e. it means that the candidate is\n        # explicitly provided by the context of an object).  This is\n        # performed by the candidate declaration step, so the first\n        # error reported is propagated.\n        return True\n    # All other errors are propagated immediately.\n    return zope.interface.verify.verifyObject(iface, candidate, True)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if not hasattr(candidate, 'providedBy'):\n        return False\n    if tentative or not hasattr(candidate, 'provides'):\n        return True\n    if iface.providedBy(candidate):\n        return True\n    if not hasattr(candidate, 'provides'):\n        return False\n    for name, method in inspect.getmembers(candidate):\n        if not hasattr(method, 'provides'):\n            return False\n        verifyObject(method, getattr(candidate, name), tentative=True)\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if not candidate.implementedBy(iface):\n        return False\n    if tentative and hasattr(candidate, 'providedBy'):\n        if not candidate.providedBy(iface):\n            raise zope.interface.Invalid(\n                \"%s does not provide %r\" % (candidate, iface))\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if not isinstance(candidate, Candidate):\n        return False\n    if not tentative:\n        try:\n            verifyObject(iface.providedBy, candidate, False)\n        except zope.interface.Invalid:\n            return False\n    try:\n        verifyObject(iface.providedBy, candidate, True)\n    except zope.interface.Invalid:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if not candidate.providedBy(iface):\n        return False\n\n    if tentative:\n        # Check that the candidate declares the interface\n        # rather than the candidate itself.\n        providedBy = iface.providedBy\n        if providedBy is None:\n            return False\n        if not providedBy(candidate):\n            raise Invalid(\n                u\"%s claims %s which is not provided by %s\" % (\n                    iface.__name__, candidate.__name__,\n                    providedBy.__name__))\n\n    # Make sure the candidate has the correct signature\n    verifyObjectSignature(iface, candidate, iface.providedBy)\n\n    # Make sure the candidate defines all the required attributes\n    verifyObjectAttributes(iface, candidate)\n\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if not hasattr(candidate, 'providedBy'):\n        return False\n    if tentative or candidate.providedBy(iface):\n        return True\n    errors = []\n    for name, result in getattr(candidate, '__provides__', {}).items():\n        try:\n            result(iface)\n        except TypeError:\n            errors.append(\n                \"%r instance of %r has an invalid type %r\" %\n                (name, iface, type(iface)))\n    if errors:\n        raise Invalid(\n            \"Multiple %s claims %r of %r\" %\n            (candidate.__class__.__name__, iface, iface.__class__))\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if candidate.__providedBy__ is None:\n        if tentative:\n            raise zope.interface.Invalid(\"%r does not provide %r\" % (candidate, iface))\n        return False\n\n    # Make sure the candidate claims that it provides the interface\n    if not iface.providedBy(candidate):\n        raise zope.interface.Invalid(\n            \"%r does not provide %r\" % (candidate, iface))\n\n    # Make sure the candidate declares all the necessary methods\n    for name, method in inspect.getmembers(candidate):\n        if not hasattr(method, '__call__'):\n            raise zope.interface.Invalid(\n                \"%r does not declare method %r\" % (candidate, name))\n\n    return True\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/verify.py", "project": "pexip/os-zope", "name": "verifyClass", "docstring": "Verify that the *candidate* might correctly provide *iface*.", "ques_id": "62b8b4c1eb7e40a82d2d1139", "code": ["def verifyClass(iface, candidate, tentative=False):\n    if not verifyInterface(iface, candidate):\n        if tentative:\n            return False\n        raise TypeError(\n            \"%r doesn't provide %r\" % (candidate, iface))\n    return True\n", "def verifyClass(iface, candidate, tentative=False):\n    if not verifyInterface(iface, candidate):\n        if tentative:\n            return candidate\n        raise AssertionError(\n            \"%r did not provide %r\" % (iface, candidate))\n    return candidate\n", "def verifyClass(iface, candidate, tentative=False):\n    if not verify(iface, candidate):\n        return False\n\n    if tentative:\n        if issubclass(iface, Configurable) and issubclass(candidate, Configurable):\n            return False\n        else:\n            return True\n\n    # We never got here, but verify that the iface is actually a Configurable\n    # subclass, and that the candidate is actually a Configurable subclass\n    if not isinstance(iface, Configurable) or not isinstance(candidate, Configurable):\n        return False\n\n    if issubclass(iface, Configurable) and not issubclass(candidate, Configurable):\n        return False\n\n    return verify(iface.__implementation__, candidate.__implementation__, tentative)\n", "def verifyClass(iface, candidate, tentative=False):\n    if not verifyInterface(iface, candidate):\n        if tentative:\n            return False\n        raise TypeError(\"%s doesn't provide %s\" % (iface, candidate))\n    return True\n", "def verifyClass(iface, candidate, tentative=False):\n    if not verifyInterface(iface, candidate):\n        if tentative:\n            return False\n        else:\n            raise TypeError(\n                \"%r doesn't provide %r for %r\" % (iface, candidate, iface))\n    return True\n", "def verifyClass(iface, candidate, tentative=False):\n    if issubclass(iface, ICandidate) and not tentative:\n        return\n\n    if not issubclass(iface, ICandidate) and issubclass(candidate, ICandidate):\n        return\n\n    if not issubclass(iface, ICandidate):\n        return  # pragma: no cover\n\n    if not issubclass(candidate, ICandidate):\n        return  # pragma: no cover\n\n    if not candidate.providedBy(iface):\n        return\n\n    if not tentative:\n        if iface.providedBy(candidate):\n            return\n\n    # We don't really need to verify the type of the candidate, just check the interface\n    # and the type of the iface.  It does not matter if the interface is not the\n    # same as the candidate, but it is not as a common mistake.\n    if iface!= candidate:\n        return\n\n    return True\n", "def verifyClass(iface, candidate, tentative=False):\n    if not verifyContent(candidate, iface):\n        if tentative:\n            return False\n        raise TypeError(\n            \"%r doesn't provide %r\" % (candidate, iface))\n    return True\n", "def verifyClass(iface, candidate, tentative=False):\n    if not candidate:\n        return\n    if not issubclass(iface, Candidate):\n        raise TypeError(\"%s does not subclass Candidate\" % iface)\n    if not issubclass(candidate, iface):\n        if tentative:\n            msg = \"%s is not an instance of %s\"\n        else:\n            msg = \"%s is not an instance of %s(%s)\"\n        raise TypeError(msg % (iface, candidate, type(candidate)))\n", "def verifyClass(iface, candidate, tentative=False):\n    verifyClass(IHasTraits, candidate)\n    if not IHasTraits.providedBy(candidate):\n        if tentative:\n            return\n        raise TypeError(\"%s doesn't provide %r\" % (iface, candidate))\n", "def verifyClass(iface, candidate, tentative=False):\n    if not verifyCandidate(iface, candidate):\n        return False\n    if tentative:\n        if not verifyTentative(iface, candidate):\n            return False\n        return True\n    if iface is None:\n        return True\n    if not verifyInterface(iface, candidate):\n        return False\n    return True\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if not verifyInterface(iface, candidate):\n        if tentative:\n            return False\n        raise TypeError(\n            \"%r doesn't provide %r\" % (candidate, iface))\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if not verifyInterface(iface, candidate):\n        if tentative:\n            return candidate\n        raise AssertionError(\n            \"%r did not provide %r\" % (iface, candidate))\n    return candidate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if not verify(iface, candidate):\n        return False\n\n    if tentative:\n        if issubclass(iface, Configurable) and issubclass(candidate, Configurable):\n            return False\n        else:\n            return True\n\n    # We never got here, but verify that the iface is actually a Configurable\n    # subclass, and that the candidate is actually a Configurable subclass\n    if not isinstance(iface, Configurable) or not isinstance(candidate, Configurable):\n        return False\n\n    if issubclass(iface, Configurable) and not issubclass(candidate, Configurable):\n        return False\n\n    return verify(iface.__implementation__, candidate.__implementation__, tentative)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if not verifyInterface(iface, candidate):\n        if tentative:\n            return False\n        raise TypeError(\"%s doesn't provide %s\" % (iface, candidate))\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if not verifyInterface(iface, candidate):\n        if tentative:\n            return False\n        else:\n            raise TypeError(\n                \"%r doesn't provide %r for %r\" % (iface, candidate, iface))\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if issubclass(iface, ICandidate) and not tentative:\n        return\n\n    if not issubclass(iface, ICandidate) and issubclass(candidate, ICandidate):\n        return\n\n    if not issubclass(iface, ICandidate):\n        return  # pragma: no cover\n\n    if not issubclass(candidate, ICandidate):\n        return  # pragma: no cover\n\n    if not candidate.providedBy(iface):\n        return\n\n    if not tentative:\n        if iface.providedBy(candidate):\n            return\n\n    # We don't really need to verify the type of the candidate, just check the interface\n    # and the type of the iface.  It does not matter if the interface is not the\n    # same as the candidate, but it is not as a common mistake.\n    if iface!= candidate:\n        return\n\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if not verifyContent(candidate, iface):\n        if tentative:\n            return False\n        raise TypeError(\n            \"%r doesn't provide %r\" % (candidate, iface))\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if not candidate:\n        return\n    if not issubclass(iface, Candidate):\n        raise TypeError(\"%s does not subclass Candidate\" % iface)\n    if not issubclass(candidate, iface):\n        if tentative:\n            msg = \"%s is not an instance of %s\"\n        else:\n            msg = \"%s is not an instance of %s(%s)\"\n        raise TypeError(msg % (iface, candidate, type(candidate)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    verifyClass(IHasTraits, candidate)\n    if not IHasTraits.providedBy(candidate):\n        if tentative:\n            return\n        raise TypeError(\"%s doesn't provide %r\" % (iface, candidate))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if not verifyCandidate(iface, candidate):\n        return False\n    if tentative:\n        if not verifyTentative(iface, candidate):\n            return False\n        return True\n    if iface is None:\n        return True\n    if not verifyInterface(iface, candidate):\n        return False\n    return True\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/advice.py", "project": "pexip/os-zope", "name": "determineMetaclass", "docstring": "Determine metaclass from 1+ bases and optional explicit __metaclass__", "ques_id": "62b8b559eb7e40a82d2d11f6", "code": ["def determineMetaclass(bases, explicit_mc=None):\n    def find_metaclass(bases):\n        for base in bases:\n            if issubclass(base, type) and issubclass(base, type):\n                return base\n            if issubclass(base, type) and issubclass(base, type):\n                return base.__metaclass__\n        return object\n\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if issubclass(base, type):\n            meta = find_metaclass(base.__bases__)\n            if meta:\n                return meta\n        elif issubclass(base, type) and find_metaclass(base.__bases__) is not meta:\n            return find_metaclass(base.__bases__)\n        explicit_mc.append(base)\n    return object\n", "def determineMetaclass(bases, explicit_mc=None):\n    bases = list(bases)\n    if explicit_mc is None:\n        explicit_mc = []\n    while len(bases) > 1:\n        try:\n            bases.remove(metaclass)\n        except ValueError:\n            break\n        if bases[0] in explicit_mc:\n            raise ValueError(\"Duplicate metaclass %r\" % (bases[0],))\n        explicit_mc.append(bases[0])\n\n    mc = None\n    for base in bases:\n        if base is object:\n            continue\n        if hasattr(base, \"__metaclass__\"):\n            if mc is None:\n                mc = base.__metaclass__\n            else:\n                if base.__metaclass__ is None:\n                    mc = base.__metaclass__\n                else:\n              ", "def determineMetaclass(bases, explicit_mc=None):\n    def is_metaclass(cls):\n        return cls is not type and issubclass(cls, type) and cls is not type\n\n    def get_bases(cls):\n        bases = []\n        for base in cls.__bases__:\n            if is_metaclass(base):\n                bases.append(base)\n            else:\n                bases.extend(get_bases(base))\n        return bases\n\n    bases = get_bases(bases)\n    if explicit_mc is None:\n        explicit_mc = []\n    if not bases:\n        # If no bases are declared, return an empty tuple\n        return tuple()\n    elif len(bases) == 1:\n        # If only one base is declared, return it\n        return bases[0], explicit_mc\n    else:\n        # If more than one base is declared, return only the first two bases\n        return bases[", "def determineMetaclass(bases, explicit_mc=None):\n    for base in bases:\n        if (issubclass(base, type) and\n                issubclass(base.__metaclass__, type) and\n                base.__metaclass__ is not type and\n                base.__metaclass__ is not ExplicitMetaclass):\n            if explicit_mc is None:\n                return base, True\n            elif base.__metaclass__ is explicit_mc:\n                return base, True\n            else:\n                return base, False\n    return None, False\n", "def determineMetaclass(bases, explicit_mc=None):\n    class metaclass(type):\n\n        def __new__(cls, name, this_bases, d):\n            mc = d.get('__metaclass__')\n            if mc is None:\n                mc = type.__new__(cls, name, bases, d)\n            else:\n                bases = [b for b in bases if b!= metaclass]\n                if explicit_mc is not None:\n                    if mc.__name__!= explicit_mc.__name__:\n                        raise TypeError(\"metaclass definition mismatch: %s vs %s\" %\n                                        (mc.__name__, explicit_mc.__name__))\n                elif mc.__name__!= explicit_mc.__name__:\n                    mc.__name__ = explicit_mc", "def determineMetaclass(bases, explicit_mc=None):\n    cls = bases[0]\n    for base in bases[1:]:\n        if issubclass(cls, base):\n            break\n        cls = base\n    if explicit_mc is not None:\n        cls = metaclass(explicit_mc, cls.__name__)\n    return cls\n", "def determineMetaclass(bases, explicit_mc=None):\n    def getMetaclass(cls):\n        cls_meta = getattr(cls, '__metaclass__', None)\n        if cls_meta is None:\n            cls_meta = getattr(cls, '__new__', cls.__new__)\n            if explicit_mc is not None:\n                cls_meta = getattr(cls, '__metaclass__', explicit_mc)\n        return cls_meta\n    result = []\n    for base in bases:\n        if hasattr(base, '__metaclass__'):\n            result.append(getMetaclass(base))\n        else:\n            result.append(base)\n    return result\n", "def determineMetaclass(bases, explicit_mc=None):\n    def find_metaclass(bases):\n        if explicit_mc is None:\n            for base in bases:\n                if hasattr(base, '__metaclass__'):\n                    return base, base.__metaclass__\n            return None, None\n        else:\n            for base in bases:\n                if hasattr(base, '__metaclass__'):\n                    if base.__metaclass__ == explicit_mc:\n                        return base, base.__metaclass__\n                if base.__metaclass__ == explicit_mc:\n                    return base, None\n            return None, None\n    bases = list(bases)\n    bases.sort()\n    metaclass = find_metaclass(bases)\n    if metaclass is None:\n        metaclass = type('Metaclass', (type('Metaclass', ", "def determineMetaclass(bases, explicit_mc=None):\n    class metaclass(type):\n\n        def __new__(cls, name, this_bases, d):\n            return type.__new__(cls, name, bases, d)\n\n        def __init__(cls, name, this_bases, d):\n            # ignore subclasses of metaclass\n            if not hasattr(d, '__subclasscheck__'):\n                return\n            # find all subclasses of metaclass\n            subclasses = []\n            for c in d.__subclasses__():\n                m = metaclass(c.__name__, c.__bases__, c.__dict__)\n                if m.__dict__.get('__metaclass__') == explicit_mc:\n                    subclasses.append(m)\n            # find first non-abstract subclass of metaclass\n            if len(subclasses) > 0 and subclasses[0].__dict_", "def determineMetaclass(bases, explicit_mc=None):\n    def find_metaclass(bases, current_mc):\n        for base in bases:\n            if base is current_mc:\n                continue\n            if hasattr(base, \"__metaclass__\"):\n                return base\n            if explicit_mc is not None:\n                if hasattr(explicit_mc, \"__metaclass__\"):\n                    return base\n                if explicit_mc is base:\n                    continue\n            raise AssertionError(\"Explicit metaclass not found\")\n        return current_mc\n\n    # find bases with __metaclass__\n    bases = [b for b in bases if b.__metaclass__ is not find_metaclass]\n    if bases:\n        return bases[0], find_metaclass(bases[1:], find_metaclass(bases[0].__bases__, None))\n    else:\n        raise AssertionError"], "level": "file_runnable", "generate_results": [{"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    def find_metaclass(bases):\n        for base in bases:\n            if issubclass(base, type) and issubclass(base, type):\n                return base\n            if issubclass(base, type) and issubclass(base, type):\n                return base.__metaclass__\n        return object\n\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if issubclass(base, type):\n            meta = find_metaclass(base.__bases__)\n            if meta:\n                return meta\n        elif issubclass(base, type) and find_metaclass(base.__bases__) is not meta:\n            return find_metaclass(base.__bases__)\n        explicit_mc.append(base)\n    return object\n", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    bases = list(bases)\n    if explicit_mc is None:\n        explicit_mc = []\n    while len(bases) > 1:\n        try:\n            bases.remove(metaclass)\n        except ValueError:\n            break\n        if bases[0] in explicit_mc:\n            raise ValueError(\"Duplicate metaclass %r\" % (bases[0],))\n        explicit_mc.append(bases[0])\n\n    mc = None\n    for base in bases:\n        if base is object:\n            continue\n        if hasattr(base, \"__metaclass__\"):\n            if mc is None:\n                mc = base.__metaclass__\n            else:\n                if base.__metaclass__ is None:\n                    mc = base.__metaclass__\n                else:\n              ", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    def is_metaclass(cls):\n        return cls is not type and issubclass(cls, type) and cls is not type\n\n    def get_bases(cls):\n        bases = []\n        for base in cls.__bases__:\n            if is_metaclass(base):\n                bases.append(base)\n            else:\n                bases.extend(get_bases(base))\n        return bases\n\n    bases = get_bases(bases)\n    if explicit_mc is None:\n        explicit_mc = []\n    if not bases:\n        # If no bases are declared, return an empty tuple\n        return tuple()\n    elif len(bases) == 1:\n        # If only one base is declared, return it\n        return bases[0], explicit_mc\n    else:\n        # If more than one base is declared, return only the first two bases\n        return bases[", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    for base in bases:\n        if (issubclass(base, type) and\n                issubclass(base.__metaclass__, type) and\n                base.__metaclass__ is not type and\n                base.__metaclass__ is not ExplicitMetaclass):\n            if explicit_mc is None:\n                return base, True\n            elif base.__metaclass__ is explicit_mc:\n                return base, True\n            else:\n                return base, False\n    return None, False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    class metaclass(type):\n\n        def __new__(cls, name, this_bases, d):\n            mc = d.get('__metaclass__')\n            if mc is None:\n                mc = type.__new__(cls, name, bases, d)\n            else:\n                bases = [b for b in bases if b!= metaclass]\n                if explicit_mc is not None:\n                    if mc.__name__!= explicit_mc.__name__:\n                        raise TypeError(\"metaclass definition mismatch: %s vs %s\" %\n                                        (mc.__name__, explicit_mc.__name__))\n                elif mc.__name__!= explicit_mc.__name__:\n                    mc.__name__ = explicit_mc", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    cls = bases[0]\n    for base in bases[1:]:\n        if issubclass(cls, base):\n            break\n        cls = base\n    if explicit_mc is not None:\n        cls = metaclass(explicit_mc, cls.__name__)\n    return cls\n", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    def getMetaclass(cls):\n        cls_meta = getattr(cls, '__metaclass__', None)\n        if cls_meta is None:\n            cls_meta = getattr(cls, '__new__', cls.__new__)\n            if explicit_mc is not None:\n                cls_meta = getattr(cls, '__metaclass__', explicit_mc)\n        return cls_meta\n    result = []\n    for base in bases:\n        if hasattr(base, '__metaclass__'):\n            result.append(getMetaclass(base))\n        else:\n            result.append(base)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    def find_metaclass(bases):\n        if explicit_mc is None:\n            for base in bases:\n                if hasattr(base, '__metaclass__'):\n                    return base, base.__metaclass__\n            return None, None\n        else:\n            for base in bases:\n                if hasattr(base, '__metaclass__'):\n                    if base.__metaclass__ == explicit_mc:\n                        return base, base.__metaclass__\n                if base.__metaclass__ == explicit_mc:\n                    return base, None\n            return None, None\n    bases = list(bases)\n    bases.sort()\n    metaclass = find_metaclass(bases)\n    if metaclass is None:\n        metaclass = type('Metaclass', (type('Metaclass', ", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    class metaclass(type):\n\n        def __new__(cls, name, this_bases, d):\n            return type.__new__(cls, name, bases, d)\n\n        def __init__(cls, name, this_bases, d):\n            # ignore subclasses of metaclass\n            if not hasattr(d, '__subclasscheck__'):\n                return\n            # find all subclasses of metaclass\n            subclasses = []\n            for c in d.__subclasses__():\n                m = metaclass(c.__name__, c.__bases__, c.__dict__)\n                if m.__dict__.get('__metaclass__') == explicit_mc:\n                    subclasses.append(m)\n            # find first non-abstract subclass of metaclass\n            if len(subclasses) > 0 and subclasses[0].__dict_", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    def find_metaclass(bases, current_mc):\n        for base in bases:\n            if base is current_mc:\n                continue\n            if hasattr(base, \"__metaclass__\"):\n                return base\n            if explicit_mc is not None:\n                if hasattr(explicit_mc, \"__metaclass__\"):\n                    return base\n                if explicit_mc is base:\n                    continue\n            raise AssertionError(\"Explicit metaclass not found\")\n        return current_mc\n\n    # find bases with __metaclass__\n    bases = [b for b in bases if b.__metaclass__ is not find_metaclass]\n    if bases:\n        return bases[0], find_metaclass(bases[1:], find_metaclass(bases[0].__bases__, None))\n    else:\n        raise AssertionError", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/cache.py", "project": "pexip/os-python-cachetools", "name": "pop", "docstring": "D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\nIf key is not found, d is returned if given, otherwise KeyError is raised.", "ques_id": "62b8d22a48ba5a41d1c3f47d", "code": ["def pop(self, key, default=__marker):\n    if key in self._keys:\n        result = self[key]\n        self._keys.remove(key)\n        return result\n    if default is self.__marker:\n        raise KeyError(key)\n    return default\n", "def pop(self, key, default=__marker):\n    if key in self:\n        value = dict.pop(self, key)\n        self._on_pop(key)\n        return value\n    if default is self.__marker:\n        raise KeyError(key)\n    return default\n", "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = None\n    return super(Cache, self).pop(key, default)\n", "def pop(self, key, default=__marker):\n    if key not in self:\n        if default is not __marker:\n            return default\n        raise KeyError(key)\n    self._keys.remove(key)\n    return dict.pop(self, key)\n", "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = None\n    return super(CaseInsensitiveDict, self).pop(self._keytransform(key), default)\n", "def pop(self, key, default=__marker):\n    if not key:\n        return default\n    key = self._translate_key(key)\n    return super(CaseInsensitiveDict, self).pop(key, default)\n", "def pop(self, key, default=__marker):\n    if key not in self:\n        if default is self.__marker:\n            raise KeyError(key)\n        return default\n    self._keys.remove(key)\n    return dict.pop(self, key)\n", "def pop(self, key, default=__marker):\n    if key in self:\n        result = super(OrderedMultiDict, self).pop(key)\n        self._list_remove(key)\n        return result\n    if default is self.__marker:\n        raise KeyError(key)\n    return default\n", "def pop(self, key, default=__marker):\n    if key in self:\n        value = dict.pop(self, key)\n        self._dirty = True\n        return value\n    if default is self.__marker:\n        raise KeyError(key)\n    return default\n", "def pop(self, key, default=__marker):\n    if key in self:\n        if self._sequence:\n            return self._sequence.pop(key)\n        else:\n            return self._dict.pop(key)\n    elif default is self.__marker:\n        raise KeyError(key)\n    else:\n        return default\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def pop(self, key, default=__marker):\n    if key in self._keys:\n        result = self[key]\n        self._keys.remove(key)\n        return result\n    if default is self.__marker:\n        raise KeyError(key)\n    return default\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if key in self:\n        value = dict.pop(self, key)\n        self._on_pop(key)\n        return value\n    if default is self.__marker:\n        raise KeyError(key)\n    return default\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = None\n    return super(Cache, self).pop(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if key not in self:\n        if default is not __marker:\n            return default\n        raise KeyError(key)\n    self._keys.remove(key)\n    return dict.pop(self, key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = None\n    return super(CaseInsensitiveDict, self).pop(self._keytransform(key), default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if not key:\n        return default\n    key = self._translate_key(key)\n    return super(CaseInsensitiveDict, self).pop(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if key not in self:\n        if default is self.__marker:\n            raise KeyError(key)\n        return default\n    self._keys.remove(key)\n    return dict.pop(self, key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if key in self:\n        result = super(OrderedMultiDict, self).pop(key)\n        self._list_remove(key)\n        return result\n    if default is self.__marker:\n        raise KeyError(key)\n    return default\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if key in self:\n        value = dict.pop(self, key)\n        self._dirty = True\n        return value\n    if default is self.__marker:\n        raise KeyError(key)\n    return default\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if key in self:\n        if self._sequence:\n            return self._sequence.pop(key)\n        else:\n            return self._dict.pop(key)\n    elif default is self.__marker:\n        raise KeyError(key)\n    else:\n        return default\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/lfu.py", "project": "pexip/os-python-cachetools", "name": "popitem", "docstring": "Remove and return the `(key, value)` pair least frequently used.", "ques_id": "62b8d23748ba5a41d1c3f497", "code": ["def popitem(self):\n    key = next(iter(self))\n    return key, self.pop(key)\n", "def popitem(self):\n    return self._freqdist.popitem()\n", "def popitem(self):\n    try:\n        return dict.popitem(self)[0]\n    except KeyError as e:\n        raise exceptions.NotFound(e)\n", "def popitem(self):\n    # We use a new dictionary to remove items from the dictionary.\n    d = {}\n    for key in self._freqdist:\n        if key not in self:\n            break\n        d[key] = self[key]\n    # Then we remove the item with the highest frequency.\n    key, val = max(d.items(), key=lambda x: x[1])\n    del d[key]\n    return key, val\n", "def popitem(self):\n    freq = dict.popitem(self)\n    self._remove_frequency(freq)\n    return freq\n", "def popitem(self):\n    return self._freqdist.popitem()\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    return self.__popitem__(0)\n", "def popitem(self):\n    result = dict.popitem(self)\n    try:\n        del self._freq[result[0]]\n    except KeyError:\n        raise KeyError(result)\n    return result\n", "def popitem(self):\n    try:\n        key = next(iter(self))\n        return (key, self[key])\n    except KeyError as e:\n        raise exceptions.NotFound(str(e))\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def popitem(self):\n    key = next(iter(self))\n    return key, self.pop(key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return self._freqdist.popitem()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        return dict.popitem(self)[0]\n    except KeyError as e:\n        raise exceptions.NotFound(e)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    # We use a new dictionary to remove items from the dictionary.\n    d = {}\n    for key in self._freqdist:\n        if key not in self:\n            break\n        d[key] = self[key]\n    # Then we remove the item with the highest frequency.\n    key, val = max(d.items(), key=lambda x: x[1])\n    del d[key]\n    return key, val\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    freq = dict.popitem(self)\n    self._remove_frequency(freq)\n    return freq\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return self._freqdist.popitem()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return self.__popitem__(0)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    result = dict.popitem(self)\n    try:\n        del self._freq[result[0]]\n    except KeyError:\n        raise KeyError(result)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = next(iter(self))\n        return (key, self[key])\n    except KeyError as e:\n        raise exceptions.NotFound(str(e))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/lru.py", "project": "pexip/os-python-cachetools", "name": "popitem", "docstring": "Remove and return the `(key, value)` pair least recently used.", "ques_id": "62b8d23a48ba5a41d1c3f499", "code": ["def popitem(self):\n    try:\n        key = self._list_pop()\n    except IndexError:\n        raise KeyError('popitem(): dictionary is empty')\n    value = dict.pop(self, key)\n    self._list_add(value)\n    return (key, value)\n", "def popitem(self):\n    try:\n        key = next(iter(self))\n        value = dict.pop(self, key)\n        self._list_remove(key)\n        return key, value\n    except KeyError as e:\n        raise exceptions.NotFound(e)\n", "def popitem(self):\n    return self._dict.popitem()\n", "def popitem(self):\n    try:\n        key = self._keys.pop()\n    except IndexError:\n        raise KeyError('popitem(): dictionary is already empty')\n    value = dict.pop(self, key)\n    return (key, value)\n", "def popitem(self):\n    try:\n        key = next(iter(self))\n        value = dict.pop(self, key)\n        self._list_remove(key)\n        return key, value\n    except KeyError as e:\n        raise exceptions.NotFound('Key \"{}\" not found'.format(e))\n", "def popitem(self):\n    if not self._keys:\n        raise KeyError('popitem(): dictionary is empty')\n\n    key = self._keys[0]\n    value = dict.pop(self, key)\n    self._keys = self._keys[1:]\n    return (key, value)\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    if not self:\n        raise KeyError('popitem(): dictionary is empty')\n\n    key = self._list_pop()\n    value = dict.pop(self, key)\n    self._list_add((key, value))\n    return key, value\n", "def popitem(self):\n    try:\n        key = next(iter(self))\n        value = dict.pop(self, key)\n        self._list_remove(key)\n        return key, value\n    except KeyError as e:\n        raise exceptions.NotFound(e)\n", "def popitem(self):\n    if not len(self):\n        raise KeyError('popitem(): dictionary is already empty')\n\n    key = self._list_pop()[0]\n    value = dict.pop(self, key)\n    self._list_add((key, value))\n    return (key, value)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def popitem(self):\n    try:\n        key = self._list_pop()\n    except IndexError:\n        raise KeyError('popitem(): dictionary is empty')\n    value = dict.pop(self, key)\n    self._list_add(value)\n    return (key, value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = next(iter(self))\n        value = dict.pop(self, key)\n        self._list_remove(key)\n        return key, value\n    except KeyError as e:\n        raise exceptions.NotFound(e)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return self._dict.popitem()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = self._keys.pop()\n    except IndexError:\n        raise KeyError('popitem(): dictionary is already empty')\n    value = dict.pop(self, key)\n    return (key, value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = next(iter(self))\n        value = dict.pop(self, key)\n        self._list_remove(key)\n        return key, value\n    except KeyError as e:\n        raise exceptions.NotFound('Key \"{}\" not found'.format(e))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    if not self._keys:\n        raise KeyError('popitem(): dictionary is empty')\n\n    key = self._keys[0]\n    value = dict.pop(self, key)\n    self._keys = self._keys[1:]\n    return (key, value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    if not self:\n        raise KeyError('popitem(): dictionary is empty')\n\n    key = self._list_pop()\n    value = dict.pop(self, key)\n    self._list_add((key, value))\n    return key, value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = next(iter(self))\n        value = dict.pop(self, key)\n        self._list_remove(key)\n        return key, value\n    except KeyError as e:\n        raise exceptions.NotFound(e)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    if not len(self):\n        raise KeyError('popitem(): dictionary is already empty')\n\n    key = self._list_pop()[0]\n    value = dict.pop(self, key)\n    self._list_add((key, value))\n    return (key, value)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/mru.py", "project": "pexip/os-python-cachetools", "name": "popitem", "docstring": "Remove and return the `(key, value)` pair most recently used.", "ques_id": "62b8d23c48ba5a41d1c3f49b", "code": ["def popitem(self):\n    try:\n        return self._container.pop()\n    except IndexError:\n        raise KeyError('popitem(): dictionary is empty')\n", "def popitem(self):\n    try:\n        return dict.popitem(self)[0]\n    except KeyError as e:\n        raise exceptions.NotFound(e)\n", "def popitem(self):\n    try:\n        return dict.popitem(self)[0]\n    except KeyError as e:\n        raise exceptions.DoesNotExist(\n            \"No item was added to the cache, or there was no prior \"\n            \"call to.popitem()\"\n        ) from e\n", "def popitem(self):\n    return self._list.popitem()\n", "def popitem(self):\n    try:\n        return dict.popitem(self)[0]\n    except KeyError as e:\n        raise exceptions.BadRequestKeyError(e)\n", "def popitem(self):\n    try:\n        return dict.popitem(self)[0]\n    except KeyError as e:\n        raise exceptions.BadRequestKeyError(e)\n", "def popitem(self):\n    try:\n        key = self._list_pop()\n    except IndexError:\n        raise KeyError('pop from empty hash')\n    self._list_remove(key)\n    return (key, self[key])\n", "def popitem(self):\n    try:\n        return dict.popitem(self)[0]\n    except KeyError as e:\n        raise exceptions.NotFound('Key {} not found.'.format(e))\n", "def popitem(self):\n    try:\n        key = list(self._semaphore)[-1]\n        value = dict.pop(self, key)\n        self._semaphore[key].release()\n        return (key, value)\n    except IndexError:\n        raise KeyError('pop from empty cache')\n", "def popitem(self):\n    try:\n        return self._semaphore.pop()\n    except IndexError:\n        raise KeyError('popitem(): dictionary is empty')\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def popitem(self):\n    try:\n        return self._container.pop()\n    except IndexError:\n        raise KeyError('popitem(): dictionary is empty')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        return dict.popitem(self)[0]\n    except KeyError as e:\n        raise exceptions.NotFound(e)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        return dict.popitem(self)[0]\n    except KeyError as e:\n        raise exceptions.DoesNotExist(\n            \"No item was added to the cache, or there was no prior \"\n            \"call to.popitem()\"\n        ) from e\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return self._list.popitem()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        return dict.popitem(self)[0]\n    except KeyError as e:\n        raise exceptions.BadRequestKeyError(e)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        return dict.popitem(self)[0]\n    except KeyError as e:\n        raise exceptions.BadRequestKeyError(e)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = self._list_pop()\n    except IndexError:\n        raise KeyError('pop from empty hash')\n    self._list_remove(key)\n    return (key, self[key])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        return dict.popitem(self)[0]\n    except KeyError as e:\n        raise exceptions.NotFound('Key {} not found.'.format(e))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = list(self._semaphore)[-1]\n        value = dict.pop(self, key)\n        self._semaphore[key].release()\n        return (key, value)\n    except IndexError:\n        raise KeyError('pop from empty cache')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        return self._semaphore.pop()\n    except IndexError:\n        raise KeyError('popitem(): dictionary is empty')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/rr.py", "project": "pexip/os-python-cachetools", "name": "popitem", "docstring": "Remove and return a random `(key, value)` pair.", "ques_id": "62b8d23e48ba5a41d1c3f49e", "code": ["def popitem(self):\n    try:\n        key = list(self)[0]\n    except IndexError:\n        raise KeyError('popitem(): dictionary is empty')\n    else:\n        return key, self.pop(key)\n", "def popitem(self):\n    try:\n        k = list(self._saved_keys)[0]\n        v = dict.pop(self, k)\n        self._dirty = True\n        return k, v\n    except IndexError:\n        raise KeyError('Cannot remove from an empty dictionary')\n", "def popitem(self):\n    try:\n        key = next(iter(self))\n    except StopIteration:\n        raise KeyError('There is nothing to popitem.')\n    value = dict.pop(self, key)\n    return key, value\n", "def popitem(self):\n    try:\n        k = self.__choice.pop()\n    except IndexError:\n        raise KeyError('Cannot pop from an empty dictionary')\n    else:\n        return (k, self[k])\n", "def popitem(self):\n    for key, value in super().popitem():\n        yield key, value\n", "def popitem(self):\n    try:\n        key = next(iter(self))\n    except StopIteration:\n        raise KeyError\n    else:\n        value = dict.popitem(self)\n        self.__delitem__(key)\n        return key, value\n", "def popitem(self):\n    key = random.choice(list(self))\n    return (key, self[key])\n", "def popitem(self):\n    return self.__choice.popitem()\n", "def popitem(self):\n    try:\n        key = next(iter(self))\n    except StopIteration:\n        raise KeyError('popitem(): dictionary is empty')\n    else:\n        value = self.pop(key)\n        return (key, value)\n", "def popitem(self):\n    try:\n        key = self.__choice()\n    except IndexError:\n        raise KeyError('popitem(): dictionary is empty')\n    else:\n        return key, dict.pop(self, key)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def popitem(self):\n    try:\n        key = list(self)[0]\n    except IndexError:\n        raise KeyError('popitem(): dictionary is empty')\n    else:\n        return key, self.pop(key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        k = list(self._saved_keys)[0]\n        v = dict.pop(self, k)\n        self._dirty = True\n        return k, v\n    except IndexError:\n        raise KeyError('Cannot remove from an empty dictionary')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = next(iter(self))\n    except StopIteration:\n        raise KeyError('There is nothing to popitem.')\n    value = dict.pop(self, key)\n    return key, value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        k = self.__choice.pop()\n    except IndexError:\n        raise KeyError('Cannot pop from an empty dictionary')\n    else:\n        return (k, self[k])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    for key, value in super().popitem():\n        yield key, value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = next(iter(self))\n    except StopIteration:\n        raise KeyError\n    else:\n        value = dict.popitem(self)\n        self.__delitem__(key)\n        return key, value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    key = random.choice(list(self))\n    return (key, self[key])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return self.__choice.popitem()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = next(iter(self))\n    except StopIteration:\n        raise KeyError('popitem(): dictionary is empty')\n    else:\n        value = self.pop(key)\n        return (key, value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = self.__choice()\n    except IndexError:\n        raise KeyError('popitem(): dictionary is empty')\n    else:\n        return key, dict.pop(self, key)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "sqlparams/__init__.py", "project": "cpburnz/python-sql-parameters", "name": "_create_in_regex", "docstring": "Create the in-style parameter regular expression.\n\nReturns the in-style parameter regular expression (:class:`re.Pattern`).", "ques_id": "62b43425903eeb48555d3ea1", "code": ["def _create_in_regex(self) -> Pattern:\n    in_regex = Pattern(self.IN_STYLE_PATTERN)\n    in_regex.set_group(self.IN_GROUP)\n\n    return in_regex\n", "def _create_in_regex(self) -> Pattern:\n\n    if self._in_regex is not None:\n        return self._in_regex\n\n    pattern = \"(?P<\" + self._param.in_name + \">\" + self._param.regex + \")\"\n    self._in_regex = re.compile(pattern, re.IGNORECASE)\n    return self._in_regex\n", "def _create_in_regex(self) -> Pattern:\n    return re.compile(self._in_regex)\n", "def _create_in_regex(self) -> Pattern:\n    if self._re_in:\n        in_str = self._re_in.format(self._param)\n    else:\n        in_str = self._param\n    return re.compile(in_str, re.IGNORECASE)\n", "def _create_in_regex(self) -> Pattern:\n    in_style = self._get_parameter_value(self._in_param)\n    if not in_style:\n        in_style = self._get_parameter_value(self._out_param)\n    if not in_style:\n        return None\n\n    return re.compile(\n        \"^{}$\".format(in_style),\n        flags=re.IGNORECASE | re.UNICODE | re.UNICODE | re.VERBOSE\n    )\n", "def _create_in_regex(self) -> Pattern:\n    in_regex = re.compile(\n        r'''\n        ^\n        (?P<in_style>\n            (?P<param>[a-zA-Z_]+)\n            (?:\\((?P<param_type>\\w+)\\))?\n            \\[(?P<param_regex_group>\\w+)\\]\n        )\n        $\n    ''',\n        re.VERBOSE\n    )\n\n    return in_regex\n", "def _create_in_regex(self) -> Pattern:\n\n    pattern = (\n        r\"\\b(?P<param_name>\"\n        r\"(?:(?P<in_param_name>\"\n        r\"(?:{param_regex_symbol})|{param_regex_braces})\"\n        r\")?)\"\n        r\"\\b(?P<param_value>\"\n        r\"(?P<in_param_value>\"\n        r\"(?P<in_param_value_symbol>\"\n        r\"(?:{param_regex_braces})|{param_regex_braces})\"\n        r\")?)\"\n        r\"\\b(?P<param_unit>\"\n        r\"(?P<in_param_unit>\"\n        r\"(?P<param_unit_symbol>\"\n        r\"(?P<param_regex_braces}))?)\"\n        r\")?)\"\n        r\"\\b(?P<param_required>\"\n        r\"(?P<required_param_name>\"\n        r\"(?P<param_required_value>\"\n        r\"(?P<param_required_unit>\"\n        r\"(?P<param_required_unit_symbol>\"\n        r\"(", "def _create_in_regex(self) -> Pattern:\n    in_regex = self._config[\"in-style\"]\n    if in_regex.startswith(\"(\") and in_regex.endswith(\")\"):\n        in_regex = in_regex[1:-1]\n    in_regex = in_regex.replace(\"(?P<word>.+?)\", r\"\\1\")\n    return re.compile(in_regex, re.UNICODE)\n", "def _create_in_regex(self) -> Pattern:\n    pattern = re.compile(self.IN_PATTERN)\n    return pattern\n", "def _create_in_regex(self) -> Pattern:\n    pattern = \"(?P<{name}>{param_name})\"\n    return re.compile(pattern.format(name=self.in_name,\n                                     param_name=self.param_name))\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def _create_in_regex(self) -> Pattern:\n    in_regex = Pattern(self.IN_STYLE_PATTERN)\n    in_regex.set_group(self.IN_GROUP)\n\n    return in_regex\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n\n    if self._in_regex is not None:\n        return self._in_regex\n\n    pattern = \"(?P<\" + self._param.in_name + \">\" + self._param.regex + \")\"\n    self._in_regex = re.compile(pattern, re.IGNORECASE)\n    return self._in_regex\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    return re.compile(self._in_regex)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    if self._re_in:\n        in_str = self._re_in.format(self._param)\n    else:\n        in_str = self._param\n    return re.compile(in_str, re.IGNORECASE)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    in_style = self._get_parameter_value(self._in_param)\n    if not in_style:\n        in_style = self._get_parameter_value(self._out_param)\n    if not in_style:\n        return None\n\n    return re.compile(\n        \"^{}$\".format(in_style),\n        flags=re.IGNORECASE | re.UNICODE | re.UNICODE | re.VERBOSE\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    in_regex = re.compile(\n        r'''\n        ^\n        (?P<in_style>\n            (?P<param>[a-zA-Z_]+)\n            (?:\\((?P<param_type>\\w+)\\))?\n            \\[(?P<param_regex_group>\\w+)\\]\n        )\n        $\n    ''',\n        re.VERBOSE\n    )\n\n    return in_regex\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n\n    pattern = (\n        r\"\\b(?P<param_name>\"\n        r\"(?:(?P<in_param_name>\"\n        r\"(?:{param_regex_symbol})|{param_regex_braces})\"\n        r\")?)\"\n        r\"\\b(?P<param_value>\"\n        r\"(?P<in_param_value>\"\n        r\"(?P<in_param_value_symbol>\"\n        r\"(?:{param_regex_braces})|{param_regex_braces})\"\n        r\")?)\"\n        r\"\\b(?P<param_unit>\"\n        r\"(?P<in_param_unit>\"\n        r\"(?P<param_unit_symbol>\"\n        r\"(?P<param_regex_braces}))?)\"\n        r\")?)\"\n        r\"\\b(?P<param_required>\"\n        r\"(?P<required_param_name>\"\n        r\"(?P<param_required_value>\"\n        r\"(?P<param_required_unit>\"\n        r\"(?P<param_required_unit_symbol>\"\n        r\"(", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    in_regex = self._config[\"in-style\"]\n    if in_regex.startswith(\"(\") and in_regex.endswith(\")\"):\n        in_regex = in_regex[1:-1]\n    in_regex = in_regex.replace(\"(?P<word>.+?)\", r\"\\1\")\n    return re.compile(in_regex, re.UNICODE)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    pattern = re.compile(self.IN_PATTERN)\n    return pattern\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    pattern = \"(?P<{name}>{param_name})\"\n    return re.compile(pattern.format(name=self.in_name,\n                                     param_name=self.param_name))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "sqlparams/__init__.py", "project": "cpburnz/python-sql-parameters", "name": "_create_converter", "docstring": "Create the parameter style converter.\n\nReturns the parameter style converter (:class:`._converting._Converter`).", "ques_id": "62b43426903eeb48555d3ea2", "code": ["def _create_converter(self) -> _converting._Converter:\n    return _Converter(self._param_spec, self._input_types, self._output_types)\n", "def _create_converter(self) -> _converting._Converter:\n\n    converter = _converting._Converter()\n    converter.add_parameter(_parameters.Parameter.from_str(\n        'x', 'Input value', min=0, max=100))\n\n    return converter\n", "def _create_converter(self) -> _converting._Converter:\n    return _Converter(self)\n", "def _create_converter(self) -> _converting._Converter:\n    style_converter = _converting._Converter()\n    style_converter.add_type(_constants.TYPE_BOOLEAN)\n    style_converter.add_type(_constants.TYPE_NUMBER)\n    style_converter.add_parameter(\"value\", None)\n\n    return style_converter\n", "def _create_converter(self) -> _converting._Converter:\n    converter = _converting._Converter()\n    converter.types = self.types\n    converter.parameters = self.parameters\n    return converter\n", "def _create_converter(self) -> _converting._Converter:\n    converter = _converting._Converter()\n    converter.for_type(_to_enum(self._type), _to_enum(self._to_type))\n\n    return converter\n", "def _create_converter(self) -> _converting._Converter:\n    param_style = self._get_param_style()\n    converter = _converters.get(param_style)\n    if converter is None:\n        raise _errors.UnknownStyle(param_style)\n    return converter\n", "def _create_converter(self) -> _converting._Converter:\n    return _Converter(self._parameters)\n", "def _create_converter(self) -> _converting._Converter:\n    return _Converter(self._parameters, self._param_defs)\n", "def _create_converter(self) -> _converting._Converter:\n    converter = _converting._Converter()\n    converter.add_type(_constants.Type.STRING, None, None)\n    converter.add_parameter(_constants.Parameter.TIME, None)\n    converter.add_parameter(_constants.Parameter.FRACTION, None)\n    converter.add_parameter(_constants.Parameter.POTENTIAL, None)\n    converter.add_parameter(_constants.Parameter.QUANTITY, None)\n    converter.add_parameter(_constants.Parameter.VOLUME, None)\n    converter.add_parameter(_constants.Parameter.PERCENTAGE, None)\n    converter.add_parameter(_constants.Parameter.PERCENTAGE_UNIT, None)\n    converter.add_parameter(_constants.Parameter.PERCENTAGE_EXPONENTIAL, None)\n    return converter\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def _create_converter(self) -> _converting._Converter:\n    return _Converter(self._param_spec, self._input_types, self._output_types)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n\n    converter = _converting._Converter()\n    converter.add_parameter(_parameters.Parameter.from_str(\n        'x', 'Input value', min=0, max=100))\n\n    return converter\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    return _Converter(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    style_converter = _converting._Converter()\n    style_converter.add_type(_constants.TYPE_BOOLEAN)\n    style_converter.add_type(_constants.TYPE_NUMBER)\n    style_converter.add_parameter(\"value\", None)\n\n    return style_converter\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    converter = _converting._Converter()\n    converter.types = self.types\n    converter.parameters = self.parameters\n    return converter\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    converter = _converting._Converter()\n    converter.for_type(_to_enum(self._type), _to_enum(self._to_type))\n\n    return converter\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    param_style = self._get_param_style()\n    converter = _converters.get(param_style)\n    if converter is None:\n        raise _errors.UnknownStyle(param_style)\n    return converter\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    return _Converter(self._parameters)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    return _Converter(self._parameters, self._param_defs)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    converter = _converting._Converter()\n    converter.add_type(_constants.Type.STRING, None, None)\n    converter.add_parameter(_constants.Parameter.TIME, None)\n    converter.add_parameter(_constants.Parameter.FRACTION, None)\n    converter.add_parameter(_constants.Parameter.POTENTIAL, None)\n    converter.add_parameter(_constants.Parameter.QUANTITY, None)\n    converter.add_parameter(_constants.Parameter.VOLUME, None)\n    converter.add_parameter(_constants.Parameter.PERCENTAGE, None)\n    converter.add_parameter(_constants.Parameter.PERCENTAGE_UNIT, None)\n    converter.add_parameter(_constants.Parameter.PERCENTAGE_EXPONENTIAL, None)\n    return converter\n", "is_pass": false, "return_code": 1}]}
{"file_path": "dateutil/parser/isoparser.py", "project": "pexip/os-python-dateutil", "name": "isoparse", "docstring": "Parse an ISO-8601 datetime string into a :class:`datetime.datetime`.\n\nAn ISO-8601 datetime string consists of a date portion, followed\noptionally by a time portion - the date and time portions are separated\nby a single character separator, which is ``T`` in the official\nstandard. Incomplete date formats (such as ``YYYY-MM``) may *not* be\ncombined with a time portion.\n\nSupported date formats are:\n\nCommon:\n\n- ``YYYY``\n- ``YYYY-MM`` or ``YYYYMM``\n- ``YYYY-MM-DD`` or ``YYYYMMDD``\n\nUncommon:\n\n- ``YYYY-Www`` or ``YYYYWww`` - ISO week (day defaults to 0)\n- ``YYYY-Www-D`` or ``YYYYWwwD`` - ISO week and day\n\nThe ISO week and day numbering follows the same logic as\n:func:`datetime.date.isocalendar`.\n\nSupported time formats are:\n\n- ``hh``\n- ``hh:mm`` or ``hhmm``\n- ``hh:mm:ss`` or ``hhmmss``\n- ``hh:mm:ss.ssssss`` (Up to 6 sub-second digits)\n\nMidnight is a special case for `hh`, as the standard supports both\n00:00 and 24:00 as a representation. The decimal separator can be\neither a dot or a comma.\n\n\n.. caution::\n\n    Support for fractional components other than seconds is part of the\n    ISO-8601 standard, but is not currently implemented in this parser.\n\nSupported time zone offset formats are:\n\n- `Z` (UTC)\n- `\u00b1HH:MM`\n- `\u00b1HHMM`\n- `\u00b1HH`\n\nOffsets will be represented as :class:`dateutil.tz.tzoffset` objects,\nwith the exception of UTC, which will be represented as\n:class:`dateutil.tz.tzutc`. Time zone offsets equivalent to UTC (such\nas `+00:00`) will also be represented as :class:`dateutil.tz.tzutc`.\n\n:param dt_str:\n    A string or stream containing only an ISO-8601 datetime string\n\n:return:\n    Returns a :class:`datetime.datetime` representing the string.\n    Unspecified components default to their lowest value.\n\n.. warning::\n\n    As of version 2.7.0, the strictness of the parser should not be\n    considered a stable part of the contract. Any valid ISO-8601 string\n    that parses correctly with the default settings will continue to\n    parse correctly in future versions, but invalid strings that\n    currently fail (e.g. ``2017-01-01T00:00+00:00:00``) are not\n    guaranteed to continue failing in future versions if they encode\n    a valid date.\n\n.. versionadded:: 2.7.0", "ques_id": "62b8966c755ee91dce50a154", "code": ["def isoparse(self, dt_str):\n    if not isinstance(dt_str, six.string_types):\n        raise ValueError('isoparse() requires a string parameter')\n    dt_str = dt_str.replace('T','')\n    dt_str = dt_str.strip()\n\n    # isoparse does not accept fractional seconds, so parse it manually:\n    if dt_str.endswith('.') and dt_str[:-1].endswith('.'):\n        dt_str = dt_str[:-1]\n\n    if self._isoparse_invalid_formats_allowed(dt_str):\n        return self._parse_isoparse(dt_str)\n    elif self._isoparse_invalid_timezone(dt_str):\n        return self._parse_isoparse(dt_str, self._get_timezone(dt_str))\n    else:\n        return self._parse_isoparse(dt_str, self._get_local_tz(dt_str))\n", "def isoparse(self, dt_str):\n    parsed = self.parse_datetime(dt_str)\n    if parsed is None:\n        parsed = self.parse_time(dt_str)\n    if parsed is None:\n        return parsed\n    return parsed\n", "def isoparse(self, dt_str):\n    if self._isoparse_re.match(dt_str):\n        dt_str = self._isoparse_re.sub(r'-', dt_str)\n        return datetime.datetime(*(int(x) for x in dt_str.split('-')))\n\n    raise ValueError('Not a valid ISO-8601 datetime string: %r' % dt_str)\n", "def isoparse(self, dt_str):\n    if isinstance(dt_str, datetime.datetime):\n        return dt_str\n    elif isinstance(dt_str, six.string_types):\n        return self.parse_iso_datetime(dt_str)\n    else:\n        raise ValueError('Unable to parse datetime string:'+ dt_str)\n", "def isoparse(self, dt_str):\n    if not isinstance(dt_str, str):\n        raise ValueError('isoparse() only accepts strings')\n\n    parsed = self._parse(dt_str)\n\n    if parsed is None:\n        return None\n\n    return datetime.datetime(*parsed)\n", "def isoparse(self, dt_str):\n    # type: (str) -> datetime.datetime\n    \"\"\"Parse an ISO-8601 datetime string into a :class:`datetime.datetime`.\n\n    An ISO-8601 datetime string consists of a date portion, followed optionally\n    by a time portion, followed optionally by a time portion - the date\n    and time portions are separated by a single character separator, which\n    is ``T`` in the official standard. Incomplete date formats may *not*\n    be combined with a time portion. Supported date formats are:\n\n    Common: - ``YYYY`` - `YYY-MM` or ``YYY-MM-DD`` or ``YYYMMDD``\n    - `YYYYMMDD` - or ``YYYYYMMDD`` - or ``YYYYYMMDD`` - or ``YYYMMDD``\n                    (uncommon, non-standard standard but is not implemented in\n                    this parser. Support fractional components other than\n                    seconds are part of the standard)\n\n    \"\"\"\n    return datetime.datetime(*(\n  ", "def isoparse(self, dt_str):\n    parsed = parse(dt_str, self._datetime_formats)\n    if parsed['year'] is None:\n        parsed['year'] = parsed['month']\n        parsed['month'] = parsed['day']\n        parsed['day'] = parsed['hour']\n        parsed['hour'] = parsed['minute']\n        parsed['minute'] = parsed['second']\n    return parsed\n", "def isoparse(self, dt_str):\n    return isoparse(dt_str, self.tzinfos)\n", "def isoparse(self, dt_str):\n    return datetime.datetime.strptime(dt_str, ISO8601_DATE_FORMAT).replace(tzinfo=pytz.utc)\n", "def isoparse(self, dt_str):\n    return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def isoparse(self, dt_str):\n    if not isinstance(dt_str, six.string_types):\n        raise ValueError('isoparse() requires a string parameter')\n    dt_str = dt_str.replace('T','')\n    dt_str = dt_str.strip()\n\n    # isoparse does not accept fractional seconds, so parse it manually:\n    if dt_str.endswith('.') and dt_str[:-1].endswith('.'):\n        dt_str = dt_str[:-1]\n\n    if self._isoparse_invalid_formats_allowed(dt_str):\n        return self._parse_isoparse(dt_str)\n    elif self._isoparse_invalid_timezone(dt_str):\n        return self._parse_isoparse(dt_str, self._get_timezone(dt_str))\n    else:\n        return self._parse_isoparse(dt_str, self._get_local_tz(dt_str))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    parsed = self.parse_datetime(dt_str)\n    if parsed is None:\n        parsed = self.parse_time(dt_str)\n    if parsed is None:\n        return parsed\n    return parsed\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    if self._isoparse_re.match(dt_str):\n        dt_str = self._isoparse_re.sub(r'-', dt_str)\n        return datetime.datetime(*(int(x) for x in dt_str.split('-')))\n\n    raise ValueError('Not a valid ISO-8601 datetime string: %r' % dt_str)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    if isinstance(dt_str, datetime.datetime):\n        return dt_str\n    elif isinstance(dt_str, six.string_types):\n        return self.parse_iso_datetime(dt_str)\n    else:\n        raise ValueError('Unable to parse datetime string:'+ dt_str)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    if not isinstance(dt_str, str):\n        raise ValueError('isoparse() only accepts strings')\n\n    parsed = self._parse(dt_str)\n\n    if parsed is None:\n        return None\n\n    return datetime.datetime(*parsed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    # type: (str) -> datetime.datetime\n    \"\"\"Parse an ISO-8601 datetime string into a :class:`datetime.datetime`.\n\n    An ISO-8601 datetime string consists of a date portion, followed optionally\n    by a time portion, followed optionally by a time portion - the date\n    and time portions are separated by a single character separator, which\n    is ``T`` in the official standard. Incomplete date formats may *not*\n    be combined with a time portion. Supported date formats are:\n\n    Common: - ``YYYY`` - `YYY-MM` or ``YYY-MM-DD`` or ``YYYMMDD``\n    - `YYYYMMDD` - or ``YYYYYMMDD`` - or ``YYYYYMMDD`` - or ``YYYMMDD``\n                    (uncommon, non-standard standard but is not implemented in\n                    this parser. Support fractional components other than\n                    seconds are part of the standard)\n\n    \"\"\"\n    return datetime.datetime(*(\n  ", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    parsed = parse(dt_str, self._datetime_formats)\n    if parsed['year'] is None:\n        parsed['year'] = parsed['month']\n        parsed['month'] = parsed['day']\n        parsed['day'] = parsed['hour']\n        parsed['hour'] = parsed['minute']\n        parsed['minute'] = parsed['second']\n    return parsed\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    return isoparse(dt_str, self.tzinfos)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    return datetime.datetime.strptime(dt_str, ISO8601_DATE_FORMAT).replace(tzinfo=pytz.utc)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "dateutil/parser/_parser.py", "project": "pexip/os-python-dateutil", "name": "parse", "docstring": "Parse the date/time string into a :class:`datetime.datetime` object.\n\n:param timestr:\n    Any date/time string using the supported formats.\n\n:param default:\n    The default datetime object, if this is a datetime object and not\n    ``None``, elements specified in ``timestr`` replace elements in the\n    default object.\n\n:param ignoretz:\n    If set ``True``, time zones in parsed strings are ignored and a\n    naive :class:`datetime.datetime` object is returned.\n\n:param tzinfos:\n    Additional time zone names / aliases which may be present in the\n    string. This argument maps time zone names (and optionally offsets\n    from those time zones) to time zones. This parameter can be a\n    dictionary with timezone aliases mapping time zone names to time\n    zones or a function taking two parameters (``tzname`` and\n    ``tzoffset``) and returning a time zone.\n\n    The timezones to which the names are mapped can be an integer\n    offset from UTC in seconds or a :class:`tzinfo` object.\n\n    .. doctest::\n       :options: +NORMALIZE_WHITESPACE\n\n        >>> from dateutil.parser import parse\n        >>> from dateutil.tz import gettz\n        >>> tzinfos = {\"BRST\": -7200, \"CST\": gettz(\"America/Chicago\")}\n        >>> parse(\"2012-01-19 17:21:00 BRST\", tzinfos=tzinfos)\n        datetime.datetime(2012, 1, 19, 17, 21, tzinfo=tzoffset(u'BRST', -7200))\n        >>> parse(\"2012-01-19 17:21:00 CST\", tzinfos=tzinfos)\n        datetime.datetime(2012, 1, 19, 17, 21,\n                          tzinfo=tzfile('/usr/share/zoneinfo/America/Chicago'))\n\n    This parameter is ignored if ``ignoretz`` is set.\n\n:param \\*\\*kwargs:\n    Keyword arguments as passed to ``_parse()``.\n\n:return:\n    Returns a :class:`datetime.datetime` object or, if the\n    ``fuzzy_with_tokens`` option is ``True``, returns a tuple, the\n    first element being a :class:`datetime.datetime` object, the second\n    a tuple containing the fuzzy tokens.\n\n:raises ParserError:\n    Raised for invalid or unknown string format, if the provided\n    :class:`tzinfo` is not in a valid format, or if an invalid date\n    would be created.\n\n:raises TypeError:\n    Raised for non-string or character stream input.\n\n:raises OverflowError:\n    Raised if the parsed date exceeds the largest valid C integer on\n    your system.", "ques_id": "62b896de755ee91dce50a183", "code": ["def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime\n        object and not ``None``, elements specified in ``timestr``\n        replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings\n        are ignored and a naive :class:`datetime.datetime` object is\n        returned.\n    :param tzinfos: Additional time zone names / aliases which may\n        be present in the string. This parameter maps time zone\n        names (and optionally offsets from those time zones) to\n        time zones.\n\n   ..doctest::options: +NORMALIZE_WHITESPACE\n\n        >>> from dateutil.parser import parse\n        >>> from dateutil.tz import gettz\n        >>> tzinfos = {\"BRST\": -7200, \"CST\": gettz(\"America/Chicago\")}", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n                        and not ``None``, elements specified in ``timestr``\n                        replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n                        ignored and a naive :class:`datetime.datetime`\n                        object is returned.\n    :param tzinfos: Additional time zones / aliases which may be\n                     presented in the string. This parameter maps\n                     time zone names (and optionally offsets from\n                         tzinfos) to time zone.\n                    ..doctest::options: +NO", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime\n                    object and not ``None``, elements specified in ``timestr``\n                    replace elements in the default object.\n\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n                    ignored and a naive :class:`datetime.datetime` object\n                    is returned.\n\n    :param tzinfos: Additional time zone names / aliases which may\n                    be present in the string. This parameter maps\n                    time zone names (and optionally offsets from the\n                    time zone) to time zones.\n\n                    doctest: :options: +NORMALIZE_WHITESPACE\n\n   ", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime\n                    object and not ``None``, elements specified in ``timestr``\n                    replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings\n                     are ignored and a naive :class:`datetime.datetime`\n                     object is returned.\n    :param tzinfos: Additional time zone names / aliases which may\n                    be present in the string. This parameter maps\n                    time zone names (and optionally offsets from the\n                    time zone) to time zones.\n\n                   ..doctest::options: +NORMALIZE_WHITESPACE\n    ", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n                     and not ``None``, elements specified in ``timestr``\n                     replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings\n                      replace elements in the default object.\n    :param tzinfos: Additional time zone names / aliases which\n                      may be present in the string.\n                      This parameter maps time zone names (and\n                      optionally offsets from those time zones) to\n                      time zones.\n                     ..doctest::options: +NORMALIZE_WHITESPACE\n\n    >>>", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n                      and not ``None``, elements specified in ``timestr``\n                      replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings\n                      replace elements specified in the time zone names\n                      and return a naive :class:`datetime.datetime` object\n                      object.\n    :param tzinfos: Additional time zone names / aliases which may\n                     be present in the string. This parameter maps\n                      time zone names (and optionally offsets from\n                      these time zones) to time zone", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime object\n                        and not ``None``, elements specified in ``timestr``\n                        replace elements in the default object.\n\n    :param ignoretz: If set ``True``, time zones in parsed strings\n                        replace elements specified in the string.\n\n    :param tzinfos: Additional time zones / aliases which may be\n                    presented in the string.\n\n   ..doctest::options: +NORMALIZE_WHITESPACE\n\n                    >>> from dateutil.parser import parse\n                    >>> from dateutil.tz import gettz\n                    >>> tzinfos = {\"BRST\": -7200, \"CST", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n                     and not ``None``, elements specified in ``timestr``\n                     replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n                     ignored and a naive :class:`datetime.datetime` object\n                     is returned.\n    :param tzinfos: Additional time zone names / aliases which may be\n                     presented in the string. This parameter maps time\n                     zone names (and optionally offsets from these\n                     time zones) to time zones.\n                     This parameter can be a dictionary with\n ", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n                                        and not ``None``, elements specified in\n                                                                                                                                                                                                                                                                                                                                         ", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime\n                    object and not ``None``, elements specified in ``timestr``\n                    replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings\n                     are ignored and a naive :class:`datetime.datetime`\n                     object is returned.\n    :param tzinfos: Additional time zone names / aliases which may\n                    be present in the string. This parameter maps\n                    time zone names (and optionally offsets from\n                     those time zones) to time zone.\n                   ..doctest::\n                    >>"], "level": "project_runnable", "generate_results": [{"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime\n        object and not ``None``, elements specified in ``timestr``\n        replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings\n        are ignored and a naive :class:`datetime.datetime` object is\n        returned.\n    :param tzinfos: Additional time zone names / aliases which may\n        be present in the string. This parameter maps time zone\n        names (and optionally offsets from those time zones) to\n        time zones.\n\n   ..doctest::options: +NORMALIZE_WHITESPACE\n\n        >>> from dateutil.parser import parse\n        >>> from dateutil.tz import gettz\n        >>> tzinfos = {\"BRST\": -7200, \"CST\": gettz(\"America/Chicago\")}", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n                        and not ``None``, elements specified in ``timestr``\n                        replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n                        ignored and a naive :class:`datetime.datetime`\n                        object is returned.\n    :param tzinfos: Additional time zones / aliases which may be\n                     presented in the string. This parameter maps\n                     time zone names (and optionally offsets from\n                         tzinfos) to time zone.\n                    ..doctest::options: +NO", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime\n                    object and not ``None``, elements specified in ``timestr``\n                    replace elements in the default object.\n\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n                    ignored and a naive :class:`datetime.datetime` object\n                    is returned.\n\n    :param tzinfos: Additional time zone names / aliases which may\n                    be present in the string. This parameter maps\n                    time zone names (and optionally offsets from the\n                    time zone) to time zones.\n\n                    doctest: :options: +NORMALIZE_WHITESPACE\n\n   ", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime\n                    object and not ``None``, elements specified in ``timestr``\n                    replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings\n                     are ignored and a naive :class:`datetime.datetime`\n                     object is returned.\n    :param tzinfos: Additional time zone names / aliases which may\n                    be present in the string. This parameter maps\n                    time zone names (and optionally offsets from the\n                    time zone) to time zones.\n\n                   ..doctest::options: +NORMALIZE_WHITESPACE\n    ", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n                     and not ``None``, elements specified in ``timestr``\n                     replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings\n                      replace elements in the default object.\n    :param tzinfos: Additional time zone names / aliases which\n                      may be present in the string.\n                      This parameter maps time zone names (and\n                      optionally offsets from those time zones) to\n                      time zones.\n                     ..doctest::options: +NORMALIZE_WHITESPACE\n\n    >>>", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n                      and not ``None``, elements specified in ``timestr``\n                      replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings\n                      replace elements specified in the time zone names\n                      and return a naive :class:`datetime.datetime` object\n                      object.\n    :param tzinfos: Additional time zone names / aliases which may\n                     be present in the string. This parameter maps\n                      time zone names (and optionally offsets from\n                      these time zones) to time zone", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime object\n                        and not ``None``, elements specified in ``timestr``\n                        replace elements in the default object.\n\n    :param ignoretz: If set ``True``, time zones in parsed strings\n                        replace elements specified in the string.\n\n    :param tzinfos: Additional time zones / aliases which may be\n                    presented in the string.\n\n   ..doctest::options: +NORMALIZE_WHITESPACE\n\n                    >>> from dateutil.parser import parse\n                    >>> from dateutil.tz import gettz\n                    >>> tzinfos = {\"BRST\": -7200, \"CST", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n                     and not ``None``, elements specified in ``timestr``\n                     replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n                     ignored and a naive :class:`datetime.datetime` object\n                     is returned.\n    :param tzinfos: Additional time zone names / aliases which may be\n                     presented in the string. This parameter maps time\n                     zone names (and optionally offsets from these\n                     time zones) to time zones.\n                     This parameter can be a dictionary with\n ", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n                                        and not ``None``, elements specified in\n                                                                                                                                                                                                                                                                                                                                         ", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime\n                    object and not ``None``, elements specified in ``timestr``\n                    replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings\n                     are ignored and a naive :class:`datetime.datetime`\n                     object is returned.\n    :param tzinfos: Additional time zone names / aliases which may\n                    be present in the string. This parameter maps\n                    time zone names (and optionally offsets from\n                     those time zones) to time zone.\n                   ..doctest::\n                    >>", "is_pass": false, "return_code": 1}]}
{"file_path": "dateutil/tz/_common.py", "project": "pexip/os-python-dateutil", "name": "fromutc", "docstring": "Given a timezone-aware datetime in a given timezone, calculates a\ntimezone-aware datetime in a new timezone.\n\nSince this is the one time that we *know* we have an unambiguous\ndatetime object, we take this opportunity to determine whether the\ndatetime is ambiguous and in a \"fold\" state (e.g. if it's the first\noccurrence, chronologically, of the ambiguous datetime).\n\n:param dt:\n    A timezone-aware :class:`datetime.datetime` object.", "ques_id": "62b8a4a4755ee91dce50a3d3", "code": ["def fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self.UTC)\n    return dt.astimezone(self.UTC)\n", "def fromutc(self, dt):\n    if dt.tzinfo is None:\n        raise ValueError(\"Cannot freeze naive time.\")\n    return dt.astimezone(self)\n", "def fromutc(self, dt):\n\n    if dt.tzinfo is None:\n        raise ValueError('Cannot take timezone-aware datetimes')\n\n    return dt.astimezone(self)\n", "def fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt\n\n    return dt.astimezone(self._tz)\n", "def fromutc(self, dt):\n    if self._tzinfo is not None and dt.tzinfo is not None:\n        dt = dt.astimezone(self._tzinfo)\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self._tzinfo)\n    return dt.replace(microsecond=0)\n", "def fromutc(self, dt):\n    if self._is_frozen:\n        raise FrozenError(\"Can't change time zone after freezing.\")\n\n    if dt.tzinfo is None:\n        raise ValueError(\"Cannot freeze naive timestamp without timezone.\")\n\n    # Early versions of dateutil send a warning when the time zone\n    # is explicitly set to None to indicate that the time zone is\n    # required to be set.  For backwards compatibility with earlier\n    # versions, we may need to manually set the time zone to the default\n    # time zone if set to the default time zone.\n    if self._default_tz is None:\n        dt = dt.replace(tzinfo=None)\n\n    return dt.astimezone(self)\n", "def fromutc(self, dt):\n    return dt.replace(tzinfo=self)\n", "def fromutc(self, dt):\n    if self._is_ambiguous(dt):\n        # TODO: This is a bit different than fromutc() because it's a\n        #       complicated logic and we don't want to modify the original\n        #       object.\n        dt = dt.astimezone(self._tz)\n    return dt.replace(tzinfo=None)\n", "def fromutc(self, dt):\n    return dt.replace(tzinfo=self)\n", "def fromutc(self, dt):\n    if dt.tzinfo is None:\n        raise ValueError(\"fromutc() requires a timezone-aware datetime object\")\n    return dt.astimezone(self)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self.UTC)\n    return dt.astimezone(self.UTC)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    if dt.tzinfo is None:\n        raise ValueError(\"Cannot freeze naive time.\")\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n\n    if dt.tzinfo is None:\n        raise ValueError('Cannot take timezone-aware datetimes')\n\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt\n\n    return dt.astimezone(self._tz)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    if self._tzinfo is not None and dt.tzinfo is not None:\n        dt = dt.astimezone(self._tzinfo)\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self._tzinfo)\n    return dt.replace(microsecond=0)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    if self._is_frozen:\n        raise FrozenError(\"Can't change time zone after freezing.\")\n\n    if dt.tzinfo is None:\n        raise ValueError(\"Cannot freeze naive timestamp without timezone.\")\n\n    # Early versions of dateutil send a warning when the time zone\n    # is explicitly set to None to indicate that the time zone is\n    # required to be set.  For backwards compatibility with earlier\n    # versions, we may need to manually set the time zone to the default\n    # time zone if set to the default time zone.\n    if self._default_tz is None:\n        dt = dt.replace(tzinfo=None)\n\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    return dt.replace(tzinfo=self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    if self._is_ambiguous(dt):\n        # TODO: This is a bit different than fromutc() because it's a\n        #       complicated logic and we don't want to modify the original\n        #       object.\n        dt = dt.astimezone(self._tz)\n    return dt.replace(tzinfo=None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    return dt.replace(tzinfo=self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    if dt.tzinfo is None:\n        raise ValueError(\"fromutc() requires a timezone-aware datetime object\")\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "dateutil/utils.py", "project": "pexip/os-python-dateutil", "name": "default_tzinfo", "docstring": "Sets the ``tzinfo`` parameter on naive datetimes only\n\nThis is useful for example when you are provided a datetime that may have\neither an implicit or explicit time zone, such as when parsing a time zone\nstring.\n\n.. doctest::\n\n    >>> from dateutil.tz import tzoffset\n    >>> from dateutil.parser import parse\n    >>> from dateutil.utils import default_tzinfo\n    >>> dflt_tz = tzoffset(\"EST\", -18000)\n    >>> print(default_tzinfo(parse('2014-01-01 12:30 UTC'), dflt_tz))\n    2014-01-01 12:30:00+00:00\n    >>> print(default_tzinfo(parse('2014-01-01 12:30'), dflt_tz))\n    2014-01-01 12:30:00-05:00\n\n:param dt:\n    The datetime on which to replace the time zone\n\n:param tzinfo:\n    The :py:class:`datetime.tzinfo` subclass instance to assign to\n    ``dt`` if (and only if) it is naive.\n\n:return:\n    Returns an aware :py:class:`datetime.datetime`.", "ques_id": "62b8a7b2755ee91dce50a4a7", "code": ["def default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    if is_naive(dt):\n        return dt.replace(tzinfo=tzinfo)\n    else:\n        return dt\n", "def default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    if tzinfo is None:\n        return dt\n    if is_naive(dt):\n        dt = dt.replace(tzinfo=None)\n    return dt.astimezone(tzinfo)\n", "def default_tzinfo(dt, tzinfo):\n    if isinstance(dt, datetime) and dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    elif isinstance(dt, date) and dt.tzinfo is not None:\n        dt = dt.astimezone(tzinfo)\n\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    if not is_naive(dt):\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n"], "level": "self_contained", "generate_results": [{"generate_code": "def default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n", "is_pass": true, "return_code": 0}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n\n    return dt\n", "is_pass": true, "return_code": 0}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if is_naive(dt):\n        return dt.replace(tzinfo=tzinfo)\n    else:\n        return dt\n", "is_pass": false, "return_code": 1}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n", "is_pass": true, "return_code": 0}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n", "is_pass": true, "return_code": 0}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n", "is_pass": true, "return_code": 0}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if tzinfo is None:\n        return dt\n    if is_naive(dt):\n        dt = dt.replace(tzinfo=None)\n    return dt.astimezone(tzinfo)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if isinstance(dt, datetime) and dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    elif isinstance(dt, date) and dt.tzinfo is not None:\n        dt = dt.astimezone(tzinfo)\n\n    return dt\n", "is_pass": false, "return_code": 1}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if not is_naive(dt):\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n", "is_pass": false, "return_code": 1}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n", "is_pass": true, "return_code": 0}]}
{"file_path": "src/lithium/testcases.py", "project": "MozillaSecurity/lithium", "name": "set_cut_chars", "docstring": "Set the bytes used to delimit slice points.\n\nArgs:\n    before: Split file before these delimiters.\n    after: Split file after these delimiters.", "ques_id": "6305f9991d275c6667163c50", "code": ["def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._pre_delimiter = before\n    self._post_delimiter = after\n", "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._cut_chars = before, after\n", "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._cut_chars = (before, after)\n", "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._delimiters = [before, after]\n", "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    if before is None:\n        self._cut_chars = None\n    else:\n        self._cut_chars = _b_to_u(before)\n    if after is None:\n        self._cut_chars = None\n    else:\n        self._cut_chars = _b_to_u(after)\n", "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    if not isinstance(before, bytes):\n        raise TypeError('before must be a bytes object.')\n    if not isinstance(after, bytes):\n        raise TypeError('after must be a bytes object.')\n    self._cut_chars = before, after\n", "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._delimiters = [before, after]\n", "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._delimiter = before\n    self._delimiter_len = len(before)\n    self._split_after = after\n    self._split_delimiter = None\n", "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._cut_chars = before.decode('utf-8') + ',' + after.decode('utf-8')\n", "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._set_chars(_SPLIT_FILE_DELIMITER, before, after)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._pre_delimiter = before\n    self._post_delimiter = after\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._cut_chars = before, after\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._cut_chars = (before, after)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._delimiters = [before, after]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    if before is None:\n        self._cut_chars = None\n    else:\n        self._cut_chars = _b_to_u(before)\n    if after is None:\n        self._cut_chars = None\n    else:\n        self._cut_chars = _b_to_u(after)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    if not isinstance(before, bytes):\n        raise TypeError('before must be a bytes object.')\n    if not isinstance(after, bytes):\n        raise TypeError('after must be a bytes object.')\n    self._cut_chars = before, after\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._delimiters = [before, after]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._delimiter = before\n    self._delimiter_len = len(before)\n    self._split_after = after\n    self._split_delimiter = None\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._cut_chars = before.decode('utf-8') + ',' + after.decode('utf-8')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._set_chars(_SPLIT_FILE_DELIMITER, before, after)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/protocols/diaspora/protocol.py", "project": "jaywink/federation", "name": "identify_request", "docstring": "Try to identify whether this is a Diaspora request.\n\nTry first public message. Then private message. The check if this is a legacy payload.", "ques_id": "6306292052e177c0ba469f09", "code": ["def identify_request(request: RequestType):\n    try:\n        return request.json() and request.headers[\"X-Events\"] == \"true\"\n    except (KeyError, TypeError):\n        return False\n", "def identify_request(request: RequestType):\n    if request is None:\n        return False\n    if 'xml' not in request.body:\n        return False\n    if request.body.get('xml') is None:\n        return False\n    if request.body.get('xml') == '{}':\n        return True\n    if get_xml_tag(request)!= MESSAGE_TAG:\n        return False\n    return True\n", "def identify_request(request: RequestType):\n    request_body = request.get_data()\n    if request_body is None:\n        return False\n\n    request_events = json.loads(request_body.decode('utf-8'))\n\n    if request_events.get('events') is not None:\n        return True\n\n    if request_events.get('magic_env_tag'):\n        return True\n\n    return False\n", "def identify_request(request: RequestType):\n    if not request.json:\n        return False\n\n    return request.json.get('tag', '') in (\n        settings.MKTG_URLS['ROOT'],\n        settings.MKTG_URLS['ROOT'].replace('/en/', '/'),\n    )\n", "def identify_request(request: RequestType):\n    if request is None:\n        return False\n\n    request_body = request.get_data()\n    return request_body.lower() in _events.get(request.method.upper(), [])\n", "def identify_request(request: RequestType):\n    if request.method == \"POST\":\n        return True\n    if request.method == \"PUT\":\n        return False\n    if request.method == \"DELETE\":\n        return False\n    if request.method == \"PATCH\":\n        return True\n    if request.body:\n        if request.body.strip():\n            return True\n    return False\n", "def identify_request(request: RequestType):\n    request_body = request.get_json()\n\n    if request_body and request_body.get(\"tag\"):\n        return True\n\n    return False\n", "def identify_request(request: RequestType):\n    return (\n        '/events' in request.data and\n        request.data['/events'][0]['tag'] == 'Mock_Event'\n    )\n", "def identify_request(request: RequestType):\n    return request.json is not None and request.json.get('tag') is not None\n", "def identify_request(request: RequestType):\n    if request.method == 'POST':\n        return True\n    if request.method == 'PUT':\n        if request.headers.get('Content-Type') == 'application/xml':\n            return True\n    return False\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def identify_request(request: RequestType):\n    try:\n        return request.json() and request.headers[\"X-Events\"] == \"true\"\n    except (KeyError, TypeError):\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType):\n    if request is None:\n        return False\n    if 'xml' not in request.body:\n        return False\n    if request.body.get('xml') is None:\n        return False\n    if request.body.get('xml') == '{}':\n        return True\n    if get_xml_tag(request)!= MESSAGE_TAG:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType):\n    request_body = request.get_data()\n    if request_body is None:\n        return False\n\n    request_events = json.loads(request_body.decode('utf-8'))\n\n    if request_events.get('events') is not None:\n        return True\n\n    if request_events.get('magic_env_tag'):\n        return True\n\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType):\n    if not request.json:\n        return False\n\n    return request.json.get('tag', '') in (\n        settings.MKTG_URLS['ROOT'],\n        settings.MKTG_URLS['ROOT'].replace('/en/', '/'),\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType):\n    if request is None:\n        return False\n\n    request_body = request.get_data()\n    return request_body.lower() in _events.get(request.method.upper(), [])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType):\n    if request.method == \"POST\":\n        return True\n    if request.method == \"PUT\":\n        return False\n    if request.method == \"DELETE\":\n        return False\n    if request.method == \"PATCH\":\n        return True\n    if request.body:\n        if request.body.strip():\n            return True\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType):\n    request_body = request.get_json()\n\n    if request_body and request_body.get(\"tag\"):\n        return True\n\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType):\n    return (\n        '/events' in request.data and\n        request.data['/events'][0]['tag'] == 'Mock_Event'\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType):\n    return request.json is not None and request.json.get('tag') is not None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType):\n    if request.method == 'POST':\n        return True\n    if request.method == 'PUT':\n        if request.headers.get('Content-Type') == 'application/xml':\n            return True\n    return False\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/protocols/matrix/protocol.py", "project": "jaywink/federation", "name": "identify_request", "docstring": "Try to identify whether this is a Matrix request", "ques_id": "6306292152e177c0ba469f0d", "code": ["def identify_request(request: RequestType) -> bool:\n    return request.content_type in [\"application/json\", \"text/json\"]\n", "def identify_request(request: RequestType) -> bool:\n    body = request.get_json(force=True)\n    if body and \"events\" in body:\n        return True\n    return False\n", "def identify_request(request: RequestType) -> bool:\n    return request.method in EVENTS\n", "def identify_request(request: RequestType) -> bool:\n    if request.method == \"POST\" and request.content_type == \"application/json\":\n        try:\n            request.json\n            return True\n        except json.decoder.JSONDecodeError:\n            return False\n\n    return False\n", "def identify_request(request: RequestType) -> bool:\n    return request.method in (\"POST\", \"PUT\", \"DELETE\")\n", "def identify_request(request: RequestType) -> bool:\n    return request.method in (\"GET\", \"HEAD\")\n", "def identify_request(request: RequestType) -> bool:\n    if request.content_type!= \"application/json\":\n        return False\n    try:\n        request.json\n    except ValueError:\n        return False\n    return True\n", "def identify_request(request: RequestType) -> bool:\n    return request.method in (\"POST\", \"PUT\", \"PATCH\", \"DELETE\")\n", "def identify_request(request: RequestType) -> bool:\n    return request.method in (\"GET\", \"HEAD\")\n", "def identify_request(request: RequestType) -> bool:\n    body = request.get_json()\n    return \"events\" in body\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def identify_request(request: RequestType) -> bool:\n    return request.content_type in [\"application/json\", \"text/json\"]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType) -> bool:\n    body = request.get_json(force=True)\n    if body and \"events\" in body:\n        return True\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType) -> bool:\n    return request.method in EVENTS\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType) -> bool:\n    if request.method == \"POST\" and request.content_type == \"application/json\":\n        try:\n            request.json\n            return True\n        except json.decoder.JSONDecodeError:\n            return False\n\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType) -> bool:\n    return request.method in (\"POST\", \"PUT\", \"DELETE\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType) -> bool:\n    return request.method in (\"GET\", \"HEAD\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType) -> bool:\n    if request.content_type!= \"application/json\":\n        return False\n    try:\n        request.json\n    except ValueError:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType) -> bool:\n    return request.method in (\"POST\", \"PUT\", \"PATCH\", \"DELETE\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType) -> bool:\n    return request.method in (\"GET\", \"HEAD\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: RequestType) -> bool:\n    body = request.get_json()\n    return \"events\" in body\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/entities/diaspora/utils.py", "project": "jaywink/federation", "name": "format_dt", "docstring": "Format a datetime in the way that D* nodes expect.", "ques_id": "6306292252e177c0ba469f11", "code": ["def format_dt(dt):\n    return ensure_timezone(dt).strftime('%Y-%m-%d %H:%M:%S')\n", "def format_dt(dt):\n    if dt.tzinfo is None:\n        dt = ensure_timezone(dt)\n    return dt.strftime('%H:%M')\n", "def format_dt(dt):\n    return ensure_timezone(dt).strftime('%Y-%m-%dT%H:%M:%S')\n", "def format_dt(dt):\n    return ensure_timezone(dt).strftime('%Y-%m-%d %H:%M:%S')\n", "def format_dt(dt):\n    return ensure_timezone(dt).strftime('%H:%M %d-%m-%Y')\n", "def format_dt(dt):\n    return ensure_timezone(dt.strftime('%Y-%m-%dT%H:%M:%SZ'))\n", "def format_dt(dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=pytz.utc)\n    return ensure_timezone(dt).strftime('%H:%M %d/%m/%Y')\n", "def format_dt(dt):\n    return ensure_timezone(dt.astimezone(pytz.utc)).strftime('%Y-%m-%d %H:%M:%S')\n", "def format_dt(dt):\n    return ensure_timezone(dt).strftime('%Y-%m-%d %H:%M:%S')\n", "def format_dt(dt):\n    return ensure_timezone(dt.strftime('%H:%M:%S'))\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def format_dt(dt):\n    return ensure_timezone(dt).strftime('%Y-%m-%d %H:%M:%S')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    if dt.tzinfo is None:\n        dt = ensure_timezone(dt)\n    return dt.strftime('%H:%M')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    return ensure_timezone(dt).strftime('%Y-%m-%dT%H:%M:%S')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    return ensure_timezone(dt).strftime('%Y-%m-%d %H:%M:%S')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    return ensure_timezone(dt).strftime('%H:%M %d-%m-%Y')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    return ensure_timezone(dt.strftime('%Y-%m-%dT%H:%M:%SZ'))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=pytz.utc)\n    return ensure_timezone(dt).strftime('%H:%M %d/%m/%Y')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    return ensure_timezone(dt.astimezone(pytz.utc)).strftime('%Y-%m-%d %H:%M:%S')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    return ensure_timezone(dt).strftime('%Y-%m-%d %H:%M:%S')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    return ensure_timezone(dt.strftime('%H:%M:%S'))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/text.py", "project": "jaywink/federation", "name": "find_tags", "docstring": "Find tags in text.\n\nTries to ignore tags inside code blocks.\n\nOptionally, if passed a \"replacer\", will also replace the tag word with the result\nof the replacer function called with the tag word.\n\nReturns a set of tags and the original or replaced text.", "ques_id": "6306292352e177c0ba469f1d", "code": ["def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    if replacer is None:\n        def replacer(match):\n            return match.group(1)\n\n    pattern = r\"\"\"\n    (?P<tags>(?:(?P<replacement>\\S+)\\s+\\:\\s+(?P<original>.*?)))\n    \"\"\"\n\n    return re.findall(pattern, text, flags=re.UNICODE | re.MULTILINE | re.VERBOSE)\n", "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    if replacer is not None:\n        text = replacer(text)\n    return _CODE_PATTERN.findall(text)\n", "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    regex = re.compile(r'\\[(.*?)\\]')\n    replaced = regex.sub(replacer, '', text)\n    return re.findall(regex, replaced)\n", "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    # Strip HTML tags with non-breaking spaces\n    text = re.sub(r'<.*?>', '', text)\n    # Replace HTML entities\n    text = re.sub(r'&(#?)([0-9]+)([^;]*);', r'\\1&nbsp;\\2', text)\n    # Replace code blocks\n    if replacer is not None:\n        text = replacer(text)\n    # Remove html tags and return only the original text\n    return set(re.findall(r'<.*?>', text)), text\n", "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    text = re.sub(r\"<!--.*?-->\", \"\", text)  # Remove tags\n    text = re.sub(r\"<(?![^>]*>).*?</\", \"\", text)  # Replace tags with replacer\n\n    if replacer is None:\n        return find_tags_in(text)\n    else:\n        return find_tags_in(replacer(text))\n", "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    tags = set()\n\n    if replacer:\n        text = replacer(text)\n\n    for match in TAGS_REGEX.finditer(text):\n        tag = match.group(1)\n        text = text[:match.start(1)] + replacer(text[match.start(1):match.end(1)]) + text[match.end(1):]\n        tags.add(tag)\n\n    return tags, text\n", "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    tags = set()\n    for match in _CODE_TAGS_PATTERN.finditer(text):\n        if replacer:\n            tags.add(replacer(match))\n        else:\n            tags.add(match.group())\n    return tags, text\n", "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    text = CODE_BLOCK_RE.sub(\"\", text)\n    return _find_tags_in_text(text, replacer)\n", "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    tags = set()\n    replacer = replacer or (lambda m: m.group(0))\n    text = text.replace('```', '') if '```' in text else text\n    for match in _CODE_RE.finditer(text):\n        tag = match.group(0)\n        if tag:\n            if replacer(match):\n                text = replacer(match)\n            else:\n                text = text.replace(tag, '')\n        else:\n            text = text.replace(match.group(0), '')\n    return tags, text\n", "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    tags = set()\n    if replacer is None:\n        def replacer(match):\n            return match.group(1)\n\n    pattern = r'(?:<!\\\\)(.+?)(?:</\\1>|#.+?$)'\n    replace = replacer\n    for match in re.finditer(pattern, text):\n        original = match.group(0)\n        replacement = replacer(match)\n        text = re.sub(re.escape(original), replacement, text, flags=re.I)\n        tags.add(original)\n\n    return tags, text\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    if replacer is None:\n        def replacer(match):\n            return match.group(1)\n\n    pattern = r\"\"\"\n    (?P<tags>(?:(?P<replacement>\\S+)\\s+\\:\\s+(?P<original>.*?)))\n    \"\"\"\n\n    return re.findall(pattern, text, flags=re.UNICODE | re.MULTILINE | re.VERBOSE)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    if replacer is not None:\n        text = replacer(text)\n    return _CODE_PATTERN.findall(text)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    regex = re.compile(r'\\[(.*?)\\]')\n    replaced = regex.sub(replacer, '', text)\n    return re.findall(regex, replaced)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    # Strip HTML tags with non-breaking spaces\n    text = re.sub(r'<.*?>', '', text)\n    # Replace HTML entities\n    text = re.sub(r'&(#?)([0-9]+)([^;]*);', r'\\1&nbsp;\\2', text)\n    # Replace code blocks\n    if replacer is not None:\n        text = replacer(text)\n    # Remove html tags and return only the original text\n    return set(re.findall(r'<.*?>', text)), text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    text = re.sub(r\"<!--.*?-->\", \"\", text)  # Remove tags\n    text = re.sub(r\"<(?![^>]*>).*?</\", \"\", text)  # Replace tags with replacer\n\n    if replacer is None:\n        return find_tags_in(text)\n    else:\n        return find_tags_in(replacer(text))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    tags = set()\n\n    if replacer:\n        text = replacer(text)\n\n    for match in TAGS_REGEX.finditer(text):\n        tag = match.group(1)\n        text = text[:match.start(1)] + replacer(text[match.start(1):match.end(1)]) + text[match.end(1):]\n        tags.add(tag)\n\n    return tags, text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    tags = set()\n    for match in _CODE_TAGS_PATTERN.finditer(text):\n        if replacer:\n            tags.add(replacer(match))\n        else:\n            tags.add(match.group())\n    return tags, text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    text = CODE_BLOCK_RE.sub(\"\", text)\n    return _find_tags_in_text(text, replacer)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    tags = set()\n    replacer = replacer or (lambda m: m.group(0))\n    text = text.replace('```', '') if '```' in text else text\n    for match in _CODE_RE.finditer(text):\n        tag = match.group(0)\n        if tag:\n            if replacer(match):\n                text = replacer(match)\n            else:\n                text = text.replace(tag, '')\n        else:\n            text = text.replace(match.group(0), '')\n    return tags, text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: callable = None) -> Tuple[Set, str]:\n    tags = set()\n    if replacer is None:\n        def replacer(match):\n            return match.group(1)\n\n    pattern = r'(?:<!\\\\)(.+?)(?:</\\1>|#.+?$)'\n    replace = replacer\n    for match in re.finditer(pattern, text):\n        original = match.group(0)\n        replacement = replacer(match)\n        text = re.sub(re.escape(original), replacement, text, flags=re.I)\n        tags.add(original)\n\n    return tags, text\n", "is_pass": true, "return_code": 0}]}
{"file_path": "federation/utils/text.py", "project": "jaywink/federation", "name": "process_text_links", "docstring": "Process links in text, adding some attributes and linkifying textual links.", "ques_id": "6306292352e177c0ba469f1e", "code": ["def process_text_links(text):\n    return linkify_text(text, LinkifyParser())\n", "def process_text_links(text):\n    return linkify_text(text, get_link_attrs())\n", "def process_text_links(text):\n    return linkify(text, get_link_attributes())\n", "def process_text_links(text):\n    linkified = linkify(text)\n    linkified = replace_urls(linkified)\n    return linkified\n", "def process_text_links(text):\n    text = linkify_text(text)\n    return text\n", "def process_text_links(text):\n    text = linkify(text)\n    text = text.replace('[[Category::Link]]', '[[Category::Text]]')\n    text = text.replace('[[Category::Link]] [[Link::Link]]', '[[Category::Link]] [[Link::Text]]')\n    text = text.replace('[[Category::Link]] Category::Link', '[[Category::Link]] Category::Text')\n    text = text.replace('[[Category::Link]] Category::Link Category::Link', '[[Category::Link]] Category::Text Category::Link')\n    text = text.replace('[[Category::Link]] Category::Link Category::Link Category::Link', '[[Category::Link]] Category::Text Category::Link Category::Link')\n    text = text.replace('[[Category::Link]] Category::Link Category::Link Category::Link Category::Link', '[[Category::Link]] Category::Link Category::Link Category::Link')\n    return text\n", "def process_text_links(text):\n    text = linkify_text(text)\n    return text\n", "def process_text_links(text):\n    linkify_regex = re.compile(r'\\[\\[(.*?)\\]\\]', re.DOTALL)\n    linkify_text = re.sub(linkify_regex, linkify_attributes, text)\n    return linkify_text\n", "def process_text_links(text):\n    text = replace_links(text)\n    return linkify(text)\n", "def process_text_links(text):\n    return linkify_text(text, add_attributes=True)\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def process_text_links(text):\n    return linkify_text(text, LinkifyParser())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    return linkify_text(text, get_link_attrs())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    return linkify(text, get_link_attributes())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    linkified = linkify(text)\n    linkified = replace_urls(linkified)\n    return linkified\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    text = linkify_text(text)\n    return text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    text = linkify(text)\n    text = text.replace('[[Category::Link]]', '[[Category::Text]]')\n    text = text.replace('[[Category::Link]] [[Link::Link]]', '[[Category::Link]] [[Link::Text]]')\n    text = text.replace('[[Category::Link]] Category::Link', '[[Category::Link]] Category::Text')\n    text = text.replace('[[Category::Link]] Category::Link Category::Link', '[[Category::Link]] Category::Text Category::Link')\n    text = text.replace('[[Category::Link]] Category::Link Category::Link Category::Link', '[[Category::Link]] Category::Text Category::Link Category::Link')\n    text = text.replace('[[Category::Link]] Category::Link Category::Link Category::Link Category::Link', '[[Category::Link]] Category::Link Category::Link Category::Link')\n    return text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    text = linkify_text(text)\n    return text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    linkify_regex = re.compile(r'\\[\\[(.*?)\\]\\]', re.DOTALL)\n    linkify_text = re.sub(linkify_regex, linkify_attributes, text)\n    return linkify_text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    text = replace_links(text)\n    return linkify(text)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    return linkify_text(text, add_attributes=True)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/network.py", "project": "jaywink/federation", "name": "fetch_content_type", "docstring": "Fetch the HEAD of the remote url to determine the content type.", "ques_id": "6306292652e177c0ba469f34", "code": ["def fetch_content_type(url: str) -> Optional[str]:\n    if url is None or url == \"\":\n        return None\n\n    headers = {}\n    if USER_AGENT is not None:\n        headers[\"User-Agent\"] = USER_AGENT\n\n    try:\n        req = request.urlopen(url, headers=headers)\n    except request.HTTPError as e:\n        if e.code == 404:\n            return None\n        raise\n\n    if req.getheader(\"Content-Type\") is None:\n        return None\n    return req.getheader(\"Content-Type\")\n", "def fetch_content_type(url: str) -> Optional[str]:\n    url = parse.urlsplit(url)\n    if not url.scheme:\n        return None\n\n    if url.scheme == \"https\":\n        return \"https\"\n\n    if url.scheme == \"http\":\n        user_agent = \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/537.36\"\n    else:\n        user_agent = \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/537.36\"\n\n    headers = {\"User-Agent\": user_agent}\n    try:\n        r = requests.get(url.geturl(), headers=headers)\n        if r.status_code == 200:\n            return r.headers[\"Content-Type\"]\n    except Exception:\n        pass\n\n    return None\n", "def fetch_content_type(url: str) -> Optional[str]:\n    if url is not None:\n        url = parse.urlparse(url)\n        if url.username is None:\n            user_agent = \"Mozilla/5.0 (Windows; U; Windows NT 5.1; de-DE; rv:2.1.0) Gecko/20090420 Firefox/2.0.0.11\"\n        elif url.version is None:\n            user_agent = \"Mozilla/5.0 (Windows; U; Windows NT 5.1; de-DE; rv:2.1.0) Gecko/20090420 Firefox/2.0.0.11\"\n        else:\n            user_agent = \"Mozilla/5.0 (Windows; U; Windows NT 5.1; de-DE; rv:{}.0.0.post0) Gecko/20090420 Firefox/2.0.0.11\".format(\n                url.version\n            )\n        return user_agent + \" \" + url.headers.get(\"User-Agent\", \"\")\n    return None\n", "def fetch_content_type(url: str) -> Optional[str]:\n    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n    response = requests.get(url, headers=headers)\n    if response.status_code == 200:\n        return response.headers[\"content-type\"]\n    return None\n", "def fetch_content_type(url: str) -> Optional[str]:\n    url_info = urlparse(url)\n\n    if url_info.username or url_info.password:\n        return '{}://{}'.format(url_info.scheme, url_info.netloc)\n    else:\n        return None\n", "def fetch_content_type(url: str) -> Optional[str]:\n    headers = {\"User-Agent\": USER_AGENT}\n    response = requests.get(url, headers=headers)\n\n    if response.status_code == 200:\n        return response.headers[\"content-type\"]\n    return None\n", "def fetch_content_type(url: str) -> Optional[str]:\n    url_info = urlparse(url)\n    if not (url_info.scheme and url_info.netloc):\n        return None\n\n    user_agent = \"Mozilla/5.0 (Windows; U; Windows NT 6.1; de-DE; rv:2.0.0) Gecko/2015-05-23; fr-FR; v=b.0\"\n    headers = {\"User-Agent\": user_agent}\n    response = requests.get(url, headers=headers)\n    if response.status_code!= 200:\n        return None\n    return response.headers[\"Content-Type\"]\n", "def fetch_content_type(url: str) -> Optional[str]:\n    if url:\n        headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:23.0) Gecko/20100101 Firefox/23.0\"}\n        response = requests.get(url, headers=headers)\n        if response.status_code == 200:\n            return response.headers.get(\"Content-Type\")\n    return None\n", "def fetch_content_type(url: str) -> Optional[str]:\n    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.3; WOW64) \"\n                            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n                            \"Chrome/72.0.3626.117 Safari/537.36\"}\n    try:\n        response = requests.get(url, headers=headers)\n    except requests.exceptions.RequestException as e:\n        print(\"Error fetching content type from {0}: {1}\".format(url, e))\n        return None\n\n    if response.status_code!= 200:\n        print(\"HTTP request failed ({0})\".format(response.status_code))\n        return None\n    return response.headers[\"Content-Type\"]\n", "def fetch_content_type(url: str) -> Optional[str]:\n    response = requests.get(url, headers={\"User-Agent\": USER_AGENT})\n    if response.status_code!= 200:\n        return None\n    return response.headers[\"Content-Type\"]\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def fetch_content_type(url: str) -> Optional[str]:\n    if url is None or url == \"\":\n        return None\n\n    headers = {}\n    if USER_AGENT is not None:\n        headers[\"User-Agent\"] = USER_AGENT\n\n    try:\n        req = request.urlopen(url, headers=headers)\n    except request.HTTPError as e:\n        if e.code == 404:\n            return None\n        raise\n\n    if req.getheader(\"Content-Type\") is None:\n        return None\n    return req.getheader(\"Content-Type\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> Optional[str]:\n    url = parse.urlsplit(url)\n    if not url.scheme:\n        return None\n\n    if url.scheme == \"https\":\n        return \"https\"\n\n    if url.scheme == \"http\":\n        user_agent = \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/537.36\"\n    else:\n        user_agent = \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/537.36\"\n\n    headers = {\"User-Agent\": user_agent}\n    try:\n        r = requests.get(url.geturl(), headers=headers)\n        if r.status_code == 200:\n            return r.headers[\"Content-Type\"]\n    except Exception:\n        pass\n\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> Optional[str]:\n    if url is not None:\n        url = parse.urlparse(url)\n        if url.username is None:\n            user_agent = \"Mozilla/5.0 (Windows; U; Windows NT 5.1; de-DE; rv:2.1.0) Gecko/20090420 Firefox/2.0.0.11\"\n        elif url.version is None:\n            user_agent = \"Mozilla/5.0 (Windows; U; Windows NT 5.1; de-DE; rv:2.1.0) Gecko/20090420 Firefox/2.0.0.11\"\n        else:\n            user_agent = \"Mozilla/5.0 (Windows; U; Windows NT 5.1; de-DE; rv:{}.0.0.post0) Gecko/20090420 Firefox/2.0.0.11\".format(\n                url.version\n            )\n        return user_agent + \" \" + url.headers.get(\"User-Agent\", \"\")\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> Optional[str]:\n    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n    response = requests.get(url, headers=headers)\n    if response.status_code == 200:\n        return response.headers[\"content-type\"]\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> Optional[str]:\n    url_info = urlparse(url)\n\n    if url_info.username or url_info.password:\n        return '{}://{}'.format(url_info.scheme, url_info.netloc)\n    else:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> Optional[str]:\n    headers = {\"User-Agent\": USER_AGENT}\n    response = requests.get(url, headers=headers)\n\n    if response.status_code == 200:\n        return response.headers[\"content-type\"]\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> Optional[str]:\n    url_info = urlparse(url)\n    if not (url_info.scheme and url_info.netloc):\n        return None\n\n    user_agent = \"Mozilla/5.0 (Windows; U; Windows NT 6.1; de-DE; rv:2.0.0) Gecko/2015-05-23; fr-FR; v=b.0\"\n    headers = {\"User-Agent\": user_agent}\n    response = requests.get(url, headers=headers)\n    if response.status_code!= 200:\n        return None\n    return response.headers[\"Content-Type\"]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> Optional[str]:\n    if url:\n        headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:23.0) Gecko/20100101 Firefox/23.0\"}\n        response = requests.get(url, headers=headers)\n        if response.status_code == 200:\n            return response.headers.get(\"Content-Type\")\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> Optional[str]:\n    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.3; WOW64) \"\n                            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n                            \"Chrome/72.0.3626.117 Safari/537.36\"}\n    try:\n        response = requests.get(url, headers=headers)\n    except requests.exceptions.RequestException as e:\n        print(\"Error fetching content type from {0}: {1}\".format(url, e))\n        return None\n\n    if response.status_code!= 200:\n        print(\"HTTP request failed ({0})\".format(response.status_code))\n        return None\n    return response.headers[\"Content-Type\"]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fetch_content_type(url: str) -> Optional[str]:\n    response = requests.get(url, headers={\"User-Agent\": USER_AGENT})\n    if response.status_code!= 200:\n        return None\n    return response.headers[\"Content-Type\"]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/text.py", "project": "jaywink/federation", "name": "test_tag", "docstring": "Test a word whether it could be accepted as a tag.", "ques_id": "6306292a52e177c0ba469f41", "code": ["def test_tag(tag: str) -> bool:\n    return any(t in tag for t in LEEGAL_TAG_CHARS)\n", "def test_tag(tag: str) -> bool:\n    return any(tag in char for char in LEEGAL_TAG_CHARS)\n", "def test_tag(tag: str) -> bool:\n    return not any(tag.startswith(char) for char in LEEGAL_TAG_CHARS)\n", "def test_tag(tag: str) -> bool:\n    return any(tag in c for c in LEEGAL_TAG_CHARS)\n", "def test_tag(tag: str) -> bool:\n    return all(c in tag for c in LEEGAL_TAG_CHARS)\n", "def test_tag(tag: str) -> bool:\n    return (\n        any(tag.startswith(c) for c in LEEGAL_TAG_CHARS) and\n        not any(tag.endswith(c) for c in LEEGAL_TAG_CHARS)\n    )\n", "def test_tag(tag: str) -> bool:\n    return any(tag in c for c in LEEGAL_TAG_CHARS)\n", "def test_tag(tag: str) -> bool:\n    if not tag:\n        return False\n    return any(tag.startswith(c) for c in LEEGAL_TAG_CHARS)\n", "def test_tag(tag: str) -> bool:\n    for char in LEEGAL_TAG_CHARS:\n        if char in tag:\n            return True\n    return False\n", "def test_tag(tag: str) -> bool:\n    return any(t in tag for t in LEEGAL_TAG_CHARS)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def test_tag(tag: str) -> bool:\n    return any(t in tag for t in LEEGAL_TAG_CHARS)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str) -> bool:\n    return any(tag in char for char in LEEGAL_TAG_CHARS)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str) -> bool:\n    return not any(tag.startswith(char) for char in LEEGAL_TAG_CHARS)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str) -> bool:\n    return any(tag in c for c in LEEGAL_TAG_CHARS)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str) -> bool:\n    return all(c in tag for c in LEEGAL_TAG_CHARS)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str) -> bool:\n    return (\n        any(tag.startswith(c) for c in LEEGAL_TAG_CHARS) and\n        not any(tag.endswith(c) for c in LEEGAL_TAG_CHARS)\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str) -> bool:\n    return any(tag in c for c in LEEGAL_TAG_CHARS)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str) -> bool:\n    if not tag:\n        return False\n    return any(tag.startswith(c) for c in LEEGAL_TAG_CHARS)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str) -> bool:\n    for char in LEEGAL_TAG_CHARS:\n        if char in tag:\n            return True\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str) -> bool:\n    return any(t in tag for t in LEEGAL_TAG_CHARS)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/entities/diaspora/mappers.py", "project": "jaywink/federation", "name": "xml_children_as_dict", "docstring": "Turn the children of node <xml> into a dict, keyed by tag name.\n\nThis is only a shallow conversation - child nodes are not recursively processed.", "ques_id": "6306298b52e177c0ba469fdc", "code": ["def xml_children_as_dict(node):\n    children = node.getchildren()\n    result = {}\n    for child in children:\n        tag = child.tag\n        result[tag] = child.text if child.text is not None else ''\n    return result\n", "def xml_children_as_dict(node):\n    d = {}\n    for child in node.getchildren():\n        tag = child.tag\n        d[tag] = child.text\n    return d\n", "def xml_children_as_dict(node):\n    return {child.tag: child.text for child in node}\n", "def xml_children_as_dict(node):\n    result = {}\n    for child in node:\n        tag = child.tag\n        result[tag] = child.text\n    return result\n", "def xml_children_as_dict(node):\n    return dict([(child.tag, child.text) for child in node])\n", "def xml_children_as_dict(node):\n    result = {}\n    for child in node:\n        tag = etree.QName(child).localname\n        result[tag] = child\n    return result\n", "def xml_children_as_dict(node):\n    return {child.tag: child.text for child in node}\n", "def xml_children_as_dict(node):\n    d = {}\n    for c in node.getchildren():\n        d[c.tag] = c.text\n    return d\n", "def xml_children_as_dict(node):\n    children = node.getchildren()\n    result = {}\n    for child in children:\n        tag = child.tag\n        if tag not in result:\n            result[tag] = []\n        result[tag].append(child)\n    return result\n", "def xml_children_as_dict(node):\n    d = {}\n    for child in list(node):\n        tag = child.tag\n        d[tag] = child\n    return d\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def xml_children_as_dict(node):\n    children = node.getchildren()\n    result = {}\n    for child in children:\n        tag = child.tag\n        result[tag] = child.text if child.text is not None else ''\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xml_children_as_dict(node):\n    d = {}\n    for child in node.getchildren():\n        tag = child.tag\n        d[tag] = child.text\n    return d\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xml_children_as_dict(node):\n    return {child.tag: child.text for child in node}\n", "is_pass": true, "return_code": 0}, {"generate_code": "def xml_children_as_dict(node):\n    result = {}\n    for child in node:\n        tag = child.tag\n        result[tag] = child.text\n    return result\n", "is_pass": true, "return_code": 0}, {"generate_code": "def xml_children_as_dict(node):\n    return dict([(child.tag, child.text) for child in node])\n", "is_pass": true, "return_code": 0}, {"generate_code": "def xml_children_as_dict(node):\n    result = {}\n    for child in node:\n        tag = etree.QName(child).localname\n        result[tag] = child\n    return result\n", "is_pass": true, "return_code": 0}, {"generate_code": "def xml_children_as_dict(node):\n    return {child.tag: child.text for child in node}\n", "is_pass": true, "return_code": 0}, {"generate_code": "def xml_children_as_dict(node):\n    d = {}\n    for c in node.getchildren():\n        d[c.tag] = c.text\n    return d\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xml_children_as_dict(node):\n    children = node.getchildren()\n    result = {}\n    for child in children:\n        tag = child.tag\n        if tag not in result:\n            result[tag] = []\n        result[tag].append(child)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xml_children_as_dict(node):\n    d = {}\n    for child in list(node):\n        tag = child.tag\n        d[tag] = child\n    return d\n", "is_pass": true, "return_code": 0}]}
{"file_path": "federation/entities/diaspora/mappers.py", "project": "jaywink/federation", "name": "check_sender_and_entity_handle_match", "docstring": "Ensure that sender and entity handles match.\n\nBasically we've already verified the sender is who they say when receiving the payload. However, the sender might\nbe trying to set another author in the payload itself, since Diaspora has the sender in both the payload headers\nAND the object. We must ensure they're the same.", "ques_id": "6306299052e177c0ba469fe8", "code": ["def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    sender_entity_type = get_entity_type(sender_handle)\n    if sender_entity_type!= entity_handle:\n        return False\n    return True\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    return sender_handle == entity_handle\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    return sender_handle == entity_handle\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    return sender_handle == entity_handle\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n\n    return sender_handle == entity_handle\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    return True if sender_handle == entity_handle else False\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    return sender_handle == entity_handle\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    return sender_handle == entity_handle\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle == entity_handle:\n        return True\n    else:\n        return False\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n\n    if sender_handle == entity_handle:\n        return True\n    else:\n        return False\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    sender_entity_type = get_entity_type(sender_handle)\n    if sender_entity_type!= entity_handle:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    return sender_handle == entity_handle\n", "is_pass": true, "return_code": 0}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    return sender_handle == entity_handle\n", "is_pass": true, "return_code": 0}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    return sender_handle == entity_handle\n", "is_pass": true, "return_code": 0}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n\n    return sender_handle == entity_handle\n", "is_pass": true, "return_code": 0}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    return True if sender_handle == entity_handle else False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    return sender_handle == entity_handle\n", "is_pass": true, "return_code": 0}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    return sender_handle == entity_handle\n", "is_pass": true, "return_code": 0}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle == entity_handle:\n        return True\n    else:\n        return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n\n    if sender_handle == entity_handle:\n        return True\n    else:\n        return False\n", "is_pass": true, "return_code": 0}]}
{"file_path": "federation/hostmeta/generators.py", "project": "jaywink/federation", "name": "get_nodeinfo_well_known_document", "docstring": "Generate a NodeInfo .well-known document.\n\nSee spec: http://nodeinfo.diaspora.software\n\n:arg url: The full base url with protocol, ie https://example.com\n:arg document_path: Custom NodeInfo document path if supplied (optional)\n:returns: dict", "ques_id": "630629b952e177c0ba46a043", "code": ["def get_nodeinfo_well_known_document(url, document_path=None):\n    return {\n        \"document_url\": url,\n        \"document_path\": document_path,\n    }\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    info = {'url': url, 'document_path': document_path}\n    return info\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    return {\n        \"document_path\": document_path or url,\n        \"url\": url,\n    }\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    result = {\n        \"url\": url,\n        \"document_path\": document_path\n    }\n    return result\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    result = {\n        \"@id\": url,\n        \"@context\": \"http://schema.org/\",\n        \"type\": \"Document\",\n        \"url\": url,\n        \"document_path\": document_path,\n        \"version\": get_version(url),\n    }\n    return result\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    nodeinfo = {'url': url, 'document_path': document_path}\n\n    if url.startswith('/'):\n        nodeinfo['url'] = url\n\n    return nodeinfo\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    result = {\n        \"document_path\": document_path or url,\n        \"url\": url,\n    }\n    if url.startswith(\"/\"):\n        result[\"url\"] = url[1:]\n\n    if \"://\" in url:\n        result[\"document_path\"] = \"file://\" + result[\"document_path\"]\n\n    return result\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n\n    doc = {\n        \"url\": url,\n        \"document_path\": document_path or url,\n    }\n\n    return doc\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    result = {\n        'document_path': document_path or url,\n        'url': url,\n    }\n\n    if url.startswith(DOCUMENT_PREFIX):\n        result['document_path'] = url[len(DOCUMENT_PREFIX):]\n\n    return result\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    return {\n        \"document_path\": document_path,\n        \"url\": url\n    }\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    return {\n        \"document_url\": url,\n        \"document_path\": document_path,\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    info = {'url': url, 'document_path': document_path}\n    return info\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    return {\n        \"document_path\": document_path or url,\n        \"url\": url,\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    result = {\n        \"url\": url,\n        \"document_path\": document_path\n    }\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    result = {\n        \"@id\": url,\n        \"@context\": \"http://schema.org/\",\n        \"type\": \"Document\",\n        \"url\": url,\n        \"document_path\": document_path,\n        \"version\": get_version(url),\n    }\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    nodeinfo = {'url': url, 'document_path': document_path}\n\n    if url.startswith('/'):\n        nodeinfo['url'] = url\n\n    return nodeinfo\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    result = {\n        \"document_path\": document_path or url,\n        \"url\": url,\n    }\n    if url.startswith(\"/\"):\n        result[\"url\"] = url[1:]\n\n    if \"://\" in url:\n        result[\"document_path\"] = \"file://\" + result[\"document_path\"]\n\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n\n    doc = {\n        \"url\": url,\n        \"document_path\": document_path or url,\n    }\n\n    return doc\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    result = {\n        'document_path': document_path or url,\n        'url': url,\n    }\n\n    if url.startswith(DOCUMENT_PREFIX):\n        result['document_path'] = url[len(DOCUMENT_PREFIX):]\n\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    return {\n        \"document_path\": document_path,\n        \"url\": url\n    }\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/protocols/diaspora/signatures.py", "project": "jaywink/federation", "name": "verify_relayable_signature", "docstring": "Verify the signed XML elements to have confidence that the claimed\nauthor did actually generate this message.", "ques_id": "630629d052e177c0ba46a0a1", "code": ["def verify_relayable_signature(public_key, doc, signature):\n\n    if not isinstance(doc, etree._Element):\n        raise ValueError(\"The claimed author didn't generate the document\")\n\n    if not isinstance(signature, etree._Element):\n        raise ValueError(\"The claimed author didn't generate the signature\")\n\n    signature_elem = etree.XML(signature.decode('utf-8'))\n\n    if signature_elem.find(\".//RelayState\") is None:\n        raise ValueError(\"The claimed author didn't generate the signature\")\n\n    if not _verify_signature(public_key, doc, signature_elem):\n        raise ValueError(\"The claimed author didn't claim the expected relay state\")\n", "def verify_relayable_signature(public_key, doc, signature):\n    return verify_signature(public_key, doc, signature,'relayable')\n", "def verify_relayable_signature(public_key, doc, signature):\n    return _verify_signature(public_key, doc, signature, relayable_sig_version)\n", "def verify_relayable_signature(public_key, doc, signature):\n    if not signature:\n        return\n\n    doc = etree.fromstring(doc)\n    relay_signature = doc.find('relaySignature')\n    if not relay_signature:\n        return\n\n    if relay_signature.text!= signature:\n        raise VerificationError(\"Message does not verify signature\")\n", "def verify_relayable_signature(public_key, doc, signature):\n    return verify_signature(public_key, doc, signature)\n", "def verify_relayable_signature(public_key, doc, signature):\n    if not verify_signature(public_key, doc, signature):\n        raise SignatureMismatch()\n", "def verify_relayable_signature(public_key, doc, signature):\n\n    if not isinstance(signature, str):\n        raise TypeError(\"signature must be a string\")\n\n    if not isinstance(public_key, str):\n        raise TypeError(\"public_key must be a string\")\n\n    if len(signature)!= 64:\n        raise ValueError(\"signature must be 64 bytes\")\n\n    pk = etree.XML(public_key)\n    sk = etree.XML(doc)\n\n    cs = _etree.XML(_pk.xml_text())\n    cs_sig = _etree.XML(_pk.xml_signature())\n\n    if cs!= cs_sig:\n        raise SignatureMismatch(_pk.xml_text(), _pk.xml_signature())\n", "def verify_relayable_signature(public_key, doc, signature):\n    signature_data = serialize_xml_element(doc)\n    return verify_signature(public_key, signature_data, signature)\n", "def verify_relayable_signature(public_key, doc, signature):\n    if not isinstance(doc, etree._Element):\n        raise ValueError('doc must be an etree._Element')\n    if not isinstance(signature, etree._Element):\n        raise ValueError('signature must be an etree._Element')\n    if not isinstance(public_key, etree._Element):\n        raise ValueError('public_key must be an etree._Element')\n    if not len(signature) == 64:\n        raise ValueError('signature must be 64 chars')\n    if not len(public_key) == 64:\n        raise ValueError('public_key must be 64 chars')\n\n    xml_root = doc.getroot()\n    relay_node = xml_root.find('{%s}Relay' % ns_map['taxii'])\n    if relay_node is None:\n        raise ValueError('XML root missing relay')\n    if relay_node.attrib['relay_id']!= str(uuid.uuid4()):\n        raise ValueError('invalid message relay_id: %s'", "def verify_relayable_signature(public_key, doc, signature):\n    try:\n        return _verify_signature(public_key, doc, signature)\n    except SignatureMismatch:\n        return False\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n\n    if not isinstance(doc, etree._Element):\n        raise ValueError(\"The claimed author didn't generate the document\")\n\n    if not isinstance(signature, etree._Element):\n        raise ValueError(\"The claimed author didn't generate the signature\")\n\n    signature_elem = etree.XML(signature.decode('utf-8'))\n\n    if signature_elem.find(\".//RelayState\") is None:\n        raise ValueError(\"The claimed author didn't generate the signature\")\n\n    if not _verify_signature(public_key, doc, signature_elem):\n        raise ValueError(\"The claimed author didn't claim the expected relay state\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    return verify_signature(public_key, doc, signature,'relayable')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    return _verify_signature(public_key, doc, signature, relayable_sig_version)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    if not signature:\n        return\n\n    doc = etree.fromstring(doc)\n    relay_signature = doc.find('relaySignature')\n    if not relay_signature:\n        return\n\n    if relay_signature.text!= signature:\n        raise VerificationError(\"Message does not verify signature\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    return verify_signature(public_key, doc, signature)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    if not verify_signature(public_key, doc, signature):\n        raise SignatureMismatch()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n\n    if not isinstance(signature, str):\n        raise TypeError(\"signature must be a string\")\n\n    if not isinstance(public_key, str):\n        raise TypeError(\"public_key must be a string\")\n\n    if len(signature)!= 64:\n        raise ValueError(\"signature must be 64 bytes\")\n\n    pk = etree.XML(public_key)\n    sk = etree.XML(doc)\n\n    cs = _etree.XML(_pk.xml_text())\n    cs_sig = _etree.XML(_pk.xml_signature())\n\n    if cs!= cs_sig:\n        raise SignatureMismatch(_pk.xml_text(), _pk.xml_signature())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    signature_data = serialize_xml_element(doc)\n    return verify_signature(public_key, signature_data, signature)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    if not isinstance(doc, etree._Element):\n        raise ValueError('doc must be an etree._Element')\n    if not isinstance(signature, etree._Element):\n        raise ValueError('signature must be an etree._Element')\n    if not isinstance(public_key, etree._Element):\n        raise ValueError('public_key must be an etree._Element')\n    if not len(signature) == 64:\n        raise ValueError('signature must be 64 chars')\n    if not len(public_key) == 64:\n        raise ValueError('public_key must be 64 chars')\n\n    xml_root = doc.getroot()\n    relay_node = xml_root.find('{%s}Relay' % ns_map['taxii'])\n    if relay_node is None:\n        raise ValueError('XML root missing relay')\n    if relay_node.attrib['relay_id']!= str(uuid.uuid4()):\n        raise ValueError('invalid message relay_id: %s'", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    try:\n        return _verify_signature(public_key, doc, signature)\n    except SignatureMismatch:\n        return False\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/diaspora.py", "project": "jaywink/federation", "name": "parse_diaspora_webfinger", "docstring": "Parse Diaspora webfinger which is either in JSON format (new) or XRD (old).\n\nhttps://diaspora.github.io/diaspora_federation/discovery/webfinger.html", "ques_id": "630629e052e177c0ba46a0c4", "code": ["def parse_diaspora_webfinger(document: str) -> Dict:\n    result = {}\n    try:\n        hcard_url = document.split('<a href=\"')[1].split('\"')[0]\n        result[\"hcard_url\"] = hcard_url\n    except IndexError:\n        pass\n    return result\n", "def parse_diaspora_webfinger(document: str) -> Dict:\n    try:\n        json_data = json.loads(document)\n        return json_data['hcard_url']\n    except JSONDecodeError:\n        return {}\n", "def parse_diaspora_webfinger(document: str) -> Dict:\n    return json.loads(document)\n", "def parse_diaspora_webfinger(document: str) -> Dict:\n    try:\n        hcard_url = json.loads(document)['hcard_url']\n    except (ValueError, KeyError):\n        hcard_url = ''\n    return {\n        'hcard_url': hcard_url\n    }\n", "def parse_diaspora_webfinger(document: str) -> Dict:\n    try:\n        json_data = json.loads(document)\n        return json_data[\"hcard_url\"]\n    except ValueError:\n        return None\n", "def parse_diaspora_webfinger(document: str) -> Dict:\n    return json.loads(WebfingerParser.read(document))\n", "def parse_diaspora_webfinger(document: str) -> Dict:\n    try:\n        json_data = json.loads(document)\n    except ValueError as e:\n        logger.error(\"Failed to parse webfinger data: %s\", e)\n        return {}\n\n    return {\n        \"hcard_url\": json_data.get(\"hcard_url\"),\n        \"webfinger\": json_data.get(\"webfinger\"),\n    }\n", "def parse_diaspora_webfinger(document: str) -> Dict:\n    try:\n        with io.BytesIO(document.encode()) as f:\n            return json.load(f)\n    except ValueError:\n        return {}\n", "def parse_diaspora_webfinger(document: str) -> Dict:\n    data = json.loads(document)\n    hcard_url = data.get(\"hcard_url\")\n    if hcard_url:\n        return {\"url\": hcard_url}\n    else:\n        return {\"url\": \"\"}\n", "def parse_diaspora_webfinger(document: str) -> Dict:\n    try:\n        return json.loads(document)['hcard_url']\n    except ValueError:\n        raise ValueError(\n            'The document is not in JSON format. It contained no links.')\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def parse_diaspora_webfinger(document: str) -> Dict:\n    result = {}\n    try:\n        hcard_url = document.split('<a href=\"')[1].split('\"')[0]\n        result[\"hcard_url\"] = hcard_url\n    except IndexError:\n        pass\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: str) -> Dict:\n    try:\n        json_data = json.loads(document)\n        return json_data['hcard_url']\n    except JSONDecodeError:\n        return {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: str) -> Dict:\n    return json.loads(document)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: str) -> Dict:\n    try:\n        hcard_url = json.loads(document)['hcard_url']\n    except (ValueError, KeyError):\n        hcard_url = ''\n    return {\n        'hcard_url': hcard_url\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: str) -> Dict:\n    try:\n        json_data = json.loads(document)\n        return json_data[\"hcard_url\"]\n    except ValueError:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: str) -> Dict:\n    return json.loads(WebfingerParser.read(document))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: str) -> Dict:\n    try:\n        json_data = json.loads(document)\n    except ValueError as e:\n        logger.error(\"Failed to parse webfinger data: %s\", e)\n        return {}\n\n    return {\n        \"hcard_url\": json_data.get(\"hcard_url\"),\n        \"webfinger\": json_data.get(\"webfinger\"),\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: str) -> Dict:\n    try:\n        with io.BytesIO(document.encode()) as f:\n            return json.load(f)\n    except ValueError:\n        return {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: str) -> Dict:\n    data = json.loads(document)\n    hcard_url = data.get(\"hcard_url\")\n    if hcard_url:\n        return {\"url\": hcard_url}\n    else:\n        return {\"url\": \"\"}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: str) -> Dict:\n    try:\n        return json.loads(document)['hcard_url']\n    except ValueError:\n        raise ValueError(\n            'The document is not in JSON format. It contained no links.')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/network.py", "project": "jaywink/federation", "name": "try_retrieve_webfinger_document", "docstring": "Try to retrieve an RFC7033 webfinger document. Does not raise if it fails.", "ques_id": "630629e152e177c0ba46a0d1", "code": ["def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n\n    try:\n        return urlopen(URL_WEBFINGER_DOCUMENT.format(handle)).read().decode(\"utf-8\")\n    except HTTPError:\n        return None\n", "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        handle.open()\n        handle.seek(0)\n        return handle.read()\n    except Exception:\n        return None\n", "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        return urlopen(\"https://rfc7033.net/rfc/\" + handle).read()\n    except URLError:\n        return None\n", "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        with urlopen(handle) as response:\n            return response.read().decode(\"utf-8\")\n    except HTTPError as e:\n        if e.code == 404:\n            return None\n        else:\n            raise\n", "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        with open(handle, \"rb\") as f:\n            return f.read().decode(\"utf-8\")\n    except (OSError, IOError):\n        return None\n", "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        handle.open()\n        handle.seek(0)\n        return handle.read()\n    except (urllib.error.URLError, urllib.error.HTTPError):\n        return None\n    finally:\n        handle.close()\n", "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        return urlopen(DOCUMENT_URL + handle).read().decode(\"utf-8\")\n    except HTTPError:\n        return None\n", "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n\n    try:\n        return urlopen(URL_WEBFINGER_DOCUMENT.format(handle)).read().decode('utf-8')\n    except HTTPError:\n        return None\n", "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        with open(handle, \"rb\") as handle:\n            return handle.read()\n    except (OSError, FileNotFoundError):\n        return None\n", "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        return urlopen(DOCUMENT_URL + handle).read().decode(\"utf-8\")\n    except HTTPError:\n        return None\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n\n    try:\n        return urlopen(URL_WEBFINGER_DOCUMENT.format(handle)).read().decode(\"utf-8\")\n    except HTTPError:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        handle.open()\n        handle.seek(0)\n        return handle.read()\n    except Exception:\n        return None\n", "is_pass": true, "return_code": 0}, {"generate_code": "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        return urlopen(\"https://rfc7033.net/rfc/\" + handle).read()\n    except URLError:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        with urlopen(handle) as response:\n            return response.read().decode(\"utf-8\")\n    except HTTPError as e:\n        if e.code == 404:\n            return None\n        else:\n            raise\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        with open(handle, \"rb\") as f:\n            return f.read().decode(\"utf-8\")\n    except (OSError, IOError):\n        return None\n", "is_pass": true, "return_code": 0}, {"generate_code": "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        handle.open()\n        handle.seek(0)\n        return handle.read()\n    except (urllib.error.URLError, urllib.error.HTTPError):\n        return None\n    finally:\n        handle.close()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        return urlopen(DOCUMENT_URL + handle).read().decode(\"utf-8\")\n    except HTTPError:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n\n    try:\n        return urlopen(URL_WEBFINGER_DOCUMENT.format(handle)).read().decode('utf-8')\n    except HTTPError:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        with open(handle, \"rb\") as handle:\n            return handle.read()\n    except (OSError, FileNotFoundError):\n        return None\n", "is_pass": true, "return_code": 0}, {"generate_code": "def try_retrieve_webfinger_document(handle: str) -> Optional[str]:\n    try:\n        return urlopen(DOCUMENT_URL + handle).read().decode(\"utf-8\")\n    except HTTPError:\n        return None\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/diaspora.py", "project": "jaywink/federation", "name": "retrieve_and_parse_diaspora_webfinger", "docstring": "Retrieve a and parse a remote Diaspora webfinger document.\n\n:arg handle: Remote handle to retrieve\n:returns: dict", "ques_id": "630629e152e177c0ba46a0d2", "code": ["def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    response.raise_for_status()\n    return response.json()\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    response.raise_for_status()\n    return response.json()\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    return parse_diaspora_webfinger(response.text)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    response.raise_for_status()\n    return response.json()\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    doc = retrieve_diaspora_document(handle)\n    return parse_webfinger_document(doc)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    if response.status_code!= 200:\n        raise RemoteServerError(\"Unable to retrieve remote Diaspora webfinger document: %s\" % response.text)\n    return parse_diaspora_webfinger_response(response)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    response.raise_for_status()\n\n    return parse_diaspora_webfinger_response(response)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    return _parse_diaspora_webfinger_response(response)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    if response.status_code!= 200:\n        raise ValueError('Received status code {}.'.format(response.status_code))\n    return parse_diaspora_webfinger_response(response)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    r = requests.get(handle)\n    if r.status_code == 200:\n        return r.json()\n    else:\n        return {}\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    response.raise_for_status()\n    return response.json()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    response.raise_for_status()\n    return response.json()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    return parse_diaspora_webfinger(response.text)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    response.raise_for_status()\n    return response.json()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    doc = retrieve_diaspora_document(handle)\n    return parse_webfinger_document(doc)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    if response.status_code!= 200:\n        raise RemoteServerError(\"Unable to retrieve remote Diaspora webfinger document: %s\" % response.text)\n    return parse_diaspora_webfinger_response(response)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    response.raise_for_status()\n\n    return parse_diaspora_webfinger_response(response)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    return _parse_diaspora_webfinger_response(response)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = requests.get(handle)\n    if response.status_code!= 200:\n        raise ValueError('Received status code {}.'.format(response.status_code))\n    return parse_diaspora_webfinger_response(response)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    r = requests.get(handle)\n    if r.status_code == 200:\n        return r.json()\n    else:\n        return {}\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/diaspora.py", "project": "jaywink/federation", "name": "retrieve_diaspora_host_meta", "docstring": "Retrieve a remote Diaspora host-meta document.\n\n:arg host: Host to retrieve from\n:returns: ``XRD`` instance", "ques_id": "630629e252e177c0ba46a0d6", "code": ["def retrieve_diaspora_host_meta(host):\n    url = DIAsporaConfig.host_meta_url.format(host=host)\n    response = requests.get(url)\n    response.raise_for_status()\n    return XRD(response.text)\n", "def retrieve_diaspora_host_meta(host):\n    response = requests.get(\n        DIAsporaHostMetaDatabaseUrl.format(host=host),\n        auth=(settings.USER, settings.PASSWORD),\n        timeout=60\n    )\n\n    response.raise_for_status()\n\n    return XRD(response.text)\n", "def retrieve_diaspora_host_meta(host):\n    r = requests.get(DIAspora.HOST_META_URL.format(host=host))\n    return XRD.from_xml(r.text)\n", "def retrieve_diaspora_host_meta(host):\n    if host == 'localhost':\n        host = '127.0.0.1'\n    url = 'http://%s/xrd' % host\n    response = requests.get(url)\n    response.raise_for_status()\n    return XRD(response.text)\n", "def retrieve_diaspora_host_meta(host):\n    response = requests.get(\n        DIAspora.host_meta_url.format(host)\n    )\n    response.raise_for_status()\n    return XRD(response.content)\n", "def retrieve_diaspora_host_meta(host):\n    return get_xrd_from_url(\n        DIAsporaClient.get_host_meta_url(host)\n    )\n", "def retrieve_diaspora_host_meta(host):\n    response = requests.get(\n        DIAspora.host_meta_url.format(host=host),\n        auth=(settings.USER, settings.PASSWORD),\n    )\n    response.raise_for_status()\n    return XRD(response.content)\n", "def retrieve_diaspora_host_meta(host):\n    res = requests.get(\n        DIAspora.host_meta_url.format(host=host),\n        auth=(settings.USER, settings.PASSWORD))\n    res.raise_for_status()\n    return XRD(res.text)\n", "def retrieve_diaspora_host_meta(host):\n    url = DIAspora.host_meta_url.format(host)\n    response = requests.get(url)\n    response.raise_for_status()\n    return XRD(response.text)\n", "def retrieve_diaspora_host_meta(host):\n    url = (\n        \"https://diaspora.mitre.org/xrds/{host}\"\n    ).format(host=host)\n    response = requests.get(url)\n    response.raise_for_status()\n    return XRD(response.text)\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def retrieve_diaspora_host_meta(host):\n    url = DIAsporaConfig.host_meta_url.format(host=host)\n    response = requests.get(url)\n    response.raise_for_status()\n    return XRD(response.text)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    response = requests.get(\n        DIAsporaHostMetaDatabaseUrl.format(host=host),\n        auth=(settings.USER, settings.PASSWORD),\n        timeout=60\n    )\n\n    response.raise_for_status()\n\n    return XRD(response.text)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    r = requests.get(DIAspora.HOST_META_URL.format(host=host))\n    return XRD.from_xml(r.text)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    if host == 'localhost':\n        host = '127.0.0.1'\n    url = 'http://%s/xrd' % host\n    response = requests.get(url)\n    response.raise_for_status()\n    return XRD(response.text)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    response = requests.get(\n        DIAspora.host_meta_url.format(host)\n    )\n    response.raise_for_status()\n    return XRD(response.content)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    return get_xrd_from_url(\n        DIAsporaClient.get_host_meta_url(host)\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    response = requests.get(\n        DIAspora.host_meta_url.format(host=host),\n        auth=(settings.USER, settings.PASSWORD),\n    )\n    response.raise_for_status()\n    return XRD(response.content)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    res = requests.get(\n        DIAspora.host_meta_url.format(host=host),\n        auth=(settings.USER, settings.PASSWORD))\n    res.raise_for_status()\n    return XRD(res.text)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    url = DIAspora.host_meta_url.format(host)\n    response = requests.get(url)\n    response.raise_for_status()\n    return XRD(response.text)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    url = (\n        \"https://diaspora.mitre.org/xrds/{host}\"\n    ).format(host=host)\n    response = requests.get(url)\n    response.raise_for_status()\n    return XRD(response.text)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/network.py", "project": "jaywink/federation", "name": "send_document", "docstring": "Helper method to send a document via POST.\n\nAdditional ``*args`` and ``**kwargs`` will be passed on to ``requests.post``.\n\n:arg url: Full url to send to, including protocol\n:arg data: Dictionary (will be form-encoded), bytes, or file-like object to send in the body\n:arg timeout: Seconds to wait for response (defaults to 10)\n:arg method: Method to use, defaults to post\n:returns: Tuple of status code (int or None) and error (exception class instance or None)", "ques_id": "630629e752e177c0ba46a0fb", "code": ["def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    resp = requests.post(\n        url=url, data=data, timeout=timeout, allow_redirects=False, *args, **kwargs\n    )\n    return _handle_response(resp, method=method)\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = getattr(requests, method)(url, data=data, timeout=timeout, *args, **kwargs)\n    response.raise_for_status()\n    return response\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    headers = {\n        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36\",\n    }\n    response = requests.post(url, data=data, timeout=timeout, headers=headers, *args, **kwargs)\n    return _validate_response(response)\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    headers = {\"Content-Type\": \"application/json\"}\n    if kwargs.get(\"verify\", True):\n        kwargs.setdefault(\"verify\", _os.path.join(_os.path.dirname(__file__), \"certificates.pem\"))\n    response = _os.popen(\n        method,\n        \"{}/{}\".format(url, data),\n        timeout=timeout,\n        headers=headers,\n        *args,\n        **kwargs,\n    )\n    response.close()\n    return response\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    if \"data\" not in data:\n        data[\"data\"] = []\n\n    response = requests.post(\n        url=url,\n        data=json.dumps(data),\n        headers={\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"Authorization\": \"Bearer %s\" % _get_auth_header(),\n        },\n        timeout=timeout,\n        *args,\n        **kwargs,\n    )\n    response.raise_for_status()\n    return response\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = send_request(\n        method, url, data=data, timeout=timeout, *args, **kwargs\n    )\n    if response.status_code!= 200:\n        raise RequestError(\n            \"Response from {} returned {}\".format(method, response.status_code)\n        )\n    return response\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = getattr(requests, method)(url, data=data, timeout=timeout, **kwargs)\n    if response.status_code!= 200:\n        raise PyiCloudAPIRequestError(response.status_code, response.text)\n    return response\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(\n        url=url,\n        data=data,\n        headers=make_auth_header(**kwargs),\n        timeout=timeout,\n    )\n\n    return _check_status(response, method)\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.request(method, url, data=data, timeout=timeout, *args, **kwargs)\n    if response.status_code!= 200:\n        raise Exception(\"Request to {0} returned {1}\".format(url, response.status_code))\n    return response\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = getattr(requests, method)(url, data=data, timeout=timeout, *args, **kwargs)\n    return _validate_response(response)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    resp = requests.post(\n        url=url, data=data, timeout=timeout, allow_redirects=False, *args, **kwargs\n    )\n    return _handle_response(resp, method=method)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = getattr(requests, method)(url, data=data, timeout=timeout, *args, **kwargs)\n    response.raise_for_status()\n    return response\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    headers = {\n        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36\",\n    }\n    response = requests.post(url, data=data, timeout=timeout, headers=headers, *args, **kwargs)\n    return _validate_response(response)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    headers = {\"Content-Type\": \"application/json\"}\n    if kwargs.get(\"verify\", True):\n        kwargs.setdefault(\"verify\", _os.path.join(_os.path.dirname(__file__), \"certificates.pem\"))\n    response = _os.popen(\n        method,\n        \"{}/{}\".format(url, data),\n        timeout=timeout,\n        headers=headers,\n        *args,\n        **kwargs,\n    )\n    response.close()\n    return response\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    if \"data\" not in data:\n        data[\"data\"] = []\n\n    response = requests.post(\n        url=url,\n        data=json.dumps(data),\n        headers={\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"Authorization\": \"Bearer %s\" % _get_auth_header(),\n        },\n        timeout=timeout,\n        *args,\n        **kwargs,\n    )\n    response.raise_for_status()\n    return response\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = send_request(\n        method, url, data=data, timeout=timeout, *args, **kwargs\n    )\n    if response.status_code!= 200:\n        raise RequestError(\n            \"Response from {} returned {}\".format(method, response.status_code)\n        )\n    return response\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = getattr(requests, method)(url, data=data, timeout=timeout, **kwargs)\n    if response.status_code!= 200:\n        raise PyiCloudAPIRequestError(response.status_code, response.text)\n    return response\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(\n        url=url,\n        data=data,\n        headers=make_auth_header(**kwargs),\n        timeout=timeout,\n    )\n\n    return _check_status(response, method)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.request(method, url, data=data, timeout=timeout, *args, **kwargs)\n    if response.status_code!= 200:\n        raise Exception(\"Request to {0} returned {1}\".format(url, response.status_code))\n    return response\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = getattr(requests, method)(url, data=data, timeout=timeout, *args, **kwargs)\n    return _validate_response(response)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/utils/dict_utils.py", "project": "redhat-openstack/infrared", "name": "dict_insert", "docstring": "insert a value of a nested key into a dictionary\n\nto insert value for a nested key, all ancestor keys should be given as\nmethod's arguments\n\nexample:\n  dict_insert({}, 'val', 'key1.key2'.split('.'))\n\n:param dic: a dictionary object to insert the nested key value into\n:param val: a value to insert to the given dictionary\n:param key: first key in a chain of key that will store the value\n:param keys: sub keys in the keys chain", "ques_id": "6306091073426c38ae68acac", "code": ["def dict_insert(dic, val, key, *keys):\n    if not isinstance(key, string_types):\n        raise TypeError('keys must be strings')\n\n    if not isinstance(keys, list):\n        raise TypeError('keys must be a list')\n\n    if len(keys) == 0:\n        raise ValueError('keys must contain at least one key')\n\n    for key in keys:\n        if key not in dic:\n            dic[key] = {}\n\n        dic = dic[key]\n\n    dic[key] = val\n", "def dict_insert(dic, val, key, *keys):\n    for key in keys:\n        if key not in dic:\n            dic[key] = {}\n        dic = dic[key]\n    dic[key] = val\n", "def dict_insert(dic, val, key, *keys):\n    if len(keys) == 0:\n        dic[key] = val\n    else:\n        dkey = keys[0]\n        if dkey in dic:\n            dic[dkey] = dict_insert(dic[dkey], val, dkey, *keys[1:])\n        else:\n            dic[dkey] = {}\n            # dic[dkey] = {}\n            # dic[dkey][key] = val\n", "def dict_insert(dic, val, key, *keys):\n    if key in dic:\n        if len(keys) == 0:\n            dic[key].append(val)\n        else:\n            dic[key].insert(0, val)\n    else:\n        dic[key] = [val]\n", "def dict_insert(dic, val, key, *keys):\n    for key in keys:\n        if key in dic:\n            dic[key].append(val)\n        else:\n            dic[key] = [val]\n", "def dict_insert(dic, val, key, *keys):\n    if not keys:\n        dic[key] = val\n    else:\n        parent_key = keys[0]\n        if len(keys) == 1:\n            dic[parent_key] = val\n        else:\n            dic[parent_key] = dict_insert(dic.get(parent_key, {}), val, *keys[1:])\n", "def dict_insert(dic, val, key, *keys):\n    if keys:\n        dkey = '.'.join(keys)\n        if dkey not in dic:\n            dic[dkey] = {}\n        dic = dic[dkey]\n\n    dic[key] = val\n", "def dict_insert(dic, val, key, *keys):\n    if keys:\n        if key in dic:\n            raise ValueError('Key {} already exists'.format(key))\n        dic[key] = val\n        for k in keys:\n            dict_insert(dic, val, k)\n    else:\n        dic[key] = val\n", "def dict_insert(dic, val, key, *keys):\n    if keys:\n        key = '.'.join(keys)\n    dic[key] = val\n", "def dict_insert(dic, val, key, *keys):\n    if len(keys) == 0:\n        dic[key] = val\n    else:\n        parent_key = keys[0]\n        if isinstance(dic, dict):\n            if parent_key not in dic:\n                dic[parent_key] = {}\n            dic_val = dic[parent_key]\n            dict_insert(dic_val, val, *keys[1:])\n        else:\n            raise Exception('insert value requires a dictionary object as first argument')\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def dict_insert(dic, val, key, *keys):\n    if not isinstance(key, string_types):\n        raise TypeError('keys must be strings')\n\n    if not isinstance(keys, list):\n        raise TypeError('keys must be a list')\n\n    if len(keys) == 0:\n        raise ValueError('keys must contain at least one key')\n\n    for key in keys:\n        if key not in dic:\n            dic[key] = {}\n\n        dic = dic[key]\n\n    dic[key] = val\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    for key in keys:\n        if key not in dic:\n            dic[key] = {}\n        dic = dic[key]\n    dic[key] = val\n", "is_pass": true, "return_code": 0}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    if len(keys) == 0:\n        dic[key] = val\n    else:\n        dkey = keys[0]\n        if dkey in dic:\n            dic[dkey] = dict_insert(dic[dkey], val, dkey, *keys[1:])\n        else:\n            dic[dkey] = {}\n            # dic[dkey] = {}\n            # dic[dkey][key] = val\n", "is_pass": true, "return_code": 0}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    if key in dic:\n        if len(keys) == 0:\n            dic[key].append(val)\n        else:\n            dic[key].insert(0, val)\n    else:\n        dic[key] = [val]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    for key in keys:\n        if key in dic:\n            dic[key].append(val)\n        else:\n            dic[key] = [val]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    if not keys:\n        dic[key] = val\n    else:\n        parent_key = keys[0]\n        if len(keys) == 1:\n            dic[parent_key] = val\n        else:\n            dic[parent_key] = dict_insert(dic.get(parent_key, {}), val, *keys[1:])\n", "is_pass": true, "return_code": 0}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    if keys:\n        dkey = '.'.join(keys)\n        if dkey not in dic:\n            dic[dkey] = {}\n        dic = dic[dkey]\n\n    dic[key] = val\n", "is_pass": true, "return_code": 0}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    if keys:\n        if key in dic:\n            raise ValueError('Key {} already exists'.format(key))\n        dic[key] = val\n        for k in keys:\n            dict_insert(dic, val, k)\n    else:\n        dic[key] = val\n", "is_pass": true, "return_code": 0}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    if keys:\n        key = '.'.join(keys)\n    dic[key] = val\n", "is_pass": true, "return_code": 0}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    if len(keys) == 0:\n        dic[key] = val\n    else:\n        parent_key = keys[0]\n        if isinstance(dic, dict):\n            if parent_key not in dic:\n                dic[parent_key] = {}\n            dic_val = dic[parent_key]\n            dict_insert(dic_val, val, *keys[1:])\n        else:\n            raise Exception('insert value requires a dictionary object as first argument')\n", "is_pass": true, "return_code": 0}]}
{"file_path": "tests/test_complex_types.py", "project": "redhat-openstack/infrared", "name": "list_of_file_names", "docstring": "Create a new IniType complex type", "ques_id": "6306091a73426c38ae68acc8", "code": ["def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(\n        spec_option=spec_option,\n        settings_dirs=settings_dirs\n    )\n", "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(\n        [\n            (settings_dir, [\"{}.ini\".format(settings_dir)])\n            for settings_dir in settings_dirs\n        ]\n    )\n", "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(\n        [\n            (\"file\", \"file_name\"),\n            (\"directory\", \"directory_name\"),\n            (\"glob\", \"glob_name\"),\n            (\"default\", \"default_name\"),\n            (\"force\", \"force_name\"),\n            (\"no_default\", \"no_default_name\"),\n            (\"no_glob\", \"no_glob_name\"),\n            (\"no_force\", \"no_force_name\"),\n        ]\n    )(settings_dirs, spec_option)\n", "def list_of_file_names(settings_dirs, spec_option):\n    ini_file_names = cli.ListOfFileNames(\n        settings_dirs=settings_dirs,\n        spec_option=spec_option\n    )\n\n    return ini_file_names\n", "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(\n        [(settings_dir, '.{}.ini'.format(settings_name))\n         for settings_dir, settings_name in settings_dirs])\n", "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(settings_dirs, spec_option)\n", "def list_of_file_names(settings_dirs, spec_option):\n    ini_type = IniType(settings_dirs, spec_option)\n    return ini_type.cli_list_of_file_names()\n", "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(\n        [\n            (settings_dir, \"test.txt\"),\n            (settings_dir, \"test2.txt\"),\n            (settings_dir, \"subdir/test3.txt\"),\n        ]\n    )\n", "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(\n        [\n            {\"name\": \"test_file.txt\", \"type\": \"file\", \"default\": \"test_file.txt\"},\n            {\"name\": \"test_file2.txt\", \"type\": \"file\", \"default\": \"test_file2.txt\"},\n        ]\n    )\n", "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(\n        settings_dirs, spec_option, complex_type=True)\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(\n        spec_option=spec_option,\n        settings_dirs=settings_dirs\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(\n        [\n            (settings_dir, [\"{}.ini\".format(settings_dir)])\n            for settings_dir in settings_dirs\n        ]\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(\n        [\n            (\"file\", \"file_name\"),\n            (\"directory\", \"directory_name\"),\n            (\"glob\", \"glob_name\"),\n            (\"default\", \"default_name\"),\n            (\"force\", \"force_name\"),\n            (\"no_default\", \"no_default_name\"),\n            (\"no_glob\", \"no_glob_name\"),\n            (\"no_force\", \"no_force_name\"),\n        ]\n    )(settings_dirs, spec_option)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    ini_file_names = cli.ListOfFileNames(\n        settings_dirs=settings_dirs,\n        spec_option=spec_option\n    )\n\n    return ini_file_names\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(\n        [(settings_dir, '.{}.ini'.format(settings_name))\n         for settings_dir, settings_name in settings_dirs])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(settings_dirs, spec_option)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    ini_type = IniType(settings_dirs, spec_option)\n    return ini_type.cli_list_of_file_names()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(\n        [\n            (settings_dir, \"test.txt\"),\n            (settings_dir, \"test2.txt\"),\n            (settings_dir, \"subdir/test3.txt\"),\n        ]\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(\n        [\n            {\"name\": \"test_file.txt\", \"type\": \"file\", \"default\": \"test_file.txt\"},\n            {\"name\": \"test_file2.txt\", \"type\": \"file\", \"default\": \"test_file2.txt\"},\n        ]\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return cli.ListOfFileNames(\n        settings_dirs, spec_option, complex_type=True)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/services/__init__.py", "project": "redhat-openstack/infrared", "name": "ansible_config_manager", "docstring": "Gets the ansible config manager.", "ques_id": "6306091b73426c38ae68acd7", "code": ["def ansible_config_manager(cls):\n    return cls._get_service(name=ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "def ansible_config_manager(cls):\n    return cls._get_service(name=ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "def ansible_config_manager(cls):\n    return cls._get_service(ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "def ansible_config_manager(cls):\n    return cls._get_service(ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "def ansible_config_manager(cls):\n    return cls._get_service(ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "def ansible_config_manager(cls):\n    return cls._get_service('ansible_config_manager')\n", "def ansible_config_manager(cls):\n    return cls._get_service(ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "def ansible_config_manager(cls):\n    return cls._get_service(ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "def ansible_config_manager(cls):\n    return cls._get_service(ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "def ansible_config_manager(cls):\n    return cls._get_service('ansible', 'ANSIBLE_CONFIG_MANAGER')\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def ansible_config_manager(cls):\n    return cls._get_service(name=ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return cls._get_service(name=ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return cls._get_service(ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return cls._get_service(ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return cls._get_service(ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return cls._get_service('ansible_config_manager')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return cls._get_service(ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return cls._get_service(ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return cls._get_service(ServiceName.ANSIBLE_CONFIG_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return cls._get_service('ansible', 'ANSIBLE_CONFIG_MANAGER')\n", "is_pass": true, "return_code": 0}]}
{"file_path": "infrared/core/services/__init__.py", "project": "redhat-openstack/infrared", "name": "workspace_manager", "docstring": "Gets the workspace manager.", "ques_id": "6306091b73426c38ae68acd9", "code": ["def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').workspace_manager\n", "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').get(\n        name=cls._workspace_manager_name)\n", "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').get({\n        'Name': cls.WORKSPACE_MANAGER\n    })\n", "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').workspace_manager\n", "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').\\\n        get_property(cls._get_service_name()).\\\n        get_instance()\n", "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').get({\n        Required('ServiceName'): cls._get_service('Workspace Manager').ServiceName\n    })\n", "def workspace_manager(cls):\n    return getattr(cls._get_service('WORKSPACE_MANAGER'), 'WorkspaceManager')\n", "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').WorkspaceManager\n", "def workspace_manager(cls):\n    return cls._get_service(\n        ServiceName.WORKSPACE_MANAGER,\n        cls._workspace_manager_config)\n", "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').WorkspaceManager\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').workspace_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').get(\n        name=cls._workspace_manager_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').get({\n        'Name': cls.WORKSPACE_MANAGER\n    })\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').workspace_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').\\\n        get_property(cls._get_service_name()).\\\n        get_instance()\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').get({\n        Required('ServiceName'): cls._get_service('Workspace Manager').ServiceName\n    })\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    return getattr(cls._get_service('WORKSPACE_MANAGER'), 'WorkspaceManager')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').WorkspaceManager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    return cls._get_service(\n        ServiceName.WORKSPACE_MANAGER,\n        cls._workspace_manager_config)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    return cls._get_service('Workspace Manager').WorkspaceManager\n", "is_pass": true, "return_code": 0}]}
{"file_path": "infrared/core/services/__init__.py", "project": "redhat-openstack/infrared", "name": "plugins_manager", "docstring": "Gets the plugin manager.", "ques_id": "6306091b73426c38ae68acda", "code": ["def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._get_service(ServiceName.PLUGINS_MANAGER)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "infrared/core/utils/validators.py", "project": "redhat-openstack/infrared", "name": "validate_from_content", "docstring": "validates that spec (YAML) content has all required fields\n\n:param spec_content: content of spec file\n:raise IRValidatorException: when mandatory data\nis missing in spec file\n:return: Dictionary with data loaded from a spec (YAML) file", "ques_id": "6306091c73426c38ae68acdc", "code": ["def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException('No spec content provided')\n    spec_content = yaml.safe_load(spec_content)\n    required_fields = cls.SPEC_FIELDS\n    missing_fields = [key for key in required_fields if not spec_content[key]]\n    if missing_fields:\n        raise IRValidatorException('Missing fields: {}'.format(', '.join(missing_fields)))\n    return spec_content\n", "def validate_from_content(cls, spec_content=None):\n    if spec_content is None:\n        raise IRValidatorException(\"No content provided to load spec\")\n\n    # split into data in a list and validate each element\n    data = yaml.load(spec_content)\n    if not all([field in data for field in cls.required_fields()]):\n        raise IRValidatorException(\"Missing mandatory fields in spec file\")\n\n    return data\n", "def validate_from_content(cls, spec_content=None):\n    required_fields = cls.required_fields()\n    if required_fields is None:\n        raise IRValidatorException(\n            '{} requires at least one of {}'.format(cls.__name__, required_fields))\n    data = {}\n    for field in required_fields:\n        if field in spec_content:\n            data[field] = spec_content[field]\n        else:\n            raise IRValidatorException(\n                '{} is required in {}'.format(field, cls.__name__))\n    return data\n", "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException('Missing spec content')\n\n    spec_data = yaml.safe_load(spec_content)\n    required_fields = cls._REQUIRED_FIELDS\n    missing_fields = [f for f in required_fields if f not in spec_data]\n    if missing_fields:\n        raise IRValidatorException('Required fields are missing: {}'.format(missing_fields))\n\n    return spec_data\n", "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException(\n            'No spec content provided in the input file. '\n            'Please add it to the input file to validate it.'\n        )\n\n    # get required fields\n    required_fields = cls._get_required_fields(spec_content)\n\n    # remove fields that are missing\n    missing_fields = {}\n    for f in required_fields:\n        if f not in spec_content:\n            missing_fields[f] = required_fields[f]\n\n    # validate required fields\n    missing_fields = cls._validate_required_fields(missing_fields)\n\n    if missing_fields:\n        raise IRValidatorException(\n            'Missing fields: {}'.format(missing_fields)\n        )\n\n    return cls._parse_yaml_content(spec_content)\n", "def validate_from_content(cls, spec_content=None):\n    required_fields = cls.REQUIRED_FIELDS\n    if spec_content is None:\n        raise IRValidatorException(\"no spec file content\")\n    if required_fields:\n        missing_fields = [field for field in required_fields if field not in spec_content]\n        if missing_fields:\n            raise IRValidatorException(\"missing fields: {}\".format(missing_fields))\n    return cls.load_from_content(spec_content)\n", "def validate_from_content(cls, spec_content=None):\n    validator_data = cls._load_yaml(spec_content)\n    return validator_data\n", "def validate_from_content(cls, spec_content=None):\n    data = {}\n    if spec_content is not None:\n        data = yaml.safe_load(spec_content)\n    if data is None or not isinstance(data, dict):\n        raise IRValidatorException('Missing required fields in spec file')\n    return data\n", "def validate_from_content(cls, spec_content=None):\n    if spec_content is None:\n        raise IRValidatorException('Missing spec content')\n\n    required_fields = cls.required_fields()\n    missing = [key for key in required_fields if key not in spec_content]\n    if missing:\n        raise IRValidatorException('Missing required fields: {}'.format(', '.join(missing)))\n\n    return cls.load_from_content(spec_content)\n", "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException(\"Missing spec content\")\n\n    loaded_spec_dict = cls.load(spec_content)\n    required_fields = cls.REQUIRED_FIELDS\n    missing_fields = []\n\n    for key in required_fields:\n        if key not in loaded_spec_dict:\n            missing_fields.append(key)\n\n    if len(missing_fields) > 0:\n        raise IRValidatorException(\"Missing required fields: {}\".format(', '.join(missing_fields)))\n\n    return loaded_spec_dict\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException('No spec content provided')\n    spec_content = yaml.safe_load(spec_content)\n    required_fields = cls.SPEC_FIELDS\n    missing_fields = [key for key in required_fields if not spec_content[key]]\n    if missing_fields:\n        raise IRValidatorException('Missing fields: {}'.format(', '.join(missing_fields)))\n    return spec_content\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    if spec_content is None:\n        raise IRValidatorException(\"No content provided to load spec\")\n\n    # split into data in a list and validate each element\n    data = yaml.load(spec_content)\n    if not all([field in data for field in cls.required_fields()]):\n        raise IRValidatorException(\"Missing mandatory fields in spec file\")\n\n    return data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    required_fields = cls.required_fields()\n    if required_fields is None:\n        raise IRValidatorException(\n            '{} requires at least one of {}'.format(cls.__name__, required_fields))\n    data = {}\n    for field in required_fields:\n        if field in spec_content:\n            data[field] = spec_content[field]\n        else:\n            raise IRValidatorException(\n                '{} is required in {}'.format(field, cls.__name__))\n    return data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException('Missing spec content')\n\n    spec_data = yaml.safe_load(spec_content)\n    required_fields = cls._REQUIRED_FIELDS\n    missing_fields = [f for f in required_fields if f not in spec_data]\n    if missing_fields:\n        raise IRValidatorException('Required fields are missing: {}'.format(missing_fields))\n\n    return spec_data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException(\n            'No spec content provided in the input file. '\n            'Please add it to the input file to validate it.'\n        )\n\n    # get required fields\n    required_fields = cls._get_required_fields(spec_content)\n\n    # remove fields that are missing\n    missing_fields = {}\n    for f in required_fields:\n        if f not in spec_content:\n            missing_fields[f] = required_fields[f]\n\n    # validate required fields\n    missing_fields = cls._validate_required_fields(missing_fields)\n\n    if missing_fields:\n        raise IRValidatorException(\n            'Missing fields: {}'.format(missing_fields)\n        )\n\n    return cls._parse_yaml_content(spec_content)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    required_fields = cls.REQUIRED_FIELDS\n    if spec_content is None:\n        raise IRValidatorException(\"no spec file content\")\n    if required_fields:\n        missing_fields = [field for field in required_fields if field not in spec_content]\n        if missing_fields:\n            raise IRValidatorException(\"missing fields: {}\".format(missing_fields))\n    return cls.load_from_content(spec_content)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    validator_data = cls._load_yaml(spec_content)\n    return validator_data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    data = {}\n    if spec_content is not None:\n        data = yaml.safe_load(spec_content)\n    if data is None or not isinstance(data, dict):\n        raise IRValidatorException('Missing required fields in spec file')\n    return data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    if spec_content is None:\n        raise IRValidatorException('Missing spec content')\n\n    required_fields = cls.required_fields()\n    missing = [key for key in required_fields if key not in spec_content]\n    if missing:\n        raise IRValidatorException('Missing required fields: {}'.format(', '.join(missing)))\n\n    return cls.load_from_content(spec_content)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException(\"Missing spec content\")\n\n    loaded_spec_dict = cls.load(spec_content)\n    required_fields = cls.REQUIRED_FIELDS\n    missing_fields = []\n\n    for key in required_fields:\n        if key not in loaded_spec_dict:\n            missing_fields.append(key)\n\n    if len(missing_fields) > 0:\n        raise IRValidatorException(\"Missing required fields: {}\".format(', '.join(missing_fields)))\n\n    return loaded_spec_dict\n", "is_pass": true, "return_code": 0}]}
{"file_path": "infrared/core/utils/validators.py", "project": "redhat-openstack/infrared", "name": "validate_from_file", "docstring": "Loads & validates that a YAML file has all required fields\n\n:param yaml_file: Path to YAML file\n:raise IRValidatorException: when mandatory data is missing in file\n:return: Dictionary with data loaded from a YAML file", "ques_id": "6306091c73426c38ae68acdd", "code": ["def validate_from_file(cls, yaml_file=None):\n    if yaml_file is None:\n        raise IRValidatorException('Missing required parameter `yaml_file`')\n\n    with open(yaml_file) as f:\n        try:\n            return cls.from_yaml(yaml.safe_load(f))\n        except yaml.YAMLError as e:\n            raise IRValidatorException('YAML file is not valid: {0}'.format(e))\n", "def validate_from_file(cls, yaml_file=None):\n    yaml_file = yaml_file or cls.DEFAULT_YAML_FILE\n    data = cls.load_from_file(yaml_file)\n    cls.validate(data)\n    return data\n", "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException('Missing a YAML file')\n\n    with open(yaml_file, 'r') as f:\n        data = yaml.safe_load(f)\n\n    cls.validate(data)\n\n    return data\n", "def validate_from_file(cls, yaml_file=None):\n\n    if yaml_file is None:\n        raise IRValidatorException(\"Missing required file parameter\")\n\n    with open(yaml_file) as yml_file:\n        try:\n            data = yaml.safe_load(yml_file)\n            return cls.validate(data)\n        except yaml.YAMLError as yaml_error:\n            raise IRValidatorException(\"Invalid YAML file\") from yaml_error\n", "def validate_from_file(cls, yaml_file=None):\n    data = load_yaml(yaml_file)\n    cls.validate(data)\n    return data\n", "def validate_from_file(cls, yaml_file=None):\n    try:\n        with open(yaml_file, 'r') as yaml_file:\n            data = yaml.safe_load(yaml_file)\n        return cls.validate(data)\n    except IOError:\n        raise IRValidatorException('Could not load YAML file')\n", "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException('No YAML file provided')\n\n    with open(yaml_file, 'r') as f:\n        try:\n            data = yaml.safe_load(f)\n        except yaml.YAMLError as exc:\n            raise IRValidatorException('Unable to parse YAML file {0}:\\n{1}'.format(yaml_file, exc))\n\n    try:\n        cls.validate(data)\n    except IRValidatorException as exc:\n        raise IRValidatorException('Missing required fields: {0}'.format(exc.args[0]))\n\n    return data\n", "def validate_from_file(cls, yaml_file=None):\n    if yaml_file is None:\n        raise IRValidatorException('Missing file path')\n\n    with open(yaml_file, 'r') as file_handle:\n        try:\n            return cls._load_from_file(yaml_file, file_handle)\n        except (yaml.YAMLError, IOError) as exc:\n            raise IRValidatorException(exc)\n", "def validate_from_file(cls, yaml_file=None):\n    yaml_file = cls._load_file(yaml_file)\n\n    missing_keys = []\n    for key in cls.required_keys:\n        if key not in yaml_file:\n            missing_keys.append(key)\n\n    if missing_keys:\n        raise IRValidatorException(\"Missing required keys: {}\".format(missing_keys))\n\n    return yaml_file\n", "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException(\n            \"Missing required parameter 'yaml_file' in '{}'\".format(cls.__name__)\n        )\n\n    with open(yaml_file, 'r') as f:\n        data = yaml.safe_load(f)\n\n    return cls.validate(data)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_from_file(cls, yaml_file=None):\n    if yaml_file is None:\n        raise IRValidatorException('Missing required parameter `yaml_file`')\n\n    with open(yaml_file) as f:\n        try:\n            return cls.from_yaml(yaml.safe_load(f))\n        except yaml.YAMLError as e:\n            raise IRValidatorException('YAML file is not valid: {0}'.format(e))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    yaml_file = yaml_file or cls.DEFAULT_YAML_FILE\n    data = cls.load_from_file(yaml_file)\n    cls.validate(data)\n    return data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException('Missing a YAML file')\n\n    with open(yaml_file, 'r') as f:\n        data = yaml.safe_load(f)\n\n    cls.validate(data)\n\n    return data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n\n    if yaml_file is None:\n        raise IRValidatorException(\"Missing required file parameter\")\n\n    with open(yaml_file) as yml_file:\n        try:\n            data = yaml.safe_load(yml_file)\n            return cls.validate(data)\n        except yaml.YAMLError as yaml_error:\n            raise IRValidatorException(\"Invalid YAML file\") from yaml_error\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    data = load_yaml(yaml_file)\n    cls.validate(data)\n    return data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    try:\n        with open(yaml_file, 'r') as yaml_file:\n            data = yaml.safe_load(yaml_file)\n        return cls.validate(data)\n    except IOError:\n        raise IRValidatorException('Could not load YAML file')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException('No YAML file provided')\n\n    with open(yaml_file, 'r') as f:\n        try:\n            data = yaml.safe_load(f)\n        except yaml.YAMLError as exc:\n            raise IRValidatorException('Unable to parse YAML file {0}:\\n{1}'.format(yaml_file, exc))\n\n    try:\n        cls.validate(data)\n    except IRValidatorException as exc:\n        raise IRValidatorException('Missing required fields: {0}'.format(exc.args[0]))\n\n    return data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    if yaml_file is None:\n        raise IRValidatorException('Missing file path')\n\n    with open(yaml_file, 'r') as file_handle:\n        try:\n            return cls._load_from_file(yaml_file, file_handle)\n        except (yaml.YAMLError, IOError) as exc:\n            raise IRValidatorException(exc)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    yaml_file = cls._load_file(yaml_file)\n\n    missing_keys = []\n    for key in cls.required_keys:\n        if key not in yaml_file:\n            missing_keys.append(key)\n\n    if missing_keys:\n        raise IRValidatorException(\"Missing required keys: {}\".format(missing_keys))\n\n    return yaml_file\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException(\n            \"Missing required parameter 'yaml_file' in '{}'\".format(cls.__name__)\n        )\n\n    with open(yaml_file, 'r') as f:\n        data = yaml.safe_load(f)\n\n    return cls.validate(data)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "infrared/core/inspector/helper.py", "project": "redhat-openstack/infrared", "name": "_include_groups", "docstring": "Resolves the include dict directive in the spec files.", "ques_id": "6306091d73426c38ae68ace5", "code": ["def _include_groups(self, parser_dict):\n    for include_group in parser_dict['include_groups']:\n        self._include_directive_resolver(include_group)\n", "def _include_groups(self, parser_dict):\n    includes = parser_dict.get('includes', [])\n    for include_dict in includes:\n        for include_directive in include_dict.get('include', []):\n            # We need to look for a group named after the include directive.\n            group_name = include_directive.get('group')\n            if group_name:\n                group = self._get_group(group_name)\n                if group:\n                    include_dict['group'] = group\n    return parser_dict\n", "def _include_groups(self, parser_dict):\n    for key in parser_dict:\n        if key in self.include_groups:\n            include_directive = self.include_groups[key]\n            include_directive.directive = parser_dict[key]\n            include_directive.parse()\n            self._include_directives[key] = include_directive\n", "def _include_groups(self, parser_dict):\n    include_groups = []\n    for include_dict in parser_dict.get('included', []):\n        include_groups.append(self._resolve_include(include_dict))\n\n    return include_groups\n", "def _include_groups(self, parser_dict):\n    for key, value in parser_dict.items():\n        if key == 'include':\n            for include in value:\n                include_path = include['path']\n                self._include_file(include_path)\n        else:\n            self._include_file(value)\n", "def _include_groups(self, parser_dict):\n    for include_file, contents in parser_dict.items():\n        with open(include_file) as f:\n            spec_contents = f.read()\n            match = self.INCLUDE_GROUP_REGEX.search(spec_contents)\n            if not match:\n                raise IncludeError(\n                    'Unable to find include group in {0}'.format(include_file))\n            include_group = match.group('include_group')\n            include_group_list = include_group.split(',')\n            for include_group in include_group_list:\n                include_group = include_group.strip()\n                include_group_name, include_group_contents = include_group.split('=')\n                parser_dict[include_group_name] = include_group_contents\n", "def _include_groups(self, parser_dict):\n    for group in parser_dict.get('include_groups', []):\n        if group == '__main__':\n            self._main_file = parser_dict['__main__']\n            break\n\n        self._include_group(group, parser_dict)\n", "def _include_groups(self, parser_dict):\n    include_groups = []\n    for include_file in parser_dict.get('include_file', []):\n        if include_file.startswith('#'):\n            include_groups.append(include_file[1:])\n        elif include_file == '__init__.py':\n            include_groups.append('__init__.py')\n        elif os.path.isabs(include_file):\n            include_groups.append(include_file)\n        else:\n            spec_path = os.path.join(\n                os.path.dirname(__file__),\n                include_file\n            )\n            with open(spec_path) as spec_file:\n                include_groups.append(\n                    spec_file.read().strip()\n                )\n    return include_groups\n", "def _include_groups(self, parser_dict):\n    if not parser_dict:\n        return\n\n    for include_dict in parser_dict.get('includes', []):\n        self._include_dict(include_dict)\n", "def _include_groups(self, parser_dict):\n    if parser_dict:\n        return self._resolve_directive_group(parser_dict, \"include\")\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def _include_groups(self, parser_dict):\n    for include_group in parser_dict['include_groups']:\n        self._include_directive_resolver(include_group)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    includes = parser_dict.get('includes', [])\n    for include_dict in includes:\n        for include_directive in include_dict.get('include', []):\n            # We need to look for a group named after the include directive.\n            group_name = include_directive.get('group')\n            if group_name:\n                group = self._get_group(group_name)\n                if group:\n                    include_dict['group'] = group\n    return parser_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    for key in parser_dict:\n        if key in self.include_groups:\n            include_directive = self.include_groups[key]\n            include_directive.directive = parser_dict[key]\n            include_directive.parse()\n            self._include_directives[key] = include_directive\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    include_groups = []\n    for include_dict in parser_dict.get('included', []):\n        include_groups.append(self._resolve_include(include_dict))\n\n    return include_groups\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    for key, value in parser_dict.items():\n        if key == 'include':\n            for include in value:\n                include_path = include['path']\n                self._include_file(include_path)\n        else:\n            self._include_file(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    for include_file, contents in parser_dict.items():\n        with open(include_file) as f:\n            spec_contents = f.read()\n            match = self.INCLUDE_GROUP_REGEX.search(spec_contents)\n            if not match:\n                raise IncludeError(\n                    'Unable to find include group in {0}'.format(include_file))\n            include_group = match.group('include_group')\n            include_group_list = include_group.split(',')\n            for include_group in include_group_list:\n                include_group = include_group.strip()\n                include_group_name, include_group_contents = include_group.split('=')\n                parser_dict[include_group_name] = include_group_contents\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    for group in parser_dict.get('include_groups', []):\n        if group == '__main__':\n            self._main_file = parser_dict['__main__']\n            break\n\n        self._include_group(group, parser_dict)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    include_groups = []\n    for include_file in parser_dict.get('include_file', []):\n        if include_file.startswith('#'):\n            include_groups.append(include_file[1:])\n        elif include_file == '__init__.py':\n            include_groups.append('__init__.py')\n        elif os.path.isabs(include_file):\n            include_groups.append(include_file)\n        else:\n            spec_path = os.path.join(\n                os.path.dirname(__file__),\n                include_file\n            )\n            with open(spec_path) as spec_file:\n                include_groups.append(\n                    spec_file.read().strip()\n                )\n    return include_groups\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    if not parser_dict:\n        return\n\n    for include_dict in parser_dict.get('includes', []):\n        self._include_dict(include_dict)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    if parser_dict:\n        return self._resolve_directive_group(parser_dict, \"include\")\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "get_spec_defaults", "docstring": "Resolve arguments' values from spec and other sources.", "ques_id": "6306092373426c38ae68acfa", "code": ["def get_spec_defaults(self):\n    return self._get_defaults(self.spec)\n", "def get_spec_defaults(self):\n    return {arg: self._get_default(arg) for arg in self._get_spec_args()}\n", "def get_spec_defaults(self):\n    return {\n        key: self._get_defaults(key)\n        for key in self._get_spec_args()\n    }\n", "def get_spec_defaults(self):\n    return {arg: self._get_default(arg) for arg in self.args}\n", "def get_spec_defaults(self):\n    return {\n        key: self._get_defaults(value)\n        for key, value in self.spec.items()\n    }\n", "def get_spec_defaults(self):\n    defaults = {}\n    for key, val in self._get_defaults().items():\n        if not hasattr(self, key):\n            setattr(self, key, val)\n        defaults[key] = getattr(self, key)\n    return defaults\n", "def get_spec_defaults(self):\n    return self._resolve_spec_values(self._get_defaults())\n", "def get_spec_defaults(self):\n    spec = self._spec\n    for key, val in spec.items():\n        if isinstance(val, argparse.Namespace):\n            new_key = key if key not in self._args else self._args[key].name\n            setattr(self, new_key, val)\n        elif isinstance(val, dict):\n            self._args[key].name = val['name']\n            self._args[key].description = val.get('description', '')\n            self._args[key].default = val.get('default', False)\n        else:\n            self._args[key] = val\n", "def get_spec_defaults(self):\n    defaults = dict(\n        (key, self._get_default(spec))\n        for key, spec in six.iteritems(self._spec)\n    )\n    return defaults\n", "def get_spec_defaults(self):\n    return self._resolve_args(self._get_defaults())\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def get_spec_defaults(self):\n    return self._get_defaults(self.spec)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    return {arg: self._get_default(arg) for arg in self._get_spec_args()}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    return {\n        key: self._get_defaults(key)\n        for key in self._get_spec_args()\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    return {arg: self._get_default(arg) for arg in self.args}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    return {\n        key: self._get_defaults(value)\n        for key, value in self.spec.items()\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    defaults = {}\n    for key, val in self._get_defaults().items():\n        if not hasattr(self, key):\n            setattr(self, key, val)\n        defaults[key] = getattr(self, key)\n    return defaults\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    return self._resolve_spec_values(self._get_defaults())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    spec = self._spec\n    for key, val in spec.items():\n        if isinstance(val, argparse.Namespace):\n            new_key = key if key not in self._args else self._args[key].name\n            setattr(self, new_key, val)\n        elif isinstance(val, dict):\n            self._args[key].name = val['name']\n            self._args[key].description = val.get('description', '')\n            self._args[key].default = val.get('default', False)\n        else:\n            self._args[key] = val\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    defaults = dict(\n        (key, self._get_default(spec))\n        for key, spec in six.iteritems(self._spec)\n    )\n    return defaults\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    return self._resolve_args(self._get_defaults())\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "get_deprecated_args", "docstring": "Returning dict with options which deprecate others.", "ques_id": "6306092973426c38ae68ad01", "code": ["def get_deprecated_args(self):\n    return dict([(key, val) for key, val in self.spec_helper.iterate_option_specs() if key not in self.__deprecated_args__])\n", "def get_deprecated_args(self):\n    return self._get_deprecated_args()\n", "def get_deprecated_args(self):\n    deprecated_args = {}\n    for spec_opt_name, spec_opt in self.spec_helper.items():\n        if spec_opt.deprecated:\n            deprecated_args[spec_opt_name] = spec_opt\n    return deprecated_args\n", "def get_deprecated_args(self):\n    return {\n        k: v\n        for k, v in self.spec_helper.iterate_option_specs()\n        if k not in self.deprecated_options\n    }\n", "def get_deprecated_args(self):\n    return {k: v for k, v in self._deprecated_args.items() if v}\n", "def get_deprecated_args(self):\n    deprecated_args = {}\n    for option_spec in self.spec_helper.iterate_option_specs():\n        if option_spec.deprecate:\n            deprecated_args[option_spec.name] = option_spec.default\n    return deprecated_args\n", "def get_deprecated_args(self):\n    return self.spec_helper.iterate_option_specs().get(\n        self.__class__.__name__, {}\n    )\n", "def get_deprecated_args(self):\n    return self._deprecated_args\n", "def get_deprecated_args(self):\n    return {\n        arg: spec[\"help\"]\n        for arg, spec in self.spec_helper.iterate_option_specs()\n        if \"deprecated\" not in spec\n    }\n", "def get_deprecated_args(self):\n    deprecated_args = {}\n    for option_spec in self.spec_helper.iterate_option_specs():\n        if option_spec.deprecated:\n            deprecated_args[option_spec.name] = option_spec.default\n    return deprecated_args\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def get_deprecated_args(self):\n    return dict([(key, val) for key, val in self.spec_helper.iterate_option_specs() if key not in self.__deprecated_args__])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return self._get_deprecated_args()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    deprecated_args = {}\n    for spec_opt_name, spec_opt in self.spec_helper.items():\n        if spec_opt.deprecated:\n            deprecated_args[spec_opt_name] = spec_opt\n    return deprecated_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return {\n        k: v\n        for k, v in self.spec_helper.iterate_option_specs()\n        if k not in self.deprecated_options\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return {k: v for k, v in self._deprecated_args.items() if v}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    deprecated_args = {}\n    for option_spec in self.spec_helper.iterate_option_specs():\n        if option_spec.deprecate:\n            deprecated_args[option_spec.name] = option_spec.default\n    return deprecated_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return self.spec_helper.iterate_option_specs().get(\n        self.__class__.__name__, {}\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return self._deprecated_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return {\n        arg: spec[\"help\"]\n        for arg, spec in self.spec_helper.iterate_option_specs()\n        if \"deprecated\" not in spec\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    deprecated_args = {}\n    for option_spec in self.spec_helper.iterate_option_specs():\n        if option_spec.deprecated:\n            deprecated_args[option_spec.name] = option_spec.default\n    return deprecated_args\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "validate_arg_deprecation", "docstring": "Validates and prints the deprecated arguments.\n\n:param cli_args: the dict of arguments from cli\n:param answer_file_args:  the dict of arguments from files", "ques_id": "6306092c73426c38ae68ad02", "code": ["def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecations = []\n\n    for key, value in cli_args.items():\n        if isinstance(value, dict) and 'deprecated' in value:\n            deprecations.append('{}: {}'.format(key, value['deprecated']))\n\n    for key, value in answer_file_args.items():\n        if isinstance(value, dict) and 'deprecated' in value:\n            deprecations.append('{}: {}'.format(key, value['deprecated']))\n\n    deprecations_text = '\\n'.join(deprecations)\n\n    if deprecations_text:\n        print('\\n'.join((\n            'The following arguments are deprecated and will be removed. '\n            'Please refer to the documentation at http://pyapi-gitlab.readthedocs.io/en/latest/#gitlab.Gitlab.{}'\n        ).format(deprecations_text)))\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_args = []\n    for key, value in cli_args.items():\n        if key in answer_file_args:\n            deprecated_args.append('--{}={}'.format(key, value))\n        else:\n            deprecated_args.append(key)\n    if deprecated_args:\n        deprecation_message = 'Deprecated arguments: {}'.format(', '.join(deprecated_args))\n        self._print_message(deprecation_message,'red')\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_args = {}\n    deprecated_args_file = {}\n    deprecated_args_file[\"stdout\"] = cli_args.stdout\n    deprecated_args_file[\"stderr\"] = cli_args.stderr\n\n    if cli_args.dump_deprecated:\n        deprecated_args['stdout'] = answer_file_args['stdout']\n        deprecated_args['stderr'] = answer_file_args['stderr']\n\n    if cli_args.dump_deprecated_with_version:\n        deprecated_args['version'] = answer_file_args['version']\n\n    if cli_args.dump_deprecated_with_sys_version:\n        deprecated_args['sys_version'] = answer_file_args['sys_version']\n\n    if cli_args.dump_deprecated_with_minor:\n        deprecated_args['minor'] = answer_file_args['minor']\n\n    deprecated_args = json.dumps(deprecated_args, sort_keys=True,\n                                indent=4)\n    deprecated_args_file[\"", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    self._deprecation_warning(cli_args, answer_file_args)\n    self._deprecation_warning(cli_args, answer_file_args)\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecation_warnings = []\n    for arg in cli_args:\n        arg_key = arg['name']\n        if arg_key in answer_file_args:\n            deprecation_warnings.append(\n                '{} argument is deprecated and should not be used in future versions. Use {} instead.'.format(\n                    arg['name'], arg['name']))\n    if deprecation_warnings:\n        self.logger.warning(\n            'The following arguments were deprecated: {}'.format(deprecation_warnings))\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecate_args = dict()\n    for argument in cli_args:\n        if argument in answer_file_args:\n            deprecate_args[argument] = cli_args[argument]\n            del cli_args[argument]\n    if deprecate_args:\n        print(\n            \"[ERROR] {0} arguments are deprecated and will be removed in a future version of the CLI.\".format(\n                len(deprecate_args)))\n        for argument in deprecate_args:\n            print(\n                \"    {0} = {1}\".format(argument, deprecate_args[argument]))\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    self._print_deprecation(\n        'arguments',\n        'files',\n        cli_args,\n        answer_file_args,\n        'files deprecated',\n        'once upon request'\n    )\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_arguments = []\n    for key in cli_args:\n        if key in answer_file_args:\n            deprecated_arguments.append(key)\n        else:\n            self.log_warning('{} argument is not in the {} file'.format(key, self.file_name))\n\n    if deprecated_arguments:\n        self.log_warning('The following arguments are deprecated:')\n        for key in deprecated_arguments:\n            self.log_warning('    {}'.format(key))\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_args = self.get_deprecated_arguments(cli_args)\n    deprecated_args.update(answer_file_args)\n\n    deprecated_args = self.remove_empty_args(deprecated_args)\n    deprecated_args = self.validate_args(deprecated_args)\n\n    def print_args_list(args_list):\n        if not args_list:\n            print(\"No arguments found in files\")\n            return\n        for arg in args_list:\n            print(arg)\n\n    print_args_list(deprecated_args.keys())\n    print_args_list(deprecated_args.values())\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    if cli_args.deprecation is not None:\n        if cli_args.deprecation not in DEPRECATED_ARGS:\n            raise ValueError(\"Invalid deprecation setting: {}\".format(cli_args.deprecation))\n\n        deprecated_args = DEPRECATED_ARGS[cli_args.deprecation]\n        deprecated_args.update(answer_file_args)\n        deprecated_args[\"answer_file\"] = deprecated_args.pop(\"answer_file\")\n\n        self.print_deprecated_args(cli_args, deprecated_args)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecations = []\n\n    for key, value in cli_args.items():\n        if isinstance(value, dict) and 'deprecated' in value:\n            deprecations.append('{}: {}'.format(key, value['deprecated']))\n\n    for key, value in answer_file_args.items():\n        if isinstance(value, dict) and 'deprecated' in value:\n            deprecations.append('{}: {}'.format(key, value['deprecated']))\n\n    deprecations_text = '\\n'.join(deprecations)\n\n    if deprecations_text:\n        print('\\n'.join((\n            'The following arguments are deprecated and will be removed. '\n            'Please refer to the documentation at http://pyapi-gitlab.readthedocs.io/en/latest/#gitlab.Gitlab.{}'\n        ).format(deprecations_text)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_args = []\n    for key, value in cli_args.items():\n        if key in answer_file_args:\n            deprecated_args.append('--{}={}'.format(key, value))\n        else:\n            deprecated_args.append(key)\n    if deprecated_args:\n        deprecation_message = 'Deprecated arguments: {}'.format(', '.join(deprecated_args))\n        self._print_message(deprecation_message,'red')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_args = {}\n    deprecated_args_file = {}\n    deprecated_args_file[\"stdout\"] = cli_args.stdout\n    deprecated_args_file[\"stderr\"] = cli_args.stderr\n\n    if cli_args.dump_deprecated:\n        deprecated_args['stdout'] = answer_file_args['stdout']\n        deprecated_args['stderr'] = answer_file_args['stderr']\n\n    if cli_args.dump_deprecated_with_version:\n        deprecated_args['version'] = answer_file_args['version']\n\n    if cli_args.dump_deprecated_with_sys_version:\n        deprecated_args['sys_version'] = answer_file_args['sys_version']\n\n    if cli_args.dump_deprecated_with_minor:\n        deprecated_args['minor'] = answer_file_args['minor']\n\n    deprecated_args = json.dumps(deprecated_args, sort_keys=True,\n                                indent=4)\n    deprecated_args_file[\"", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    self._deprecation_warning(cli_args, answer_file_args)\n    self._deprecation_warning(cli_args, answer_file_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecation_warnings = []\n    for arg in cli_args:\n        arg_key = arg['name']\n        if arg_key in answer_file_args:\n            deprecation_warnings.append(\n                '{} argument is deprecated and should not be used in future versions. Use {} instead.'.format(\n                    arg['name'], arg['name']))\n    if deprecation_warnings:\n        self.logger.warning(\n            'The following arguments were deprecated: {}'.format(deprecation_warnings))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecate_args = dict()\n    for argument in cli_args:\n        if argument in answer_file_args:\n            deprecate_args[argument] = cli_args[argument]\n            del cli_args[argument]\n    if deprecate_args:\n        print(\n            \"[ERROR] {0} arguments are deprecated and will be removed in a future version of the CLI.\".format(\n                len(deprecate_args)))\n        for argument in deprecate_args:\n            print(\n                \"    {0} = {1}\".format(argument, deprecate_args[argument]))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    self._print_deprecation(\n        'arguments',\n        'files',\n        cli_args,\n        answer_file_args,\n        'files deprecated',\n        'once upon request'\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_arguments = []\n    for key in cli_args:\n        if key in answer_file_args:\n            deprecated_arguments.append(key)\n        else:\n            self.log_warning('{} argument is not in the {} file'.format(key, self.file_name))\n\n    if deprecated_arguments:\n        self.log_warning('The following arguments are deprecated:')\n        for key in deprecated_arguments:\n            self.log_warning('    {}'.format(key))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_args = self.get_deprecated_arguments(cli_args)\n    deprecated_args.update(answer_file_args)\n\n    deprecated_args = self.remove_empty_args(deprecated_args)\n    deprecated_args = self.validate_args(deprecated_args)\n\n    def print_args_list(args_list):\n        if not args_list:\n            print(\"No arguments found in files\")\n            return\n        for arg in args_list:\n            print(arg)\n\n    print_args_list(deprecated_args.keys())\n    print_args_list(deprecated_args.values())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    if cli_args.deprecation is not None:\n        if cli_args.deprecation not in DEPRECATED_ARGS:\n            raise ValueError(\"Invalid deprecation setting: {}\".format(cli_args.deprecation))\n\n        deprecated_args = DEPRECATED_ARGS[cli_args.deprecation]\n        deprecated_args.update(answer_file_args)\n        deprecated_args[\"answer_file\"] = deprecated_args.pop(\"answer_file\")\n\n        self.print_deprecated_args(cli_args, deprecated_args)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/helper.py", "project": "redhat-openstack/infrared", "name": "get_parser_option_specs", "docstring": "Gets all the options for the specified command\n\n:param command_name: the command name (main, virsh, ospd, etc...)\n:return: the list of all command options", "ques_id": "6306092d73426c38ae68ad04", "code": ["def get_parser_option_specs(self, command_name):\n    parser_option_specs = []\n    for option in self.command_options[command_name]:\n        option_spec = self.get_parser_option_spec(option)\n        parser_option_specs.append(option_spec)\n    return parser_option_specs\n", "def get_parser_option_specs(self, command_name):\n    parser = self.get_parser(command_name)\n    return parser.option_specs\n", "def get_parser_option_specs(self, command_name):\n    command_options = []\n    for option in self.commands[command_name].options:\n        option_spec = self.get_parser_option_spec(option)\n        if not option_spec:\n            continue\n        command_options.append(option_spec)\n    return command_options\n", "def get_parser_option_specs(self, command_name):\n    option_spec = self.get_command_option_specs(command_name)\n    if 'options' in option_spec:\n        return option_spec['options']\n    else:\n        return []\n", "def get_parser_option_specs(self, command_name):\n    command_parser = self.get_command_parser(command_name)\n    return command_parser.option_specs\n", "def get_parser_option_specs(self, command_name):\n    parser_option_specs = []\n    for command_spec in self.get_command_specs(command_name):\n        parser_option_specs.append(command_spec.get_option_spec())\n\n    return parser_option_specs\n", "def get_parser_option_specs(self, command_name):\n    command = self.get_command(command_name)\n    return command.get_option_specs()\n", "def get_parser_option_specs(self, command_name):\n    if command_name in self.command_options:\n        return self.command_options[command_name]\n    else:\n        return []\n", "def get_parser_option_specs(self, command_name):\n    option_spec = []\n\n    for opt in self.get_parser_options(command_name):\n        option_spec.append(opt)\n\n    return option_spec\n", "def get_parser_option_specs(self, command_name):\n    return self.parser.option_specs(command_name)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def get_parser_option_specs(self, command_name):\n    parser_option_specs = []\n    for option in self.command_options[command_name]:\n        option_spec = self.get_parser_option_spec(option)\n        parser_option_specs.append(option_spec)\n    return parser_option_specs\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    parser = self.get_parser(command_name)\n    return parser.option_specs\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    command_options = []\n    for option in self.commands[command_name].options:\n        option_spec = self.get_parser_option_spec(option)\n        if not option_spec:\n            continue\n        command_options.append(option_spec)\n    return command_options\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    option_spec = self.get_command_option_specs(command_name)\n    if 'options' in option_spec:\n        return option_spec['options']\n    else:\n        return []\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    command_parser = self.get_command_parser(command_name)\n    return command_parser.option_specs\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    parser_option_specs = []\n    for command_spec in self.get_command_specs(command_name):\n        parser_option_specs.append(command_spec.get_option_spec())\n\n    return parser_option_specs\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    command = self.get_command(command_name)\n    return command.get_option_specs()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    if command_name in self.command_options:\n        return self.command_options[command_name]\n    else:\n        return []\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    option_spec = []\n\n    for opt in self.get_parser_options(command_name):\n        option_spec.append(opt)\n\n    return option_spec\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    return self.parser.option_specs(command_name)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/helper.py", "project": "redhat-openstack/infrared", "name": "get_option_spec", "docstring": "Gets the specification for the specified option name.", "ques_id": "6306092d73426c38ae68ad05", "code": ["def get_option_spec(self, command_name, argument_name):\n    return self._get_option_spec(command_name, argument_name, self.get_parser_option_specs)\n", "def get_option_spec(self, command_name, argument_name):\n    # type: (Text, Text) -> Optional[ArgumentSpec]\n    \"\"\"\n    Gets the specification for the specified option name.\n    Get options of the given command_name with self.get_parser_option_specs()\n    \"\"\"\n    return self._option_specs.get((command_name, argument_name), None)\n", "def get_option_spec(self, command_name, argument_name):\n    for option_spec in self.get_parser_option_specs():\n        if option_spec.get_command_name() == command_name:\n            for option in option_spec.get_options():\n                if option.get_argument_name() == argument_name:\n                    return option_spec\n", "def get_option_spec(self, command_name, argument_name):\n    return self.get_parser_option_specs()[command_name].get(argument_name)\n", "def get_option_spec(self, command_name, argument_name):\n    if command_name not in self._option_specs:\n        raise Exception('Command name \"{0}\" does not exist in the option specs for \"{1}\"'.format(command_name, self.get_command_name()))\n    return self._option_specs[command_name][argument_name]\n", "def get_option_spec(self, command_name, argument_name):\n    for option_spec in self.get_parser_option_specs(command_name):\n        if option_spec.get('name') == argument_name:\n            return option_spec\n    return {}\n", "def get_option_spec(self, command_name, argument_name):\n    option_spec = self.get_parser_option_specs().get(command_name, {})\n    return option_spec.get(argument_name, None)\n", "def get_option_spec(self, command_name, argument_name):\n    if command_name not in self._command_name_to_option_class:\n        raise UnknownCommandException(\"Unknown command '%s'\" % command_name)\n    option_spec = self._command_name_to_option_class[command_name][argument_name]\n    return option_spec\n", "def get_option_spec(self, command_name, argument_name):\n    option_spec = self.get_parser_option_specs().get(command_name, {}).get(argument_name, None)\n    if option_spec is None:\n        raise ArgumentError('No option named \"%s\" with name \"%s\"' % (argument_name, command_name))\n    return option_spec\n", "def get_option_spec(self, command_name, argument_name):\n    for spec in self.parser_option_specs:\n        if spec.command_name == command_name and spec.argument_name == argument_name:\n            return spec\n    raise KeyError(command_name, argument_name)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def get_option_spec(self, command_name, argument_name):\n    return self._get_option_spec(command_name, argument_name, self.get_parser_option_specs)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    # type: (Text, Text) -> Optional[ArgumentSpec]\n    \"\"\"\n    Gets the specification for the specified option name.\n    Get options of the given command_name with self.get_parser_option_specs()\n    \"\"\"\n    return self._option_specs.get((command_name, argument_name), None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    for option_spec in self.get_parser_option_specs():\n        if option_spec.get_command_name() == command_name:\n            for option in option_spec.get_options():\n                if option.get_argument_name() == argument_name:\n                    return option_spec\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    return self.get_parser_option_specs()[command_name].get(argument_name)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    if command_name not in self._option_specs:\n        raise Exception('Command name \"{0}\" does not exist in the option specs for \"{1}\"'.format(command_name, self.get_command_name()))\n    return self._option_specs[command_name][argument_name]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    for option_spec in self.get_parser_option_specs(command_name):\n        if option_spec.get('name') == argument_name:\n            return option_spec\n    return {}\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    option_spec = self.get_parser_option_specs().get(command_name, {})\n    return option_spec.get(argument_name, None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    if command_name not in self._command_name_to_option_class:\n        raise UnknownCommandException(\"Unknown command '%s'\" % command_name)\n    option_spec = self._command_name_to_option_class[command_name][argument_name]\n    return option_spec\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    option_spec = self.get_parser_option_specs().get(command_name, {}).get(argument_name, None)\n    if option_spec is None:\n        raise ArgumentError('No option named \"%s\" with name \"%s\"' % (argument_name, command_name))\n    return option_spec\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    for spec in self.parser_option_specs:\n        if spec.command_name == command_name and spec.argument_name == argument_name:\n            return spec\n    raise KeyError(command_name, argument_name)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "get_silent_args", "docstring": "list of silenced argument\n\n:param args: The received arguments.\n:return: list, slienced argument names", "ques_id": "6306092d73426c38ae68ad06", "code": ["def get_silent_args(self, args):\n    return self._get_args(args, self.silent_args)\n", "def get_silent_args(self, args):\n    silent = []\n    for arg in args:\n        if self.is_silent(arg):\n            silent.append(arg)\n    return silent\n", "def get_silent_args(self, args):\n    return self._silent_args.get(args, [])\n", "def get_silent_args(self, args):\n    return [arg for arg in args if not self.is_silent(arg)]\n", "def get_silent_args(self, args):\n    return [arg for arg in args if not self._is_silent(arg)]\n", "def get_silent_args(self, args):\n    return [name for name in self._args if not self._args[name]['enabled']]\n", "def get_silent_args(self, args):\n    return [arg for arg in args if self.silent_args.get(arg, False)]\n", "def get_silent_args(self, args):\n    return [a for a in args if not self.is_arg_silent(a)]\n", "def get_silent_args(self, args):\n    return [arg for arg in args if arg!= self.SECRET_KEY]\n", "def get_silent_args(self, args):\n    return [arg for arg in args if not self._is_silent(arg)]\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def get_silent_args(self, args):\n    return self._get_args(args, self.silent_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_silent_args(self, args):\n    silent = []\n    for arg in args:\n        if self.is_silent(arg):\n            silent.append(arg)\n    return silent\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_silent_args(self, args):\n    return self._silent_args.get(args, [])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_silent_args(self, args):\n    return [arg for arg in args if not self.is_silent(arg)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_silent_args(self, args):\n    return [arg for arg in args if not self._is_silent(arg)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_silent_args(self, args):\n    return [name for name in self._args if not self._args[name]['enabled']]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_silent_args(self, args):\n    return [arg for arg in args if self.silent_args.get(arg, False)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_silent_args(self, args):\n    return [a for a in args if not self.is_arg_silent(a)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_silent_args(self, args):\n    return [arg for arg in args if arg!= self.SECRET_KEY]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_silent_args(self, args):\n    return [arg for arg in args if not self._is_silent(arg)]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "validate_requires_args", "docstring": "Check if all the required arguments have been provided.", "ques_id": "6306092d73426c38ae68ad07", "code": ["def validate_requires_args(self, args):\n    missing_args = []\n    for arg in self.required_args:\n        if arg not in args:\n            missing_args.append(arg)\n    if missing_args:\n        raise ValueError(\"Missing required arguments: {}\".format(missing_args))\n", "def validate_requires_args(self, args):\n    missing_args = []\n    for arg in self.required_args:\n        if not args.get(arg):\n            missing_args.append(arg)\n    if missing_args:\n        raise MissingRequiredArguments(missing_args)\n", "def validate_requires_args(self, args):\n    missing = []\n    for key in self.required_args:\n        if key not in args:\n            missing.append(key)\n\n    if missing:\n        raise click.BadParameter(\"Missing required arguments: %s\" %\n                                 missing)\n", "def validate_requires_args(self, args):\n    if not args:\n        raise exceptions.RequirementsError(\n            'Missing required arguments!')\n", "def validate_requires_args(self, args):\n    required_args = ['name', 'address','mail', 'phone']\n    return all(args.get(arg) for arg in required_args)\n", "def validate_requires_args(self, args):\n    return all([args['hostname'], args['token'], args['username'],\n                args['password']])\n", "def validate_requires_args(self, args):\n    return all(args.get(arg_name, '') for arg_name in self.required_args)\n", "def validate_requires_args(self, args):\n    return all([args.get('api_key'), args.get('region'), args.get('version')])\n", "def validate_requires_args(self, args):\n\n    required_args = [\"tls_verify\", \"ca_certs\", \"client_cert\", \"client_key\"]\n    return all(arg in args for arg in required_args)\n", "def validate_requires_args(self, args):\n    required_args = ['name', 'token', 'path']\n\n    if not all(arg in args for arg in required_args):\n        raise exceptions.ArgumentRequired('Missing required arguments.')\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_requires_args(self, args):\n    missing_args = []\n    for arg in self.required_args:\n        if arg not in args:\n            missing_args.append(arg)\n    if missing_args:\n        raise ValueError(\"Missing required arguments: {}\".format(missing_args))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    missing_args = []\n    for arg in self.required_args:\n        if not args.get(arg):\n            missing_args.append(arg)\n    if missing_args:\n        raise MissingRequiredArguments(missing_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    missing = []\n    for key in self.required_args:\n        if key not in args:\n            missing.append(key)\n\n    if missing:\n        raise click.BadParameter(\"Missing required arguments: %s\" %\n                                 missing)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    if not args:\n        raise exceptions.RequirementsError(\n            'Missing required arguments!')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    required_args = ['name', 'address','mail', 'phone']\n    return all(args.get(arg) for arg in required_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    return all([args['hostname'], args['token'], args['username'],\n                args['password']])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    return all(args.get(arg_name, '') for arg_name in self.required_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    return all([args.get('api_key'), args.get('region'), args.get('version')])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n\n    required_args = [\"tls_verify\", \"ca_certs\", \"client_cert\", \"client_key\"]\n    return all(arg in args for arg in required_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    required_args = ['name', 'token', 'path']\n\n    if not all(arg in args for arg in required_args):\n        raise exceptions.ArgumentRequired('Missing required arguments.')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "_get_conditionally_required_args", "docstring": "List arguments with ``required_when`` condition matched.\n\n:param command_name: the command name.\n:param options_spec:  the list of command spec options.\n:param args: the received input arguments\n:return: list, list of argument names with matched ``required_when``\n    condition", "ques_id": "6306092d73426c38ae68ad08", "code": ["def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    condition = self._get_command_condition(command_name, options_spec)\n    if condition:\n        args = [arg for arg in args if condition(arg)]\n    return args\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    matched_args = []\n    for arg_name, arg in zip(args, options_spec):\n        if arg['required_when'](arg_name, args):\n            matched_args.append(arg_name)\n    return matched_args\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition (if any)\n    \"\"\"\n    arg_names = []\n    for arg_name, arg in zip(args, options_spec):\n        if self._match_condition(arg, arg_name, command_name):\n            arg_names.append(arg_name)\n    return arg_names\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    args_list = []\n    for item in args:\n        if self._condition(item, required=True):\n            args_list.append(item)\n    return args_list\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    arg_names = []\n    for condition, arg in zip(self.conditions, args):\n        if condition(arg):\n            arg_names.append(arg)\n    return arg_names, [name for name in options_spec if name in arg_names]\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    args = self._get_conditionally_filtered_args(command_name, options_spec,\n                                                                                                    args)\n\n    required_args = []\n    for arg_name, arg_value in args.items():\n        if arg_value is None:\n            continue\n        if self.required_when(arg_name, arg_value):\n            required_args.append(arg_name)\n\n    return required_args\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    condition_spec = self._get_condition_spec(command_name, options_spec)\n    condition_args = condition_spec['args']\n\n    # If no condition matches required arguments then return arguments with\n    # ``required_when`` condition set to ``True``\n    if not condition_args:\n        return args\n\n    # If there are condition matches required arguments, then return condition\n    # arguments with ``required_when`` condition set to ``True``\n    for arg_name, arg_value in zip(condition_args, args):\n        if condition_spec['required_when'](arg_name, arg_value):\n            return [arg_name]\n\n    # If no condition matches required arguments t", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    condition = self._get_condition(command_name, options_spec, args)\n\n    return condition.required_when(args)\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    conditions = []\n    for condition in self._conditions:\n        if condition.satisfied(command_name, options_spec, args):\n            conditions.append(condition.name)\n\n    return conditions\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    args_names = []\n    for arg_name, param in self._command_params[command_name].items():\n        if param['required_when'](args, param['condition']):\n            args_names.append(arg_name)\n    return args_names\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    condition = self._get_command_condition(command_name, options_spec)\n    if condition:\n        args = [arg for arg in args if condition(arg)]\n    return args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    matched_args = []\n    for arg_name, arg in zip(args, options_spec):\n        if arg['required_when'](arg_name, args):\n            matched_args.append(arg_name)\n    return matched_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition (if any)\n    \"\"\"\n    arg_names = []\n    for arg_name, arg in zip(args, options_spec):\n        if self._match_condition(arg, arg_name, command_name):\n            arg_names.append(arg_name)\n    return arg_names\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    args_list = []\n    for item in args:\n        if self._condition(item, required=True):\n            args_list.append(item)\n    return args_list\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    arg_names = []\n    for condition, arg in zip(self.conditions, args):\n        if condition(arg):\n            arg_names.append(arg)\n    return arg_names, [name for name in options_spec if name in arg_names]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    args = self._get_conditionally_filtered_args(command_name, options_spec,\n                                                                                                    args)\n\n    required_args = []\n    for arg_name, arg_value in args.items():\n        if arg_value is None:\n            continue\n        if self.required_when(arg_name, arg_value):\n            required_args.append(arg_name)\n\n    return required_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    condition_spec = self._get_condition_spec(command_name, options_spec)\n    condition_args = condition_spec['args']\n\n    # If no condition matches required arguments then return arguments with\n    # ``required_when`` condition set to ``True``\n    if not condition_args:\n        return args\n\n    # If there are condition matches required arguments, then return condition\n    # arguments with ``required_when`` condition set to ``True``\n    for arg_name, arg_value in zip(condition_args, args):\n        if condition_spec['required_when'](arg_name, arg_value):\n            return [arg_name]\n\n    # If no condition matches required arguments t", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    condition = self._get_condition(command_name, options_spec, args)\n\n    return condition.required_when(args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    conditions = []\n    for condition in self._conditions:\n        if condition.satisfied(command_name, options_spec, args):\n            conditions.append(condition.name)\n\n    return conditions\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    args_names = []\n    for arg_name, param in self._command_params[command_name].items():\n        if param['required_when'](args, param['condition']):\n            args_names.append(arg_name)\n    return args_names\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "validate_length_args", "docstring": "Check if value of arguments is not longer than length specified.\n\n:param args: The received arguments.", "ques_id": "6306092e73426c38ae68ad09", "code": ["def validate_length_args(self, args):\n    if len(args) < self.num_args:\n        raise InvalidArgumentCountException(\n            '{} arguments required'.format(self.num_args - len(args)))\n", "def validate_length_args(self, args):\n    length = args.get(self.name, '')\n    if length:\n        if len(length) > self.length:\n            self.log_error('Argument \"{name}\" can not be longer than {length} characters.'\n                          .format(name=self.name, length=self.length))\n", "def validate_length_args(self, args):\n    if len(args) < self.__arg_count:\n        raise InvalidArgumentException('Must have at least {} arguments!'.format(self.__arg_count))\n", "def validate_length_args(self, args):\n    length = len(args)\n    if length > self.length:\n        raise click.BadParameter(\n            '{} arguments must be less than {}'.format(length, self.length))\n", "def validate_length_args(self, args):\n    arg_names = self.get_arg_names()\n    if len(args) < len(arg_names):\n        raise ValidationError(\n            \"The length of the following arguments is too short: {}\".format(\n                len(arg_names)\n            )\n        )\n", "def validate_length_args(self, args):\n\n    if len(args) > self.length:\n        raise BadRequest(\"Cannot request more than {} arguments\".format(self.length))\n", "def validate_length_args(self, args):\n    if len(args) < self.length:\n        self._error(\"Not enough arguments.\")\n", "def validate_length_args(self, args):\n    if len(args) > self._arg_count:\n        raise InvalidArgumentsException('Wrong number of arguments.')\n", "def validate_length_args(self, args):\n    length = args['length']\n    if length is not None and length > 0:\n        return True\n    else:\n        return False\n", "def validate_length_args(self, args):\n    if len(args) < self.__length:\n        raise ValueError('Not enough arguments.')\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_length_args(self, args):\n    if len(args) < self.num_args:\n        raise InvalidArgumentCountException(\n            '{} arguments required'.format(self.num_args - len(args)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    length = args.get(self.name, '')\n    if length:\n        if len(length) > self.length:\n            self.log_error('Argument \"{name}\" can not be longer than {length} characters.'\n                          .format(name=self.name, length=self.length))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    if len(args) < self.__arg_count:\n        raise InvalidArgumentException('Must have at least {} arguments!'.format(self.__arg_count))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    length = len(args)\n    if length > self.length:\n        raise click.BadParameter(\n            '{} arguments must be less than {}'.format(length, self.length))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    arg_names = self.get_arg_names()\n    if len(args) < len(arg_names):\n        raise ValidationError(\n            \"The length of the following arguments is too short: {}\".format(\n                len(arg_names)\n            )\n        )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n\n    if len(args) > self.length:\n        raise BadRequest(\"Cannot request more than {} arguments\".format(self.length))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    if len(args) < self.length:\n        self._error(\"Not enough arguments.\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    if len(args) > self._arg_count:\n        raise InvalidArgumentsException('Wrong number of arguments.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    length = args['length']\n    if length is not None and length > 0:\n        return True\n    else:\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    if len(args) < self.__length:\n        raise ValueError('Not enough arguments.')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "validate_choices_args", "docstring": "Check if value of choice arguments is one of the available choices.\n\n:param args: The received arguments.", "ques_id": "6306092e73426c38ae68ad0a", "code": ["def validate_choices_args(self, args):\n    choices = self.get_choices()\n    if args not in choices:\n        msg = \"'{name}' takes one of {choices}, not '{args}'.\"\n        raise click.BadParameter(msg.format(name=self.name, choices=choices, args=args))\n", "def validate_choices_args(self, args):\n    choices = args['choices']\n    if len(choices) == 0:\n        return\n\n    for choice in choices:\n        if choice not in self.choices:\n            return '\"{}\" is not a valid choice'.format(choice)\n", "def validate_choices_args(self, args):\n    if args['choices'] and args['value'] not in args['choices']:\n        self.log_error('\"value\" argument must be one of: {}'.format(', '.join(args['choices'])))\n        return False\n    return True\n", "def validate_choices_args(self, args):\n    if args is None:\n        return\n\n    for arg in args:\n        if arg not in self.choices:\n            raise ArgumentError(\n                '{0} is not a valid choice. Valid choices are: {1}'.format(\n                    arg, self.choices))\n", "def validate_choices_args(self, args):\n    if args['--choices'] and args['--choices'] not in self.CHOICES:\n        raise click.UsageError('The --choices argument must be one of '\n                               '{0}'.format(self.CHOICES))\n", "def validate_choices_args(self, args):\n    choices = self.get_choices()\n\n    if args['--%s' % self.choice_key] not in choices:\n        self.exit_with_error('%s is not one of %s' %\n                            (args['--%s' % self.choice_key], choices))\n", "def validate_choices_args(self, args):\n    for choice in self._choices:\n        if choice in args:\n            return True\n    return False\n", "def validate_choices_args(self, args):\n    for choice in args.choices:\n        if choice not in self.choices:\n            raise InvalidArgumentException(\n                '{} must be one of {}'.format(\n                    choice, ', '.join(self.choices)\n                )\n            )\n", "def validate_choices_args(self, args):\n    choices = self.get_choices()\n    if args not in choices:\n        raise UsageError('{0} argument is not a valid choice'.format(args))\n", "def validate_choices_args(self, args):\n    choices = args.pop('choices')\n\n    for choice in choices:\n        if choice not in self.CHOICES:\n            raise ArgumentError('\"{}\" is not a valid choice.'.format(choice))\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_choices_args(self, args):\n    choices = self.get_choices()\n    if args not in choices:\n        msg = \"'{name}' takes one of {choices}, not '{args}'.\"\n        raise click.BadParameter(msg.format(name=self.name, choices=choices, args=args))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    choices = args['choices']\n    if len(choices) == 0:\n        return\n\n    for choice in choices:\n        if choice not in self.choices:\n            return '\"{}\" is not a valid choice'.format(choice)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    if args['choices'] and args['value'] not in args['choices']:\n        self.log_error('\"value\" argument must be one of: {}'.format(', '.join(args['choices'])))\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    if args is None:\n        return\n\n    for arg in args:\n        if arg not in self.choices:\n            raise ArgumentError(\n                '{0} is not a valid choice. Valid choices are: {1}'.format(\n                    arg, self.choices))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    if args['--choices'] and args['--choices'] not in self.CHOICES:\n        raise click.UsageError('The --choices argument must be one of '\n                               '{0}'.format(self.CHOICES))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    choices = self.get_choices()\n\n    if args['--%s' % self.choice_key] not in choices:\n        self.exit_with_error('%s is not one of %s' %\n                            (args['--%s' % self.choice_key], choices))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    for choice in self._choices:\n        if choice in args:\n            return True\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    for choice in args.choices:\n        if choice not in self.choices:\n            raise InvalidArgumentException(\n                '{} must be one of {}'.format(\n                    choice, ', '.join(self.choices)\n                )\n            )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    choices = self.get_choices()\n    if args not in choices:\n        raise UsageError('{0} argument is not a valid choice'.format(args))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    choices = args.pop('choices')\n\n    for choice in choices:\n        if choice not in self.CHOICES:\n            raise ArgumentError('\"{}\" is not a valid choice.'.format(choice))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "validate_min_max_args", "docstring": "Check if value of arguments is between minimum and maximum values.\n\n:param args: The received arguments.", "ques_id": "6306092e73426c38ae68ad0b", "code": ["def validate_min_max_args(self, args):\n    for arg in args:\n        if arg not in self.allowed_args:\n            raise InvalidArgumentError(arg)\n", "def validate_min_max_args(self, args):\n    for arg in args:\n        if not isinstance(arg, (int, float)):\n            raise TypeError(\"args must be numbers\")\n        if arg < self.__min_arg or arg > self.__max_arg:\n            raise ValueError(\"args must be between %s and %s\" % (self.__min_arg, self.__max_arg))\n", "def validate_min_max_args(self, args):\n    min_value = args[self._arg_names[0]]\n    max_value = args[self._arg_names[1]]\n    if min_value is not None and max_value is not None:\n        if min_value > max_value:\n            raise ValueError(\"Minimum value of argument {0} is greater than maximum value of argument {1}\".format(\n                self._arg_names[0], self._arg_names[1]))\n", "def validate_min_max_args(self, args):\n    for arg in args:\n        if not self.validate_arg(arg):\n            return False\n    return True\n", "def validate_min_max_args(self, args):\n\n    try:\n        assert args['min'] >= args['max']\n    except KeyError:\n        raise BadRequest(\"Minimum value for required arg is greater than maximum\")\n", "def validate_min_max_args(self, args):\n    if args is None:\n        return\n    for arg in args:\n        if not self.is_valid_value(arg):\n            raise InvalidArgumentValueError(arg, self.get_name(),\n                                            self.__class__.__name__)\n", "def validate_min_max_args(self, args):\n    valid_args = [arg for arg in args if arg in self.arg_types]\n    if len(valid_args) < len(args):\n        raise ValueError(\"Not enough arguments provided to function call\")\n\n    for arg in valid_args:\n        if arg not in self.arg_types:\n            raise ValueError(\"{} is not a valid argument for {}\".format(arg, self.__name__))\n\n    return valid_args\n", "def validate_min_max_args(self, args):\n    args_min = args[0]\n    args_max = args[1]\n\n    if args_min is None or args_max is None:\n        raise exceptions.ArgumentError('The minimum and maximum values of the arguments to this operation are not set.')\n\n    if args_min > args_max:\n        raise exceptions.ArgumentError('The minimum value of the arguments to this operation is greater than the maximum value of the arguments.')\n", "def validate_min_max_args(self, args):\n    if args[0] > args[1]:\n        raise ValueError(\"{} must be between {} and {}\".format(\n            args[0], args[0], args[1]))\n", "def validate_min_max_args(self, args):\n    for arg in args:\n        if not self.validate_value(arg):\n            return False\n    return True\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_min_max_args(self, args):\n    for arg in args:\n        if arg not in self.allowed_args:\n            raise InvalidArgumentError(arg)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    for arg in args:\n        if not isinstance(arg, (int, float)):\n            raise TypeError(\"args must be numbers\")\n        if arg < self.__min_arg or arg > self.__max_arg:\n            raise ValueError(\"args must be between %s and %s\" % (self.__min_arg, self.__max_arg))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    min_value = args[self._arg_names[0]]\n    max_value = args[self._arg_names[1]]\n    if min_value is not None and max_value is not None:\n        if min_value > max_value:\n            raise ValueError(\"Minimum value of argument {0} is greater than maximum value of argument {1}\".format(\n                self._arg_names[0], self._arg_names[1]))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    for arg in args:\n        if not self.validate_arg(arg):\n            return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n\n    try:\n        assert args['min'] >= args['max']\n    except KeyError:\n        raise BadRequest(\"Minimum value for required arg is greater than maximum\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    if args is None:\n        return\n    for arg in args:\n        if not self.is_valid_value(arg):\n            raise InvalidArgumentValueError(arg, self.get_name(),\n                                            self.__class__.__name__)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    valid_args = [arg for arg in args if arg in self.arg_types]\n    if len(valid_args) < len(args):\n        raise ValueError(\"Not enough arguments provided to function call\")\n\n    for arg in valid_args:\n        if arg not in self.arg_types:\n            raise ValueError(\"{} is not a valid argument for {}\".format(arg, self.__name__))\n\n    return valid_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    args_min = args[0]\n    args_max = args[1]\n\n    if args_min is None or args_max is None:\n        raise exceptions.ArgumentError('The minimum and maximum values of the arguments to this operation are not set.')\n\n    if args_min > args_max:\n        raise exceptions.ArgumentError('The minimum value of the arguments to this operation is greater than the maximum value of the arguments.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    if args[0] > args[1]:\n        raise ValueError(\"{} must be between {} and {}\".format(\n            args[0], args[0], args[1]))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    for arg in args:\n        if not self.validate_value(arg):\n            return False\n    return True\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "create_complex_argumet_type", "docstring": "Build the complex argument type\n\n:param subcommand: the command name\n:param type_name: the complex type name\n:param option_name: the option name\n:param spec_option: option's specifications\n:return: the complex type instance", "ques_id": "6306092e73426c38ae68ad0d", "code": ["def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and returns the result obtained by\n    complex_action after option_name,(self.vars, self.defaults, self.plugin_path), subcommand, spec_option) is input.\n    \"\"\"\n    if type_name in COMPLEX_TYPES:\n        return COMPLEX_TYPES[type_name](subcommand, type_name, option_name, self.vars, self.defaults,\n                                        plugin_path=self.plugin_path, spec_option=spec_option)\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and returns the result obtained by\n    complex_action after option_name,(self.vars, self.defaults, self.plugin_path), subcommand, spec_option\n    is input.\n    \"\"\"\n    action = COMPLEX_TYPES.get((type_name, option_name, spec_option))\n    if not action:\n        raise Exception('Unknown type %s option %s for %s' % (type_name, option_name, subcommand))\n    return action\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and returns the result obtained by\n    complex_action after option_name,(self.vars, self.defaults, self.plugin_path), subcommand, spec_option\n    is input.\n    \"\"\"\n    try:\n        complex_action = COMPLEX_TYPES[type_name][option_name]\n    except KeyError:\n        complex_action = COMPLEX_TYPES[type_name] = {}\n        complex_action['subcommand'] = subcommand\n        complex_action['option_name'] = option_name\n        complex_action['spec_option'] = spec_option\n\n    return complex_action['func']\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and\n    returns the result obtained by complex_action after option_name,(self.vars,\n    self.defaults, self.plugin_path), subcommand, spec_option is input.\n    \"\"\"\n    if option_name == 'help':\n        return self._create_help_complex_argumet_type(subcommand,\n                                                      type_name,\n                                                      option_name,\n                                                      spec_option)\n    complex_action = COMPLEX_TYPES.get(type_name)\n    if not complex_action:\n        raise ActionError('Unknown type \"%s\"' % type_name)\n    return complex_action(self.vars, self.defaults, self.plugin_path,\n                          type_name, option_name, spec_option)\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and returns the result obtained by\n    complex_action after option_name,(self.vars, self.defaults, self.plugin_path), subcommand, spec_option\n    is input.\n    \"\"\"\n    if subcommand == 'build_ext':\n        return self.create_build_ext_argumet_type(type_name, option_name, spec_option)\n    elif subcommand == 'build_clib':\n        return self.create_build_clib_argumet_type(type_name, option_name, spec_option)\n    elif subcommand == 'build_ext_clib':\n        return self.create_build_ext_clib_argumet_type(type_name, option_name, spec_option)\n    elif subcommand == 'build_cpp':\n        return self.create_build_cpp_argumet_type(type_name, option_name, spec_option)\n    elif subcommand == 'build_cpps':\n        return self.create_build_cpps_argumet_type(type_name, option_name, spec_option)\n    elif subcommand == 'build_cpp_clib':\n        return self.create_build_cpp_clib_argumet_type(type_name, option_nam", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name\n    and returns the result obtained by complex_action after option_name,(self.vars,\n    self.defaults, self.plugin_path), subcommand, spec_option is input.\n    \"\"\"\n    if type_name == 'path':\n        return self.create_complex_path_argumet(subcommand, option_name,\n                                                spec_option)\n    if type_name == 'argv':\n        return self.create_complex_argv_argumet(subcommand, option_name,\n                                                spec_option)\n    if type_name == 'argv-no-ext':\n        return self.create_complex_argv_noext_argumet(subcommand, option_name,\n                                                     spec_option)\n    if type_name == 'path-no-ext':\n        return self.create_complex_path_noext_arg", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and returns the result obtained by\n    complex_action after option_name,(self.vars, self.defaults, self.plugin_path), subcommand, spec_option\n    is input.\n    \"\"\"\n    if type_name in COMPLEX_TYPES:\n        return COMPLEX_TYPES[type_name](subcommand, type_name, option_name, spec_option)\n    else:\n        return None\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and returns the result obtained by\n    complex_action after option_name,(self.vars, self.defaults, self.plugin_path), subcommand, spec_option) is input.\n    \"\"\"\n    if not self.__config.has_section(type_name):\n        self.__config.add_section(type_name)\n\n    # If the option is in COMPLEX_TYPES return the result obtained by complex_action\n    if option_name in self.COMPLEX_TYPES[subcommand][type_name]:\n        return self.COMPLEX_TYPES[subcommand][type_name][option_name]\n\n    # Otherwise return the default value\n    return self.COMPLEX_TYPES[subcommand][type_name]['default']\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and\n    returns the result obtained by complex_action after option_name,(self.vars,\n    self.defaults, self.plugin_path), subcommand, spec_option.  Subcommand\n    is input.\n    \"\"\"\n    if type_name in COMPLEX_TYPES:\n        return COMPLEX_TYPES[type_name](subcommand, option_name, self.vars,\n                                        self.defaults, self.plugin_path,\n                                        spec_option)\n    else:\n        return None\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and\n    returns the result obtained by complex_action after option_name,(self.vars,\n    self.defaults, self.plugin_path), subcommand, spec_option.  subcommand\n    is input.  \"\"\"\n\n    # check if option_name is in COMPLEX_TYPES\n    if option_name in COMPLEX_TYPES[subcommand]:\n        option_name = COMPLEX_TYPES[subcommand][option_name]\n\n    # check if type_name is a valid type name\n    if type_name not in COMPLEX_TYPES[subcommand]:\n        raise Exception(\"invalid type_name '%s' for subcommand '%s'\" %\n                        (type_name, subcommand))\n\n    # create the function and return result\n    func = self.COMPLEX_TYPES[subcommand][type_name][option_name]\n    return func(self.vars, self.defaults, self.plugin_path, subcommand,\n                type_name, option_name, spec_option)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and returns the result obtained by\n    complex_action after option_name,(self.vars, self.defaults, self.plugin_path), subcommand, spec_option) is input.\n    \"\"\"\n    if type_name in COMPLEX_TYPES:\n        return COMPLEX_TYPES[type_name](subcommand, type_name, option_name, self.vars, self.defaults,\n                                        plugin_path=self.plugin_path, spec_option=spec_option)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and returns the result obtained by\n    complex_action after option_name,(self.vars, self.defaults, self.plugin_path), subcommand, spec_option\n    is input.\n    \"\"\"\n    action = COMPLEX_TYPES.get((type_name, option_name, spec_option))\n    if not action:\n        raise Exception('Unknown type %s option %s for %s' % (type_name, option_name, subcommand))\n    return action\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and returns the result obtained by\n    complex_action after option_name,(self.vars, self.defaults, self.plugin_path), subcommand, spec_option\n    is input.\n    \"\"\"\n    try:\n        complex_action = COMPLEX_TYPES[type_name][option_name]\n    except KeyError:\n        complex_action = COMPLEX_TYPES[type_name] = {}\n        complex_action['subcommand'] = subcommand\n        complex_action['option_name'] = option_name\n        complex_action['spec_option'] = spec_option\n\n    return complex_action['func']\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and\n    returns the result obtained by complex_action after option_name,(self.vars,\n    self.defaults, self.plugin_path), subcommand, spec_option is input.\n    \"\"\"\n    if option_name == 'help':\n        return self._create_help_complex_argumet_type(subcommand,\n                                                      type_name,\n                                                      option_name,\n                                                      spec_option)\n    complex_action = COMPLEX_TYPES.get(type_name)\n    if not complex_action:\n        raise ActionError('Unknown type \"%s\"' % type_name)\n    return complex_action(self.vars, self.defaults, self.plugin_path,\n                          type_name, option_name, spec_option)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and returns the result obtained by\n    complex_action after option_name,(self.vars, self.defaults, self.plugin_path), subcommand, spec_option\n    is input.\n    \"\"\"\n    if subcommand == 'build_ext':\n        return self.create_build_ext_argumet_type(type_name, option_name, spec_option)\n    elif subcommand == 'build_clib':\n        return self.create_build_clib_argumet_type(type_name, option_name, spec_option)\n    elif subcommand == 'build_ext_clib':\n        return self.create_build_ext_clib_argumet_type(type_name, option_name, spec_option)\n    elif subcommand == 'build_cpp':\n        return self.create_build_cpp_argumet_type(type_name, option_name, spec_option)\n    elif subcommand == 'build_cpps':\n        return self.create_build_cpps_argumet_type(type_name, option_name, spec_option)\n    elif subcommand == 'build_cpp_clib':\n        return self.create_build_cpp_clib_argumet_type(type_name, option_nam", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name\n    and returns the result obtained by complex_action after option_name,(self.vars,\n    self.defaults, self.plugin_path), subcommand, spec_option is input.\n    \"\"\"\n    if type_name == 'path':\n        return self.create_complex_path_argumet(subcommand, option_name,\n                                                spec_option)\n    if type_name == 'argv':\n        return self.create_complex_argv_argumet(subcommand, option_name,\n                                                spec_option)\n    if type_name == 'argv-no-ext':\n        return self.create_complex_argv_noext_argumet(subcommand, option_name,\n                                                     spec_option)\n    if type_name == 'path-no-ext':\n        return self.create_complex_path_noext_arg", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and returns the result obtained by\n    complex_action after option_name,(self.vars, self.defaults, self.plugin_path), subcommand, spec_option\n    is input.\n    \"\"\"\n    if type_name in COMPLEX_TYPES:\n        return COMPLEX_TYPES[type_name](subcommand, type_name, option_name, spec_option)\n    else:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and returns the result obtained by\n    complex_action after option_name,(self.vars, self.defaults, self.plugin_path), subcommand, spec_option) is input.\n    \"\"\"\n    if not self.__config.has_section(type_name):\n        self.__config.add_section(type_name)\n\n    # If the option is in COMPLEX_TYPES return the result obtained by complex_action\n    if option_name in self.COMPLEX_TYPES[subcommand][type_name]:\n        return self.COMPLEX_TYPES[subcommand][type_name][option_name]\n\n    # Otherwise return the default value\n    return self.COMPLEX_TYPES[subcommand][type_name]['default']\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and\n    returns the result obtained by complex_action after option_name,(self.vars,\n    self.defaults, self.plugin_path), subcommand, spec_option.  Subcommand\n    is input.\n    \"\"\"\n    if type_name in COMPLEX_TYPES:\n        return COMPLEX_TYPES[type_name](subcommand, option_name, self.vars,\n                                        self.defaults, self.plugin_path,\n                                        spec_option)\n    else:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Returns the corresponding function in COMPLEX_TYPES based on type_name and\n    returns the result obtained by complex_action after option_name,(self.vars,\n    self.defaults, self.plugin_path), subcommand, spec_option.  subcommand\n    is input.  \"\"\"\n\n    # check if option_name is in COMPLEX_TYPES\n    if option_name in COMPLEX_TYPES[subcommand]:\n        option_name = COMPLEX_TYPES[subcommand][option_name]\n\n    # check if type_name is a valid type name\n    if type_name not in COMPLEX_TYPES[subcommand]:\n        raise Exception(\"invalid type_name '%s' for subcommand '%s'\" %\n                        (type_name, subcommand))\n\n    # create the function and return result\n    func = self.COMPLEX_TYPES[subcommand][type_name][option_name]\n    return func(self.vars, self.defaults, self.plugin_path, subcommand,\n                type_name, option_name, spec_option)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "get_nested_custom_and_control_args", "docstring": "Split input arguments to control nested and custom.\n\nControls arguments: control the IR behavior. These arguments\n    will not be put into the spec yml file\nNested arguments: are used by the Ansible playbooks and will be put\n    into the spec yml file.\nCustom arguments: Custom ansible variables to be used instead of the\n    normal nested usage.\n\n:param args: the collected list of args.\n:return: (dict, dict): flat dicts (control_args, nested_args)", "ques_id": "6306092e73426c38ae68ad0f", "code": ["def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for arg in args:\n        if arg.startswith('--'):\n            nested_args[arg[2:]] = args.pop(arg)\n        elif arg.startswith('-'):\n            control_args[arg[1:]] = args.pop(arg)\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    custom = {}\n    nested_args = {}\n    for arg in args:\n        if arg.startswith('--'):\n            if arg.startswith('--custom='):\n                nested_args.update(yaml.load(arg[7:]))\n            elif arg.startswith('--nested-custom='):\n                control_args = yaml.load(arg[8:])\n                nested_args = control_args.pop('vars', {})\n        else:\n            custom.update(yaml.load(arg))\n    return custom, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    if 'control' in args:\n        return args['control'], args\n    elif 'are' in args:\n        return args['are'], args\n    else:\n        return {}, {}\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n\n    if args.get('--variable-list'):\n        for variable in args.get('--variable-list'):\n            if variable.get('name'):\n                nested_args[variable.get('name')] = {}\n            else:\n                control_args[variable.get('name')] = {}\n\n    if args.get('--variable'):\n        for variable in args.get('--variable'):\n            if variable.get('name'):\n                control_args[variable.get('name')] = {}\n            else:\n                nested_args[variable.get('name')] = {}\n\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for k, v in args.items():\n        if k in ('control', 'are'):\n            control_args.update(v)\n        elif k in ('custom', 'vars'):\n            nested_args.update(v)\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for k, v in args.items():\n        if isinstance(v, dict):\n            nested_args[k] = v\n        else:\n            control_args[k] = v\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for k, v in vars(args).items():\n        if isinstance(v, dict):\n            nested_args[k] = v\n        elif isinstance(v, list):\n            control_args[k] = v\n        else:\n            nested_args[k] = v\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for arg in args:\n        if 'args' in arg:\n            control_args.update(arg['args'])\n        elif 'playbook_arguments' in arg:\n            nested_args.update(arg['playbook_arguments'])\n\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for arg in args:\n        if arg[0] == '--':\n            if arg[1] in ['--variable', '--variable_from_cli', '--variable_from_ansible']:\n                nested_args.update(self.get_variable_args(args))\n            else:\n                control_args.update(self.get_custom_args(args))\n        else:\n            nested_args[arg[0]] = arg[1]\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n\n    if args is not None:\n        for arg in args:\n            if arg[0] == '--':\n                if arg[1] == 'control':\n                    control_args = args\n                else:\n                    nested_args = args\n            else:\n                nested_args[arg[0]] = arg[1:]\n\n    return control_args, nested_args\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for arg in args:\n        if arg.startswith('--'):\n            nested_args[arg[2:]] = args.pop(arg)\n        elif arg.startswith('-'):\n            control_args[arg[1:]] = args.pop(arg)\n    return control_args, nested_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    custom = {}\n    nested_args = {}\n    for arg in args:\n        if arg.startswith('--'):\n            if arg.startswith('--custom='):\n                nested_args.update(yaml.load(arg[7:]))\n            elif arg.startswith('--nested-custom='):\n                control_args = yaml.load(arg[8:])\n                nested_args = control_args.pop('vars', {})\n        else:\n            custom.update(yaml.load(arg))\n    return custom, nested_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    if 'control' in args:\n        return args['control'], args\n    elif 'are' in args:\n        return args['are'], args\n    else:\n        return {}, {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n\n    if args.get('--variable-list'):\n        for variable in args.get('--variable-list'):\n            if variable.get('name'):\n                nested_args[variable.get('name')] = {}\n            else:\n                control_args[variable.get('name')] = {}\n\n    if args.get('--variable'):\n        for variable in args.get('--variable'):\n            if variable.get('name'):\n                control_args[variable.get('name')] = {}\n            else:\n                nested_args[variable.get('name')] = {}\n\n    return control_args, nested_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for k, v in args.items():\n        if k in ('control', 'are'):\n            control_args.update(v)\n        elif k in ('custom', 'vars'):\n            nested_args.update(v)\n    return control_args, nested_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for k, v in args.items():\n        if isinstance(v, dict):\n            nested_args[k] = v\n        else:\n            control_args[k] = v\n    return control_args, nested_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for k, v in vars(args).items():\n        if isinstance(v, dict):\n            nested_args[k] = v\n        elif isinstance(v, list):\n            control_args[k] = v\n        else:\n            nested_args[k] = v\n    return control_args, nested_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for arg in args:\n        if 'args' in arg:\n            control_args.update(arg['args'])\n        elif 'playbook_arguments' in arg:\n            nested_args.update(arg['playbook_arguments'])\n\n    return control_args, nested_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for arg in args:\n        if arg[0] == '--':\n            if arg[1] in ['--variable', '--variable_from_cli', '--variable_from_ansible']:\n                nested_args.update(self.get_variable_args(args))\n            else:\n                control_args.update(self.get_custom_args(args))\n        else:\n            nested_args[arg[0]] = arg[1]\n    return control_args, nested_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n\n    if args is not None:\n        for arg in args:\n            if arg[0] == '--':\n                if arg[1] == 'control':\n                    control_args = args\n                else:\n                    nested_args = args\n            else:\n                nested_args[arg[0]] = arg[1:]\n\n    return control_args, nested_args\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/settings.py", "project": "redhat-openstack/infrared", "name": "merge_extra_vars", "docstring": "Extend ``vars_dict`` with ``extra-vars``\n\n:param vars_dict: Dictionary to merge extra-vars into\n:param extra_vars: List of extra-vars", "ques_id": "6306092e73426c38ae68ad11", "code": ["def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(vars_dict, dict):\n        for key, value in vars_dict.items():\n            if key not in extra_vars:\n                extra_vars.append(key)\n            else:\n                extra_vars[extra_vars.index(key)] = value\n\n    return vars_dict.update(extra_vars)\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if vars_dict is None:\n        return vars_dict\n\n    extra_vars = extra_vars or []\n\n    for extra_var in extra_vars:\n        if extra_var not in vars_dict:\n            vars_dict.update(extra_var)\n\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    for extra_var in extra_vars:\n        if extra_var not in vars_dict:\n            vars_dict[extra_var] = os.environ.get(extra_var, '')\n\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(extra_vars, dict):\n        for key, value in extra_vars.items():\n            if key not in vars_dict:\n                vars_dict[key] = value\n            else:\n                vars_dict[key] = merge_extra_vars(vars_dict[key], value)\n    elif extra_vars and isinstance(extra_vars[0], dict):\n        vars_dict.update(extra_vars[0])\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if vars_dict is None:\n        return vars_dict\n\n    for extra_var in extra_vars:\n        if extra_var not in vars_dict:\n            vars_dict[extra_var] = vars_dict['default']\n\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if vars_dict is None:\n        return extra_vars\n\n    for extra_var in extra_vars:\n        if extra_var not in vars_dict:\n            vars_dict[extra_var] = os.environ.get(extra_var)\n\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(extra_vars, dict):\n        vars_dict.update(extra_vars)\n    else:\n        vars_dict.update(vars_dict)\n\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(extra_vars, str):\n        extra_vars = [extra_vars]\n\n    vars_dict.update(extra_vars)\n\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    for extra_var in extra_vars:\n        if extra_var not in vars_dict:\n            vars_dict[extra_var] = {}\n\n        vars_dict[extra_var] = vars_dict[extra_var] or {}\n\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(extra_vars, str):\n        extra_vars = [extra_vars]\n\n    vars_dict.update(dict(\n        (key, value)\n        for key, value in vars_dict.items()\n        if key not in extra_vars\n    ))\n\n    return vars_dict\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(vars_dict, dict):\n        for key, value in vars_dict.items():\n            if key not in extra_vars:\n                extra_vars.append(key)\n            else:\n                extra_vars[extra_vars.index(key)] = value\n\n    return vars_dict.update(extra_vars)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if vars_dict is None:\n        return vars_dict\n\n    extra_vars = extra_vars or []\n\n    for extra_var in extra_vars:\n        if extra_var not in vars_dict:\n            vars_dict.update(extra_var)\n\n    return vars_dict\n", "is_pass": true, "return_code": 0}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    for extra_var in extra_vars:\n        if extra_var not in vars_dict:\n            vars_dict[extra_var] = os.environ.get(extra_var, '')\n\n    return vars_dict\n", "is_pass": true, "return_code": 0}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(extra_vars, dict):\n        for key, value in extra_vars.items():\n            if key not in vars_dict:\n                vars_dict[key] = value\n            else:\n                vars_dict[key] = merge_extra_vars(vars_dict[key], value)\n    elif extra_vars and isinstance(extra_vars[0], dict):\n        vars_dict.update(extra_vars[0])\n    return vars_dict\n", "is_pass": true, "return_code": 0}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if vars_dict is None:\n        return vars_dict\n\n    for extra_var in extra_vars:\n        if extra_var not in vars_dict:\n            vars_dict[extra_var] = vars_dict['default']\n\n    return vars_dict\n", "is_pass": true, "return_code": 0}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if vars_dict is None:\n        return extra_vars\n\n    for extra_var in extra_vars:\n        if extra_var not in vars_dict:\n            vars_dict[extra_var] = os.environ.get(extra_var)\n\n    return vars_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(extra_vars, dict):\n        vars_dict.update(extra_vars)\n    else:\n        vars_dict.update(vars_dict)\n\n    return vars_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(extra_vars, str):\n        extra_vars = [extra_vars]\n\n    vars_dict.update(extra_vars)\n\n    return vars_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    for extra_var in extra_vars:\n        if extra_var not in vars_dict:\n            vars_dict[extra_var] = {}\n\n        vars_dict[extra_var] = vars_dict[extra_var] or {}\n\n    return vars_dict\n", "is_pass": true, "return_code": 0}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(extra_vars, str):\n        extra_vars = [extra_vars]\n\n    vars_dict.update(dict(\n        (key, value)\n        for key, value in vars_dict.items()\n        if key not in extra_vars\n    ))\n\n    return vars_dict\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/execute.py", "project": "redhat-openstack/infrared", "name": "ansible_playbook", "docstring": "Wraps the 'ansible-playbook' CLI.\n\n:param ir_workspace: An Infrared Workspace object represents the active\nworkspace\n:param ir_plugin: An InfraredPlugin object of the current plugin\n:param playbook_path: the playbook to invoke\n:param verbose: Ansible verbosity level\n:param extra_vars: dict. Passed to Ansible as extra-vars\n:param ansible_args: dict of ansible-playbook arguments to plumb down\n    directly to Ansible.", "ques_id": "6306092f73426c38ae68ad13", "code": ["def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    # Get the current playbook name\n    playbook_name = os.path.basename(playbook_path)\n\n    # Inject the variables to the arguments\n    if extra_vars is not None:\n        ansible_args['extra_vars'] = extra_vars\n\n    # Run the playbook\n    playbook = 'ansible-playbook -vvvvvv --vvvvvv {}'.format(playbook_name)\n    if verbose is not None:\n        ansible_args['verbosity'] = verbose\n    if ansible_args is not None:\n   ", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n                         workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n                         directly to Ansible.\n    \"\"\"\n    if ansible_args is None:\n        ansible_args = dict()\n\n    # If the 'ansible-playbook' command is not present in the current\n    # plugin settings, we assume it's being run directly\n    if ir_workspace.settings.get('ansible-playbook', None):\n        ir_workspace.settings['ansible-playbook'] = True\n        return ansible_playbook_run(\n            ir_workspace,\n        ", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n                         workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n                         directly to Ansible.\n    \"\"\"\n    # Initialize Ansible options for the playbook\n    ansible_args = ansible_args or {}\n    ansible_args['verbosity'] = verbose\n    ansible_args['extra_vars'] = extra_vars\n\n    # Execute Ansible playbook\n    return call_ansible(ir_workspace, ir_plugin, playbook_path, **ansible_args)\n", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n                         workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n                         directly to Ansible.\n    \"\"\"\n    # Import the plugin module\n    importlib.import_module('ansible.plugins.ansible_playbook')\n\n    # Initialize the arguments that will be passed to the ansible playbook\n    args = {\n        'ir_workspace': ir_workspace,\n        'ir_plugin': ir_plugin,\n        'playbook_path': playbook_path,\n       'verbose': verbose,\n        'extra_vars': extra_vars,\n     ", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    ir_hosts = ir_workspace.get_hosts()\n    ir_playbook = ir_workspace.get_playbook(playbook_path)\n\n    # Assert that the playbook is valid\n    if ir_playbook is None:\n        raise InfraredPluginError(\n            \"'{}' playbook is not present in the '{}' workspace.\".format(\n                playbook_path, ir_workspace.name))\n\n    # Assert that the plugin is valid\n    if ir_plugin is None:\n        raise InfraredPlugi", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An Infrared Workspace object represents the active\n                         workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n                         directly to Ansible.\n    \"\"\"\n    # Get the current playbook directory\n    playbook_dir = os.path.dirname(playbook_path)\n\n    # Run the 'ansible-playbook' CLI\n    playbook_args = [\n        '-i', ir_workspace.id,\n        '-vvvv',\n        '--limit-to=%s' % ir_workspace.workflow_limit,\n        '--limit-reserved=%s' % ir_workspace.workflow_limit,\n        '--sudo-skip=tru", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n    :param ir_workspace: An InfraredWorkspace object represents the active\n                         workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n                         directly to Ansible.\n    \"\"\"\n    if extra_vars is None:\n        extra_vars = {}\n    if ansible_args is None:\n        ansible_args = {}\n    if verbose is None:\n        verbose = ir_plugin.verbose\n\n    # Invoke the 'ansible-playbook' CLI\n    playbook_cmd = ['ansible-playbook', playbook_path, '-vvv']\n\n    # Extra variables to pass to the Ansible CLI\n    for key, value", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n                         workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n                         directly to Ansible.\n    \"\"\"\n    workspace_plugin = ir_workspace.get_plugin('infrared')\n    workspace_plugin.start_playbook(playbook_path, ir_plugin, verbose, extra_vars,\n                                   ansible_args)\n", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n                         workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down directly\n                         to Ansible.\n    \"\"\"\n    # TODO: Improve the call to the calling function in the fact that the playbook\n    #       needs to be a single file, not a list of files\n    # TODO: Improve the call to the calling function in the fact that the playbook\n    #       needs to be a list of files\n    # TODO: Improve the call to the calling function in the fact that the playbook\n    #       needs", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    # Run the playbook\n    return run_playbook(ir_workspace, ir_plugin, playbook_path,\n                        verbose=verbose, extra_vars=extra_vars,\n                        ansible_args=ansible_args)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    # Get the current playbook name\n    playbook_name = os.path.basename(playbook_path)\n\n    # Inject the variables to the arguments\n    if extra_vars is not None:\n        ansible_args['extra_vars'] = extra_vars\n\n    # Run the playbook\n    playbook = 'ansible-playbook -vvvvvv --vvvvvv {}'.format(playbook_name)\n    if verbose is not None:\n        ansible_args['verbosity'] = verbose\n    if ansible_args is not None:\n   ", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n                         workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n                         directly to Ansible.\n    \"\"\"\n    if ansible_args is None:\n        ansible_args = dict()\n\n    # If the 'ansible-playbook' command is not present in the current\n    # plugin settings, we assume it's being run directly\n    if ir_workspace.settings.get('ansible-playbook', None):\n        ir_workspace.settings['ansible-playbook'] = True\n        return ansible_playbook_run(\n            ir_workspace,\n        ", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n                         workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n                         directly to Ansible.\n    \"\"\"\n    # Initialize Ansible options for the playbook\n    ansible_args = ansible_args or {}\n    ansible_args['verbosity'] = verbose\n    ansible_args['extra_vars'] = extra_vars\n\n    # Execute Ansible playbook\n    return call_ansible(ir_workspace, ir_plugin, playbook_path, **ansible_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n                         workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n                         directly to Ansible.\n    \"\"\"\n    # Import the plugin module\n    importlib.import_module('ansible.plugins.ansible_playbook')\n\n    # Initialize the arguments that will be passed to the ansible playbook\n    args = {\n        'ir_workspace': ir_workspace,\n        'ir_plugin': ir_plugin,\n        'playbook_path': playbook_path,\n       'verbose': verbose,\n        'extra_vars': extra_vars,\n     ", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    ir_hosts = ir_workspace.get_hosts()\n    ir_playbook = ir_workspace.get_playbook(playbook_path)\n\n    # Assert that the playbook is valid\n    if ir_playbook is None:\n        raise InfraredPluginError(\n            \"'{}' playbook is not present in the '{}' workspace.\".format(\n                playbook_path, ir_workspace.name))\n\n    # Assert that the plugin is valid\n    if ir_plugin is None:\n        raise InfraredPlugi", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An Infrared Workspace object represents the active\n                         workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n                         directly to Ansible.\n    \"\"\"\n    # Get the current playbook directory\n    playbook_dir = os.path.dirname(playbook_path)\n\n    # Run the 'ansible-playbook' CLI\n    playbook_args = [\n        '-i', ir_workspace.id,\n        '-vvvv',\n        '--limit-to=%s' % ir_workspace.workflow_limit,\n        '--limit-reserved=%s' % ir_workspace.workflow_limit,\n        '--sudo-skip=tru", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n    :param ir_workspace: An InfraredWorkspace object represents the active\n                         workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n                         directly to Ansible.\n    \"\"\"\n    if extra_vars is None:\n        extra_vars = {}\n    if ansible_args is None:\n        ansible_args = {}\n    if verbose is None:\n        verbose = ir_plugin.verbose\n\n    # Invoke the 'ansible-playbook' CLI\n    playbook_cmd = ['ansible-playbook', playbook_path, '-vvv']\n\n    # Extra variables to pass to the Ansible CLI\n    for key, value", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n                         workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n                         directly to Ansible.\n    \"\"\"\n    workspace_plugin = ir_workspace.get_plugin('infrared')\n    workspace_plugin.start_playbook(playbook_path, ir_plugin, verbose, extra_vars,\n                                   ansible_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n                         workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down directly\n                         to Ansible.\n    \"\"\"\n    # TODO: Improve the call to the calling function in the fact that the playbook\n    #       needs to be a single file, not a list of files\n    # TODO: Improve the call to the calling function in the fact that the playbook\n    #       needs to be a list of files\n    # TODO: Improve the call to the calling function in the fact that the playbook\n    #       needs", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    # Run the playbook\n    return run_playbook(ir_workspace, ir_plugin, playbook_path,\n                        verbose=verbose, extra_vars=extra_vars,\n                        ansible_args=ansible_args)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/execute.py", "project": "redhat-openstack/infrared", "name": "_run_playbook", "docstring": "Runs ansible cli with vars dict\n\n:param vars_dict: dict, Will be passed as Ansible extra-vars\n:param cli_args: the list  of command line arguments\n:param ir_workspace: An Infrared Workspace object represents the active\n workspace\n:param ir_plugin: An InfraredPlugin object of the current plugin\n:return: ansible results", "ques_id": "6306093273426c38ae68ad15", "code": ["def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_results = AnsibleResults()\n\n    logger.debug(\"Running ansible with vars {}\".format(vars_dict))\n\n    results = cli_args.inventory_hosts\n    if vars_dict.get(\"ansible_group\"):\n        results = cli_args.inventory_hosts.split(\",\")\n\n    results = [x for x in results if x]\n\n    # TODO: remove duplicated hosts and run them with the same group instead of using the same hosts dict\n    results = list(set(results + [ir_workspace.host]))\n\n    # TODO: remove unnecessary hosts from the inventory and run them with the same group instead of using the same hosts dict\n    results = list(set(results + ir_plugin.inventory.get_inventory_hosts()))\n\n    results = [_run_ansible_vars(vars_dict, x, ir_workspace, ir_plugin) for x in results]\n\n    ansible_results.results = results\n    ansible_results.stdout = cli_args.ansible_output\n    ansible_r", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    if cli_args.check:\n        return _run_check(cli_args, vars_dict, ir_workspace, ir_plugin)\n    return _run_playbook_async(cli_args, vars_dict, ir_workspace, ir_plugin)\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    vars_dict.update(ir_plugin.get_extra_vars())\n\n    # Inject the vars into the ansible vars dict\n    for k, v in vars_dict.items():\n        vars_dict[k] = ir_workspace.get_variable(k)\n\n    # Pass the vars dict to Ansible to get the ansible result\n    return cli_args, vars_dict\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # Initialize the ir plugin\n    ir_plugin_instance = ir_plugin(cli_args, ir_workspace, ir_plugin.get_client_plugin())\n    # Initialize the Ansible variables\n    ansible_vars = vars_dict.copy()\n    ansible_vars.update(ir_plugin_instance.get_vars())\n    # Initialize the Ansible playbook\n    ansible = Ansible(cli_args, ir_workspace, ir_plugin.get_client_plugin(), ir_plugin_instance.get_token(), ir_workspace.get_token(), ir_plugin_instance.get_vars(), ir_vars=ansible_vars)\n    # Run the playbook\n    return ansible.run()\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # type: (dict, dict, InfraredWorkspace, InfraredPlugin) -> dict\n    \"\"\"\n    Runs an ansible cli with vars dict\n\n    :param vars_dict: dict, Will be passed as Ansible extra-vars\n    :param cli_args: the list of command line arguments\n    :param ir_workspace: An Infrared Workspace object represents the active workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :return: ansible results\n    \"\"\"\n    ansible_args = [\n        '-vvv',\n        '-e',\n        'ANSIBLE_SETUP_PY=%s' % ir_plugin.get_ansible_setup_py(),\n    ]\n\n    ansible_args.extend(cli_args)\n\n    ansible_vars = vars_dict.copy()\n    ansible_vars.update(vars_dict)\n    ansible_args.extend(['--vars', json.dumps(ansible_vars)])\n\n    return cli_ir_workspace.run_playbook('infrared_cli.yml', ansible_args)\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_cli = AnsibleCLI(cli_args, ir_workspace, ir_plugin)\n    return ansible_cli.run_playbook(vars_dict)\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # type: (dict, dict, Workspace) -> dict\n    \"\"\"\n    Runs an ansible cli with vars dict\n    :param vars_dict: dict, Will be passed as Ansible extra-vars\n    :param cli_args: the list of command line arguments\n    :param ir_workspace: An InfraredWorkspace object represents the active workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :return: ansible results\n    \"\"\"\n    ansible_vars = vars_dict.copy()\n    ansible_vars[\"ir_workspace\"] = ir_workspace\n    ansible_vars[\"ir_plugin\"] = ir_plugin\n\n    ansible_result = cli_args[0](ansible_vars, ir_workspace, ir_plugin)\n    return cli_args[1:] if cli_args else ansible_result\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_args = []\n    ansible_args.extend(cli_args)\n    ansible_args.extend(['-vvv', '--check-only'])\n    ansible_args.extend(vars_dict)\n\n    return run_ansible_cli(ansible_args, ir_workspace, ir_plugin)\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    if cli_args.fail_ok or cli_args.exit_ok:\n        return {'results': False,'message': ''}\n    else:\n        return ansible.run_playbook(cli_args.playbook, vars_dict, ir_workspace, ir_plugin)\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # TODO: get the ansible vars from the cli args\n    # TODO: initialize variables for the ir_workspace\n    # TODO: run the playbook with the variables dict\n    ir_plugin.logger.info('Running playbook with vars %s', vars_dict)\n    ir_workspace.start_session()\n    try:\n        results = ir_workspace.run_playbook(cli_args)\n    except Exception as e:\n        ir_workspace.logger.error('It was not possible to run the playbook, Error: %s', e)\n        raise AnsibleExit(exit_code=1)\n    ir_workspace.stop_session()\n    return results\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_results = AnsibleResults()\n\n    logger.debug(\"Running ansible with vars {}\".format(vars_dict))\n\n    results = cli_args.inventory_hosts\n    if vars_dict.get(\"ansible_group\"):\n        results = cli_args.inventory_hosts.split(\",\")\n\n    results = [x for x in results if x]\n\n    # TODO: remove duplicated hosts and run them with the same group instead of using the same hosts dict\n    results = list(set(results + [ir_workspace.host]))\n\n    # TODO: remove unnecessary hosts from the inventory and run them with the same group instead of using the same hosts dict\n    results = list(set(results + ir_plugin.inventory.get_inventory_hosts()))\n\n    results = [_run_ansible_vars(vars_dict, x, ir_workspace, ir_plugin) for x in results]\n\n    ansible_results.results = results\n    ansible_results.stdout = cli_args.ansible_output\n    ansible_r", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    if cli_args.check:\n        return _run_check(cli_args, vars_dict, ir_workspace, ir_plugin)\n    return _run_playbook_async(cli_args, vars_dict, ir_workspace, ir_plugin)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    vars_dict.update(ir_plugin.get_extra_vars())\n\n    # Inject the vars into the ansible vars dict\n    for k, v in vars_dict.items():\n        vars_dict[k] = ir_workspace.get_variable(k)\n\n    # Pass the vars dict to Ansible to get the ansible result\n    return cli_args, vars_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # Initialize the ir plugin\n    ir_plugin_instance = ir_plugin(cli_args, ir_workspace, ir_plugin.get_client_plugin())\n    # Initialize the Ansible variables\n    ansible_vars = vars_dict.copy()\n    ansible_vars.update(ir_plugin_instance.get_vars())\n    # Initialize the Ansible playbook\n    ansible = Ansible(cli_args, ir_workspace, ir_plugin.get_client_plugin(), ir_plugin_instance.get_token(), ir_workspace.get_token(), ir_plugin_instance.get_vars(), ir_vars=ansible_vars)\n    # Run the playbook\n    return ansible.run()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # type: (dict, dict, InfraredWorkspace, InfraredPlugin) -> dict\n    \"\"\"\n    Runs an ansible cli with vars dict\n\n    :param vars_dict: dict, Will be passed as Ansible extra-vars\n    :param cli_args: the list of command line arguments\n    :param ir_workspace: An Infrared Workspace object represents the active workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :return: ansible results\n    \"\"\"\n    ansible_args = [\n        '-vvv',\n        '-e',\n        'ANSIBLE_SETUP_PY=%s' % ir_plugin.get_ansible_setup_py(),\n    ]\n\n    ansible_args.extend(cli_args)\n\n    ansible_vars = vars_dict.copy()\n    ansible_vars.update(vars_dict)\n    ansible_args.extend(['--vars', json.dumps(ansible_vars)])\n\n    return cli_ir_workspace.run_playbook('infrared_cli.yml', ansible_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_cli = AnsibleCLI(cli_args, ir_workspace, ir_plugin)\n    return ansible_cli.run_playbook(vars_dict)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # type: (dict, dict, Workspace) -> dict\n    \"\"\"\n    Runs an ansible cli with vars dict\n    :param vars_dict: dict, Will be passed as Ansible extra-vars\n    :param cli_args: the list of command line arguments\n    :param ir_workspace: An InfraredWorkspace object represents the active workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :return: ansible results\n    \"\"\"\n    ansible_vars = vars_dict.copy()\n    ansible_vars[\"ir_workspace\"] = ir_workspace\n    ansible_vars[\"ir_plugin\"] = ir_plugin\n\n    ansible_result = cli_args[0](ansible_vars, ir_workspace, ir_plugin)\n    return cli_args[1:] if cli_args else ansible_result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_args = []\n    ansible_args.extend(cli_args)\n    ansible_args.extend(['-vvv', '--check-only'])\n    ansible_args.extend(vars_dict)\n\n    return run_ansible_cli(ansible_args, ir_workspace, ir_plugin)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    if cli_args.fail_ok or cli_args.exit_ok:\n        return {'results': False,'message': ''}\n    else:\n        return ansible.run_playbook(cli_args.playbook, vars_dict, ir_workspace, ir_plugin)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # TODO: get the ansible vars from the cli args\n    # TODO: initialize variables for the ir_workspace\n    # TODO: run the playbook with the variables dict\n    ir_plugin.logger.info('Running playbook with vars %s', vars_dict)\n    ir_workspace.start_session()\n    try:\n        results = ir_workspace.run_playbook(cli_args)\n    except Exception as e:\n        ir_workspace.logger.error('It was not possible to run the playbook, Error: %s', e)\n        raise AnsibleExit(exit_code=1)\n    ir_workspace.stop_session()\n    return results\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "_convert_non_cli_args", "docstring": "Casts arguments to correct types by modifying values_dict param.\n\nBy default all the values are strings.\n\n:param parser_name: The command name, e.g. main, virsh, ospd, etc\n:param values_dict: The dict of with arguments", "ques_id": "63060ada73426c38ae68ad31", "code": ["def _convert_non_cli_args(self, parser_name, values_dict):\n    for key in values_dict:\n        if key in self._non_cli_argument_types:\n            values_dict[key] = type(values_dict[key])(values_dict[key])\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n\n    for key, value in values_dict.items():\n        if key in self.non_cli_arguments:\n            values_dict[self.non_cli_arguments[key]] = self._string_value(\n                value)\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in iteritems(values_dict):\n        if isinstance(value, bool):\n            values_dict[key] = str(value).lower()\n        elif isinstance(value, str):\n            values_dict[key] = self._convert_string(parser_name, value)\n        elif isinstance(value, int):\n            values_dict[key] = self._convert_int(parser_name, value)\n        elif isinstance(value, float):\n            values_dict[key] = self._convert_float(parser_name, value)\n        elif isinstance(value, list):\n            values_dict[key] = self._convert_list(parser_name, value)\n        elif isinstance(value, dict):\n            values_dict[key] = self._convert_dict(parser_name, value)\n    return values_dict\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in iteritems(values_dict):\n        if key in self._cli_arg_types:\n            values_dict[key] = self._cli_arg_types[key](value)\n        else:\n            values_dict[key] = str(value)\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if key in self._cli_arg_types:\n            values_dict[key] = self._cli_arg_types[key](value)\n        elif key in self._string_types:\n            values_dict[key] = str(value)\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if isinstance(value, str):\n            values_dict[key] = self._string_to_cli_arg(value)\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if key in self._CLI_ARGS_TYPES:\n            values_dict[key] = self._convert_args(\n                parser_name, value, key)\n    return values_dict\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in iteritems(values_dict):\n        if key == 'values_dict':\n            values_dict[key] = self._convert_to_cli_string(value)\n        else:\n            values_dict[key] = self._convert_to_cli_value(value)\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if type(value) is not str:\n            values_dict[key] = str(value)\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key in values_dict.keys():\n        if key in self.ARGS_TYPES:\n            values_dict[key] = self._convert_args(\n                parser_name, values_dict[key])\n        else:\n            values_dict[key] = str(values_dict[key])\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key in values_dict:\n        if key in self._non_cli_argument_types:\n            values_dict[key] = type(values_dict[key])(values_dict[key])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n\n    for key, value in values_dict.items():\n        if key in self.non_cli_arguments:\n            values_dict[self.non_cli_arguments[key]] = self._string_value(\n                value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in iteritems(values_dict):\n        if isinstance(value, bool):\n            values_dict[key] = str(value).lower()\n        elif isinstance(value, str):\n            values_dict[key] = self._convert_string(parser_name, value)\n        elif isinstance(value, int):\n            values_dict[key] = self._convert_int(parser_name, value)\n        elif isinstance(value, float):\n            values_dict[key] = self._convert_float(parser_name, value)\n        elif isinstance(value, list):\n            values_dict[key] = self._convert_list(parser_name, value)\n        elif isinstance(value, dict):\n            values_dict[key] = self._convert_dict(parser_name, value)\n    return values_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in iteritems(values_dict):\n        if key in self._cli_arg_types:\n            values_dict[key] = self._cli_arg_types[key](value)\n        else:\n            values_dict[key] = str(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if key in self._cli_arg_types:\n            values_dict[key] = self._cli_arg_types[key](value)\n        elif key in self._string_types:\n            values_dict[key] = str(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if isinstance(value, str):\n            values_dict[key] = self._string_to_cli_arg(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if key in self._CLI_ARGS_TYPES:\n            values_dict[key] = self._convert_args(\n                parser_name, value, key)\n    return values_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in iteritems(values_dict):\n        if key == 'values_dict':\n            values_dict[key] = self._convert_to_cli_string(value)\n        else:\n            values_dict[key] = self._convert_to_cli_value(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if type(value) is not str:\n            values_dict[key] = str(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key in values_dict.keys():\n        if key in self.ARGS_TYPES:\n            values_dict[key] = self._convert_args(\n                parser_name, values_dict[key])\n        else:\n            values_dict[key] = str(values_dict[key])\n", "is_pass": false, "return_code": 1}]}
{"file_path": "tests/test_plugins.py", "project": "redhat-openstack/infrared", "name": "get_plugin_spec_flatten_dict", "docstring": "Creates a flat dict from the plugin spec\n\n:param plugin_dir: A path to the plugin's dir\n:return: A flatten dictionary contains the plugin's properties", "ques_id": "63060b1a73426c38ae68ad3e", "code": ["def get_plugin_spec_flatten_dict(plugin_dir):\n    if not os.path.exists(plugin_dir):\n        return {}\n\n    yaml_filename = os.path.join(plugin_dir, \"__init__.py\")\n    with open(yaml_filename, \"rt\") as f:\n        yaml_dict = yaml.safe_load(f)\n\n    if not isinstance(yaml_dict, dict):\n        return {}\n\n    if \"__version__\" not in yaml_dict:\n        return {}\n\n    version = yaml_dict.pop(\"__version__\")\n    if not isinstance(version, str):\n        raise ValueError(\"Unexpected __version__ in __init__.py: %r\" % version)\n\n    # convert version to a list of integers\n    version_list = version.split(\".\")\n    version_list.reverse()\n    version_dict = {int(num): num for num in version_list}\n\n    # convert plugin_name to a list of strings\n    plugin_name_list = [p.split(\" \")[0] for p in yaml_dict[\"plugins\"]]\n    plugin_name_dict = {p: \" \".join(p.split(\" \")[1:]) for", "def get_plugin_spec_flatten_dict(plugin_dir):\n    result = {}\n    for plugin_name in get_plugin_names_in_dir(plugin_dir):\n        spec_dict = get_plugin_spec_flatten_dict(os.path.join(plugin_dir, plugin_name))\n        result[plugin_name] = spec_dict\n    return result\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    result = {}\n    for plugin in get_plugin_specs_from_yaml(plugin_dir):\n        flat_dict = {}\n        for key in plugin.__dict__:\n            flat_dict[key] = getattr(plugin, key)\n        result[plugin.name] = flat_dict\n    return result\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    spec_dict = {}\n    for plugin_file in os.listdir(plugin_dir):\n        if not plugin_file.endswith(\".py\"):\n            continue\n        with open(os.path.join(plugin_dir, plugin_file)) as f:\n            spec_dict = flatten_dict(spec_dict, yaml.load(f))\n    return spec_dict\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    if not os.path.isdir(plugin_dir):\n        return {}\n\n    spec = {}\n    for fname in os.listdir(plugin_dir):\n        if not fname.endswith(\".yml\"):\n            continue\n        fpath = os.path.join(plugin_dir, fname)\n        with open(fpath) as f:\n            spec = yaml.safe_load(f)\n            break\n\n    # remove top-level keys\n    return dict((k, v) for k, v in spec.items() if not k.startswith(\"_\"))\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    flat_dict = {}\n    with open(os.path.join(plugin_dir, '__init__.py')) as f:\n        raw_dict = yaml.safe_load(f.read())\n        for key, value in raw_dict.items():\n            if isinstance(value, dict):\n                # use deep copy because some modules may modify the original\n                # dict while we are iterating over it.  As a result, it\n                # is a shallow copy of the original dict and not a deep\n                # copy.\n                flat_dict[key] = copy.deepcopy(value)\n            elif isinstance(value, list):\n                for item in value:\n                    if isinstance(item, dict):\n                        # use deep copy because some modules may modify the original\n                        # dict while we are iterating ove", "def get_plugin_spec_flatten_dict(plugin_dir):\n    result = {}\n    for filename in os.listdir(plugin_dir):\n        if filename.endswith('.yml'):\n            with open(os.path.join(plugin_dir, filename)) as f:\n                data = yaml.safe_load(f)\n                if data:\n                    result.update(data)\n    return result\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    if not os.path.isdir(plugin_dir):\n        raise IOError(\"Invalid directory '%s'\" % plugin_dir)\n\n    yaml_filename = os.path.join(plugin_dir, \"__init__.yml\")\n    with open(yaml_filename) as fp:\n        yaml_dict = yaml.safe_load(fp)\n\n    return flatten_dict_list(yaml_dict, plugin_dir)\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    result = {}\n    for plugin_name in get_plugin_names(plugin_dir):\n        try:\n            spec = get_plugin_spec(plugin_dir, plugin_name)\n            flat_dict = flatten_dict(spec)\n            result.update(flat_dict)\n        except KeyError:\n            pass\n    return result\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    if not os.path.isdir(plugin_dir):\n        return {}\n    yaml_filename = os.path.join(plugin_dir, \"__init__.yml\")\n    if not os.path.isfile(yaml_filename):\n        return {}\n    with open(yaml_filename) as f:\n        yaml_dict = yaml.safe_load(f)\n        return flatten_dict_list(yaml_dict)\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    if not os.path.exists(plugin_dir):\n        return {}\n\n    yaml_filename = os.path.join(plugin_dir, \"__init__.py\")\n    with open(yaml_filename, \"rt\") as f:\n        yaml_dict = yaml.safe_load(f)\n\n    if not isinstance(yaml_dict, dict):\n        return {}\n\n    if \"__version__\" not in yaml_dict:\n        return {}\n\n    version = yaml_dict.pop(\"__version__\")\n    if not isinstance(version, str):\n        raise ValueError(\"Unexpected __version__ in __init__.py: %r\" % version)\n\n    # convert version to a list of integers\n    version_list = version.split(\".\")\n    version_list.reverse()\n    version_dict = {int(num): num for num in version_list}\n\n    # convert plugin_name to a list of strings\n    plugin_name_list = [p.split(\" \")[0] for p in yaml_dict[\"plugins\"]]\n    plugin_name_dict = {p: \" \".join(p.split(\" \")[1:]) for", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    result = {}\n    for plugin_name in get_plugin_names_in_dir(plugin_dir):\n        spec_dict = get_plugin_spec_flatten_dict(os.path.join(plugin_dir, plugin_name))\n        result[plugin_name] = spec_dict\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    result = {}\n    for plugin in get_plugin_specs_from_yaml(plugin_dir):\n        flat_dict = {}\n        for key in plugin.__dict__:\n            flat_dict[key] = getattr(plugin, key)\n        result[plugin.name] = flat_dict\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    spec_dict = {}\n    for plugin_file in os.listdir(plugin_dir):\n        if not plugin_file.endswith(\".py\"):\n            continue\n        with open(os.path.join(plugin_dir, plugin_file)) as f:\n            spec_dict = flatten_dict(spec_dict, yaml.load(f))\n    return spec_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    if not os.path.isdir(plugin_dir):\n        return {}\n\n    spec = {}\n    for fname in os.listdir(plugin_dir):\n        if not fname.endswith(\".yml\"):\n            continue\n        fpath = os.path.join(plugin_dir, fname)\n        with open(fpath) as f:\n            spec = yaml.safe_load(f)\n            break\n\n    # remove top-level keys\n    return dict((k, v) for k, v in spec.items() if not k.startswith(\"_\"))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    flat_dict = {}\n    with open(os.path.join(plugin_dir, '__init__.py')) as f:\n        raw_dict = yaml.safe_load(f.read())\n        for key, value in raw_dict.items():\n            if isinstance(value, dict):\n                # use deep copy because some modules may modify the original\n                # dict while we are iterating over it.  As a result, it\n                # is a shallow copy of the original dict and not a deep\n                # copy.\n                flat_dict[key] = copy.deepcopy(value)\n            elif isinstance(value, list):\n                for item in value:\n                    if isinstance(item, dict):\n                        # use deep copy because some modules may modify the original\n                        # dict while we are iterating ove", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    result = {}\n    for filename in os.listdir(plugin_dir):\n        if filename.endswith('.yml'):\n            with open(os.path.join(plugin_dir, filename)) as f:\n                data = yaml.safe_load(f)\n                if data:\n                    result.update(data)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    if not os.path.isdir(plugin_dir):\n        raise IOError(\"Invalid directory '%s'\" % plugin_dir)\n\n    yaml_filename = os.path.join(plugin_dir, \"__init__.yml\")\n    with open(yaml_filename) as fp:\n        yaml_dict = yaml.safe_load(fp)\n\n    return flatten_dict_list(yaml_dict, plugin_dir)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    result = {}\n    for plugin_name in get_plugin_names(plugin_dir):\n        try:\n            spec = get_plugin_spec(plugin_dir, plugin_name)\n            flat_dict = flatten_dict(spec)\n            result.update(flat_dict)\n        except KeyError:\n            pass\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    if not os.path.isdir(plugin_dir):\n        return {}\n    yaml_filename = os.path.join(plugin_dir, \"__init__.yml\")\n    if not os.path.isfile(yaml_filename):\n        return {}\n    with open(yaml_filename) as f:\n        yaml_dict = yaml.safe_load(f)\n        return flatten_dict_list(yaml_dict)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/services/ansible_config.py", "project": "redhat-openstack/infrared", "name": "inject_config", "docstring": "Set the environment variable for config path, if it is undefined.", "ques_id": "63060b1b73426c38ae68ad42", "code": ["def inject_config(self):\n    if 'ANSIBLE_CONFIG' not in os.environ:\n        self.ansible_config_path = self.ansible_config_path\n", "def inject_config(self):\n    env_config = os.environ.get('ANSIBLE_CONFIG', '')\n\n    if not env_config:\n        env_config = self.ansible_config_path\n\n    self.config = load_config(env_config)\n", "def inject_config(self):\n    if 'ANSIBLE_CONFIG' not in os.environ:\n        os.environ['ANSIBLE_CONFIG'] = self.ansible_config_path\n", "def inject_config(self):\n    if not hasattr(self, 'ansible_config_path'):\n        self.ansible_config_path = ''\n\n    if not self.ANSIBLE_CONFIG:\n        self.ansible_config_path = self.ansible_config_path\n", "def inject_config(self):\n    if 'ANSIBLE_CONFIG' not in os.environ:\n        self.ansible_config_path = self.ansible_config_path\n", "def inject_config(self):\n    if not self.ANSIBLE_CONFIG:\n        self.ansible_config_path = self.config_path\n", "def inject_config(self):\n    if 'ANSIBLE_CONFIG' not in os.environ:\n        os.environ['ANSIBLE_CONFIG'] = self.ansible_config_path\n", "def inject_config(self):\n    if not hasattr(self.__class__, 'ANSIBLE_CONFIG'):\n        self.__class__.ANSIBLE_CONFIG = self.ansible_config_path\n", "def inject_config(self):\n    if 'ANSIBLE_CONFIG' not in os.environ:\n        os.environ['ANSIBLE_CONFIG'] = self.ansible_config_path\n", "def inject_config(self):\n    if not 'ANSIBLE_CONFIG' in os.environ:\n        os.environ['ANSIBLE_CONFIG'] = self.ansible_config_path\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def inject_config(self):\n    if 'ANSIBLE_CONFIG' not in os.environ:\n        self.ansible_config_path = self.ansible_config_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def inject_config(self):\n    env_config = os.environ.get('ANSIBLE_CONFIG', '')\n\n    if not env_config:\n        env_config = self.ansible_config_path\n\n    self.config = load_config(env_config)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def inject_config(self):\n    if 'ANSIBLE_CONFIG' not in os.environ:\n        os.environ['ANSIBLE_CONFIG'] = self.ansible_config_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def inject_config(self):\n    if not hasattr(self, 'ansible_config_path'):\n        self.ansible_config_path = ''\n\n    if not self.ANSIBLE_CONFIG:\n        self.ansible_config_path = self.ansible_config_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def inject_config(self):\n    if 'ANSIBLE_CONFIG' not in os.environ:\n        self.ansible_config_path = self.ansible_config_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def inject_config(self):\n    if not self.ANSIBLE_CONFIG:\n        self.ansible_config_path = self.config_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def inject_config(self):\n    if 'ANSIBLE_CONFIG' not in os.environ:\n        os.environ['ANSIBLE_CONFIG'] = self.ansible_config_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def inject_config(self):\n    if not hasattr(self.__class__, 'ANSIBLE_CONFIG'):\n        self.__class__.ANSIBLE_CONFIG = self.ansible_config_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def inject_config(self):\n    if 'ANSIBLE_CONFIG' not in os.environ:\n        os.environ['ANSIBLE_CONFIG'] = self.ansible_config_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def inject_config(self):\n    if not 'ANSIBLE_CONFIG' in os.environ:\n        os.environ['ANSIBLE_CONFIG'] = self.ansible_config_path\n", "is_pass": true, "return_code": 0}]}
{"file_path": "infrared/main.py", "project": "redhat-openstack/infrared", "name": "extend_cli", "docstring": "Adds the spec cli options to to the main entry point.\n\n:param subparser: the subparser object to extend.", "ques_id": "63060b1b73426c38ae68ad43", "code": ["def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('spec', help='display spec information')\n    parser.add_argument('--version', action='version', version='%(prog)s'+ __version__)\n    parser.add_argument('--all', action='store_true', help='display all specs')\n    parser.add_argument('--json', action='store_true', help='output specs as JSON')\n    parser.add_argument('--output', metavar='FILE', help='output file name')\n    parser.add_argument('--debug', action='store_true', help='enable debug mode')\n    parser.add_argument('--interactive', action='store_true', help='interactive mode')\n", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser(\n        \"install\", help=\"Install a package or group of packages to \"\n        \"the current virtualenv.\",\n    )\n    parser.add_argument(\n        \"--requirements\",\n        nargs=\"+\",\n        help=\"The name of the requirements file to be installed.\",\n    )\n    parser.add_argument(\n        \"--upgrade\",\n        action=\"store_true\",\n        help=\"Install the package or group of packages to the \"\n        \"upgraded environment.\",\n    )\n    parser.add_argument(\n        \"--no-deps\",\n        action=\"store_true\",\n        help=\"Don't install any dependencies for the current \"\n        \"virtualenv.\",\n    )\n    parser.add_argument(\n        \"--skip-dependencies\",\n        action=\"store_true\",\n        help=\"Skip the dependencies check for the current \"\n        \"virtualenv.\",\n    )\n    parser.set_defaults(func=self.install", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('install', help='Install a new package.')\n    parser.add_argument('--upgrade', action='store_true', help='Upgrade the package to the latest available version.')\n    parser.add_argument('--reinstall', action='store_true', help='Reinstall the package to the latest available version.')\n", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('add', help='add an episode to the database')\n    parser.add_argument('name', help='the name of the episode to add')\n    parser.add_argument('--description', default='', help='the description of the episode')\n    parser.add_argument('--release_date', default='', help='the release date of the episode')\n    parser.add_argument('--number', default='', help='the number of the episode to add')\n    parser.add_argument('--season', default='', help='the season of the episode to add')\n    parser.add_argument('--episode', default='', help='the episode number of the episode to add')\n", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('test', help='test a single test case')\n    parser.add_argument('--dry-run', action='store_true',\n                        help='run the test case without actually making any changes')\n    parser.add_argument('test_name', nargs='?', help='test name', default=None)\n    parser.add_argument('--failure-tolerance', type=float, default=None,\n                        help='tolerance for failure test')\n    parser.add_argument('--success-tolerance', type=float, default=None,\n                        help='tolerance for success test')\n    parser.add_argument('--test-id', type=str, default=None,\n                        help='test id for the test case')\n    parser.add_argument('--failure-threshold', type=float, default=None,\n                        help='threshold for failure test')\n    parse", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('generate', help='Generate a random password.')\n    parser.add_argument('--length', type=int, default=12, help='The length of the password')\n    parser.add_argument('--iterations', type=int, default=8, help='Number of iterations to generate the password')\n    parser.add_argument('--salt', type=str, default='password', help='The salt to use for the password')\n    parser.add_argument('--output', type=str, default='password', help='The name of the output file')\n", "def extend_cli(self, root_subparsers):\n    self._register_cli_opts(root_subparsers)\n", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser(\n        self.cli_argument.name,\n        help=self.cli_argument.description,\n        parents=[root_subparsers])\n\n    parser.set_defaults(func=self.handle)\n", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('spec', help='show spec information')\n    parser.add_argument('--name', action='store', dest='name', help='the name of the spec')\n    parser.add_argument('--version', action='store', dest='version', help='the version of the spec')\n    parser.add_argument('--env', action='store', dest='env', help='environment variables to set for the spec')\n    parser.add_argument('--config', action='store', dest='config', help='configuration file for the spec')\n    parser.add_argument('--output', action='store', dest='output', help='path to write output files to')\n", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('install', help='install a new package')\n    parser.add_argument('package_name', help='the package to be installed', nargs='?')\n    parser.add_argument('--upgrade', action='store_true', help='upgrade the package to an upgraded version')\n    parser.add_argument('--check-only', action='store_true', help='check only the package for updates')\n    parser.add_argument('--remove-old', action='store_true', help='remove the package from the index and reinstall it')\n    parser.add_argument('--require-all', action='store_true', help='require all packages')\n    parser.add_argument('--save-dir', default='.', help='the directory where the package is saved')\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('spec', help='display spec information')\n    parser.add_argument('--version', action='version', version='%(prog)s'+ __version__)\n    parser.add_argument('--all', action='store_true', help='display all specs')\n    parser.add_argument('--json', action='store_true', help='output specs as JSON')\n    parser.add_argument('--output', metavar='FILE', help='output file name')\n    parser.add_argument('--debug', action='store_true', help='enable debug mode')\n    parser.add_argument('--interactive', action='store_true', help='interactive mode')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser(\n        \"install\", help=\"Install a package or group of packages to \"\n        \"the current virtualenv.\",\n    )\n    parser.add_argument(\n        \"--requirements\",\n        nargs=\"+\",\n        help=\"The name of the requirements file to be installed.\",\n    )\n    parser.add_argument(\n        \"--upgrade\",\n        action=\"store_true\",\n        help=\"Install the package or group of packages to the \"\n        \"upgraded environment.\",\n    )\n    parser.add_argument(\n        \"--no-deps\",\n        action=\"store_true\",\n        help=\"Don't install any dependencies for the current \"\n        \"virtualenv.\",\n    )\n    parser.add_argument(\n        \"--skip-dependencies\",\n        action=\"store_true\",\n        help=\"Skip the dependencies check for the current \"\n        \"virtualenv.\",\n    )\n    parser.set_defaults(func=self.install", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('install', help='Install a new package.')\n    parser.add_argument('--upgrade', action='store_true', help='Upgrade the package to the latest available version.')\n    parser.add_argument('--reinstall', action='store_true', help='Reinstall the package to the latest available version.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('add', help='add an episode to the database')\n    parser.add_argument('name', help='the name of the episode to add')\n    parser.add_argument('--description', default='', help='the description of the episode')\n    parser.add_argument('--release_date', default='', help='the release date of the episode')\n    parser.add_argument('--number', default='', help='the number of the episode to add')\n    parser.add_argument('--season', default='', help='the season of the episode to add')\n    parser.add_argument('--episode', default='', help='the episode number of the episode to add')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('test', help='test a single test case')\n    parser.add_argument('--dry-run', action='store_true',\n                        help='run the test case without actually making any changes')\n    parser.add_argument('test_name', nargs='?', help='test name', default=None)\n    parser.add_argument('--failure-tolerance', type=float, default=None,\n                        help='tolerance for failure test')\n    parser.add_argument('--success-tolerance', type=float, default=None,\n                        help='tolerance for success test')\n    parser.add_argument('--test-id', type=str, default=None,\n                        help='test id for the test case')\n    parser.add_argument('--failure-threshold', type=float, default=None,\n                        help='threshold for failure test')\n    parse", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('generate', help='Generate a random password.')\n    parser.add_argument('--length', type=int, default=12, help='The length of the password')\n    parser.add_argument('--iterations', type=int, default=8, help='Number of iterations to generate the password')\n    parser.add_argument('--salt', type=str, default='password', help='The salt to use for the password')\n    parser.add_argument('--output', type=str, default='password', help='The name of the output file')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    self._register_cli_opts(root_subparsers)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser(\n        self.cli_argument.name,\n        help=self.cli_argument.description,\n        parents=[root_subparsers])\n\n    parser.set_defaults(func=self.handle)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('spec', help='show spec information')\n    parser.add_argument('--name', action='store', dest='name', help='the name of the spec')\n    parser.add_argument('--version', action='store', dest='version', help='the version of the spec')\n    parser.add_argument('--env', action='store', dest='env', help='environment variables to set for the spec')\n    parser.add_argument('--config', action='store', dest='config', help='configuration file for the spec')\n    parser.add_argument('--output', action='store', dest='output', help='path to write output files to')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('install', help='install a new package')\n    parser.add_argument('package_name', help='the package to be installed', nargs='?')\n    parser.add_argument('--upgrade', action='store_true', help='upgrade the package to an upgraded version')\n    parser.add_argument('--check-only', action='store_true', help='check only the package for updates')\n    parser.add_argument('--remove-old', action='store_true', help='remove the package from the index and reinstall it')\n    parser.add_argument('--require-all', action='store_true', help='require all packages')\n    parser.add_argument('--save-dir', default='.', help='the directory where the package is saved')\n", "is_pass": false, "return_code": 1}]}
